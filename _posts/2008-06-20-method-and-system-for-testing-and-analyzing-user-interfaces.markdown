---

title: Method and system for testing and analyzing user interfaces
abstract: A system and method is described in which the state of the art in automated software applications is significantly improved. According to some approaches, interface testing is implemented and based upon a verification language and a verification environment. The system and method support the concepts of constrained random test generation, coverage, constrained random generation, and dynamic checks.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09098635&OS=09098635&RS=09098635
owner: Cadence Design Systems, Inc.
number: 09098635
owner_city: San Jose
owner_country: US
publication_date: 20080620
---
Most computing devices applications and complex tools rely upon a user interface to interact with receive input from and provide information to users. There are many types of user interfaces. Common approaches to implement user interfaces include the graphical user interface GUI character user interface CUI and web based user interfaces.

Like any other development process for a complex design it is important to ensure that the process for developing a user interface involves adequate testing and verification of the performance and functionality of the interface components. In the field of computer science GUI software testing is the process of testing a product that uses a Graphical User Interface GUI to make sure it meets its written specifications. This is normally done through the use of a variety of test cases in addition to ad hoc methods involving human interaction.

To generate a comprehensive set of test cases however the test designer must be certain that their suite covers all the functionality of the system and also has to be sure that the suite fully exercises the GUI itself. The difficulty in accomplishing this task is twofold one has to deal with domain size and then one has to deal with sequences. In addition the tester faces more difficulty when they have to do regression testing.

The size problem can be easily illustrated. Unlike a CLI Command Line Interface system a GUI has many operations that need to be tested. A very small program such as Microsoft WordPad has at least 325 possible GUI operations. In a large program the number of operations can easily be an order of magnitude larger.

One possible testing approach is to perform capture playback. Capture playback is an approach where the system screen is captured as a bitmapped graphic at various times during system testing. This capturing allowed the tester to playback the testing process and compares the screens at the output phase of the test with expected screens. This validation could be automated since the screens would be identical if the case passed and different if the case failed.

However there are significant problems when one tries to implement capture playback in a complex system such as most GUI based systems. The most obvious problem one finds is that the screen in a GUI system may look different while the state of the underlying system is the same making automated validation extremely difficult. This is because a GUI allows graphical objects to vary in appearance and placement on the screen. For example fonts may be different and window colors or sizes may vary even though the system output is basically the same. This would be obvious to a user but not obvious to an automated validation system.

To combat this and other problems another approach is to go under the hood and collected GUI interaction data from the underlying windowing system. By capturing the window events into logs the interactions with the system are now in a format that is decoupled from the appearance of the GUI. The advantage is that the event streams are captured. Unfortunately significant filtering of the event streams becomes necessary when using this approach since the streams of events are usually very detailed and most events are not directly relevant to the functionality being targeted by the GUI test.

In practice it often also turns out that the overhead of maintaining regression tests across multiple software releases is sufficient to discourage the use of automated GUI testing in the first place in spite of its otherwise apparent advantages and necessity. This essentially means that existing GUI tests are not easily reusable and most be extensively modified before being used for varied GUI configurations.

Another possible approach to running tests on a GUI is to build a driver into the GUI so that commands or events can be sent to the software from another program. This method of directly sending events to and receiving events from a system is highly desirable when testing since the input and output testing can be fully automated and user error is eliminated. However this method is significantly limited by the fact that software GUIs tend to change from software release to release. Even though the underlying software major functionality may not change the fact that the GUI itself changes is often sufficient to induce a major maintenance overhead requiring manual regeneration of tests. Further issues arise in that particular solutions are limited to a single specific application only such that reuse of the test infrastructure across multiple similar or differing applications is not possible.

Therefore it is clear that there is a need for an improved approach to perform testing of user interfaces. A system and method is described in which the state of the art in automated software applications is significantly improved. According to some embodiments interface testing is implemented and based upon a verification language and a verification environment.

Other and additional objects features and advantages of the invention are described in the detailed description figures and claims.

The present invention provides a method system and computer program product for testing and analyzing user interfaces. A novel system and method is presented in which the state of the art in automated software applications is significantly improved. For the purposes of explanation the present document will be illustrated and explained with reference to Graphical User Interface GUI based applications as well as Character User Interface CUI applications. It is noted however that the present invention can be applied to any type of user interface and is not to be limited to the specific examples illustrated herein.

According to some embodiments of the invention an electronic design verification environment can be used to implement the architecture of . A Hardware Verification Language HVL is modified and extended such that instead of interfacing with simulation of a hardware device modeled in a language such as Verilog or VHDL it instead interfaces with the Graphical Character User Interface GUI CUI of the target AUT . The testbench in the verification language then drives the AUT by generating and providing a GUI CUI stimulus which emulates user behavior or external behavior by collecting AUT status and optionally GUI status and by comparing the identified status against an expected status. In one embodiment the testbench can be implemented using the e language specifications of which are available from Cadence Design Systems of San Jose Calif. A suitable verification environment is provided by the Specman tool also available from Cadence Design Systems of San Jose Calif. Other verification languages and environments can be used in conjunction with and within the spirit of the invention.

The advantage of using a HVL is that the process of performing GUI testing implicates many similar problems that have been faced in the past by ASIC designers who were forced to use Hardware Description Languages HDL s such as Verilog and VHDL to test their hardware designs. The verification engineers found the levels of abstraction allowed for by these languages to be insufficient which forced the evolution of a new class of languages dedicated to verification of hardware designs. The resulting HVLs e.g. the e language introduced higher order constructs for dealing specifically with verification problem.

In similar spirit the invention described herein addresses the issue of software application and GUI testing at a much higher level of abstraction than allowed for by the commonly employed tools. Language features of HVL s are employed along with appropriate improvements and extensions to render said HVL s and their associated regression management and analysis environments applicable to GUI testing. Use of a HVL like approach to GUI testing as described herein will allow the GUI verification engineer to use a language which is designed for complex state and sequence testing for the authoring of GUI test cases including their abilities to write constraint based randomized tests in addition to directed tests.

The invention can be employed in conjunction with regression management and test plan authoring tools to allow GUI verification personnel to define exactly what they want to verify to write and formally capture a verification plan and formally define the required coverage points. The vManager product available from Cadence Design Systems of San Jose Calif. is an example of a tool that can be used in conjunction with the invention used to perform regression management in a GUI testing environment and to allow engineers to create a testbench . Using a test plan regression manager also allows the software verification or quality assurance engineer to set up a targeted regression involving multiple tests to run regressions using the same tests with multiple seeds which control the random number generation process to analyze the regression results in terms of passed failed checks to automatically re run failed checks while preserving the random seed as necessary and finally to explicitly analyze and identify those areas of high GUI state coverage and low or missing coverage. The tracked testing metrics provide feedback for the GUI designers and product managers for the aim of robust product test and development.

As noted above the testbench communicates with the GUI elements in the AUT using a communications channel . In some embodiment the communications channel is implemented via a socket connection making it possible for the testbench execution and the AUT execution to be in separate operating system processes or even on separate machines. Other forms of inter process communication may also be used instead. In yet another embodiment the testbench and AUT components may be combined within a single operating system OS process. The communications channel provides a medium that facilitates the testbench driving the AUT and that allows the AUT to respond to those events in addition to providing query application programming interfaces APIs through which the testbench can obtain GUI object values such as for example button state values of text strings within a type in field from the AUT .

The testbench is configured to provide an improved approach to address test coverage . It is generally very difficult to know with any level of confidence or accuracy just how representative a set of GUI tests are in terms of covering all of the possible states of a GUI. With increasing functionality being provided in successive software releases the number of valid GUI states that can be arrived at for any given software application is exponentially increasing over time. To ensure a representative set of tests are used to achieve a decent level of state coverage some embodiments of the invention provides the ability to measure or otherwise quantify the degree of GUI state coverage provided by a testbench .

The testbench can also be used to configure the checks that are used to query and verify the operation and functionality of the GUI and its components . Examples of such checks are described in more detail below.

One benefit of using a verification language such as the e language to author the testbench includes the ability to generate constrained i.e. legal random values and sequences of values. This effectively allows a test to be authored as a template during the execution of which the template is realized into a sequence of concrete tests via a randomization process. A single test template can thus be used to generate a multitude of actual tests and scenarios during the run time of the tests and exercise multiple flavors of the specified scenario.

Another benefit of the present approach is that sequencing can be addressed using the testbench . This is extremely useful since some functionality of the AUT may only be accomplishable by following a complex sequence of GUI events. For example to open a file a user may have to engage in a long sequence of operations that include clicking on the File menu selecting the Open operation using a dialog box to specify the file name and then focusing the application on the newly opened window. This type of sequence can be specified in testbench .

These new schemes lead to tremendous increases in software application testing productivity especially in the GUI based applications and present a vast reduction in the overhead required for release to release testcase maintenance. Though the examples described herein are with respect to GUI s and GUI verification the reader will understand that these are intended to be exemplary only and that the spirit of the invention as a whole is not limited to just that of GUI CUI verification and validation. Other complex state based systems can equally be verified by a similar approach with application specific components being used to substitute the GUI CUI specific components described herein during the augmentation or extension of existing or yet to be determined Hardware Verification Languages.

The testbench server side extends the standard HVL environment in two major areas. First an API is provided for driving the GUI of the AUT and for sampling the state of that GUI. This API is implemented for example using e language classes and methods. Second a communications channel is provided that connects to the AUT. The server side API is responsible for communication of the GUI commands to the AUT client and for making the results of GUI queries available to the application test .

In addition to the e Language and GTX User API for GUI Command Query GUI verification engineers can define additional GUI Verification IP in the form of a custom library or libraries and specify coverage requirements checks that are to be performed sequences that are to be generated and other testing attributes. In one embodiment these components can be defined using the extended e Language.

The application test is authored in the extended e language and can either be written directly using the language extensions described via examples herein or by instantiating calling GUI Verification IP stored in customer libraries as described above or both. The application test is configured to include calls to the API .

The combined form of the application test and library extensions are processed by the verification engine and used to send drive messages to stimulate the GUI application. The verification engine also sends query messages to the GUI application to gather information about the state of the GUI.

On the application client side a GUI application is extended via incorporation of a Plug in denoted GTX Plug In in the figure . The plug in is a GUI toolkit specific implementation which translates the GUI drive commands and query messages from the testbench server into actual calls to the underlying GUI toolkit. Each underlying type of application would correspond to a plug in that is configured to interface to the correct respective language. For example plug ins can be configured to translate the drive commands and query messages into Java Qt Tcl Tk or any other suitable interface format. The plug in would present the test messages into GUI engine specific method calls such as button.click text.get and similar calls. Plug ins can be authored for any such GUI implementation language. The plug in also implements the client side of the communications protocol communicating the results of GUI Drive and Query commands back to the testbench server side .

One example type of Verification Environment class or code behavior is a specific application launcher class. This class or code would allow the testbench author to launch the application using various methods including a simple launch or a launch with command line arguments and could easily be extended to handle additional launch requirements.

A second example type of class or code behavior is the specific application class. The application class inherits from the base application class and its methods relate to application specific logic providing application window creation constructor initialization and query methods in addition to other classes representative of the application s primary design architecture and logic. Further in the case where the AUT supports a CUI in parallel to the GUI the application class supports the required API.

A third example type of class comprises the various specific window classes such as a main window class any sub window classes etc and reflects the various types of windows and sub windows in the application and their relationships. These classes further contain references to window specific logic including the various sub widgets such as trees toolbars or buttons comprising the window or sub window. The intent of these methods according to one embodiment is to create HVL language handles to AUT main window widgets only once. This reference is then returned anonymously and it is that class method which is used in all tests that need to reference and manipulate objects such as windows primary widgets tree structures etc. in the AUT application. Should that those objects get renamed or re parented the tests calling the method of the AUT main window application class will be unaffected. This is one of the advantages of the present invention in which it provides a system in which specific application tests are insulated form various changes in the GUI itself as the software evolves across releases.

At the application test is created. The application test comprises a set of statements to test the GUI written in a suitable verification language such as the e language. API calls are embedded into the application test to drive the actions that are needed to test the GUI. The embedded calls also provide the basis for generating query calls to check the state of the GUI at various points in time and to obtain information about the GUI. The application test may also incorporate or call other test components that may be stored in one or more libraries. Any GUI element and component can be stimulated using the application test. The following are some example GUI elements that can be tested in certain embodiments 

At the application test is processed by the verification engine to drive the GUI being tested. In operation the verification engine parses through the application test to identify the test instructions. The test instructions are communicated over a communications channel to the plug in that is incorporated with the application under test. The plug in translates the test instructions into the appropriate format suitable to the GUI application. The translated test instructions are then applied to the GUI to perform the specified test operations which are essentially a set off operations that performs actions and functions within the GUI.

Data collection instructions are processed at . This occurs by having the verification engine parse the application test to identify the specific types of information that are being sought by or for the test. A set of query commands would then be sent from the verification engine at the test side to the plug in at the application side. The query commands would be processed by the plug in to capture the requested information from the GUI or to capture the state of some or all of the GUI.

The collected data from the GUI is then returned for analysis at . Analysis may be performed to determine whether the GUI has properly performed the operations being tested by the application test. One approach to implement this action is to maintain a set of expected GUI results for each test that is checked against the actual results of applying the test to the GUI. Each test can receive a pass or fail indication depending upon whether the collected test results sufficiently matches the expected results.

At the analysis results are either both displayed to the user at a computer display device or stored into a compute readable medium. A regression test manager product can also be used to facilitate display and analysis of the test results.

At a component naming scheme may be incorporated with the AUT. This may be implemented for each GUI component which is to be driven or queried and allows an approach by which it registers a unique object name for each component. In one embodiment the object name is not seen or used by the user of the AUT it is however used internally during the communication of messages to ensure that desired messages are always delivered to the same object regardless of its regular widget name or position in the AUT widget hierarchy. This is done in order to facilitate preservation of test functionality across multiple relatively minor revisions of the AUT widget hierarchy.

As long as a given component functionality doesn t change its registered name it can be freely moved in the widget hierarchy of the AUT during the development cycle without unduly impacting GUI tests. For example the object e.g. such as a Load button can be re parented in a new or different enclosing layout management widget without changing its registered name. This provides a very significant advantage for the invention with regard to extensibility and scalability since testbenches written in conjunction with the original AUT GUI layout scheme will therefore continue to work with the new layout scheme. This represents a significant improvement over the current state of the art.

At the appropriate plug in is identified for the AUT. The consideration of the appropriate plug in is driven by the type and format of the GUI implementation. For example Java Qt and Tcl Tk are just some examples of the formats with which the GUI application may be implemented. According to one embodiment each such format corresponds to a different plug in. The AUT is configured to include appropriate software hooks for the plug ins using any suitable or conventional techniques. Thereafter at once the appropriate plug in has been identified the plug in is integrated with the AUT.

Such extensions are implemented as necessary as a plug in extension on the AUT side in which the new GUI components are implemented and as a corresponding plug in extension on the application test side in which corresponding new GUI Drive and Query methods are provided . This extension mechanism allows testbenches to be extended to work in conjunction with specialized or customized GUI toolkit versions. The nature of the testbench extensions can be implemented via sub classing of or introduction of new classes that share some of the same base classes as the original API as may also be the case for the extensions in the AUT side.

As noted above the verification system includes an API having method s interface s to address each of the supported GUI elements. These methods would include mechanism to initialize drive manipulate operate and or to query these elements. According to one embodiment the API design revolves around four main classes or role players 

There are pre defined relationships between some of those players. In particular an application contains a group of windows which can be opened. Each window belongs to a specific application and contains a set of widgets. Each widget belongs to a specific window.

Each of the above players also has a set of related operations. More specifically the physical GUI classes application window and widget have some GUI related operations to simulate user activity. For example an application can correspond to batch related API components e.g. to perform a command or evaluation which can be syntactically represented by do cmd and eval exp . A window can correspond to operations to move the window to the front move the window or to resize the window which can be syntactically represented by to front move and resize . A table widget can correspond to operations to click on a row double click a row or to click a column header which can be syntactically represented by click row double click row and click col header . The Verification GTX Manager can be configured to implement the operation to launch an application which can be syntactically represented by launch application .

Each of the above players also corresponds to a set of accessor query methods. For example an application player may correspond to a method such as get all windows which can be syntactically represented by get all windows . A window player can correspond to methods to get the size title or widgets of the window which can be syntactically represented by get size get title and get all widgets . A table widget player can correspond to query methods to get widget attributes get row attributes sorting or enabling which can be syntactically represented by get attributes get Row attributes is sorted and is enabled . The Verification GTX Manager can correspond to a method to get all applications which can be syntactically represented by get all applications .

Testbenches are written in the extended e language which creates instances of those classes invokes the various operational methods to drive the GUI of the AUT and invokes the accessor query methods to determine and thus be able to verify the actual state of the GUI comparing it against the expected state.

To illustrate embodiments of the invention consider the example GUI shown in . This GUI example is part of a Data Browser AUT. The Data Browser application can be used for example for showing and inspecting multiple data packets and other related data in a packet switching device or hardware description language HDL simulation thereof. The application GUI follows a standard two panel selector pattern in which the left side panel is used to select a data object from within a hierarchical tree of related data objects. Nodes within that hierarchical tree can be expanded to access lower level data objects. For any given selected data object such as a packet or list of packets in the left hand source tree the right hand panel allows more details related to the selected data structure to be inspected including the values of leaf level data fields within the structure.

The examples of show a particular syntax and format that may be employed to extend the e language to perform GUI testing. It is noted however that the example program code is merely illustrative and other formats and syntaxes may likewise be used to implement embodiments of the invention.

Code portion provides an example of how one would launch a program under test using an e language implementation. A similar statement is shown in the code portion of . The general idea is that the HVL is extended to include methods to call the launching of the program for verification. In some embodiments a mechanism can be implemented to impose a delay e.g. a one second delay to allow users to visually track and view the test. In the code example of the code segment launches the Data Browser AUT represented by e.g via a method entitled launch of the testbench. The launch method both launches the AUT and establishes an initial communication with it after it starts up as part of the communications protocol initialization described by and utilizing the communications channel described by . illustrates bow the GUI of might behave during test initialization under certain implementations.

One or more verification portions and can be included at or near the beginning of the program code. The verification portion is used for example to verify that the window title has the correct and expected title .

As shown in the example program code also includes code portions to drive the GUI to query the state of GUI elements and to verify if the GUI is operating correctly based upon the test stimuli. For example code portion shows an example of syntax that can be used to check the contents of the data tree within the GUI. Code portion shows an example of syntax that can be used to check header text within the GUI. Code portion shows an example of syntax that can be used to check expansion of correct rows being added to the data tree within the GUI.

A particular section of code portion is reproduced in to illustrate the operations to drive the GUI to query the state of GUI elements and to verify if the GUI is operating correctly based upon the test stimuli. Some GUI Query methods from the snippet shown in include 

The query methods allow the testbench to retrieve from the AUT the title of the current window the index of the selected row within the left hand side tree panel etc. The command drive methods allowing the testbench to drive the AUT to enter an item sys.packets in the ExpName combobox and to expand a particular row within the tree. As shown in line executes a mechanism to expand a row in the left hand side portion of the GUI of . An example of the effect of this operation upon the GUI of is illustrated in . Line shows an example of syntax that can be used to query the GUI to check the contents of the data tree within the GUI. The API and verification engine within the verification system includes a mechanism to convert these methods to deliver drive commands and query commands to the plug in at the AUT. The plug in would convert these drive commands and query commands into the appropriate native format to drive and query the GUI.

Lines within show examples of syntax that can be used to check the results of the query of line against expected values. This can be used to implement HVL code concepts which are used to advantageously test the GUI e.g. by using the e language check that construct which is used to verify i.e. to check that a desired or expected condition actually occurred. It will be understood by those skilled in the art that other languages and HVL constructs with similar semantics could be equally employed without departing from the spirit of the invention. The code example near the top of the sub listing of shows how the Data Browser is inspected to verify check that that the window title is actually Data Browser via the appropriate string pattern matching operation. Two subsequent checks near the bottom of the listing verify that the actual name of the root index 0 row of the tree is sys and check that the currently selected row corresponds to the expected string packets .

One advantage of using a HVL based approach to GUI testing as described herein is the ability to randomize tests which are effectively authored as templates using the HVL. Tests can be synthesized by randomly generating values each time the test is run. This concept is illustrated by the code portions and of . A portion of these sample code portions been re stated in the code listing of . Here the mechanism referred to as the gen new num method is used to generate a random row number within the range of row values supported by the data tree in the right hand side panel of the GUI that shows the packet field values in .

According to some embodiments the random number is generated in a constrained manner based upon a legal row that fits within the size of the child data structure. In effect the new number is generated that is constrained by the number of children in the tree. Further that randomly generated row is then passed as an argument to the click row method of the child DataTree tree on the right hand side of . In other words the randomly generated number is used to order the GUI to click on the appropriate row index and row elements to test. Examples of the AUT responding to this random row selection are shown in and in which packet is selected and a and id data fields within data packet are respectively selected.

Similarly a randomization of the selected packet index next selects packet in the packet browser of the left hand side panel along with a correspond random selection of two of the data fields for that particular packet. These are fields size and Ibits illustrated by and .

It is noted that the example test has been authored in such a way as to be usable with trees of an arbitrary size and the method scales to both large and small trees accordingly. Hence the GUI test author can generate a fully legal random selection of row index tests from the single test template of . The example listing in is thus highly re usable across multiple tests regardless of the number of data packets present.

Further some embodiments relate to constrained randomization to include the use of the keeping keyword as shown in the following code snippet and can be equally used by GUI test writers to preserve required relationships. In the case of the following code snippet a child num value is randomly generated while constraining its value to be less than the number of available children.

Another advantage of embodiments of the present invention is the ability to instruct the testbench and verification environment to record coverage of certain GUI states. This advantage relates to the concepts of coverage checking and coverage metrics. To explain consider that there is a potentially large number of the different variations and configuration combinations that can be set within the GUI. If data values are randomly generated it is possible that certain combinations and corner cases are not exercised by a particular run of the test.

In the example shown in the e language event and cover constructs are used as shown in the sub listing. In particular consider that there may be multiple element types and multiple list kinds within the GUI. Embodiments of the invention provide a mechanism to determine and record cross cover combinations e.g. to generate intersections of multiple coverages via HVL language constructs. In addition negative GUI testing testing to ensure that various error conditions are handled appropriately can also be efficiently addressed.

Coverage of particular states can be achieved during a given regression run along with Hits Goal metrics and other factors. In the illustrated example it can be seen that one particular combination of list with key and when sub type was never checked i.e. that particular cross check combination was never verified during the execution of the testbench thereby indicating a possible hole or lack of coverage in the testbench. The same techniques can be used without change to verify certain GUI states and cross checks combinations of states with particular values of inputs are checked.

Embodiments of the invention can be configured to perform regression testing of the GUI. The reason to perform regression testing is because the GUI itself may change significantly across versions of the application even though the underlying application may not. A test initially designed to follow a certain path through the GUI may no longer be able to follow that path in a subsequent revision of the software since a button menu item or dialog may not be where it used to be may have been renamed or re parented. In addition and even more common in some embodiments regression testing can be implemented to catch any new bugs created in the introduction of new features or based upon changes made to fix existing bugs.

Returning back to a determination is made at whether further testing is required. If so then at the test can be configured e.g. by changing some or all of the constraints or test conditions. The process then returns back to to execute the revised test.

Yet another advantage of the present approach is that the testbench that has been created in the verification language can be checked debugged and maintained using standard HVL debugging browser tools. A debugger tool can be used to debug a GUI CUI testbench allowing tracking of the tests on a step by step basis. Some example functionality that can be applied to debug the testbench include 1 setting breakpoints on lines methods on a change of a value 2 exploring the stack when program execution stops 3 adding watch points that are evaluated automatically after each stop 4 performing step in step over and step back HVL such as e language program language statements 5 choosing a variable and evaluate it 6 ability to add delete disable enable breakpoints and 7 setting conditional breakpoints.

In another embodiment a data browser window can be used to inspect HVL such as e language program data and can be used to inspect GUI CUI Software Testbench program data e.g. to inspect the stimuli as well as examining the verification environment instances.

The Specman Source Browser and Specman Source Line debugger available from Cadence Design Systems Inc. of San Jose Calif. are examples of suitable tools that can be used in conjunction with embodiments of the invention to debug and browse a testbench that has been created in the e language.

Therefore what has been described is an advantageous and much improved approach for performing interface testing based upon a verification language. The present approach scales to very large and complex GUIs and is minimally sensitive to relatively minor changes across software releases even slight changes make existing tests unusable in existing GUI automated testing software. Therefore the invention significantly eliminates or reduces overhead in test maintenance. Test case operation is independent of changes in fonts window colors or sizes. The invention allows for the creation of re useable GUI Verification IP and addresses the common tendency for legacy feature testbenches to become diluted irrelevant by maintaining original test intent throughout the lifetime of a software product.

The present approach can be configured to provide GUI Toolkit independence and as a result operating system independence as well. A GUI can be re implemented in a different faster better toolkit e.g. ported from Tcl to Qt or Java and the prior written tests able to continue to run via switching in a different AUT plug in. This allows for a GUI to be ported to a different OS via Toolkit independence and the prior existing regression tests to go along with it without needing to expend significant porting effort or cost. This further allows reuse of test cases for various operating environments and data content and allows sharing of verification IP components for generic components and even potentially creating commercial IP verification for common components. This approach also provides for straight forward GUI testing logic by reflecting the real GUI components in the verification environment API

In some embodiments the approach removes requirement that all states be exhaustively exercised in order to guarantee good coverage and allows explicit analysis of coverage metrics including cross combinations intersections of states. The user can have confidence for GUI state coverage measurement which users of more simple line of code based coverage methods cannot . Extremely focused testing can be implemented as desired which can avoid the clutter of irrelevant events which tend to be densely populated in log file based methods . Embodiments allow for constraint based randomized tests which further allows for a monte carlo approach to testing where exhaustive testing is not possible due to lack of resources. Randomized tests can be conducted in conjunction with directed tests.

Another advantage is that the present approach requires less manual regeneration of tests. The test methodology is expandable and can be customized to support specific and unusual GUI components in specific applications.

In some implementations a dedicated verification environment is provided for GUI application testing. This gives the ability to formally enter and capture a test plan including desired coverage metrics as well as the ability to execute and track a test plan. The user can easily inspect and or analyze results of running a test plan can re run failed tests can modify the tests to improve the actual coverage and can effectively manage a testplan containing thousands of tests.

According to one embodiment the invention is based on languages that have been expressly designed for dealing with similar problems i.e. large complex and sequence related states. Existing languages and corresponding set of tools can be used that gained a significant volume of user experience and represent the market leader in the verification arena.

Improved regression creation and management is also provided. This allows for easy browsing of GUI regression test pass fail status from within a single environment and also allows for easy replay of failing tests to verify bug fix via automated preservation of random seeds associated with failing tests.

Advanced debugging functionality may be implemented with the invention. This allows for step by step execution of the test for debugging purposes using a professional source code debugger. This in conjunction with the coverage analysis also allows for easy determination of important conditions which have not been verified e.g. where sequence of operations A has been done in conjunction with all combinations of some other set of inputs B. It is noted that any debugging functionality may be suitably used in conjunction with the invention including existing debugging functionality. In some embodiments the e language is extended to implement the invention where existing debugging functionality can be used without any change.

According to one embodiment of the invention computer system performs specific operations by processor executing one or more sequences of one or more instructions contained in system memory . Such instructions may be read into system memory from another computer readable usable medium such as static storage device or disk drive . In alternative embodiments hard wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus embodiments of the invention are not limited to any specific combination of hardware circuitry and or software. In one embodiment the term logic shall mean any combination of software or hardware that is used to implement all or part of the invention.

The term computer readable medium or computer usable medium as used herein refers to any medium that participates in providing instructions to processor for execution. Such a medium may take many forms including but not limited to non volatile media and volatile media. Non volatile media includes for example optical or magnetic disks such as disk drive . Volatile media includes dynamic memory such as system memory .

Common forms of computer readable media includes for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge or any other medium from which a computer can read.

In an embodiment of the invention execution of the sequences of instructions to practice the invention is performed by a single computer system . According to other embodiments of the invention two or more computer systems coupled by communication link e.g. LAN PTSN or wireless network may perform the sequence of instructions required to practice the invention in coordination with one another.

Computer system may transmit and receive messages data and instructions including program i.e. application code through communication link and communication interface . Received program code may be executed by processor as it is received and or stored in disk drive or other non volatile storage for later execution.

In the foregoing specification the invention has been described with reference to specific embodiments thereof. It will however be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention. For example the above described process flows are described with reference to a particular ordering of process actions. However the ordering of many of the described process actions may be changed without affecting the scope or operation of the invention. The specification and drawings are accordingly to be regarded in an illustrative rather than restrictive sense.

