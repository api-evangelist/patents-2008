---

title: Semantic classification and enhancement processing of images for printing applications
abstract: A printing system enables the printing of enhanced documents using a semantic classification scheme. A printing system receives an image to be printed. The system classifies the image according to the semantic classification scheme and, based on this classification, performs enhancement processing on the image. Depending on the desired application, the printing system may recognize and classify any number of image types and may then perform various enhancement processing functions on the image, where the type of enhancement processing performed is based on the classification of the image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08373905&OS=08373905&RS=08373905
owner: Ricoh Co., Ltd.
number: 08373905
owner_city: Tokyo
owner_country: JP
publication_date: 20081212
---
This application is a continuation of U.S. application Ser. No. 11 031 516 filed Jan. 7 2005 which is a continuation in part of co pending U.S. application Ser. No. 10 813 950 filed Mar. 30 2004 which claims the benefit of U.S. Provisional Application No. 60 506 303 filed Sep. 25 2003 and U.S. Provisional Application No. 60 506 302 filed Sep. 25 2003 each of which is incorporated by reference in its entirety.

This invention relates generally to printing and in particular to printing systems that have functionality for classifying an image and performing enhancement processing thereon based on its classification to improve the printed result.

As digital cameras become more ubiquitous especially those integrated into cellular phones they play an increasingly important role in the capture and sharing of visual information in the workplace. In a meeting for example an attendee may use a digital camera to capture an image of the contents of a whiteboard information on a set of slides a business card or a scene with other people. Workplace studies have shown that people would use a digital camera in the office to capture these kinds of images if a camera were available. See e.g. Brown et al. A diary study of information capture in working life Proceedings of ACM CHI 2000 Conference on Human Factors in Computing Systems vol. 1 p. 438 45 2000 . Accordingly cameras and other image capture devices present a unique opportunity to increase workplace productivity.

But while many people in the workplace are apt to find uses for capturing images fundamental limitations remain. For example office workers generally have little time for classifying and organizing the images they capture. In addition although capturing images in the workplace is relatively easy improving those images for printing is not. The average office worker lacks the technical knowledge to apply the appropriate post processing to an image before printing it to achieve a high quality printout. Moreover the types of enhancements that should be applied to an image tend to vary depending on the semantic type of the image. For example a digital picture of a whiteboard would have different enhancement needs than a digital picture of someone s business card. Accordingly the task of enhancing an image varies by the image type further complicating the enhancement process.

Some existing systems detect low level features in images e.g. contrast darkness or color and automatically apply some type of image processing to improve the images before printing. However these systems lack the ability to apply more meaningful post processing to the images that is tailored for the particular semantic class of the image rather than just on the low level properties of the image. Because existing systems can at best detect only low level features of an image the types of post processing they can perform is correspondingly limited to basic image processing which may not be adequate to improve the quality of the image.

To satisfy the needs unmet by conventional technologies a printing system enables enhancement processing of an image that is specially tailored for the image s type as represented by a semantic classification of the image. Accordingly an image received by a printing system is classified according to at least one semantic category. While various embodiments may include any number and variety of semantic classifications in one example the classifications include whiteboard images business card images document images slide images and regular images. Once the image s semantic category is identified enhancement processing is applied to the image where the type of enhancement processing applied is based on the image s semantic classification. The enhanced version of the image can then be prepared for printing and sent to a printing output system to generate a printed representation of the image. Due to the enhancement processing this printed representation is improved over that which would result in the absence of enhancement processing.

In one embodiment printing system for organizing images captured in an office environment includes an interface for receiving an image from an image capture device. After an image is received by the interface a semantic classifier module coupled to the interface determines a semantic category for the image based at least in part on content within the image. Based on the semantic category into which the image was classified an enhancement processing module enhances the image. In this way the enhancement of the image can be specially tailored for different types of images. An output system receives the enhanced image from the enhancement processing module and prepares the enhanced image for printing. The image can then be printed on a printer coupled to or integrated with the output system or the image may be delivered to a number of users for printing or viewing at a later time.

In another embodiment the output system may select one or more print options for a printed output of the image based on the semantic category into which the image was classified. Such print options include but are not limited to a layout orientation a paper source or an ink selection. The printing system can make an intelligent guess about certain print options because it knows what type of image is to be printed. These options may be selected automatically before printing or set as defaults changeable by a user. Moreover the set of default print options for each semantic class may be user specific stored separately on each user s image capture device or together on a central preferences server.

Various embodiments of a printing system enable the printing of enhanced images using a semantic classification scheme. is a high level diagram of a flow process in which captured images are received classified and enhanced for printing in accordance with one embodiment of the invention. A printing system includes an interface which can receive an image to be printed from an image capture device . The image capture device may be a digital camera a cellular phone with camera functionality a video recorder a video or still picture output device a picture scanner or any other device capable of producing an image suitable for printing. Accordingly the printing system may receive the image from any of a number of sources including a computer a network device a portable device having media storage e.g. a digital camera a media broadcast or any of a number of different sources. Depending on the source the interface of the printing system includes appropriate hardware and software interfaces for communicating therewith such as described in co pending U.S. application Ser. No. 10 814 932 filed Mar. 30 2004 co pending U.S. application Ser. No. 10 814 751 filed Mar. 30 2004 and co pending U.S. application Ser. No. 10 813 847 filed Mar. 30 2004 each of which is incorporated by reference in its entirety.

Once the interface receives the captured image the interface provides the image to a semantic classification module . The semantic classification module classifies the image according to a semantic classification scheme which is described in more detail below. Unlike low level attributes which provide basic statistical information about an image an image s semantic classification indicates what type of item the image represents. Although various categories of semantic classifications may be used one set of semantic categories that may be useful in an office environment includes whiteboard images business card images document images slide images and regular images. In this example set the semantic classification would differentiate images of business cards from images of a whiteboard.

Once the image is classified the system may then perform various enhancement processing functions on the image where the type of enhancement processing performed is based on the classification of the image. Accordingly the semantic classification module provides the image and its semantic classification to an enhancement processing module . The enhancement processing module performs enhancement processing on the image based on the semantic classification of the image. Generally this enhancement processing improves the quality of the printed result such as by increasing the readability of the printed output and or adding information thereto. Enhancement processing of various types of images is described in more detail below. To enhance an image for improving its readability the enhancement processing module may modify the image to be printed or replace the image altogether with an improved substitute. For example if the image were determined to be a whiteboard image a type of whiteboard cleanup enhancement processing may be used to make the image more readable and to eliminate any excess border region. In another example if the image were determined to be a business card image a database of business cards may be searched for a scanned copy of the business card and if located the scanned copy may be printed instead of the image thereof for a higher quality printout.

A number of embodiments of the printing system described herein thus demonstrate how a printing system can be configured in a limitless number of combinations to solve or address various needs that exist. In one embodiment the printing system comprised a multifunction printer as described in co pending U.S. application Ser. No. 10 814 931 filed Mar. 30 2004 a networked multifunction printer as described in co pending U.S. application Ser. No. 10 814 948 filed Mar. 30 2004 or a stand alone multifunction printing system as described in co pending U.S. application Ser. No. 10 814 386 filed Mar. 30 2004 each of which is incorporated by reference in its entirety.

Although a general diagram is shown in for the printing system it will be understood that various embodiments of the system described herein can be implemented in a variety of architectural configurations. For example in addition to being a standalone appliance the printing system may be a peripheral to a meeting room portal or an office portal. A meeting room portal is an appliance in a meeting room that records meetings for example the video and audio of a meeting. An office portal is an appliance that keeps a record of the visual and audible events that take place in an office. It will be appreciated that the classification and enhancement processing capabilities of the printing system are a useful addition to either a meeting room portal or an office portal. Additionally the printing system may be integrated within an office copier.

Because the semantic classification of an image provides insight into the type of image determining an image s classification entails more than computing low level attributes of the image. In one embodiment the classification is determined by analyzing the structure and contents of text regions in the image as well as analyzing color content within the image. By examining certain features in the image an intelligent guess as to the type of image can be made. Although the following embodiment is described with respect to classifying images among an example set of semantic categories in an office environment document images whiteboard images business card images slide images and regular images it will be appreciated that the classification scheme may be applied to other groups of categories based on the same principles described herein.

In one embodiment the semantic classification scheme uses feature extraction to isolate certain features in the image. One set of important features is the textual content of the image. Accordingly text regions in the image are first identified. Because the text regions in a typical image are often not level a preprocessing step is applied to the image to perform skew correction on the text regions. A number of commercially available software programs are available for finding text regions and performing skew correction on those text regions. However these software programs are typically optimized for high resolution document images obtained via scanning so the programs may not be suitable for all types of image capture devices . For example they may not work well with digital camera images that have lower resolution e.g. lower DPI and JPEG artifacts and they also may not work well for detecting text regions with hand written strokes such as the ones found on whiteboard images .

To identify text regions for such low resolution images in one embodiment the image is first resampled to a resolution of 960 720. Using the well known Canny edge detector or any other suitable algorithm strong horizontal edges are then found in the image. These edges are smeared with a 64 2 pyramid smearing filter and the text like regions are found by performing thresholding a morphological closing operation and then connected component analysis. Text like regions that do not conform certain height and width ratio are filtered out. Any number of known algorithms can be used to identify text regions in the image for example as described in R. Lienhart and A. Wernicke Localizing and Segmenting Text in Images Videos and Web Pages IEEE Transactions on CSVT p. 256 268 2002 .

To perform skew correction on the text like regions lines in the direction of spread are then fitted to each text region and a histogram of the tangent of the lines is computed. The histogram is filtered with a 5 tab smoothing filter and the histogram bin with the maximum value is selected to be the skew angle. The text regions are rotated and binarized based on this computed skew angle for example using Otsu s method on 32 32 blocks. See N. Otsu A threshold selection method from gray level histograms IEEE Transactions on Systems Man and Cybernetics p. 62 66 1979. illustrate this process of text detection and skew correction with illustrating a received image illustrating detected text regions in the image and illustrating the text regions detected in the image corrected and binarized according to the determined skew angle.

The text regions are scanned using an optical character recognition OCR algorithm to extract the textual content in the regions. Commercial OCR packages are widely available such as Transym OCR available from Transym Computer Services Ltd. Based on the OCR output the following features may be computed 

Features extracted from connected component height histograms may be useful for separating machine print from handwriting which is in turn useful for differentiating whiteboard images from document images. Connected component height analysis is a well known tool described for example in S. N. Srihari Y C. Shin V. Ramanaprasad and D S. Lee Name and Address Block Reader System for Tax Form Processing ICDAR p. 5 10 1995 . In this analysis connected component height histograms are generally computed only for connected components i.e. individual letters or markings in the regions that are identified as being text regions. In one embodiment the following features are computed from the connected component height histograms 

Because letters are connected in handwriting more so than that of machine print the average height to width ratio of connected components in a handwriting text region is typically much smaller than that of the machine print. Based on this The following are computed 

Some whiteboard images may contain very few foreground strokes and it can be difficult to differentiate such whiteboard images from regular images i.e. photographs based purely on text region features. However unlike regular images whiteboard images usually contain a large relatively uniform background that has a light color. By detecting such a large light background region in an image therefore whiteboard images can be differentiated from regular images. In one embodiment two color features are computed to highlight these properties. An 8 bin luminance histogram of the image is computed. The index of the dominant luminance pairs is computed by 

Once these features are computed they are placed in a feature vector F which is composed of the ten features described above F tc N P P y y y XS I P . Because each of the semantic categories can be differentiated from the other categories using one or more of these features this entire set of features computed for the image can be used to determine the particular semantic category to which the image belongs.

In one embodiment an image s feature vector is matched to a particular semantic category using a Support Vector Machine SVM classifier. SVM is a known technique to implement a binary classifier and SVM classifiers such as SVM Light are commercially available. SVM is a useful algorithm for matching feature vectors in this context because it offers excellent classification performance in many different domains. In one embodiment SVM is implemented in a hierarchical fashion to obtain a multi class classifier. That is first the image is tested to determine whether it is a regular image. If not the image is then tested to determine whether it is a business card image and so on. In one embodiment the image is tested in the following order regular business card slide document and then whiteboard. The kernel function in SVM plays the role of mapping the feature vector to higher dimension space where an optimal separating hyperplane can be found that classifies two classes by the minimal expected test error. The kernel function employed in one embodiment is a radial basis function useful because it offers better performance than the polynomial and linear kernel functions.

In one experimental test a database of images contained 58 whiteboard images e.g. as shown in 88 document images e.g. as shown in 115 business card images e.g. as shown in and 103 regular images e.g. as shown in . Most of the images in the database were captured by a Ricoh CAPLIO digital camera. The classifiers were trained using 20 random images from each class and the classification results are presented in the table below. As shown the system was able to classify 85 of the images with a 93 accuracy.

An enhancement processing algorithm is applied to the classified images to improve the quality of the printed image. Which enhancement processing algorithm is applied to the image depends on the type of the image as indicated by its semantic classification. Because the enhancement depends on the classification of the image the enhancement can be specially tailored for each image leading to improved overall quality. Moreover different print options such as paper source ink selection and layout orientation can be pre selected based on the image classification leading to an improved user expenence.

If the image is determined to be just a regular image e.g. a digital photograph of a scene special category specific processing may not be necessary. But when the image is determined to be of a special type such as a whiteboard document business card or slide the system may perform enhancement processing based on the determined image category. Of course basic image processing may still be performed independent of the image type. For example in addition to any classification specific enhancement processing the printing system may also apply scaling contrast adjustment watermarks and other common image enhancements.

An image of a whiteboard typically contains a lot of excess information beyond the contents of the whiteboard. This excess information includes regions on the image outside the whiteboard as well as the color of the whiteboard itself. In one embodiment enhancement processing of a whiteboard image is designed to make the background of the whiteboard white reduce images outside the border of the whiteboards and increase the contrast of the handwritten strokes that are printed on the whiteboard to improve their readability. Several methods can be used to achieve varying results.

In one embodiment the contrast of the image was enhanced using the assumption that the background of the whiteboard is white. This assumption may not always lead to good results however because 1 when the white balance settings in a digital camera are not set correctly the captured whiteboard image may have variety of background colors besides white such as red or dark blue and 2 the illumination of the whiteboard is usually not uniform and the flash reflecting on the whiteboard usually significantly brighter than the rest of the whiteboard significantly reduces the contrast enhancement accuracy. In another embodiment the whiteboard image is binarized while the colors of the foreground strokes are preserved. This method also does not always work well. For whiteboard images that are compressed by a digital camera using JPEG compression foreground strokes suffer from ringing and chroma bleeding artifacts caused by the fact that some high frequency data is omitted during compression. When binarization is directly performed on the images with JPEG artifacts bright rings around the text lines cause the binarized text lines to be very thin. As a result printed whiteboard images are less readable.

Another embodiment for whiteboard enhancement is based on background segmentation background subtraction and color enhancement. Background estimation can be performed for an image by first computing the maximum luminance value max and the minimum min luminance value. The image is then divided into 32 32 blocks. For each block the local luminance minimum min local luminance maximum max local luminance variance and variance of red green and blue values and are computed. The following conditions are then tested for each block 

If the conditions are not met a Fisher discriminant analysis is performed for the block. The analysis is performed both on luminance and saturation values of the pixels separately to classify foreground and background pixels. Discriminant analysis on luminance samples results in two classes with the mean values mland ml and the analysis of chrominance samples results in two classes with the mean values msand ms. When the foreground strokes are in black then generally classification using the luminance samples results in a better background foreground separation. When the foreground strokes are in light colors such as light red or yellow then classification of the pixels using the chroma values results in a better background foreground separation. The degree of separation can be determined by how far apart the mean values of the two classes are i.e. ms ms. If the separation in luminance samples is higher the average color of the pixels belonging to the class with higher luminance mean value is selected as the background color for that block. This is motivated by the fact that background is likely to have lighter color than the foreground strokes where the foreground strokes are in black. If the separation in chrominance samples is higher the average color of the pixels belonging to the class with lower saturation values is selected as the background color. This is motivated by the fact that a whiteboard background is likely to have lower color saturation than the foreground strokes where the foreground strokes are in color. After background pixels are determined a 5 5 smoothing filter is applied to the background image. illustrates a background computed for an example captured whiteboard image of .

Once the background for the whiteboard image has been estimated the background is subtracted from the original image to obtain a foreground image. illustrates a foreground image for the whiteboard image of after the background of was subtracted therefrom. After the subtraction very light colored pixels are filtered out to eliminate noise and the pixel values in the resulting foreground image are normalized to 1. The foreground image is then enhanced by a S shaped curve fitting of the colors where the enhanced color components R G and B are computed by

In another embodiment additional information about the whiteboard image can be added to the enhanced image. For example a URL or a barcode image encoding a URL or other link can be appended. This URL or other link may be a link to the audio video of the meeting in which the whiteboard image was created. The appended information could also include a listing of the attendees at the meeting the business cards of the attendees the slides presented at the meeting or any other information relevant to the whiteboard image.

As an alternative to modifying an image to improve its readability the enhancement processing module may retrieve another version of a matching document. As shown in the enhancement processing module is coupled to an image database which may contain documents slides business cards and other related information. The database may include a document database such as E cabinet or Document Mall. Presumably a version of an image in the image database is of a better quality than the corresponding image captured by the image capture device. For example if someone takes a digital photograph of the front page of a document the original electronic version of the document would be a better representation of the document than the photograph. Moreover the retrieved version could include the entire document not just a single page thereof.

In one embodiment when a captured image is identified as a document image the enhancement processing module attempts to match the document image with a document in the image database . A great many methods exist for document image matching. One suitable method is based on n gram word matching where n grams where n 1 and n 2 of the text extracted from the captured image is matched against to those of the database . See e.g. Berna Erol Jonathan J. Hull Jamey Graham and Dar Shyang Lee Prescient Paper Multimedia Document Creation with Document Image Matching IEEE ICPR Conference 2004. When a matching document with a high confidence score is found that document is retrieved and replaces the originally captured image. If a matching document is not found in the database the enhancement processing module may attempt to retrieve the original document from a public source such as the Internet using a search engine. If no original document can be matched to the image the captured image may just be enhanced to increase its contrast and isolate and skew correct its text using a method as described above with respect to whiteboard image enhancing.

As with whiteboard images additional information about a document image can be printed on paper along with the image. If the image is a document image the appended information may include a URL or other link to the document s electronic version in a document versioning system or it may include bibliographical information about the document.

If the image has been determined to be a business card image the enhancement processing module may adjust the contrast and perform text identification and skew correction as described for whiteboard images. Alternatively the enhancement processing module may search for a scanned version of the business card and any associated contact or personal identification. Business card scanners are commonly used in the workplace and some appliances keep a database of business cards that are scanned in by the visitors such as the Visotor s Kiosk described in U.S. application Ser. No. 09 714 785 filed Nov. 15 2000 which is incorporated by reference in its entirety . If a captured image is classified as a business card image and the database includes business card information the enhancement processing module may query the database to obtained scanned version of the business card image. If a matched business card is found that version is substituted for the captured business card image. Moreover the enhanced business card image may also include appended information about the person identified in the business card such as a link to the web page of the person a photograph of the person and the dates that person visited the company.

If the image has been determined to be a slide image the enhancement processing module may adjust the contrast and perform text identification and skew correction as described for whiteboard images. However meeting and presentation recorders are becoming more common. If the database includes such information for presentations the captured slide image can be used to identify the presentation in which the slides were shown. In this way the enhancement processing module can retrieve either the original presentation slides or the recorded presentation slides. Techniques for identifying a presentation from a captured slide are known as described for example in Berna Erol Dar Shyang Lee and Jonathan J. Hull Retrieval of Presentations using Digital Camera Images IEEE CVPR Conference 2004 and in Berna Erol Jonathan J. Hull and Dar Shyang Lee Linking Multimedia Presentations with their Symbolic Source Documents Algorithm and Applications ACM Multimedia Conference 2003. If a better version of the slide image is identified that version is used to replace the captured slide image.

In addition information about a slide image can be appended to the enhanced slide image. If the image is a slide image the appended information may include a URL or other link to the corresponding presentation on an intranet a listing of the attendees at the meeting the business cards of the attendees or any other information relevant to the meeting in which the slides were presented.

The printing system preferably includes a user interface that presents the result of the automatic image classification to the user allowing the user to accept the classification result or change it to another image type. The user interface may be integrated in a printer in a computing device coupled to the printer or in the image capture device . The user interface may thus comprise a display system software for communicating with an attached display or any number of embodiments described in co co pending U.S. application Ser. No. 10 814 700 filed Mar. 30 2004 co pending U.S. application Ser. No. 10 814 500 filed Mar. 30 2004 and co pending U.S. application Ser. No. 10 814 845 filed Mar. 30 2004 each of which is incorporated by reference in its entirety. In one embodiment if the user does not interact with the interface for a predetermined time period the proceeds with the enhancement processing and or printing based on the automatically identified image type. illustrate example dialog boxes in which a user can confirm the system s classification and enhancement processing of a whiteboard image a document image a business card image or a regular image respectively. In addition to confirming the output of the classification result the dialog box can allow the user to specify the semantic image class and or the post processing steps manually.

As a result of the semantic classification printer can automatically select the paper feed and ink to use. For example if the image to be printed is classified as a regular photo then the printer should use high quality photo paper and ink to print the image. In the contrary if the image is classified as a whiteboard image the printer can use a low quality letter size paper and low quality e.g. black and white ink or toner for printing. Similarly if the image to be printed is identified as a document image and the original document is being printed the printer can print the document as double sided. Accordingly the printer interface may guide the user to place the proper paper to the paper feed depending on the image content. For example if image is detected as a regular image the user can be guided to place a photo paper to the paper feed. Similarly if the image detected is a color presentation the user can be directed to install the proper ink or toner cartage in the printer.

The layout of the document may also depend on the image classification result. For example if the image type is whiteboard the image can be printed such that the text parts of the whiteboard image are enlarged eliminating the large white space that is usually present in whiteboard images and making the content of the whiteboard image more readable. Similarly the layout of the text portions can be changed to make the text regions more readable.

User preferences can be established for one or more of the image classification types providing default printer settings e.g. paper source layout and the like for each or a subset of the image types. These settings can be stored by the printing system the portable image capture device e.g. on the digital camera or cellular phone or on a shared preferences server. If stored on the printing system the preferences can be indexed by a unique identifier such as a phone number. The default preferences can be applied in a way that is completely automatic or partially automatic such as by asking the user for confirmation.

In one embodiment instead of directly printing an enhanced image the image is delivered to one or more users who can then print the document at will. The delivery can be automatic based on an image s classification. For example if image is classified as a slide image the output system can send an electronic output containing the full set of slides to the known participants of the meeting. The output system could also send business cards and whiteboard images that are associated with the meeting.

While examples of suitable printing systems are described above the description of the printing system and its image classification and processing functionalities is not meant to be limiting. Depending on the intended application a printing system can take many different forms other than the typical office or home use printer with which most people are familiar. Therefore it should be understood that the definition of a printer or printing system encompasses any device or devices capable of producing an image words or any other markings on a surface or other tangible medium. Although printing on paper is discussed above it should be understood that a printer in accordance with various embodiments of the present invention could produce an image words or other markings onto a variety of tangible media such as transparency sheets for overhead projectors film slides canvass glass stickers or any other medium that accepts such markings.

Moreover any of the steps operations or processes described herein can be performed or implemented with one or more software modules or hardware modules alone or in combination with other devices. It should further be understood that portions of the printer described in terms of hardware elements may be implemented with software and that software elements may be implemented with hardware such as hard coded into a dedicated circuit. In one embodiment a software module is implemented with a computer program product comprising a computer readable medium containing computer program code which can be executed by a computer processor for performing the steps operations or processes described herein. The software module may be executed on a computer system coupled to a printer or it may be integrated within a printer driver that controls the printer. Alternatively the functionalities described herein regardless of their implementation may be embedded within a printer.

In alternative embodiments the printing system can use multiple application servers for example acting in cooperation. Any of the requests or messages sent or received by the printer can be sent across a network using local cables such as IEEE 1394 Universal Serial Bus using wireless networks such as IEEE 802.11 or IEEE 802.15 networks or in any combination of the above or any other known techniques.

The processing steps and other functions described herein may be performed entirely on a printing system by hardware software firmware or a combination thereof embedded in the system. In other embodiments some or all of the steps can be performed off the system in conjunction with one or more electronic devices capable of performing some or all of the steps and or functions. Some embodiments of the printing system can thus balance any classification and enhancement processing of received images among the printing system and any number of coupled electronic devices such as a source device e.g. a digital camera or cellular phone with picture capability a personal computer or an external network service. By conducting at least some of the processing on the printing system the system can relieve some of the processing load on the external electronic devices that would otherwise carry this processing load.

The foregoing description of the embodiments of the invention has been presented for the purpose of illustration it is not intended to be exhaustive or to limit the invention to the precise forms disclosed. Persons skilled in the relevant art can appreciate that many modifications and variations are possible in light of the above teachings. It is therefore intended that the scope of the invention be limited not by this detailed description but rather by the claims appended hereto.

