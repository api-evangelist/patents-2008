---

title: Ink editing architecture
abstract: A system and process for capturing and rendering ink is described. An ink canvas object may contain none, one, or more objects or elements and may specify the z-order of the objects or elements. The ink canvas object may host a variety of objects or elements and, therefore, provide ink functionality to the objects or elements, even though the objects or elements themselves may not have ink functionality. The ink canvas object is attached to an ink editor that has an associated modifiable ink editor behavior, whereby ink specific behaviors are collected in the ink edit behavior.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08072433&OS=08072433&RS=08072433
owner: Microsoft Corporation
number: 08072433
owner_city: Redmond
owner_country: US
publication_date: 20080402
---
This application is a divisional of U.S. Ser. No. 11 845 430 filed on Aug. 27 2007 which is a divisional of U.S. Ser. No. 10 692 015 filed on Oct. 24 2003 which is a continuation in part of U.S. Ser. No. 10 644 896 filed on Aug. 21 2003 entitled Ink Collection and Rendering whose contents are expressly incorporated herein.

Aspects of the present invention relate to information capturing and rendering. More specifically aspects of the present invention relate to providing an architecture for editing electronic ink.

People often rely on graphical representations more than textual representations of information. They would rather look at a picture than a block of text that may be equivalent to the picture. For instance a home owner may cut out pictures from magazines to show contractors exactly what is desired when remodeling a kitchen or bathroom. Textual descriptions of the same material often fall short. The tool that the home owner may use is no more complex than a pair of scissors.

In the computing world however attempting to capture and convey the identical content is cumbersome. Typical computer systems do not provide an easy interface for capturing and conveying graphically intensive content. Rather they are optimized for capturing and rendering text. For instance typical computer systems especially computer systems using graphical user interface GUI systems such as Microsoft WINDOWS are optimized for accepting user input from one or more discrete input devices such as a keyboard for entering text and a pointing device such as a mouse with one or more buttons for driving the user interface.

Some computing systems have expanded the input and interaction systems available to a user by allowing the use of a stylus to input information into the systems. The stylus may take the place of both the keyboard for data entry as well as the mouse for control . Some computing systems receive handwritten electronic information or electronic ink and immediately attempt to convert the electronic ink into text. Other systems permit the electronic ink to remain in the handwritten form.

Despite the existence of a stylus various approaches to combining electronic ink with a typical graphical user interface may be cumbersome for developers of third party applications. Accordingly there is a need in the art for an improved system for capturing editing and rendering ink that is friendly for third party developers.

Aspects of the present invention address one or more of the issues mentioned above thereby providing better content capture editing and rendering for use by third party developers. In some embodiments the ink capturing editing and rendering aspects may be manifest as an object that is part of a structure in which each element in an interface may be specified in depth or z order . In some cases the object may render the various elements in the interface in their specified z order and then render ink on the top most layer. In other cases the ink and other elements may be intermingled. Additional aspects of the invention relate to providing an architecture for editing ink.

Aspects of the present invention relate to an improved ink capturing editing and rendering system and method. Aspects of the invention permit one or more of the following 

This document is divided into sections to assist the reader. These sections include characteristics of ink terms general purpose computing environment ordering of objects constructors properties methods and events of objects relationships clipping ink editor and ink editor behaviors erasing ink selection modes sub element editing renderer integration and interface definitions

As known to users who use ink pens physical ink the kind laid down on paper using a pen with an ink reservoir may convey more information than a series of coordinates connected by line segments. For example physical ink can reflect pen pressure by the thickness of the ink pen angle by the shape of the line or curve segments and the behavior of the ink around discreet points and the speed of the nib of the pen by the straightness line width and line width changes over the course of a line or curve . Because of these additional properties emotion personality emphasis and so forth can be more instantaneously conveyed than with uniform line width between points.

Electronic ink or ink relates to the capture and display of electronic information captured when a user uses a stylus based input device. Electronic ink refers to a sequence of strokes where each stroke is comprised of a sequence of points. The points may be represented using a variety of known techniques including Cartesian coordinates X Y polar coordinates r and other techniques as known in the art. Electronic ink may include representations of properties of real ink including pressure angle speed color stylus size and ink opacity. Electronic ink may further include other properties including the order of how ink was deposited on a page a raster pattern of left to right then down for most western languages a timestamp indicating when the ink was deposited indication of the author of the ink and the originating device at least one of an identification of a machine upon which the ink was drawn or an identification of the pen used to deposit the ink among other information.

Ink A sequence or set of strokes with properties. A sequence of strokes may include strokes in an ordered form. The sequence may be ordered by the time captured or by where the strokes appear on a page or in collaborative situations by the author of the ink. Other orders are possible. A set of strokes may include sequences of strokes or unordered strokes or any combination thereof. Further some properties may be unique to each stroke or point in the stroke for example pressure speed angle and the like . These properties may be stored at the stroke or point level and not at the ink level.

Stroke A sequence or set of captured points. For example when rendered the sequence of points may be connected with lines. Alternatively the stroke may be represented as a point and a vector in the direction of the next point. In short a stroke is intended to encompass any representation of points or segments relating to ink irrespective of the underlying representation of points and or what connects the points.

Point Information defining a location in space. For example the points may be defined relative to a capturing space for example points on a digitizer a virtual ink space the coordinates in a space into which captured ink is placed and or display space the points or pixels of a display device .

Elements Objects that are placed in a tree with their placement in the tree serving as an order. They are also handle persistence of ink and input.

Adorners Adorners are visual decorations attached to objects by editing tools. They serve at least two purposes 

Service A component with no restrictions on type which can be specified enabled or disabled by its type at any element in a tree structure. The element where the service is defined is known as its scope. The service is available for all children of the element unless explicitly disabled or replaced. Services may be defined and enable programmatically or declaratively.

Designer A design component with knowledge of a particular element. It translates conceptual commands like move to a tree and property changes specific for the element e.g. could be change of X Y or Dock depending on parent element 

Edit Behavior A component often a service. though not necessarily responsible for processing input events. Receives events from an edit router component.

Edit Router Manages one or more edit behavior components using a stack where behaviors can be temporarily suspended and resumed and or a group where multiple behaviors can be active simultaneously . Routes events to active edit behavior component s with an optional event filter.

Event Filter An optional filter that may be attached to an edit router component for preliminary processing of events. It can modify events or event routing.

Selection A component representing content currently selected by the user. The selection is not necessarily a collection of elements. It may be a range or ranges of text area of an image and the like. Also the selection can be mixed combinations of different elements ranges of text areas of an image and the like . Specific data types which require special handling in selection may have a selection type associated with them. Selection Type describes an object implementing ISelection. ISelection is an interface that allows an editing framework to determine which editor to use for a specific element. A specific editor is generally associated with a selection. The editor selection pair describes a majority of data type specific editing logic.

Editor A super edit behavior component that is responsible for activating subordinate edit behaviors. It can do this based on heuristics or based on an attached property that specifies the activation of the subordinate edit behaviors .

Selection Router A specialized edit router which creates selection and editor objects as needed and directs events to the appropriate editor based on type of element the event comes from. Selection router and an optionally associated event filter is responsible for in place activation and managing mixed selection.

A basic input output system BIOS containing the basic routines that help to transfer information between elements within the computer such as during start up is stored in the ROM . The computer also includes a hard disk drive for reading from and writing to a hard disk not shown a magnetic disk drive for reading form or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM or other optical media. The hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical disk drive interface respectively. The drives and their associated computer readable media provide nonvolatile storage of computer readable instructions data structures program modules and other data for the personal computer . It will be appreciated by those skilled in the art that other types of computer readable media that can store data that is accessible by a computer such as magnetic cassettes flash memory cards digital video disks Bernoulli cartridges random access memories RAMs read only memories ROMs and the like may also be used in the example operating environment.

A number of program modules can be stored on the hard disk drive magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . A user can enter commands and information into the computer through input devices such as a keyboard and pointing device . Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port game port or a universal serial bus USB . Further still these devices may be coupled directly to the system bus via an appropriate interface not shown . A monitor or other type of display device is also connected to the system bus via an interface such as a video adapter . In addition to the monitor personal computers typically include other peripheral output devices not shown such as speakers and printers. In one embodiment a pen digitizer and accompanying pen or stylus are provided in order to digitally capture freehand input. Although a direct connection between the pen digitizer and the serial port interface is shown in practice the pen digitizer may be coupled to the processing unit directly parallel port or other interface and the system bus by any technique including wirelessly. Also the pen may have a camera associated with it and a transceiver for wirelessly transmitting image information captured by the camera to an interface interacting with bus . Further the pen may have other sensing systems in addition to or in place of the camera for determining strokes of electronic ink including accelerometers magnetometers and gyroscopes.

Furthermore although the digitizer is shown apart from the monitor the usable input area of the digitizer may be co extensive with the display area of the monitor . Further still the digitizer may be integrated in the monitor or may exist as a separate device overlaying or otherwise appended to the monitor .

The computer can operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer can be a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the local network through a network interface or adapter . When used in a WAN networking environment the personal computer typically includes a modem or other means for establishing a communications over the wide area network such as the Internet. The modem which may be internal or external is connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the personal computer or portions thereof may be stored in the remote memory storage device. Further the system may include wired and or wireless capabilities. For example network interface may include Bluetooth SWLan and or IEEE 802.11 class of combination abilities. It is appreciated that other wireless communication protocols may be used in conjunction with these protocols or in place of these protocols.

It will be appreciated that the network connections shown are illustrative and other techniques for establishing a communications link between the computers can be used. The existence of any of various well known protocols such as TCP IP Ethernet FTP HTTP and the like is presumed and the system can be operated in a client server configuration to permit a user to retrieve web pages from a web based server. Any of various conventional web browsers can be used to display and manipulate data on web pages.

A programming interface or more simply interface may be viewed as any mechanism process protocol for enabling one or more segment s of code to communicate with or access the functionality provided by one or more other segment s of code. Alternatively a programming interface may be viewed as one or more mechanism s method s function call s module s object s etc. of a component of a system capable of communicative coupling to one or more mechanism s method s function call s module s etc. of other component s . The term segment of code in the preceding sentence is intended to include one or more instructions or lines of code and includes e.g. code modules objects subroutines functions and so one regardless of the terminology applied or whether the code segments are separately compiled or whether the code segments are provided as source intermediate or object code whether the code segments are utilized in a runtime system or process or whether they are located on the same or different machines or distributed across multiple machines or whether the functionality represented by the segments of code are implemented wholly in software wholly in hardware or a combination of hardware and software.

Notionally a programming interface may be viewed generically as shown in or . illustrates an interface Interface as a conduit through which first and second code segments communicate. illustrates an interface as comprising interface objects I and I which may or may not be part of the first and second code segments which enable first and second code segments of a system to communicate via medium M. In the view of one may consider interface objects I and I as separate interfaces of the same system and one may also consider that objects I and I plus medium M comprise the interface. Although show bi directional flow and interfaces on each side of the flow certain implementations may only have information flow in one direction or no information flow as described below or may only have an interface object on one side. By way of example and not limitation terms such as application programming interface API entry point method function subroutine remote procedure call and component object model COM interface are encompassed within the definition of programming interface.

Aspects of such a programming interface may include the method whereby the first code segment transmits information where information is used in its broadest sense and includes data commands requests etc. to the second code segment the method whereby the second code segment receives the information and the structure sequence syntax organization schema timing and content of the information. In this regard the underlying transport medium itself may be unimportant to the operation of the interface whether the medium be wired or wireless or a combination of both as long as the information is transported in the manner defined by the interface. In certain situations information may not be passed in one or both directions in the conventional sense as the information transfer may be either via another mechanism e.g. information placed in a buffer file etc. separate from information flow between the code segments or non existent as when one code segment simply accesses functionality performed by a second code segment. Any or all of these aspects may be important in a given situation e.g. depending on whether the code segments are part of a system in a loosely coupled or tightly coupled configuration and so this list should be considered illustrative and non limiting.

This notion of a programming interface is known to those skilled in the all and is clear from the foregoing detailed description of the invention. There are however other ways to implement a programming interface and unless expressly excluded these too are intended to be encompassed by the claims set forth at the end of this specification. Such other ways may appear to be more sophisticated or complex than the simplistic view of but they nonetheless perform a similar function to accomplish the same overall result. We will now briefly describe some illustrative alternative implementations of a programming interface.

A communication from one code segment to another may be accomplished indirectly by breaking the communication into multiple discrete communications. This is depicted schematically in . As shown some interfaces can be described in terms of divisible sets of functionality. Thus the interface functionality of may be factored to achieve the same result just as one may mathematically provide 24 or 2 times 2 times 3 times 2. Accordingly as illustrated in the function provided by interface Interface may be subdivided to convert the communications of the interface into multiple interfaces Interface A Interface B Interface C etc. while achieving the same result. As illustrated in the function provided by interface I may be subdivided into multiple interfaces I I I etc. while achieving the same result. Similarly interface I of the second code segment which receives information from the first code segment may be factored into multiple interfaces I I I etc. When factoring the number of interfaces included with the 1st code segment need not match the number of interfaces included with the 2nd code segment. In either of the cases of the functional spirit of interfaces Interface and I remain the same as with respectively. The factoring of interfaces may also follow associative commutative and other mathematical properties such that the factoring may be difficult to recognize. For instance ordering of operations may be unimportant and consequently a function carried out by an interface may be carried out well in advance of reaching the interface by another piece of code or interface or performed by a separate component of the system. Moreover one of ordinary skill in the programming arts can appreciate that there are a variety of ways of making different function calls that achieve the same result.

In some cases it may be possible to ignore add or redefine certain aspects e.g. parameters of a programming interface while still accomplishing the intended result. This is illustrated in . For example assume interface Interface of includes a function call Square input precision output a call that includes three parameters input precision and output and which is issued from the 1st Code Segment to the 2nd Code Segment. If the middle parameter precision is of no concern in a given scenario as shown in it could just as well be ignored or even replaced with a meaningless in this situation parameter. One may also add an additional parameter of no concern. In either event the functionality of square can be achieved so long as output is returned after input is squared by the second code segment. Precision may very well be a meaningful parameter to some downstream or other portion of the computing system however once it is recognized that precision is not necessary for the narrow purpose of calculating the square it may be replaced or ignored. For example instead of passing a valid precision value a meaningless value such as a birth date could be passed without adversely affecting the result. Similarly as shown in interface I is replaced by interface I redefined to ignore or add parameters to the interface. Interface I may similarly be redefined as interface I redefined to ignore unnecessary parameters or parameters that may be processed elsewhere. The point here is that in some cases a programming interface may include aspects such as parameters which are not needed for some purpose and so they may be ignored or redefined or processed elsewhere for other purposes.

It may also be feasible to merge some or all of the functionality of two separate code modules such that the interface between them changes form. For example the functionality of may be converted to the functionality of respectively. In the previous 1st and 2nd Code Segments of are merged into a module containing both of them. In this case the code segments may still be communicating with each other but the interface may be adapted to a form which is more suitable to the single module. Thus for example formal Call and Return statements may no longer be necessary but similar processing or response s pursuant to interface Interface may still be in effect. Similarly shown in part or all of interface I from may be written inline into interface I to form interface I . As illustrated interface I is divided into Iand I and interface portion Ihas been coded in line with interface I to form interface I . For a concrete example consider that the interface I from performs a function call square input output which is received by interface I which after processing the value passed with input to square it by the second code segment passes back the squared result with output. In such a case the processing performed by the second code segment squaring input can be performed by the first code segment without a call to the interface.

A communication from one code segment to another may be accomplished indirectly by breaking the communication into multiple discrete communications. This is depicted schematically in . As shown in one or more piece s of middleware Divorce Interface s since they divorce functionality and or interface functions from the original interface are provided to convert the communications on the first interface Interface to conform them to a different interface in this case interfaces InterfaceA InterfaceB and InterfaceC. This might be done e.g. where there is an installed base of applications designed to communicate with say an operating system in accordance with an Interface protocol but then the operating system is changed to use a different interface in this case interfaces InterfaceA InterfaceB and InterfaceC. The point is that the original interface used by the 2nd Code Segment is changed such that it is no longer compatible with the interface used by the 1st Code Segment and so an intermediary is used to make the old and new interfaces compatible. Similarly as shown in a third code segment can be introduced with divorce interface DI to receive the communications from interface I and with divorce interface DI to transmit the interface functionality to for example interfaces I and I redesigned to work with DI but to provide the same functional result. Similarly DI and DI may work together to translate the functionality of interfaces I and I of to a new operating system while providing the same or similar functional result.

Yet another possible variant is to dynamically rewrite the code to replace the interface functionality with something else but which achieves the same overall result. For example there may be a system in which a code segment presented in an intermediate language e.g. Microsoft IL Java ByteCode etc. is provided to a Just in Time JIT compiler or interpreter in an execution environment such as that provided by the .Net framework the Java runtime environment or other similar runtime type environments . The JIT compiler may be written so as to dynamically convert the communications from the 1st Code Segment to the 2nd Code Segment i.e. to conform them to a different interface as may be required by the 2nd Code Segment either the original or a different 2nd Code Segment . This is depicted in . As can be seen in this approach is similar to the Divorce scenario described above. It might be done e.g. where an installed base of applications are designed to communicate with an operating system in accordance with an Interface protocol but then the operating system is changed to use a different interface. The JIT Compiler could be used to conform the communications on the fly from the installed base applications to the new interface of the operating system. As depicted in this approach of dynamically rewriting the interface s may be applied to dynamically factor or otherwise alter the interface s as well.

It is also noted that the above described scenarios for achieving the same or similar result as an interface via alternative embodiments may also be combined in various ways serially and or in parallel or with other intervening code. Thus the alternative embodiments presented above are not mutually exclusive and may be mixed matched and combined to produce the same or equivalent scenarios to the generic scenarios presented in . It is also noted that as with most programming constructs there are other similar ways of achieving the same or similar functionality of an interface which may not be described herein but nonetheless are represented by the spirit and scope of the invention i.e. it is noted that it is at least partly the functionality represented by and the advantageous results enabled by an interface that underlie the value of an interface.

The stylus may be equipped with one or more buttons or other features to augment its selection capabilities. In one embodiment the stylus could be implemented as a pencil or pen in which one end constitutes a writing portion and the other end constitutes an eraser end and which when moved across the display indicates portions of the display are to be erased. Other types of input devices such as a mouse trackball or the like could be used. Additionally a user s own finger could be the stylus and used for selecting or indicating portions of the displayed image on a touch sensitive or proximity sensitive display. Consequently the term user input device as used herein is intended to have a broad definition and encompasses many variations on well known input devices such as stylus . Region shows a feedback region or contact region permitting the user to determine where the stylus as contacted the display surface .

In various embodiments the system provides an ink platform as a set of COM component object model services that an application can use to capture manipulate and store ink. One service enables an application to read and write ink using the disclosed representations of ink. The ink platform may also include a markup language including a language like the extensible markup language XML . Further the system may use DCOM as another implementation. Yet further implementations may be used including the Win32 programming model and the .Net programming model from Microsoft Corporation.

In an alternative approach the ink may lie underneath other elements. For instance ink may be rendered and then elements rendered on top. The rendering of ink may be intermixed with the rendering of the elements.

To control the layering order of content an object may be used to handle this task. For simplicity this disclosure refers to an object that may handle this task related to ink as an ink canvas object in that it is functionally similar to how a painter applies paint in layers to a physical canvas . In one example the ink canvas may be an element. In another example the ink canvas may be an object where all elements are objects but not all objects are elements . For simplicity the ink canvas is referred to herein as an object. The ink canvas object is shown in with various constructors properties methods and events. It is appreciated that the various constructors properties methods and events are shown for illustrative purposes only. Some all or additional ones may be present in various forms in other examples of an ink canvas object without departing from this invention. The ink canvas object may host zero or more elements or objects. The ink canvas object may render ink for hosted elements or objects or those elements or objects may render ink for themselves.

The following Figures and description thereof illustrate various examples of methods properties events and constructors. It is appreciated that in some instances various items may be hidden from outside access yet accessible by a different mechanism. For instance a method may be used to return an ink object selected ink strokes an ink stream or an array of bytes. This method may be used in place of accessing a property that may contain this information. Methods may be used to access or set properties respond to or throw events and the like. Properties may describe the states of methods and or events. Events may indicate when properties are set or when methods have been executed. Other examples follow from these but are not listed here.

Various aspects may or may not be present in an ink canvas object. First an ink canvas object may host elements and or objects. The elements and objects may be rendered by the ink canvas object or may render themselves. The ink canvas object may be hosted in a tree based organizational structure. The ink canvas object may be created in a markup language for instance HTML XML and or XAML and the like . The ink canvas object may include recognition functionality including handwriting recognition shape recognition drawing recognition annotation recognition and the like . The ink canvas object may include extensible editing functionality. Finally the ink canvas object may include a variety of application programming interfaces that permit a developer to write applications that interact with the ink canvas object. One or more of these aspects may be present in an ink canvas object.

In addition to the above properties the ink canvas object may or may not further include one or more ink recognition properties.

It is appreciated that the above properties are listed for illustrative purposes only. Other properties may be used in addition to or in place of the above properties with the ink canvas object.

In addition to the above methods the ink canvas object may or may not further include one or more ink recognition methods.

It is appreciated that the above methods are listed for illustrative purposes only. Other methods may be used in addition to or in place of the above methods with the ink canvas object.

In addition to the above events the ink canvas object may or may not further include ink recognition events.

It is appreciated that the above events are listed for illustrative purposes only. Other events may be used in addition to or in place of the above events with the ink canvas object.

The ink editor manages the various behaviors as shown by the arrows from the ink editor to each of the behaviors . The various behaviors may be grouped according to relative function. For instance the creation or selection of a subset of content in sub element may be performed by various selection behaviors including but not limited to the lasso selection behavior and the rubberband selection behavior . The selected content in sub element may be modified and or manipulated by various behaviors as well by for example the move behavior and resize behavior among others .

Referring back to the ink canvas object it may be used with no children to have a region where the user can draw. Also the ink canvas object may be used on top of any other element or object or control since the ink canvas object may host any other type of element. This allows the developer to easily make anything annotatable or have any background for inking. It is appreciated that ink may be rendered at various levels intermixed with elements above or below elements in accordance with aspects of the invention.

Since the InkCanvas can host any other type of element the ability to ink does not need to be enabled for all other types of panels. The following is another example of a code snippet that allows association between the ink canvas and a flow panel where the ink will be displayed 

The following shows the ink object being associated with the element itself it is available as a dynamic property or as a .NET property for convenience 

The editor may use heuristics to determine which edit behavior to activate in response to input events from the computer system. In a number of scenarios the ink editor does not have heuristics to guide this decision so it may rely on an attached property for instance one that specifies the ink editing mode editing mode which may be a property specified as InkEditingBehavior.EditingMode to help disambiguate the user s intentions .

In some cases such as when the ink editor is in a selection mode for instance a property as follows InkEditingBehavior.EditingMode Select heuristics may exist. They may be the same as other editors

The edit behaviors that ink editor uses may be generic or may have some aspects that are different from other editor functions. First the ink editor may or may not detach and revert to another mode on a stylus up or mouse up events. Alternatively they may remain attached and functioning after these events. Remaining attached permits the mode to maintain its cursor and listen for ink gestures predefined ink movements that are not to be interpreted as ink . Second they may remove themselves when the editing mode specified changes to a mode they do not support. This detaching may be delayed when engaged in an action associated with a mode for instance collecting a stroke until the end of the action for instance a stylus or pen up event .

The following description and drawings describe various elements objects and interactions between them. As an illustration of the general references in the description the Figures may include references to illustrative examples of how one may name objects and related methods and properties. For instance a method that acts on a selected ink element when a selection changes may be named SelectedInkElement.OnSelectionChanged .

Alternatively in step the system determines whether the derived class is between a pen down and pen up event the user is still writing . This may be represented by stylusdown and stylusup events. If no then in step the property change handler is removed and the system deactivates the current ink editing behavior so it will no longer receive input events. If yes then in step the system waits for a stylus up notification. In step the stylus up notification is received and the system steps back to step .

The InkEditingBehavior.EditingMode property has at least four possible values and at least four corresponding EditBehaviors that are activated. The EditBehavior that is activated for each EditingMode value is customizable by setting the corresponding AttachedProperty 

Three examples are provided where various behaviors may or may not be used. First if one sets the erasing mode to erase then the call may appear as follows 

Second a one may set a custom behavior for the same erase. Here a third party may have written a behavior entitled MyEraserBehavior that inherits from InkEditingBehavior. This call may be expressed as follows 

Third one may set a custom behavior that does not inherit from the existing modes erase for example . Here a third party may have written InsertSpaceBehavior 

The ink editor may be attached by a selection router during a change in focus event or on focus event . show this process in greater detail.

In step the ink editor is attached and an on attach handler called OnAttach may be an event that reflects when the ink editor is attached . In step the system determines if the editing mode is ink. If yes then the system determines whether an ink collection behavior is enabled in step . If no then the system performs no operation and no changes are made in step . If yes then the ink collection behavior is activated in step . Next an edit mode change notification is provided to a user through a user interface for example in step . In step the system determines whether the new editing mode is supported. If not the system waits for a stylus tip event. In step the stylus up or mouse up event notification is received and the process returns to step with control returned to the ink editor .

If the editing mode from step was not ink then the system determines in step whether the editing mode is an erase mode. If yes then the system determines whether an erase behavior is enabled in step . If no then the system performs no operation in step . If yes then the erasing behavior is activated in step control may be transferred as well to the erasing behavior . Next the system moves to step as described above.

If no from step the system determines if the editing mode is a custom editing mode in step . If yes then the system determines whether the custom editing mode is enabled in step . If no then the system performs no operation in step . If yes the custom behavior is activated for the ink editor in step control may be transferred to the custom behavior as well . Next the system sends the editing mode change notification in step .

If no from step the editing mode is set to a selection mode in step in . Here the system may monitor for a stylus down mouse down or stylus move mouse move event. If the user performs a mouse down stylus move event in step then the system determines whether a cursor is located over an adorner in step . If yes then the cursor is changed to an edit behavior s cursor in step . If no from step then the system determines in step whether the cursor is over a child element or a selected ink element. If yes then the cursor is changed to a default cursor in step . If no from step then the cursor is changed to a cursor associated with the ink editor s selection behavior cursor.

From step if a mouse down stylus down event was received in step then the system determines whether the cursor is over an adorner in step . If yes an edit behavior associated with the adorner is activated. Control may also be transferred to this edit behavior. The system then performs based on the adorner edit behavior until a stylus up mouse up event is received in step .

If no from step then the system determines in step whether the cursor is over a child element or over a selected ink element. If yes then if a move behavior is enabled step then a move behavior is activated and control may be passed to it in step . The move behavior continues until a mouse or stylus up event is received in step .

If a move behavior is not enabled as determined by step the system performs no operation as shown in step .

If no from step then the system determines whether an ink editor selection behavior is enabled in step . If no then the system performs no operation state in step . If yes from step then the current selection in the attached element is cleared and the ink editor selection behavior is activated in step . Control may also be passed to the ink edit selection behavior of step . The selection behavior continues until a mouse or stylus up event is received in step .

Using the process of one may change various editing modes for instance. If there is an active edit behavior active between the stylus down event stylus move and stylus up sequence of events the system may deactivate it until the stylus up event. In this regards a current edit behavior may continue functioning until removed by a complete sequence of events.

The edit behaviors described above for ink erase and custom may or may not inherit their characteristics from the ink edit behavior control.

The EraserBehavior may listen to the pointer or stylus events. If listening to just the pointer events it will receive the pointer s current location. If listening to the pen events it may also receive the penis angle pressure and other information. As erasing may be pressure and angle insensitive listening to the pen events may be excessive. Accordingly in one aspect one may limit listening to only pointer information.

Some aspects of the invention relate to point erasing. Point erasing is a dynamic real time ink editing process that involves building the contour of a moving erasing shape eraser hit testing that contour against specified ink strokes and splitting or clipping the hit strokes at the areas crossed by the eraser.

In one aspect of point erasing is a hit testing approach that that finds the areas on an ink stroke contour hit by the eraser and determines the points where the stroke should be split or clipped for dynamic feedback. The points of splitting clipping are found such that there s no or minimal space between the erasing contour and the resulting ink that gives the user an experience of smooth and precise point erasing.

Point erasing supports erasing of ink strokes rendered with round and rectangular stylus shapes with variable as well as constant pressure. It provides a significant WYSIWYG experience by taking into account ink rendering transformations.

Various selection modes are possible including a lasso selection in which the path of a pen determines which elements are encompassed in the selection. Here the selection modes may listen to the pointer or stylus events. If listening to just the pointer events it will receive the pointer s current location. If listening to the pen events it may also receive the pen s angle pressure and other information. As selection modes may be pressure and angle insensitive listening to the pen events may be excessive. Accordingly in one aspect one may limit listening to only pointer information.

Ink strokes may be grouped into ink objects. Strokes may be stored in a variety of formats. If one needed to move delete or resize an ink object these operations may be limited by the characteristics of the actual combinations of strokes in the ink object making predictability of what will happen based on these operations impossible.

Accordingly in some aspects of the invention one may be able to manipulate smaller parts of the ink strokes then an entire ink stroke. In some aspects one may relate a sub element to a designer. The designer may be used to make changes in the element s content. The sub element designer translates instructions from the system into changes in the element s content. For example move instructions may tell the sub element s associated designer to perform a move operation. The sub element s designer translates those instructions into changes to the content in this case moving the selected ink strokes or portions of ink strokes .

An example of how one may perform sub element editing is described below and with reference to . Prior to the process of one deposits ink. For example one may have a form with an ink canvas on it. The editing mode was ink and the ink collection behavior was used to draw ink. Next the ink editing behavior s editing mode may be switched to a selection mode. When the pen goes down and drags across the screen a rubber band behavior is pushed on the edit router by the ink editor and assumes control as shown in step . The rubber band behavior responds to pointer move or pen move messages from the edit router by drawing feedback for the user for instance a rubber band around the ink .

Next a pointer up or pen up event occurs. The area that is highlighted is inspected by the rubber band behavior in step . It may perform a hit test operation to see what elements or objects are encountered or at least partially encompassed by the rubber band. It hit tests using the designer of the element for which it is enabled. The hit test may be a method associated with the designer. In this case the designer for the ink canvas then inspects the ink canvas for any ink strokes in the hit test region. If one or more exists the designer creates a selected ink element and returns it to the rubber band behavior which in turn inserts it into the service handling selection in step .

Next when the selected ink is constructed it is passed the collection of strokes in the collection of ink that which the selection was performed on . The ink canvas presenter or renderer is informed to listen to the selection service s selection changed event in step so that the ink canvas presenter knows which strokes not to render.

Now the rubber band behavior references a single selected ink group returned from a hit test method from the ink canvas designer. The rubber band behavior informs the selection service about the ink and deactivates itself in step . Control may be returned to the ink editor.

Other services may also be notified of the change. Here a selection adorner service may have received a notification from the selection service that the global selection has changed. In response the selection adorner service may inspect the collection of elements in the selection service and find the single selected ink in the selection. Next the selection adorner service determines for each element in the selection service in step which edit behavior are enabled on the selected ink for instance move resize rotates and the like in step . It may then ask each of the enabled edit behaviors in step what their adorners are and create a set of the adorners in step . The set of adorners may then be rendered on the element in step . It may also get a list in step of the adorners enabled on each element in the edit behavior list of step .

The ink editor may still be in control. It may listen to pointer move and pointer down events. When a pointer move event occurs it determines if the pointer is over an adorner. If it is it asks the adorner for its cursor and changes the cursor to it.

If the pointer down event happens on one of these adorners the corresponding edit behavior is activated. In this case the resize behavior becomes active. It responds to that activation by determining the designer of the element it is attached to.

In pointer move events the resize behavior responds by calling methods on the designer of the element methods like extend right and extend bottom .

The selected ink s designer may override these virtual extend XXX methods to track the actions being taken. It may respond by scaling the ink to the new area. The selected ink s designer may be aware of various instructions including resizing. Move and rotate instructions may simply be acted on the ink.

The selected ink has been manipulated and has now been de selected. When the selected ink was constructed one of the things it did was to ask the selection service to notify it when the selection has changed. The selected ink responds to this notification by fixing up the strokes with the change that has occurred during editing scaling rotation resize .

To determine whether an object is included within a selection region determined by rubberbanding or by a lasso selection one may provide a volume threshold of an object that is to be within a selection region for the object to be selected. Ink and other objects may have the same threshold. Alternatively ink and other objects may have different thresholds. For instance for arbitrary objects one may set the threshold between 50 and 70 and for ink one may set the threshold between 70 and 90 . Of course these ranges are for illustrative purposes only. They may differ based on user developer experiences or desires.

To determine the volume of an object enclosed by a selection the object may be filled with ordered points or random points. The ratio between those points contained within the selection region may be compared with the total number of points yielding a percentage of inclusion. If the percentage of inclusion falls within the ranges set forth above or as modified the object or ink may be the to fall within the selection region. Optionally to minimize the delay for large objects and increase the accuracy for small objects the number of points placed inside the objects may vary based on size. For instance for small objects the density of points may be high. For large objects the density of points may be low. Or alternatively the densities may be the same for all objects.

The following lists process steps that may be used to determine whether a region is included. Referring to in step the coordinates of the ink or object is converted to ink canvas coordinates. In step points are found and placed on a line within or bounding the object for instance a bounding box of the object may be used or the contour of the object used . In step points may be connected to form additional lines. In step additional points may be placed on the lines until a desired density is reached. In step the set of points is hit tested against a selection region to determine which ink or objects fall within the selection region or meet the threshold levels previously set.

Sub element editing as applied to ink starts by determining the bounding box for the selected ink strokes. Another ink canvas is created. Here it may be created in the size of the bounding box surrounding ink . The selected ink strokes are copied or moved into the new ink canvas the location of ink is determined by a coordinate system of the ink canvas . With the new ink canvas the identifying information of ink is the same it s relation in the new ink canvas is that same as that in ink canvas . In other words ink is offset from the origin of the ink canvas coordinate system by vector . Here ink canvas may be repositioned and ink be moved as well as it resides now in ink canvas . However the location of the canvas and ink are separated from each other thereby leading to possible confusion in trying to manipulate or select ink .

To address this potential for confusion vector is then applied as an offset to the ink canvas so that it shows ink within its borders .

The following describes how the selected ink control knows which strokes to render. The selected ink is passed a strokes collection when instantiated. A presenter associated with the selected ink control knows how to render the strokes. The issue is determining which strokes not to render. The presenter associated with the ink canvas checks the selection service to determine if selected ink associated with the ink canvas is in the current selection. If it is the presenter accesses the selected ink s strokes property to determine the strokes not to render. Optionally the presenter may only listen to the selection service when selected ink is about to be inserted. This may occur based on method that instructs the presenter to limit to what it listens. For instance one may use a method similar to InkCanvasPresenter.WatchSelection.

To demonstrate this consider the fact that there are two ways to cause ink to be selected. First a user may manually select strokes using a lasso selection behavior or a rubberband behavior. Second a developer may programmatically set the selection in the ink canvas. The selection may be set as a property in the ink canvas.

The net effect is the same selected ink is created and inserted into the selection service. Before insertion one may optionally tell the ink canvas presenter to listen for a change event for instance the selection service having been changed using a watch selection method . If however when the ink canvas presenter receives the selection changed event and no selected ink is present in the selection it may deactivate itself from the selection changed event.

From step the selected ink element is instantiated. It includes a constructor laving strokes and a method that operates when the selection is changed for ink. Its name may be selectedinkelement.onselectionchanged.

Constructor performs the following it stores a stroke collection and registers for the selection service selection change event in step .

When the selection has been changed the system determines whether the selected ink element is in the selection service in step . If yes the system performs no operation in step . If not then the system applies changes to the strokes in step . In step the selected ink element unregisters from listening to the selection change event .

Referring to ink canvas presenter contains a method ink canvas presenter watch selection . The method may be registered for a selection service selection changed event . The ink canvas presenter may also contain a method ink canvas presenter on selected changed event that operates in response to the selection service changed event . In step the system determines whether there is a selected ink element in the selection service. If yes then the system gets the stroke collection in step . In step the system invalidates ink canvas and does not render the selected strokes. If no from step then the system unregisters from the selection service selection changed event in step . Next in step the system invalidates the ink canvas and renders all strokes.

Selected ink element is instantiated containing a constructor relating to strokes . The constructor stores a stroke collection and registers for a selection service selection change event .

The selected ink element also contains method selected ink on selection changed . In step the system determines if the selected ink element is in the selection service If yes then the system performs no operation in step . If no from step the system applies changes to the strokes in step and unregisters from selection changed notifications in step .

In step the system calls the ink canvas presenter watch selection method . The watch selection method registers one for the selection service selection changed event . When the selection is changed the ink canvas presenter may execute method . In step the system determines if there is a selected in element in the selection service. If yes the strokes collection is obtained. Next the ink canvas is invalidated and no strokes are rendered in step . If no from step the system unregisters from the selection service selection changed notification in step . Finally the system invalidates ink canvas and renders all strokes.

The differences between the two codepaths of and A and B include how the selection is initiated and who inserts the selected ink into the selection service.

The following provides a list of interface definitions that may or may not be used. It is appreciated that these interfaces are show for illustrative purposes only. The interfaces may be augmented or otherwise modified including separated and still remain within the scope of the aspects of the invention.

This interface may be used to associate implementing classes with the ServiceConverter. This allows a type conversion between a string and a service for parser support 

Aspects of the present invention have been described in terms of illustrative embodiments thereof. Numerous other embodiments modifications and variations within the scope and spirit of the appended claims will occur to persons of ordinary skill in the art from a review of this disclosure.

