---

title: Flexible music composition engine
abstract: An apparatus, method and system for generating music in real time are provided. A pipeline for coordinating generation of a musical piece is created. At least one producer is loaded into the pipeline, the at least one producer for producing at least one high level musical element of the musical piece, independent of other producers in the pipeline. At least one generator is called by the at least one producer, the at least one generator for generating at least one low level music element of the musical piece. The at least one low level musical element and the at least one high level musical element are integrated, such that the musical piece is generated in real time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08058544&OS=08058544&RS=08058544
owner: The University of Western Ontario
number: 08058544
owner_city: London, Ontario
owner_country: CA
publication_date: 20080919
---
This application is a National Phase entry of International Patent Application Serial No. PCT CA2008 001648 filed 19 Sep. 2008 and claims the benefit of priority of U.S. Provisional Patent Application No. 60 974 109 filed 21 Sep. 2007 which are hereby incorporated by reference.

The specification relates generally to automated music composition and specifically to an apparatus method and system for a flexible music composition engine which generates music in real time.

There is increasing interest and demand for adaptive music composition systems which can change the character of generated music in real time for use in diverse areas such as video game music generation film score composition and development of interactive composition tools. Previous music composition systems have tended to be monolithic and complex in their approach to automated music composition and have not been successful in mimicking human composed pieces of music. Furthermore previous music composition systems have not been successful at adapting the music being generated to mood as it develops in a game or a film etc. Rather the previous music composition systems rely on calling up different snippets of music that are classified under the given mood. This can be expensive for the makers of a video game as a composing and or licensing fee must be paid for each snippet of music used. The complexity of the previous music composition systems have also made them difficult to use by a non specialist.

A first aspect of the specification provides a flexible music composition engine comprising a processing unit. The processing unit is enabled to create a pipeline for coordinating generation of a musical piece. The processing unit is further enabled to load at least one producer into the pipeline the at least one producer for producing at least one high level musical element of the musical piece independent of other producers in the pipeline. The processing unit is further enabled to call at least one generator via the at least one producer the at least one generator for generating at least one low level musical element of the musical piece. The processing unit is further enabled to integrate the at least one low level musical element and the at least one high level musical element such that the processing unit produces the musical piece in real time.

The processing unit can be further enabled to call at least one performer object for controlling the generation of the musical piece and load the pipeline into the performer object upon initialization of the generation of the musical piece. The performer object can be enabled to make repeated calls on the pipeline until the musical piece is of a given length and each call of the repeated calls generates at least one block of the musical piece.

The at least one generator can be associated with a style of the musical piece such that the at least one low level musical element provides the musical piece with the style. The at least one producer can be enabled to call a plurality of generators including the at least one generator each of the plurality of generators associated with a different style such that a character of the musical piece can change from the style to the different style when a new generator is called. The processing unit can be further enabled to receive data indicative of the different style and in response trigger the at least one producer to call the generator associated with the different style to change the character of the musical piece in real time.

The processing unit can be further enabled to monitor at least one setting associated with the generation of the musical piece and in response to a change in the at least one setting trigger the at least one producer to call a new generator associated with the setting to change the character of the musical piece in real time.

Generating at least one low level musical element can be based on at least one of selecting a pattern from a pattern library and randomly generating the at least one low level musical element. Randomly generating the at least one low level musical element can comprise pseudo randomly generating the at least one low level musical element such that the same low level musical element is generated for a given seed value. The at least one pattern library can comprise at least one of a harmonic pattern library a motif pattern library a meter pattern library and a mode pattern library.

The at least one generator can comprise a structure generator callable by the section producer the structure generator for generating the at least one section such that the section producer produces a linear progression of sections to form a structure of the musical piece. Producing at least one section can comprise producing at least one section according to at least one of length section number and section type. The section type can comprise at least one of a regular section and an end section. Producing the at least one block of a section of the musical piece can comprise sequentially producing blocks until the section is of a given length. The at least one generator is callable by the block producer and can comprise at least one of a harmonic generator for generating a harmonic pattern a meter generator for generating a meter and a mode generator for generating a mode. The at least one generator is callable by the line producer and can comprise a motif generator for generating a motif pattern independent of a mode and a harmonic pattern. The line producer can be further enabled to map the motif pattern onto a previously generated harmonic pattern by 

converting the motif pattern to a harmony adjusted motif based on the previously generated harmonic pattern 

resolving each the note in the motif pattern into at least one of a pitch of the previously generated mode and a nearby dissonant note based on the harmonic chords in the previously generated harmonic pattern.

The processing unit further can be enabled to convert the musical piece to an output format that is at least one of playable by an output device and storable in a data file. The flexible music composition engine can further comprise the output device the output device controllable by the processing unit. The output device can be enabled to output the musical piece.

The processing unit can be further enabled to adjust at least one musical element of the musical piece such that the musical piece reflects a given emotional character by 

retrieving at least one mood parameter associated with at least one musical element the at least one mood parameter specifying how the at least one musical element is to be adjusted to reflect the given emotional character 

receiving at least one weight parameter specifying the degree to which the music is to be adjusted to reflect the given emotional character wherein the at least one weight parameter can comprise a percentage that the music is to be adjusted to reflect the given emotional character and wherein the adjusting the at least one mood parameter based on the at least one weight parameter can comprise adjusting the at least one mood parameter based on the percentage and

adjusting the at least one mood parameter based on the at least one weight parameter prior to the adjusting the at least one musical element.

The flexible music composition engine can further comprise an interface for receiving control data from at least one of a media device and a multimedia application the interface in communication with the processing unit such that the processing unit produces the musical piece in real time based on the control data. The media device can comprise at least one of a video device a videogame device a telephonic device. The flexible music composition engine can further comprise at least one of the media device and the multimedia application.

A second aspect of the specification provides a method of generating music in real time in a computing device including a processing unit the method executable in the processing unit. The method comprises creating a pipeline for coordinating generation of a musical piece. The method further comprises loading at least one producer into the pipeline the at least one producer for producing at least one high level musical element of the musical piece independent of other producers in the pipeline. The method further comprises calling at least one generator by the at least one producer the at least one generator for generating at least one low level musical element of the musical piece. The method further comprises integrating the at least one low level musical element and the at least one high level musical element such that the processing unit produces the musical piece in real time.

A third aspect of the specification provides a system for generating music in real time. The system comprises a processing unit enabled to create a pipeline for coordinating generation of a musical piece. The processing unit is further enabled to load at least one producer into the pipeline the at least one producer for producing at least one high level musical element of the musical piece independent of other producers in the pipeline The processing unit is further enabled to call at least one generator by the at least one producer the at least one generator for generating at least one low level musical element of the musical piece. The processing unit is further enabled to integrate the at least one low level musical element and the at least one high level musical element such that the processing unit produces the musical piece in real time. The system further comprises at least one output device in communication with the processing unit enabled to output the musical piece. The system further comprises at least one media device in communication with the processing unit enabled to produce multimedia data and control data the control data for triggering the processing unit to change a style of the musical piece synchronous with the multimedia data.

In some embodiments the processing unit is in communication with a media device and further enabled to receive control data from the media device such that the processing unit generates the music in real time based on the control data . For example the media device can comprise at least one of a video device a videogame device and a telephonic device and can include but is not limited to any suitable combination of a processing unit memory communication interface input devices output devices etc. As data is generated at the media device the music being generated can be adjusted to reflect the data at the media device . In a non limiting example if the media device comprises a videogame device as events occur in a videogame the music can be generated to reflect the events e.g. happy music for happy events and sad music for sad events . In another non limiting example the media device comprises a telephonic device.

In some embodiments the processing unit is in communication with an input device and control data can be received from the input device . Hence a user interacting with the input device can determine the control data . The input device can include but is not limited to a keyboard a pointing device a touch screen etc.

In some embodiments the processing unit is an element of a computing device the computing device comprising an interface and a memory the interface for receiving the control data and or control data and the memory for storing the application M until the application M is processed by the processing unit . The memory can also store any data used in the processing of the application M and or any data generated during the processing of the application M. The computing device can include but is not limited to a personal computer a laptop computer and a mobile computing device.

The memory can comprise any suitable combination of persistent memory and volatile memory including but not limited to any suitable combination of a removable diskette CD ROM ROM fixed disk USB drive hard drive RAM etc.

In yet further embodiments the processing unit is in communication with a memory external to the computing device e.g. via a communications network not depicted the memory for storing the application M until the application M is processed by the processing unit . The memory can also store any data used in the processing of the application M and or any data generated during the processing of the application M.

In yet further embodiments the processing unit the output device and the media device can be elements of a computing device with processing for the media device also occurring in the processing unit . For example the computing device can include but is not limited to a computer a laptop computer a mobile computer a mobile computing device video device a videogame device and a telephonic device.

In any event the processing unit upon processing the application M generally comprises a flexible music composition engine enabled to generate music in real time and or generate music on demand for example during game play of a video game such that the music generated can be influenced by game events and change character on the fly.

Hence the processing unit in combination with the application M described hereafter meets several goals 

 a Permit flexibility in the composition process. The processing unit can either generate music without any restrictions or a user e.g. a human composer can guide musical choices.

 c Incorporate a multi level application programming interface which makes the functionality of the processing unit accessible to users with varying levels of musical and or programming knowledge.

 d Reuse musical elements such as note sequences and harmonic structure both from existing composed pieces or computer generated material.

 e Alternatively allow music to be altered based on emotional characteristics such as happiness sadness anxiety liveliness etc.

In some non limiting embodiments the application M is generally an object oriented system written in any suitable programming language including but not limited to C C and or Java. It includes high level classes such as Musician and Instrument that model real world entities involved in music composition. Furthermore the application M comprises a pipelined architecture in the generation process to allow a structured yet flexible approach to composition the inclusion of optional pattern libraries for storing and accessing musical information and an optional emotion mapper which allows music to be altered according to emotional characteristics. Each of these will be described below.

Furthermore the application M can be embedded within application software to facilitate online dynamic composition of music for immediate use within that application. For example using the engine in a video game would allow endless variety in the game music and since composition is done dynamically the generated music could be tuned to reflect emotional context during game play. Alterations to the music could be initiated from within the game by the game player or both. In addition the application M can be used as a basis for stand alone composition tools. For example consider a system which would permit collaboration among human composers who could exchange parts of pieces created with the engine or share virtual musicians instruments and musical elements. the application M s architecture can also support the creation of virtual bands and jam sessions.

Attention is now directed to which depicts the architecture of the application M according to non limiting embodiments as well as a block diagram of output from the application M e.g. a musical piece which can be used by the processing unit to control the output device .

Each of the pipeline the producers the generators and the other high level classes can be stored in the memory and or the memory until processed by the processing unit and or called by the appropriate element of the application M e.g. generators are stored until called by a producer .

the application M can also comprise an emotion mapper described below for adjusting at least one musical element of a musical piece such that the musical piece reflects a given emotional character.

When initiating the system the producers and generators are loaded into the pipeline . In some non limiting embodiments the producers and generators are created before being loaded into the pipeline . In these embodiments a Generator Factory not depicted can be used create the generators .

The structure generator is enabled to create the overall sectional structure of a musical piece e.g. ABA form .

The harmonic generator is enabled to create a sequence of chords for each section e.g. I IV V I of a musical piece.

The mode generator is enabled to create modes for a musical piece e.g. start in F progress to C divert to D and return to F .

The motif generator is enabled to create sequences of notes e.g. a four note ascending scale of sixteenth notes for a musical piece.

Each generator can contain at least one random and or pseudo random number component which is used for decisions it needs to make.

Each generator can also contain at least one Pattern Library not depicted which provides the generator with musical elements it can use directly or as starting points for musical element generation. Pattern libraries can be created prior to processing the application M and generally comprise data embodying musical knowledge. For example a Bach MotifPattern library can contain motifs from compositions by Johann Sebastian Bach. Similarly a Bach Harmonic pattern library can contain harmonic patterns from compositions by Johann Sebastian Bach. In some embodiments pattern libraries can be added to a generator enabling distribution of new pattern libraries after the application M has been installed in a computing device. In yet further embodiments users and or the application M can add to the pattern libraries. In some embodiments the pattern library or libraries can be stored in the memory and or the memory .

Furthermore in some embodiments there can be a plurality of each of the generators with each group of generators associated with a different style. For example in some embodiments such a group can comprise a structure generator a harmonic generator a meter generator a mode generator and a motif generator each associated with a jazz style and another group of a structure generator a harmonic generator a meter generator a mode generator and a motif generator each associated with a classical style.

The section producer is enabled to use e.g. call the structure generator to produce at least one section the section comprising a chunk of a musical piece with an associated length for example in seconds. Each section contains a number of blocks which comprise segments of the piece for example 4 bars composed of a musical line played by each musician .

The block producer is enabled for producing at least one block of a section of the musical piece using a harmonic pattern created by the harmonic generator when the harmonic generator is called by the block producer . The block producer is further enabled to call each of the meter generator and the mode generator to produce a meter and a mode respectively for the block .

The line producer is enabled to produce the musical lines using the motif generator to create the actual note sequences in musical lines played by each musician . In some embodiments the line producer is enabled to produce musical lines with varied articulation e.g. staccato vs. legato playing or any other articulation known to a person of skill in the art.

The output producer is enabled to convert the musical piece to any suitable output format including but not limited to MIDI way mp3 and or streamed formats. Furthermore the output producer can be enabled to store an output data file e.g. in the memory and or the memory comprising the musical piece and or output the musical piece to the output device .

It is understood that while each of the producers the generators etc. are described with respect to given functionality the processing unit performs the associated functionality upon processing of each producer and generator .

Attention is now directed to which depicts a method for generating music in real time according to non limiting embodiments. In order to assist in the explanation of the method it will be assumed that the method is performed using the system using the architecture of the application M depicted in . Furthermore the following discussion of the method will lead to a further understanding of the system and the architecture of and their various components. However it is to be understood that the system and or the architecture of and or the method can be varied and need not work exactly as discussed herein in conjunction with each other and that such variations are within the scope of present embodiments.

At step a play request is received by the performer for example by the processing unit upon processing the application M. Furthermore it is understood that the performer has been pre configured to initiate with a given number of musicians each with the pre configured properties as described above though as will be described the number of musicians and or their properties can be changed such that musical piece being generated changes accordingly in real time. In some embodiments the performer can further receive a given style which is subsequently passed to each of the producers in the pipeline such that each producer can call generators associated with the given style.

At step the performer activates the pipeline based on settings such as pre configured settings and or the given style and or the control data or . At step it is determined if there any changes to the settings for example pre configured settings may be changed to a new configuration via the input device the given style may change to a new style and or the control data or may indicate that settings have changed e.g. new style different events occurring at the media device such as new events in a video game .

If no changes to the settings have occurred for example as will be the case when processing unit first processes the application M then a pipeline process P is initiated and or continues at step the pipeline process P described below. In general however the pipeline process P is enabled to generate sections and or blocks of the musical piece.

If however it is determined at step that changes to the settings have occurred then at step the pipeline process P is interrupted and at step the performer and the pipeline are updated such that the musical piece is now generated according to the new settings. In a non limiting example game play in a videogame may become more intense or less intense and the emotional characteristics of the musical piece can be adjusted accordingly and or the tempo or style of the musical piece can be adjusted accordingly. In another non limiting example a user interacting with the processing unit via the input device can add or subtract musicians change style mood instruments etc.

Once the performer and the pipeline are updated the pipeline process continues at step . At step it is determined if the musical piece is complete based on the pre configured settings and or the control data or . For example the pre configured settings may indicate that the musical piece is to be of a given length and or a given number of sections. If the musical piece is finished the processing unit waits for a new play request at step . If the musical piece is not finished steps are repeated to continue to generate the musical piece.

Attention is now directed to which depicts the pipeline process P according to a non limiting embodiment. At an optional step the emotion mapper can be called to adjust global settings e.g. musical characteristics that are not changed elsewhere such as tempo volume etc. .

At step it is determined if a new section is needed. If the application M is being initialized then by default at least one new section is needed. If a new section is needed at step the section is requested from the section producer in a method A depicted in . Turning to A in it is determined if a structural pattern is needed. If so at step the section producer calls the structure generator which provides a structural pattern. In any event at step the section producer gets a new and or the next section in the structural pattern. The length of each section can be determined via control data or control data which can be passed to or retrieved by the structure generator . At step the new section is returned to pipeline e.g. in step in P of .

Returning to if no section is needed at step or alternatively once the new section is returned at step at step a block is requested from the block producer in a method B depicted in . Turning to B in at step a new block is created of a given pre configured and or randomly and or pseudo randomly determined length for example 4 bars . At step the block producer gets a meter by calling the meter generator and at step the block producer gets a mode by calling the mode generator . A meter and mode respectively are subsequently returned based on pre configured settings and or the given style and or the control data or

At an optional step the emotion mapper can adjust the mode according to pre configured settings and or the given style and or the control data or

At step the block producer gets a harmonic pattern by calling the harmonic generator . A harmonic pattern is subsequently returned based on pre configured settings and or the given style and or the control data or . At an optional step the emotion mapper can adjust the harmonic pattern according to pre configured settings and or the given style and or the control data or

Returning again to at step the musical line or a plurality of musical lines according to the number of musicians in the performer is requested from the line producer in a method C depicted in . Turning to C in at step a musician is retrieved by the line producer i.e. the data representing an instrument a mood an ability and a style associated with a musician is retrieved . At step the line producer calls a routine D or Produce Musical Line to produce the musical line for the retrieved musician the routine D described below. At step it is determined if there are more musicians for which a musical line is to be produced. If so the next musician is retrieved at step . If not the block is assembled and returned at step to the pipeline i.e. in step in P of the block now populated with the musical line s .

Attention is now directed to which depicts the routine D for producing the musical line s . The routine starts at step where it is determined if the musical line being produced is finished. If not e.g. the routine D is initializing or the length of the block has not been reached then at steps to the style of the motif to be returned is determined based on pre configured settings and or the given style and or the control data or . At step it is determined if a global style e.g. the given style is to be used. If so at step the motif generator associated with the global style i.e. the given style is selected. If not at step it is determined if the style of a musician e.g. a style is to be used. If so at step the motif generator associated with the style of the musician is selected. If not at step the motif generator associated with a default style associated with the performer and or the pipeline is selected. In any event once the appropriate motif generator has been selected at step the motif pattern is returned from the appropriate motif generator

Indeed steps similar to steps can be repeated when any producer makes a call to a generator based on style. For example in steps and calls to the appropriate generator can be determined via decisions similar to those made in step and .

At an optional step the emotion mapper can adjust the motif according to pre configured settings and or the given style and or the control data or

At the motif is harmonically adjusted and added to the musical line described below . At it is again determined if the musical line is finished i.e. the length of the block has been reached . If not step are repeated and if so at step the musical line is returned to the pipeline i.e. in step in C of .

Attention is again directed to where once the musical line s have been returned at step the output producer generates output data. The output data can be saved to a file i.e. in the memory and or the memory or used to control the output device to play the musical piece that has been generated.

Returning again to it is understood that the application M monitors the settings through all of the steps depicted in and adjusts the generation of the musical piece accordingly. In other words steps can occur before during or after any of the steps depicted in such that the pipeline process P is interruptible at step at any appropriate step depicted in such that the performer and the pipeline can be updated at step . In some embodiments the interruption of the pipeline process P can be delayed if interruption of the pipeline process P results in a discontinuity in the generation of the musical piece e.g. a dead space where no dead space is desired .

In some embodiments the musical piece is updated between blocks . However as in some embodiments music generation can occur much more quickly than playback i.e. by the output device and thus many blocks can be generated while the first block is playing. Hence to support dynamic alteration of the musical piece some of these embodiments comprise a means of keeping track of which block is currently being played a means of altering and or replacing subsequent blocks when a change to a setting occurs.

Furthermore in other embodiments alterations can occur gradually rather than abruptly and or sometimes gradually and sometimes abruptly. In embodiments where gradual change occurs parameters for starting and end points of the transition are determined and blocks in between are generated accordingly. In these embodiments present and future parameters are tracked.

Attention is now directed to which depicts a method for generating music in real time. In order to assist in the explanation of the method it will be assumed that the method is performed using the system using the architecture of the application M depicted in . Furthermore the following discussion of the method will lead to a further understanding of the system and the architecture of and their various components. However it is to be understood that the system and or the architecture of and or the method can be varied and need not work exactly as discussed herein in conjunction with each other and that such variations are within the scope of present embodiments. In some embodiments the method is a summary of the methods processes and routines of . It is hence understood that method is generally performed by the processing device .

At step the pipeline is created. In a non limiting embodiment the pipeline is created by the performer but in other embodiments the pipeline may be created by another entity.

At step at least one producer is loaded into the pipeline the at least one producer for producing at least one high level musical element of the musical piece independent of other producers in the pipeline. Non limiting examples of a high level musical element include but are not limited to sections blocks and musical lines .

At step at least one generator is called within the at least one producer the at least one generator for generating at least one low level musical element of the musical piece. Non limiting examples of a low level musical elements include but are not limited to structure meter mode harmonic pattern and motif pattern.

At step the at least one low level musical element and the at least one high level musical element are integrated for example by the processing unit such that the musical piece is produced in real time.

It is understood that steps can be repeated and or interleaved as desired. Hence new high level elements can be produced before or after the low level elements the new high level elements to be integrated with new low level elements. Further blocks and or sections can be output as they are produced before or after new high level elements are produced and or new low level elements are produced and or integrated with the new high level elements.

Furthermore steps can be repeated as required to continue generation of the musical piece until the musical piece of a given length or the method is interrupted. Furthermore it is understood that due to the pipeline architecture steps could occur in parallel.

Furthermore while steps are being executed by the processing device settings for the high level and low level musical elements are being monitored to determine a change to the settings for example at step . If no change is detected the method continues at step . If however a change to the settings is detected at step at step the method is interrupted at any suitable point to update the pipeline and or performer . In effect the method then returns either to step such that new high level elements can be produced or to step or step such that new low level elements can be produced. Hence the musical piece can be changed in real time on the fly .

In other words within the system once the producers have been initialized they are loaded into the pipeline which oversees the generation process and calls on each producer in turn to assemble the piece.

Furthermore at step if desired the emotion mapper can be used to adjust the low level musical elements for mood dependent adjustments.

The elements of the application M that are involved in music creation generally reflect real life counterparts. At the highest level the application M deals with the following classes musician Instrument Performer various piece characteristics style mode meter and mood .

A musician plays an instrument and has a mood . Also a musician has an ability and knows a number of styles . The intention is to model a real musician who can play one instrument at a time but has the ability to play that instrument in different styles with varying ability Consider a pianist who is classically trained but also plays some improvisational jazz. This pianist can be modelled as a musician who knows at least three styles classical jazz and her own style a personal repertoire of improvisational riffs.

Furthermore storing an ability for the musician enables modelling of good and bad musicians Further aspects of ability can be ability to play an instrument in tune ability to follow a beat ability to contain a mood and play in the manner desired by a conductor. The styles known by a musician can also reflect ability . On the other hand it may be desired to model a musician with limited ability perhaps in a video game role imagine a bar scene where a bad band is playing . It may also be desired to create an application where one has to train musicians or one might want bad musicians simply for the entertainment value of hearing them play.

By modelling musicians in this manner users can develop and trade musicians with one another. For example users can have collections of musicians each with their own skill set. The musicians can be shared traded combined into groups and marketed.

The use of pattern libraries accessible by the generators enables new music to be generated by reusing compositional elements either elements from existing pieces or elements which have been previously generated. A pattern library can be thought of as a repository of musical ideas. The four libraries which can be used by the application M include but are not limited to a harmonic pattern library a motif pattern library a mode pattern library and a meter pattern library. Furthermore the pattern libraries enable the system to compose in different styles and to provide a mechanism for exchanging and storing musical ideas. Each of these goals will be discussed in turn.

To answer the question What style is this piece of music a person of skill in the art would listen for clues among the musical elements of the piece to determine its classification. The instruments being played are often an initial hint the sound of the piece . Further to that attention would be paid to the rhythmic structure the harmony the melody the mode and the meter and transitions between elements. Consider the knowledge of a jazz trumpet player for instance Louis Armstrong. He knows typical harmonic progressions that will be used in a piece and has many riffs in mind that he can use and improvise on. In embodiments of the application M this knowledge can be captured in the harmonic library and motif library respectively.

How the pattern libraries are used can be determined by the implementation of the generators . In some embodiments a generator could use the pattern libraries as its only compositional resource that is all the musical elements returned by the generator are those taken from the library. In other embodiments the generator could use patterns from the pattern libraries as starting points which are then modified. In yet further embodiments a generator could return a mixture of patterns from the pattern libraries and generated patterns. In yet other embodiments a generator could ignore the pattern libraries entirely and return only generated patterns. Thus the pattern libraries comprise rich musical resources which can be flexibly used depending on the desired musical outcome.

Regarding the exchange of musical ideas consider a situation where you meet someone using the application M who has a musician that is very dynamic guitar player let us call the musician in this instance Jesse Cook . The knowledge of the guitar player is contained in his known styles which comprise pattern libraries and generators the guitar player can use for music composition. A musician called Louis Armstrong could to learn how to make his trumpet sound like a flamenco guitar by incorporating the riffs from Jesse Cook s motif library into Louis Armstrong s existing motif library. Another different possibility is that Jesse Cook could be added to a band e.g. a performer comprising a plurality of musicians . A further possibility is that the two musicians Jesse Cook and Louis Armstrong could jam together. Or you could ask Jesse Cook and Louis Armstrong to collaborate in an Ensemble e.g. another performer comprising a plurality of musicians . Could they influence each other while playing All of these functions are supported by pattern libraries as repositories of musical knowledge.

Furthermore in some embodiments more than one type of pattern library can be used by and or loaded into the generators such that sources from more than one style can be combined in the same musical piece. Further in these embodiments a user can try pattern library combinations without having to make any changes to the pattern libraries themselves.

In other embodiments musicians can be enabled to use their own pattern libraries rather than a common pattern library determined by the generator .

In yet further embodiments pattern libraries can be added and or modified during composition enabling repetition in a musical piece and reuse of motifs in future compositions.

The pipeline architecture described with reference to enables features of real time music generation which are difficult to achieve in the prior art. The music generation process within the pipeline can be pictured as an assembly line for constructing musical blocks. Each of the producers along the pipeline fills in the elements its generators create until the finished block is eventually passed to the output producer for playback. The producers all work independently which means the generation process can be parallelized. Furthermore to dynamically alter a composition a different generator can be substituted in a producer without affecting the rest of the pipeline e.g. when a style and or setting changes .

Another feature of the application M is the incorporation of mood as a factor which can affect music generation. Mood is considered in two contexts individual musicians have a mood which can be adjusted independently of other musicians and a piece can have a mood. For example imagine an orchestra with 27 members. Suppose that the bassoon player is depressed because she just learned that she can no longer afford her car payments on her musician s salary. Suppose that the orchestra conductor is trying to achieve a happy sound at the end of the piece currently being played. Depending on how professional the bassoon player is she will play in a way which reflects her own sad mood and the desired happy mood to varying degrees.

The emotion mapper is an implementation of a class which makes adjustments to musical elements based for example on the emotions happy and sad though in other embodiments adjustments to musical elements can be based on other emotions. The emotion mapper can be configured to adjust musical characteristics such as the mode motif pattern pitch and tempo etc. The logic behind the emotion based changes can be based on research in music psychology.

In some embodiments all mood adjustments can be made based on the mood characteristics of the first musician in a performer or based on a global mood setting. In other embodiments mood adjustments can be made based on the mood of each musician in a performer . However in these embodiments some characteristics of a musical piece may be adjusted independent of each mood of a musician . For example mood can affect tempo of the piece however it may be desired that tempo be constant for all musicians . In other embodiments interesting musical results may occur if musicians play at different tempos depending on their mood .

In some non limiting embodiments while the mood class contains a plurality of emotional descriptors the emotion mapper alters music based on a subset of the plurality of emotional descriptors. For example in some embodiments the emotion mapper alters music based on the emotions happy and sad . However it is understood that the emotion mapper can be configured to alter music based on any suitable subset. It is also understood that the emotion mapper can be updated to include further emotional descriptors and or updated if understanding changes on how emotions translate into changes to musical elements.

In some non limiting embodiments the emotion mapper adjusts at least one musical element of the musical piece such that the musical piece reflects a given emotional characteristic by the receiving at least one weight parameter specifying the degree to which the music is to be adjusted to reflect the given emotional character wherein the at least one weight parameter comprises a percentage that the music is to be adjusted to reflect the given emotional character and wherein the adjusting the at least one mood parameter based on the at least one weight parameter comprises adjusting the at least one mood parameter based on the percentage. For example the weight parameters can be received from the media device and or the input device via the control data and respectively. The emotion mapper then adjusts the at least one musical element based on the at least one mood parameter.

The motif generator is enabled to generate sequences of notes and rests with associated timing independent of both mode and harmony. This is best illustrated by a non limiting example described hereafter.

Consider the opening phrase of Mozart s Sonata in A K.331 as depicted in . A person of skill in the art would understand that the right hand melody in the first bar begins on C the third of the scale and is played over the tonic chord in root position in the bass harmony I . In the second bar in the left hand part we see the exact same melodic pattern this time starting on G played over the dominant chord in first inversion harmony V .

Within Table 1 Pitches are positions in the mode relative to the root of the harmonic chord with the root as 0 Locations indicate an offset from the beginning of the bar location 0.0 and Durations specify the length of the note. Locations and durations are expressed in terms of number of beats for example in 6 8 time an eighth note is one beat .

Encoding motifs in this manner enables capturing a musical pattern associated with a sequence of notes without restriction to a specific mode or harmonic chord and further enables composed pieces and or musical lines to be transposed and reinterpreted in any mode. Moreover as illustrated in the above example a particular pattern of notes often appears more than once during a piece but serves a different function depending on the underlying harmony.

In some embodiments the motif generator can operate in at least one of a pattern library based mode and pseudo random mode described below . Hence when a motif is requested e.g. by the line producer the motif generator first checks whether a pattern library has been loaded. If it has the motif generator attempts to retrieve a motif of a specified and or randomly and or pseudo randomly determined length e.g. a given number of beats and a desired type e.g. an end pattern which is one that could be found at the end of a section or regular pattern which is one that could be found elsewhere in a section or either . If any suitable patterns are found they are returned. Otherwise a new pattern will be generated randomly and or pseudo randomly.

Any suitable method of randomly generating motifs may be used in motif creation. In some non limiting embodiments two random generators and or pseudo random generators may be used including but not limited to a number generator and a pitch generator. A loop continues generating notes rests as long as the desired number of beats has not been filled. The motifs are generated according to musically plausible rules and probabilities which may be stored in the memory and or the memory .

In some embodiments a pseudo random number generator may be used to generate motifs. Indeed as pseudo random number generators are deterministic if the motif generator is initialized with the same seed values during two different runs the motifs produced will be exactly the same.

Indeed it is understood that any of the musical elements generated by any of the generators may be generated using either a pattern library or randomly and or pseudo randomly the latter generated using a pseudo random number generator. Non limiting examples of a pseudo random number generator include but are not limited to a Mersenne Twister a Blum Blum Shub an inversive congruential generator ISAAC cipher Lagged Fibonacci generator Linear congruential generator Linear feedback shift register and Multiply with carry. Other pseudo random number generators will occur to persons of skill in the art and are within the scope of present embodiments.

Use of a pseudo random number generator further enables checkpointing of the pipeline during music generation so that musical elements can be saved and repeated.

As previously mentioned the motif is encoded in a mode independent and harmony independent manner. Thus the pitches that are generated and stored are actually relative pitches to the root of the harmonic chord in a mode. Consider the following non limiting example Suppose the motif contains the pitches values 0 1 0. If that motif is eventually resolved in a position where it appears as part of the I chord in C would be resolved to the actual pitches for C D C. However if that same motif were used in a position where the harmony required the V chord in C the motif would now be resolved to G A G. Suppose now that the motif contains the pitch values 0 0.5 1 0. The value 0.5 indicates that a note between the first and second tone should be sounded if it exists this will produce a dissonance . Thus in C for chord I 0 0.5 1 0 would be resolved as C C. D C. If an attempt is made to resolve a dissonant note where one does not exist for example between E and F in C one of the neighbouring notes is selected instead.

In some embodiments motifs can be generated based on a desired type e.g. an end motif which is one that could be found at the end of a block or section or a regular motif which is one that could be found elsewhere in a block or section or either . In other embodiments motifs can be generated that are typical for different instruments piano vs. violin vs. guitar vs. electronic etc. .

In any event the line producer maps the motif pattern onto a previously generated harmonic pattern by converting the motif pattern to a harmony adjusted motif based on the previously generated harmonic pattern bringing each note in the motif pattern into a range of a previously generated mode and resolving each note in the motif pattern into at least one of a pitch of the previously generated mode and a nearby dissonant note based on the harmonic chords in the previously generated harmonic pattern.

Generating a harmonic structure for a musical piece enables groups of musicians to perform a piece together which will sound musically coordinated. As previously noted the line producer is the entity in the pipeline which resolves motifs into notes that fit into chords within a mode. When multiple musicians are playing together in an Ensemble the harmonic structure of the block being generated is determined e.g. a harmonic pattern is chosen and then each musical line is generated based on this same harmonic pattern. The result is that even though each musician is playing a different musical line from the others and possibly different instruments each with its own range at any given time each musician can be playing a motif which fits into the current harmonic chord and mode for the piece. It is understood that this is not meant to imply that every note each musician plays will be consonant with all other notes sounding at that time that would be musically uninteresting. Rather musicians might be playing passing tones ornaments dissonant notes and so on but the harmonic analysis of each of their musical lines will be similar.

Music can be generated in the application M in any mode which can be supported by the technology used to drive the output device . For example in some non limiting embodiments music can be generated in the application M in any mode which can be supported by the output format. This is a very flexible implementation which allows music played to be played in any major or minor key or using a whole tone scale chromatic scale blues scale Japanese scale etc. The restrictions imposed by an output format are illustrated using the non limiting example of the output format being the MIDI format. The restrictions imposed by the MIDI format on the scale are that the period of repetition for the scale is an octave and that the smallest distance between two notes is a semi tone. Thus an octave is divided into 12 semi tones designated by consecutive whole numbers in the MIDI format i.e. 0 1 2 3 4 5 6 7 8 9 10 11 . Note that these are normal restrictions for Western music. The pattern of the scale is stored using offsets from the starting note of the scale. These offsets specify the number of semi tones between steps in the scale. For example every major scale has the following step pattern 0 2 4 5 7 9 11. To specify which major scale is desired we also store the starting note of the scale which is a whole number between 0 and 11 which corresponds to an offset from MIDI pitch 0 which represents C.

However motifs can be resolved into any mode regardless of the mode in which they were originally specified. While some motifs might sound strange if the mode into which they are resolved contains less tones than the mode in which they were designed the situation can be resolved using any suitable method. For example in some non limiting embodiments a resolution method which can be used is that the notes are wrapped around using a modulus style 360 computation i.e. the sixth note in a five note mode becomes the first note one octave higher .

In some embodiments flexibility in the application M is enabled via implementing all the key classes as Abstract classes which can be subclassed according to the goals of a programmer. As an example consider the Abstract class MotifGenerator i.e. motif generator . Now suppose that a developer wishes to have a MotifGenerator which is designed to create jazz style motifs. This can be accomplished by writing a class JazzMotifGenerator which extends MotifGenerator and provides implementations of all the abstract methods. All the other principal classes in the application M can follow this same pattern and thus the application M is easily extensible and enhanced.

Data structures for the musical elements are also flexible. As previously mentioned the mode can be anything which is supported by the output format. The piece length can be user defined or determined by the application M. Any available instruments compatible with the output format can be used e.g. MIDI instruments . Motifs can be as long or as short as desired. Any number of pattern libraries can be developed and used. Any harmonic chords can be defined which include any number of notes. Musical styles are completely user defined. And so on.

In some embodiments musicians can play together as a coordinated ensemble in which the musicians perform a piece with a harmonic structure followed by all the musicians . In other embodiments musicians can play together in a jamming mode in which musicians rely on their own musical knowledge to decide what to play.

In some embodiments the application M can be processed within a processing unit of the media device such that the application M is an embedded component in an application product such as a video game. In other embodiments the application M can be processed by the processing unit as a stand alone music composition application.

In further embodiments the application M can be implemented as an emotional equalizer. For example a mood is generally a collection of emotional descriptors each present to a different degree. Hence an emotional equalizer comprising the computing device the output device and the input device could enable a listener to alter a music s mood as it is playing for example via the input device . The emotional equalizer could also be either a hardware or a software device which would operate like a stereo equalizer except that the sliders would be marked with emotional descriptors rather than frequency ranges. So while listening rather than turning up the bass in the song a listener could turn up the happy. 

Furthermore environmental music could altered based on data received from sensors. For example the processing unit can be generating music played in an elevator. Sensors in the elevator could detect the number of persons in the elevator and or their mood. Sensors would then transmit control data similar to control data or and the application M can adjust the music accordingly.

The application M can further enable Internet based musical collaboration. For example three users collaborating via the Internet each of whom has a collection of musicians with different qualities and abilities could cause those musicians to perform together and the results could be heard by all the users.

Those skilled in the art will appreciate that in some embodiments the functionality of the application M may be implemented using pre programmed hardware or firmware elements e.g. application specific integrated circuits ASICs electrically erasable programmable read only memories EEPROMs etc. or other related components. In other embodiments the functionality of the application M may be achieved using a computing apparatus that has access to a code memory not shown which stores computer readable program code for operation of the computing apparatus. The computer readable program code could be stored on a computer readable storage medium which is fixed tangible and readable directly by these components e.g. removable diskette CD ROM ROM fixed disk USB drive . Alternatively the computer readable program code could be stored remotely but transmittable to these components via a modem or other interface device connected to a network including without limitation the Internet over a transmission medium. The transmission medium may be either a non wireless medium e.g. optical and or digital and or analog communications lines or a wireless medium e.g. microwave infrared free space optical or other transmission schemes or a combination thereof.

Persons skilled in the art will appreciate that there are yet more alternative implementations and modifications possible for implementing the embodiments and that the above implementations and examples are only illustrations of one or more embodiments. The scope therefore is only to be limited by the claims appended hereto.

