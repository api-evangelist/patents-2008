---

title: Correlative multi-label image annotation
abstract: Correlative multi-label image annotation may entail annotating an image by indicating respective labels for respective concepts. In an example embodiment, a classifier is to annotate an image by implementing a labeling function that maps an input feature space and a label space to a combination feature vector. The combination feature vector models both features of individual ones of the concepts and correlations among the concepts.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07996762&OS=07996762&RS=07996762
owner: Microsoft Corporation
number: 07996762
owner_city: Redmond
owner_country: US
publication_date: 20080213
---
This U.S. Nonprovisional Patent Application claims the benefit of copending U.S. Provisional Patent Application No. 60 974 381 filed on 21 Sep. 2007 and entitled Correlative Multi Label Video Annotation . U.S. Provisional Patent Application No. 60 974 381 is hereby incorporated by reference in its entirety herein.

Many textual documents have been made available over the internet in the past 10 20 years. Search engines are capable of indexing these textual documents based on the words that they contain. People can find a desired relevant topic with a keyword search using a search engine after the indexing has been performed. Thus textual documents are fairly accessible over the internet.

More recently especially in the last 5 10 years images are increasingly being made available over the internet. For example images including videos are being uploaded to websites that enable the images to be viewed and otherwise shared. It is already difficult to locate a video that addresses a desired topic and the rate at which images are being added to the internet is increasing. In contrast with textual documents videos often do not include a sufficiently representative set of textual words if they include any. Consequently it is difficult for current search engines to index or otherwise organize the vast collection of videos on the internet.

One approach to organizing videos is to annotate each video with one or more concepts. The annotated concepts can then be indexed for subsequent searching and retrieval of the associated videos. This annotation can be performed manually by people that view each video. However manual approaches to annotating videos are time consuming financially untenable and prone to inconsistencies resulting from viewers subjectivities. Automated approaches have also been developed. These automated approaches can be significantly more efficient than manual ones and can be scaled accordingly. Unfortunately current automated approaches to annotating videos produce many mislabeled concepts.

Correlative multi label image annotation may entail annotating an image by indicating respective labels for respective concepts. In an example embodiment a classifier is to annotate an image by implementing a labeling function that maps an input feature space and a label space to a combination feature vector. The combination feature vector models both features of individual ones of the concepts and correlations among the concepts.

In another example embodiment a method includes creating a concept feature modeling portion and a concept correlation modeling portion that are combined to form a combination feature vector. The concept feature modeling portion is created responsive to low level features of an image to model connections between the low level features of the image and individual concepts that are to be annotated and the concept correlation modeling portion is created to model correlations among at least a subset of the concepts that are to be annotated. The method further includes solving a labeling function responsive to the combination feature vector to produce a concept label vector for the image the concept label vector including label indicators respectively associated with the concepts that are to be annotated.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. Moreover other method system apparatus device media procedure API arrangement etc. embodiments are described herein.

Automatically annotating concepts for videos is relevant to semantic level video browsing search and navigation. The research on video annotation evolved through two paradigms. The first paradigm uses binary classification to detect each individual concept in a concept set. It achieved limited success because it does not model the inherent correlations between concepts such as urban and building concepts. The second paradigm adds a second step on top of the individual concept detectors to fuse multiple concepts. However its performance varies because the errors incurred in the first detection step can propagate to the second fusion step and therefore degrade the overall performance. The first paradigm of individual concept detection and annotation is introduced in Section 1.1 and the second paradigm of the two step context based conceptual fusion CBCF annotation is introduced in Section 1.2.

A third paradigm of integrated feature and concept multi label annotation is introduced in Section 1.3 and is described further below in Sections 2 4. In contrast with the first two paradigms an example embodiment of the third paradigm simultaneously classifies concepts and models correlations among them in a single step. This integrated approach may be realized using for instance a correlative multi label CML support vector machine SVM . Alternative approaches to CML implementations include using it in conjunction with Boosting graph based MEM and other general or specialized concept detection mechanisms in lieu of SVM.

Generally automatically annotating video at the semantic concept level can be investigated in the context of multimedia research. Concepts of interest may include a wide range of categories such as scenes e.g. urban sky mountain etc. objects e.g. airplane car face etc. events e.g. explosion fire people marching etc. certain named entities e.g. person place etc. and so forth.

There are two primary types of annotation processes multi labeling and multi class. In a multi labeling process a video clip can be annotated with multiple labels. For example a video clip can be classified as urban building and road simultaneously. In contrast a multi class annotation process labels only one concept to each video clip. Most real world problems are addressed with multi label annotation processes. In addition multi label processes are generally considered more complex and challenging than multi class ones because multi labeling involves non exclusive detection and classification. Example embodiments that are described herein focus on multi label annotation schemes.

Each image may be a single picture a frame of a sequence of images for a video some combination thereof and so forth. Without loss of generality correlative multi label image annotation and aspects thereof are at times referred to herein below in the context of video annotation e.g. labeled video concepts . With labeled concepts each respective concept may be associated with a respective label indicator .

In an example embodiment image is applied to multi label classifier . Multi label classifier accepts image as input and performs a classification procedure to produce labeled concepts . Because it is a multi label classification procedure labeled concepts include multiple concepts having respective label indicators . For each of the multiple concepts multi label classifier determines whether a particular concept is applicable to the input image and assigns a label indicator accordingly. For example a concept may or may not be applicable to a given image and thus may be assigned a relevant or a not relevant label indicator respectively.

Six concepts . . . are detectable by six respective individual concept detectors . . . . These six concepts are outdoor face person people marching road and walking running . Although six concepts and six concept detectors are specifically shown more or fewer than six may be implemented. Additionally different concepts than those six that are illustrated may alternatively be implemented. The individual concept detectors . . . output respective label indicators . . . . Each indication may be relevant present positive or not relevant absent negative.

With individual detector paradigm multiple video concepts are detected individually and independently without considering correlations between them. That is the multi label video annotation is translated into a set of binary detectors with presence absence of the label being indicated for each concept . A typical approach is to independently train a concept model using an SVM model or a maximum entropy model MEM . Thus individual detector paradigm may be realized using a set of individual SVMs for detection and annotation of video concepts . An equivalent mathematical alternative is to stack this set of detectors into a single discriminative classifier. However both the individual detectors and the stacked classifier are at their cores independent binary classification formulations.

The first paradigm approaches achieved only limited success. In the real world video concepts do not exist in isolation. Instead they appear correlatively and they naturally interact with each other at the semantic level. For example the presence of a crowd concept often occurs together with the presence of people but the concepts of boat ship and truck do not commonly co occur. Furthermore although simple concepts can be modeled directly from low level features it is usually quite difficult to individually learn the models of certain complex concepts e.g. people marching from the low level features alone. Instead the complex concepts can be better inferred based on correlations with other concepts. For instance the likelihood of the concept of people marching being present can be boosted if both crowd and walking running occurs in a video clip.

One approach to refining the results of the individual detectors is to implement a Context Based Concept Fusion CBCF strategy. Example CBCF strategies include a probabilistic Bayesian multinet approach and an ontology based multi classification approach. The probabilistic Bayesian multinet explicitly models the relationship between multiple concepts through a factor graph that is built upon the underlying video ontology semantics. The ontology based multi classification approach is learned via a training process so as to detect video concepts.

More specifically each concept is first separately modeled by an independent classifier and then a predefined ontology hierarchy is investigated to improve the detection accuracy of the individual classifiers . A two step Discriminative Model Fusion DMF approach has been proposed to mine the unknown or indirect relationships to specific concepts by constructing model vectors based on detection scores of individual classifiers . An SVM is then trained to refine the detection results of the individual classifiers . An alternative strategy can also be used to fuse the individual detections such as a Logistic Regression LR or a CBCF based active learning method. With a CBCF based active learning method users are involved to annotate a few concepts for extra video clips and these manual annotations are then utilized to help infer and improve detections of other concepts.

Although it is intuitively correct that contextual relationships can help improve the detection accuracy of individual detectors experiments with the above identified CBCF approaches have shown that such improvement is not always stable. In fact the overall performance can actually be worse than individual detectors alone. This unstable performance gain can be due to either or both of the following two reasons.

First CBCF methods are built on top of the individual independent binary concept detectors with a second step to fuse them. However the output of the individual independent detectors can be unreliable therefore their detection errors can propagate to the second fusion step. As a result the final annotating label indications can be corrupted by these incorrect predictions. From a philosophical point of view the CBCF approaches do not follow the Principle of Least Commitment because they are prematurely committed to irreversible individual predictions in the first step which may or may not be corrected in the second fusion step.

Second there is often insufficient data for the conceptual fusion step. With CBCF methods the samples are split into two parts for each step. The samples for the second step of conceptual fusion are usually insufficient compared to the samples used in the first training step. Unfortunately the correlations between the concepts are usually complex and insufficient data can lead to over fitting in the fusion step. Consequently the obtained predictions may be incapable of being reliably generalized.

In contrast with the individual detector paradigm and the two step CBCF paradigm introduced above an integrated multi label annotation paradigm is described herein. Example embodiments of this integrated feature correlation paradigm simultaneously model both the individual concepts and their correlative interactions in a single formulation.

In an example embodiment low level features are extracted from one or more images . Low level features are applied to correlative multi label image annotator . Correlative multi label image annotator thus accepts as input low level features . It also accepts as input multiple correlations among two or more concepts . For the sake of visual clarity only a portion of the correlations that are illustrated in are indicated by the reference numeral . Based on concept features and concept correlations that are considered simultaneously e.g. in a single step or formulation correlative multi label image annotator produces label indicators . Specifically respective label indicators . . . represent the presence or absence of respective concepts . . . . It should be understood that this approach models concepts and correlations simultaneously hence the dashed line graph of need not be explicitly built during the annotation process.

Certain example embodiments for correlative multi label image annotation as described herein embrace the following two attributes. First certain embodiments adhere to the Principle of Least Commitment. Because the learning and optimization are performed in a single step for each of the concepts simultaneously the error propagation problem created by the two step paradigm e.g. by CBCF can be avoided. Second the entirety of the samples can be efficiently used simultaneously when modeling the individual concepts as well as their correlations. The risk of over fitting due to the unavailability of sufficient samples when modeling the conceptual correlations as occurs with the two step paradigm is therefore significantly reduced.

To summarize the first paradigm does not address concept correlations. The second paradigm attempts to address this deficiency by introducing a second and separate correlation step. With the third paradigm on the other hand the issue of concept correlations may be addressed at the root in a single step. In Section 2 below example embodiments for CML are described from a mathematical perspective. This description includes an example classification model and an example learning strategy. In Section 3 an example approach for implementing CML using a Gibbs Random Fields GRFs representation is described. The GRF implementation can also provide an intuitive interpretation as to how example CML embodiments capture the individual concepts as well as the conceptual correlations. Section 4 addresses example implementation issues including concept label vector prediction and concept scoring. Section 5 describes an example device that may be used to realize embodiments for correlative multi label image annotation.

Other general and specific example embodiments are described herein below. Although certain example aspects may be described in a given context of specific hardware and or software such description is by way of example only. Thus the example embodiments described herein may be implemented fully or partially in hardware software firmware fixed logic circuitry combinations thereof and so forth.

In this section example embodiments for correlative multi labeling CML models for image including video image semantic annotation are described. In Subsection 2.1 an example mathematical formulation of the multi labeling classification function is presented. Additionally how this function captures the correlations among the different concepts as well as how individual concepts are related to low level features is described. In Subsection 2.2 an example classification learning procedure for the CML model is presented. Example methods for CML image annotation are described in Subsection 2.3.

In an example embodiment low level features which are extracted from image are applied to multi label classifier . Alternatively a multi label classifier may be capable of extracting low level features from an input image . Multi label classifier evaluates labeling function given low level features concept detection data and concept correlation data and responsive to combination feature vector to produce concept label vector . Concept label vector corresponds to labeled concepts of . It includes multiple concepts and respectively associated label indicators . Formulation and evaluation of labeling function are described further below in Subsections 2.1 and 2.3. An example operation of correlative multi label image annotation system is described in Section 2.3.

Example embodiment s especially with regard to example mathematical formulations for a multi label classification model are described in this subsection. References are made to correlative multi label image annotation system of by way of example. Let x x x . . . x X denote the input pattern representing feature vectors e.g. low level features extracted from video clips or other images. Let y Y 1 1denote the K dimensional concept label vector e.g. concept label vector of an example image e.g. image in which each entry y 1 1 of y indicates the membership e.g. label indicator of this example image in the iconcept e.g. concept . X and Y represent the input feature space and label space respectively of the data set.

An algorithm aims at learning a labeling function e.g. labeling function such as without loss of generality a linear discriminative function as given by Eqn. 1 1 where x y is a vector function mapping from X Y to a new combination feature vector e.g. combination feature vector and w is the linear combination weight vector e.g. weight vector . With such a discriminative function for an input pattern x the output label vector y e.g. concept label vector can be predicted by maximizing over the argument y as shown by Eqn. 2 max . 2 

As is described in the following Section 3 such a discriminative function can be intuitively understood with a GRF framework when considering the following defined feature vector x y . The constructed combination feature x y is a high dimensional feature vector whose elements can be partitioned into two portions of two types concept characteristics and concept correlations. As is explained further herein below these two types of elements account for the modeling of individual concepts and their correlative interactions respectively. The types 1 and 2 of the first and second portions respectively are described below.

Type 1 The elements for the concept feature modeling portion e.g. concept characteristics portion of the combination feature vector are given by way of example via Eqn. 3 

These entries of the concept feature modeling portion of the combination feature vector x y serve to model the connection between the low level feature x and the labels yof the concepts. In an example implementation they may have functionality that is similar to traditional models e.g. SVM Boosting graph based MEM a combination thereof etc. that map from relatively low level features to relatively high level concepts. However as is explained herein above it is insufficient for a multi labeling algorithm to account only for modeling the connections between the concept labels and the low level features without considering the semantic correlations among different concepts. Consequently another element type of the combination feature vector x y is employed to investigate the correlations among the semantic concepts including between two or more such concepts.

Type 2 The elements for the concept correlation modeling portion e.g. concept correlations portion of the combination feature vector are given by way of example via Eqn. 4 

It should be understood that high order correlations among these concepts can also be modeled but doing so entails using a greater number of training samples and or computations than for pair wise correlations. Nevertheless it should be noted that by some measures an order 2 model successfully trades off between model complexity and concept correlation complexity and it achieves an appreciable improvement in concept detection performance as compared to the individual detector and the two step paradigms introduced above.

For an example embodiment the two types of elements 1 and 2 from Eqns. 3 and 4 above are concatenated to form the combined feature vector x y . It is apparent that the dimension of the combined feature vector x y is 2KD 4C 2K D K 1 . Thus when the variables K and D are large the dimension of the vector x y is extraordinary high. For example if K 39 and D 200 the combined feature vector x y has 18 564 dimensions. However this vector is sparse as a consequence of the indicator function in Eqns. 3 and 4 .

As a result the kernel function e.g. the dot product between the two vectors x y and tilde over x tilde over y can be represented in a relatively compact form as indicated by Eqn. 5 

Example embodiment s for learning a classifier are described in this subsection. Generally the misclassification error and a loss function are defined first. The empirical risk can then be obtained. The error is to be reduced if not minimized so as to attain an optimal weight vector w. In order to give the model a better generalization capability a regularization term is added and a slack variable is introduced. The Lagrange dual problem is solved by sequential minimal optimization which produces an optimal w. Thus the process arrives at a classification function for the classifier. The output label vector y can be predicted by the classifier for any given input sample x by maximizing the labeling function F through the label vector space Y.

More specifically using the combined feature vector that is constructed above in the form of its kernel representation as presented by Eqn. 5 the learning procedure trains a classification model as specified in Eqn. 1 . The procedure can be understood as being analogous to the training of a conventional SVM. Given an example xand its label vector yfrom the training set x y then according to Eqns. 1 and 2 a misclassification occurs in circumstance s as delineated by Eqn. 6 0 6 where y x y x y . Thus the empirical prediction risk on the training set with respect to the parameter w can be expressed as shown by Eqn. 7 

A goal for learning the classifier is to find a parameter w that minimizes the empirical error circumflex over R x y w . Considering computational efficiencies in practice the following convex loss that upper bounds l x y w can be used to avoid directly minimizing the step function loss l x y w as shown by Eqn. 9 1 9 where is a hinge loss in classification. Correspondingly the following empirical hinge risk that upper bounds circumflex over R x y w is defined by Eqn. 10 

Accordingly a regularized version of circumflex over R x y w can be formulated that minimizes an appropriate combination of the empirical error and a regularization term w to avoid over fitting of the learned model. This is given by Eqn. 11 min circumflex over R x y w w 11 where is a strictly monotonically increasing function and is a parameter that trades off between the empirical risk and the regularizer. Such a regularization term can give some smoothness to the obtained function so that the nearby mapped x y tilde over x tilde over y have a similar function value as F x y w F tilde over x tilde over y w . Such a local smoothness assumption is intuitive and can ameliorate the negative influence of the noise training data.

In practice the above optimization problem can be solved by reducing it to a convex quadratic problem. Analogous to approaches for SVMs by introducing a slack variable y for each pair x y the optimization formulation in Eqn. 11 can be rewritten as shown by Eqn. 12 

Upon introducing Lagrange multipliers y into the above inequalities and formulating the Lagrangian dual according to the Karush Kuhn Tucker KKT theorem the mathematics above are further reduced to the following convex quadratic problem QP of Eqn. 13 

Different from those dual variables in conventional SVMs that only depend on the training data of observations and the associated label pairs x y 1 i n the Lagrangian duals in Eqn. 13 depend on the assignment of labels y which are not limited to the true label of y. An iterative approach is used to find the active constraints and the associated label variable y that most violates the constraints in Eqn. 9 as y arg maxF x y w and F y 

With reference to for an example embodiment low level features of image are used to form combination feature vector of labeling function . After training of multi label classifier concept detection data defines how general low level features are interrelated with different concepts and concept correlation data defines how different concepts are correlatively interrelated with each other. Concept characteristics portion is created based at least in part on concept detection data and responsive to low level features . Concept correlations portion is created based at least in part on concept correlation data and responsive to different assignments of concept labels. Concept characteristics and concept correlations are combined e.g. via concatenation to form combination feature vector of labeling function . Multi label classifier evaluates labeling function to produce a concept label vector .

Flow diagram includes nine blocks blocks and blocks A B and . By way of example the description of flow diagram includes references to other figures such as and . In an example embodiment of flow diagram at block a classifier is learned. For example a multi label classifier may be learned using the procedure described above in Subsection 2.2. Alternatively the classifier can be learned offline such that an implementation of correlative multi label image annotation does not entail the classifier learning of block .

At block an image is input to the classifier. For example an image may be input to multi label classifier . At block low level features of the image are extracted. For example low level features may be extracted from image . The extraction may be performed by multi label classifier or another processing component involved in the correlative multi label image annotation method. If another processing component performs the extraction the extracted low level features may be provided to multi label classifier .

At block a combination feature vector is formed. For example a combination feature vector for a labeling function of multi label classifier may be formed. An example implementation of the action s of block may be further described with reference to blocks A and or B.

At block A a concept feature modeling portion is created. For example a concept characteristics portion of combination feature vector may be created. For instance concept characteristics may be created in accordance with Eqn. 3 above. At block B a concept correlation modeling portion is created. For example a concept correlations portion of combination feature vector may be created by converting correlations among concepts into features. For instance concept correlations may be created in accordance with Eqn. 4 above.

At block a labeling function is solved to attain a concept label vector responsive to the combination feature vector. For example labeling function may be evaluated to attain concept label vector responsive to combination feature vector . An example implementation of the action s of block may be further described with reference to block .

At block the concept label vector that maximizes the labeling function may be found. For example a concept label vector that returns a relatively high value for labeling function may be found. In other words it may be computationally impractical to precisely and explicitly solve for the maximizing concept label vector. However this maximum concept label vector may be estimated. Example approaches to such estimations are described herein below in the context of using GRFs but other approaches may be implemented. Other approaches to solving a labeling classification function include by way of example but not limitation an exhaustive search of the whole space a heuristic search e.g. using a genetic algorithm etc. some combination thereof and so forth.

At block the concept label vector is output. For example concept label vector may be output by multi label classifier . Concept label vector may be stored in memory presented e.g. displayed printed etc. to a user and or transmitted to another device. Concept label vector may be further analyzed and or used as part of another procedure such as in conjunction with the indexing of images providing search results and so forth.

In this section example embodiment s for implementing correlative multi label image annotation using Gibbs Random Fields GRFs are described. This GRF representation also provides an intuitive interpretation of certain embodiments for the correlative multi labeling image annotation model.

Such a probability function with an exponential form can express a wide range of probabilities that are strictly positive over the set Y. It can be seen that when inferring the best label vector y maximizing P y x w according to the MAP criterion is equal to minimizing the energy function H y x w or equivalently maximizing F x y w which is in accordance with Eqn. 2 above. Therefore certain embodiments of correlative multi label image annotation may be implemented using a GRF representation.

Based on this GRF representation for multi labeling image concepts the CML model can be interpreted probabilistically in a natural intuitive manner. By substituting Eqn. 17 into Eqn. 18 the following Eqn. 19 is produced 

With this formulation P y x w is factored into two types of multipliers. The first multiplier type P y x accounts for the probability of a label yfor the concept p given x. These factors model the relations between the concept label and the low level feature x. It should be noted that P y x corresponds to the first type 1 of the constructed features from Eqn. 3 . It demonstrates that the first type of the elements in the combined feature vector x y serves to capture the connections between x and the individual concept labels. A similar analysis can be applied to the second type of the multipliers P y y x . These factors model the correlative interrelations between the different concepts. This second type of the multipliers thus demonstrates that the constructed features of the second type 2 from Eqn. 4 above account for the correlations among the concept labels.

The description and explanation in this section of a GRF representation further illuminates the applicability of certain aspects of the described CML embodiments including the corresponding constructed combination feature vector x y for the multi labeling problem of image semantic annotation. In the following section additional CML description is given in the context of an example GRF representation.

In this section example implementations for embodiments of correlative multi label image annotation are described. These implementations pertain to thresholding correlation values of interacting concepts in Subsection 4.1 concept label vector prediction in Subsection 4.2 and concept scoring in Subsection 4.3 . The interacting concepts subsection recognizes that some correlations are stronger than others. The concept label vector prediction subsection further describes the nexus between finding a concept vector for correlative multi label image annotation and a GRF representation. The concept scoring subsection addresses how a confidence value can be associated with each labeled concept for a given image.

In this subsection example implementation s for handling different levels of correlation values for interacting concepts are described. In Section 3 above example approaches to implementing CML algorithms using GRFs are described. As is explained in Section 3 the neighborhood set N is a collection of the interacting concept pairs. With such a straightforward GRF implementation this set can contain up to all possible pairs for CML concept correlation analysis. However all possible concept pairs or other correlation sets need not be used in an analysis.

For example in practice some concept pairs may have rather weak interactions including ones that are positively weak or negatively weak. For instance the concept pairs airplane walking running and people marching corporate leader usually do not have correlations that are very strong. Based on this observation the relatively strongly interacted concept pairs can be focused into the set N. Accordingly the kernel function of Eqn. 5 that may be used with CML may be modified to be as shown below in Eqn. 20 . 20 

The selection of concept pairs can be manually determined by experts or automatically selected by data driven approaches. A selection process that is at least partly automatic is described below for an example implementation. First normalized mutual information MI is used to measure the correlations of each concept pair p q . The normalized mutual information may be determined in accordance with Eqn. 21 

In such an implementation the label prior probabilities P y and P y can be estimated from the labeled ground truth of the training dataset. According to information theory the larger is the NormMI p q the stronger is the correlative interaction between concept pair p and q. Such a normalized measure of concept interrelation can have the following three properties First it is normalized into the interval 0 1 0 NormMI p q 1. Second NormMI p q 0 when the concept p and q are statistically independent. Third NormMI p p 1.

The above three properties are accordant with an intuitive interpretation of concept interactions and they can be proven based on the above definitions. From the above properties it is apparent that the normalized mutual information is scaled into the interval 0 1 by the minimum concept entropy. With such a scaling the normalized mutual information considers the concept correlations regardless of whether the concepts are positively or negatively correlated.

In an example embodiment the concept pairs whose correlations are larger than a predetermined threshold are selected for inclusion in the CML analysis using the normalized mutual information. More generally correlations among concept sets may be subjected to a threshold. Concept sets can include two concept sets e.g. concept pairs three concepts sets four concept sets and so forth. A thresholding unit to implement a predetermined threshold for correlation values among concepts is described herein below with particular reference to .

In this subsection example implementation s for concept label vector prediction are described. Once a classification function is obtained the best predicted concept vector y can be obtained from Eqn. 2 . The most direct approach is to enumerate all possible label vectors in Y to find the best one. However the size of the set Y becomes exponentially large with the incrementing of the concept number K and thus the enumeration and evaluation of all possible concept vectors can be time consuming with today s computational technology. For example when K 39 the size of Y is 2 5.5 10.

However from the description of how certain CML embodiments can be implemented with GRF representations the prediction of the best concept vector y can be performed on the corresponding GRF form. Consequently many popular approximate inference techniques on GRF can be adopted to predict y such as Annealing Simulation Gibbs Sampling and so forth. Specifically these approximation techniques can be based on the output optimal dual variables y in Eqn. 14 . From the description in Section 3 above the dual form of the GRF energy function of Eqn. 17 can be attained accordingly. Such a dual energy function comes from Eqn. 14 . Substituting Eqn. 14 into Eqn. 1 and considering the kernel representation of Eqn. 5 the following Eqns. 24 and 25 are obtained 

In this subsection example implementation s are described for confidence scoring of labeled concepts. The output of certain example embodiment s for a CML algorithm as described herein above given a sample x is the predicted binary concept label vector y . However for certain applications e.g. video retrieval applications etc. concept scoring can be relevant. To account for applications that may include indexing a ranking score for each concept of each sample may be produced. With these scores retrieved images e.g. pictures video clips etc. can be ranked according to the likelihood of a detected concept actually being relevant. By way of example the concept scoring may be computed responsive to a conditional expectation of the label value.

For an example implementation a ranking scoring scheme is based on the probability form e.g. as realized by Eqn. 27 . Given the predicted concept vector y the conditional expectation of yfor the concept p can be computed as shown by Eqns. 28 29 and 30 1 1 28 where

4.4 Example Correlative Multi Label Image Annotation Schemes Including Concept Correlation Thresholding and Concept Scoring

As shown there are K concept scorers and K respective conditional expectation determiners that are respectively associated therewith. For the sake of clarity only one conditional expectation determiner is explicitly illustrated in . In this implementation there is a respective concept scorer and conditional expectation determiner pair for each concept being labeled. However other alternatives may be implemented. For example a concept scorer and or a conditional expectation determiner may be shared across multiple concepts. As another example a single conditional expectation determiner may be responsible for determining scores for multiple concept scorers .

In an example embodiment individual concept portion is created responsive to image and or low level features . Concept correlations portion is created responsive to thresholding unit and those concept sets having correlations that exceed a predetermined threshold. For example thresholding unit may use normalized mutual information MI to measure the correlation value strengths of each concept set as is described herein above in Section 4.1. Those concept sets that exceed a predetermined threshold are included in thresholded concept sets .

Individual concept portion and concept correlations portion are combined to form combination feature vector . Labeling function evaluator evaluates a labeling classification function responsive to combination feature vector to estimate or otherwise produce concept label vector . Given the estimated or predicted concept label vector a conditional expectation of a given concept label indicator for its associated concept is computed by conditional expectation determiner using the expectation of the label value as is described herein above in Section 4.3. The resulting concept score that is produced by concept scorer provides an estimate of the confidence level of the label indication.

Generally a device may represent any computer or processing capable device such as a server device a workstation or other general computing device a data storage repository apparatus a personal digital assistant PDA a mobile phone a gaming platform an entertainment device a router computing node a mesh or other network node a wireless access point some combination thereof and so forth. As illustrated device includes one or more input output I O interfaces at least one processor and one or more media . Media include processor executable instructions .

In an example embodiment of device I O interfaces may include i a network interface for communicating across network ii a display device interface for displaying information on a display screen iii one or more human device interfaces and so forth. Examples of i network interfaces include a network card a modem one or more ports a network communications stack a radio and so forth. Examples of ii display device interfaces include a graphics driver a graphics card a hardware or software driver for a screen or monitor a screen and so forth. Examples of iii human device interfaces include those that communicate by wire or wirelessly to human device interface equipment e.g. a keyboard a remote a mouse or other graphical pointing device etc. as well as a speaker microphone and so forth.

Generally processor is capable of executing performing and or otherwise effectuating processor executable instructions such as processor executable instructions . Media is comprised of one or more processor accessible media. In other words media may include processor executable instructions that are executable by processor to effectuate the performance of functions by device . Processor executable instructions may be embodied as software firmware hardware fixed logic circuitry some combination thereof and so forth.

Thus realizations for correlative multi label image annotation may be described in the general context of processor executable instructions. Generally processor executable instructions include routines programs applications coding modules protocols objects components metadata and definitions thereof data structures application programming interfaces APIs etc. that perform and or enable particular tasks and or implement particular abstract data types. Processor executable instructions may be located in separate storage media executed by different processors and or propagated over or extant on various transmission media.

Processor s may be implemented using any applicable processing capable technology and one may be realized as a general purpose processor e.g. a central processing unit CPU a microprocessor a controller etc. a graphics processing unit GPU a special purpose processor a derivative or combination thereof and so forth. Media may be any available media that is included as part of and or accessible by device . It includes volatile and non volatile media removable and non removable media storage and transmission media e.g. wireless or wired communication channels hard coded logic media combinations thereof and so forth. Media is tangible media when it is embodied as a manufacture and or as a composition of matter. For example media may include an array of disks or flash memory for longer term mass storage of processor executable instructions random access memory RAM for shorter term storing of instructions that are currently being executed and or otherwise processed link s on network for transmitting communications and so forth.

As specifically illustrated media comprises at least processor executable instructions . Generally processor executable instructions when executed by processor enable device to perform the various functions described herein. Such functions include but are not limited to i those acts that are performable by the components of and or ii those acts that are illustrated in flow diagram of iii those acts that are performable by the components of scheme of iv those pertaining to a representation by and or an evaluation of a GRF of v those acts that are performed to implement the algorithms and equations e.g. equations 1 2 3 4 etc. that are described herein combinations thereof and so forth.

The devices acts aspects features functions procedures components techniques algorithms etc. of are illustrated in diagrams that are divided into multiple blocks and other elements. However the order interconnections interrelationships layout etc. in which are described and or shown are not intended to be construed as a limitation and any number of the blocks and or other elements can be modified combined rearranged augmented omitted etc. in any manner to implement one or more systems methods devices procedures media apparatuses arrangements etc. for correlative multi label image annotation.

Although systems media devices methods procedures apparatuses mechanisms schemes approaches processes arrangements and other example embodiments have been described in language specific to structural logical algorithmic and functional features and or diagrams it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claimed invention.

