---

title: Indexing technique to deal with data skew
abstract: A method for facilitating join operations between a first database table and a second database table within a database system. The first database table and the second database table share at least one common index column. The method includes creating a new index column in the second database table that is populated with a limited number of distinct calculated values for the purpose of increasing the overall number of distinct values collectively assumed by the columns common between the two tables. An intermediate table is created, the intermediate table including the common columns of the first database table, the second database table, and the new index column. An index is defined of the intermediate table to be the column(s) common between the first and second tables. An index is defined of the second table to be the column(s) common between the first database table, the second database table and the new index column.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09208186&OS=09208186&RS=09208186
owner: Teradata US, Inc.
number: 09208186
owner_city: Dayton
owner_country: US
publication_date: 20080326
---
Computer systems generally include one or more processors interfaced to a temporary data storage device such as a memory device and one or more persistent data storage devices such as disk drives. Each disk drive generally has an associated disk controller. Data is transferred between the disk drives and the disk controllers. Data is also transferred between the disk controllers and the memory device over a communications bus or similar.

Data organization in a computer system such as that above is important in relational database systems that deal with complex queries against large volumes of data. Relational database systems allow data to be stored in tables that are organized as both a set of columns and a set of rows. Standard commands are used to define the columns and rows of tables and data is subsequently entered in accordance with the defined structure.

The defined table structure is locally maintained but may not correspond to the physical organization of the data. In a parallel shared nothing relational database data can be stored across multiple data storage facilities each data storage facility in turn including one or more disk drives. Data partitioning can be performed in order to enhance parallel processing across multiple data storage facilities.

Hash partitioning is a partitioning scheme in which a predetermined hash function and map is used to assign rows in a table to respective processing modules and data storage facilities. The hashing function generates a hash bucket number and the hash numbers are mapped to data storage facilities.

Natural data skew can be particularly troublesome for certain customer scenarios. It is important to have a primary index choice for a big table that fairly evenly distributes the rows across the processing modules. It is also important to ensure that there are efficient joins to other tables in a data warehouse implemented on the above system.

Described below is a method for facilitating join operations between a first database table and a second database table within a database system. The first database table and the second database table share at least one common index column. The method includes creating a new index column in the second database table that is populated with a limited number of distinct calculated values for the purpose of increasing the overall number of distinct values collectively assumed by the columns common between the two tables. An intermediate table is created the intermediate table including the common columns of the first database table the second database table and the new index column. An index is defined of the intermediate table to be the column s common between the first and second tables. An index is defined of the second table to be the column s common between the first database table the second database table and the new index column.

Also described below is a method of indexing a database table within a distributed database system. The system comprises a plurality of processing nodes and data storage facilities. The method includes creating an index structure mapping specific key values to a list of logical row id pointers to individual rows. Operations to the index structure are dynamically determined during insert update and delete operations when a threshold for the number of multiple row id pointers corresponding to a single index key value has or has not been exceeded. A logical pointer is computed that identifies both the processing node and storage facility containing the row being indexed but only an approximate range of storage blocks that potentially may contain the row. The index structure is consolidated by only storing a single vague row id pointer for the corresponding rows where the associated skew threshold has been exceeded and a specific row id pointer otherwise.

The data warehouse includes one or more processing modules that manage the storage and retrieval of data in data storage facilities . Each of the processing modules manages a portion of a database that is stored in a corresponding one of the data storage facilities . Each of the data storage facilities includes one or more disk drives.

The system stores data in one or more tables in the data storage facilities . The rows of the tables are stored across multiple data storage facilities to ensure that the system workload is distributed evenly across the processing modules . A parsing engine organizes the storage of data and the distribution of table rows among the processing modules . The parsing engine also coordinates the retrieval of data from the data storage facilities over network in response to queries received from a user at a mainframe or a client computer connected to a network . The database system usually receives queries and commands to build tables in a standard format such as SQL.

The primary key of the subscriber table is subscriber id and other descriptive fields such as subscriber name are stored in the subscriber table but not in the cdr table .

The primary key columns for the cdr table includes a subscriber id field but additional fields such as call date and call time that are not stored in the subscriber table . The cdr table includes further descriptive fields for example a number called field .

In a practical application of database schema it is not unusual for the main cdr table to consist of billions of records tracking each individual call placed on the carrier s network. The most useful analysis of data requires a join to other tables for example subscriber table and it is usually most efficient if the database administrator defines the primary index for the cdr table to be a non unique primary index matching the table one would most likely join to. In this case that would mean defining the primary index of the cdr table to be just the single column subscriber id .

Unfortunately however natural data skew can result in tens of thousands if not millions of rows in the cdr table all corresponding to a single subscriber id key. In this situation it is difficult to store the table efficiently within a Teradata system without sacrificing join performance available to joins within a single processing module .

The N value used for modulo N is user configurable but the value 127 is illustrated in the following example equation key1 HASHBUCKET HASHROW call date call time 127

By defining the primary index of this cdr table to be the composite key of subscriber id and key and then loading the cdr key table with the distinct keys from cdr table we get the best of both worlds. The primary index distribution of cdr table table is tolerable because the number of distinct values stored in the primary index has increased. The primary index distribution of the cdr key bridge table is tolerable because the MOD N function has limited the number of distinct key values per subscriber id.

The hashing equation is deterministic and randomizes distinct key values. Hot spots that might normally be caused by simplistic MOD N functions alone. The need is avoided to correlate input data records with the assigned key values .

One example is where a particular loading process is aborted in the middle and has to be re started. Since the HASHBUCKET HASHROW J J . . . Jn MOD N function is deterministic records that were loaded after the restart will get assigned the same key value as they would have been before the restart even though no lists were maintained to track which call date call time values mapped to which key values.

The examples illustrated so far are all solutions that any customer or consultant could implement provided that they understood the method and could employ a black box function for computing the new key values used for distributing the skew. The difficulty however is that applications need to be aware of the intermediate bridge table s and load processes need to be tied down to a specific algorithm for computing the key values.

A more elegant approach would be to let the database administrator create an index structure that can quickly find rows in the cdr table even though the primary index covers more than just the subscriber id field . One can do something like that today with the CREATE JOIN INDEX or CREATE HASH INDEX syntax but those mechanisms create an index structure that has a distinct row id per row in the cdr table . If there are literally tens of thousands if not millions of cdr table rows for certain subscriber id key values then the join index or hash index data structure suffers from the same skewing issue as the base table.

All of the discussion applies equally well to certain types of join indexes as they do to hash indexes as well as to 64 bit addressing with appropriate allowances for differing byte alignments and low level row formats.

Once the above hash index is created a single record in the hash index structure consists of a fixed part that stores the actual subscriber id value and a repeating part that consists of a sequence of row identifiers. Although does not explicitly show this the fixed part and repeating part structures are stored in region of the row whereas the row header is region . In the example that we are following region will contain a single subscriber id value along with a list of row id pointers to the base table rows in cdr table . The only commonality associated with the list of row id pointers in the fixed part is that they are all point to rows in the Teradata file system that all have the same subscriber id indicated by the value stored in the fixed part.

A typical row identifier might have the hexadecimal value 02A4 C245 for the row hash and 0000 0001 for the row uniqueness portion . Our proposed solution is that in the presence of data skew we will store a vague row identifier that identifies a scan range within the Teradata File System to find the associated rows instead of storing a distinct row id for every single base table row in the cdr table table with the relevant subscriber id key. A range flag is defined that distinguishes a vague row identifier from a conventional row identifier. One example of a range flag is a uniqueness value that is unlikely to occur normally. One example is the value FFFF FFFF for a uniqueness value and the scan range might be to only scan those File System blocks surrounding row hash 02A4 C245. This would be represented with the vague row id of 02A4 C200 FFFF FFFF.

Whenever the hash index structure is updated to add a new row id pointer the system checks to see if long lists of multiple row identifiers can be consolidated together into a single vague row id. If a vague row id already exists in the hash index structure and the new row id to be added fits within it s scope then no change is needed to the hash index structure.

The number of pointer keys that have to be stored in the hash index structure is reduced at the cost of slightly increased scan time to find actual rows in an underlying base table.

Inserts into the index structure can be effected by upsert checking. The deletion of rows is slightly more complicated. An extra check is required to validate if other keys within the same row identifier range still exist in the cdr table after deleting a particular row. It is envisaged that a garbage collection technique could forego the additional check on individual delete statements in favour of a periodic batch process to revalidate the index structure.

It is also envisaged that a special syntax is defined on the create hash index statement to more specifically define this case. The following restrict primary phrase instead of the column  list could be used with the restriction that the by column  list is a proper subset of the primary index columns.

The text above describes one or more specific embodiments of a broader invention. The invention also is carried out in a variety of alternative embodiments and thus is not limited to those described here. Those other embodiments are also within the scope of the following claims.

