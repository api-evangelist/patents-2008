---

title: System and method for integrating data quality metrics into enterprise data management processes
abstract: A method and system for assessing data quality stored in an enterprise database is provided. In response to a request by a user, a pre-determined event, or other event, a profile is chosen from a list of profiles stored in a profile database based on the request, wherein the profile includes a set of rules for calculating data quality metrics and for triggering workflow processes. One or more data records are received from one or more enterprise databases. The data quality metrics of the one or more data records based on the set of rules for calculating data quality metrics is calculated. Based on the calculated data quality metrics and rules for triggering workflow, a determination is made regarding whether to trigger one or more workflow processes: and, if so, triggering the one or more workflow processes; and/or converting the calculated data quality metrics to a representation for display.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08892534&OS=08892534&RS=08892534
owner: SAP SE
number: 08892534
owner_city: Walldorf
owner_country: DE
publication_date: 20080703
---
Companies may need to measure and ensure the data quality stored in their enterprise database systems. Data quality may be reflected in different aspects. A reasonable measurement of data quality may need to take into account of all these aspects. The measurement of data quality may further depend on several surrounding factors e.g. security of the database system which may drastically change the results if ignored.

Existing discrete technologies and algorithms for measuring data quality have not been systematically integrated to take into account of all aspects of data quality. Current data quality assessment services concern themselves only with part of the whole range of data quality aspects. That is they do not provide a user with a comprehensive assessment of the enterprise data quality. Moreover they do not offer the flexibility of customizing the assessment to the user s general data environment or to the different scenarios in which the user may want to run the assessment. Furthermore the results of data quality measurements are not linked to a triggering mechanism that may automatically trigger workflow processes based on the assessment of data quality and pre determined rules.

Embodiments of the present invention provide a system method and computer readable medium including instructions which integrate data quality metrics into enterprise data management processes based on configuration rules. Data quality is measured by using a set of metrics that take into account of all different aspects of data quality. An integrated business rule based engine may flexibly take into account of all possible surrounding factors e.g. different scenarios and purposes of a data quality assessment. In addition data quality assessment modules may be linked with a workflow engine or a business process management BPM engine so that all kinds of workflows or processes may be triggered either during the assessment or based on the results of the data quality assessment where the assessment may use e.g. SAP MDM functionality linked to data storages.

Embodiments of the present invention provide a holistic approach on data quality. Different data metrics are calculated and the results of which are usable by a rules engine to determine the next steps and or actions e.g. human interaction or different roles or the call of data cleansing or enhancement services. In an embodiment the rules also take into account the different scenarios e.g. data create update and or regular periodic check of data records data type and or who triggered the action.

Embodiments of the present application allow a corporation to automatically assess the data quality stored in its enterprise databases using an enterprise database management system e.g. a SAP Master Data Management MDM system. The data quality may include multiple aspects measured in terms of data quality metrics e.g. completeness accuracy provenance consistency time reference accessibility and value adding. Within an enterprise database management system the data may be organized in a certain way e.g. according to vendors or business partners. For each vendor the system may need to check a list of vendor master data e.g. for duplicate names duplicate addresses duplicate bank information completeness of bank information and address validation etc.

The assessment of data quality may be provided using rules that may be set up by using metrics. The rules may be aggregated into a profile for the convenience of a user. For example a user may login in a certain role and choose a specific profile for a certain task. The user may create a new profile for a new task by configuration of rules specified to the profile. Based on profiles and rules specified in the profiles the data quality assessment system may make calculations to determine the data quality stored in the enterprise database. Based on the determination the system may display the results to the user in an appropriate representation or automatically trigger workflow processes according to a set of triggering rules and the calculated results.

For exemplary purposes an MDM system is discussed with respect to some of the embodiments of the present invention. This reference is not meant to limit the scope of the application to just one specific MDM system. And instead the embodiments herein apply to other enterprise database management systems.

The calculated results may trigger the workflow engine to start certain processes e.g. for a correction of data quality according to the profile or rules specified in the profile. In addition based on the profile or rules specified in the profile the system may convert the results into a representation suitable for displaying to the user.

The MetricsCalculation module may retrieve data from MDM or directly from the MDM database to modules included therein e.g. modules of Accessibility Provenance ValueAdding Inconsistency Duplicates Completeness Time and Accuracy . The MetricsCalculation module may also retrieve data from external services provided to the MetricsCalculation module directly or through an EnrichmentAdapter . According to an embodiment of the present invention the EnrichmentAdapter may provide data retrieved from an address validation service e.g. a Trillium Software application to the Accuracy module or to the Inconsistency module . Additionally a SpellCheck and a DomainLookup may provide external services of spell check and Internet domain name lookup respectively to the Accuracy module . A Dun Bradstreet DUNS number validation service e.g. via a D B enrichment adapter or other such service number may provide external services of validating DUNS number to the Accuracy module the Inconsistency module and the Provenance module . A Business Intelligence module and SAP systems may provide external services respectively of data gained from supplier evaluation or information about frequency of use derived from transactions using supplier data to the ValueAdding module . A Compliance Information module may provide external services of legal compliance requirements to the Provenance module . The MetricsCalculation module may also be provided with an external survey service through a Surveys module for calculating weights. The results from the Surveys module may be based on inputs from a DataCollector module a DataCustodian module and a DataConsumer module . The output of the Surveys module may be provided to the Accessibility module and the Provenance module in addition to the MetricsCalculation module .

Based on the data retrieved from MDM or directly from MDM database and the outputs at the modules of Accessibility Provenance ValueAdding Inconsistency Duplicates Completeness Time and Accuracy the MetricsCalculation module may retrieve a profile from the Profile Storage and calculate a result of data quality metrics according to the profile retrieved. Based on the results and security data retrieved from MDM or directly from MDM database a Security module may calculate security metrics according to the profile retrieved from the Profile Storage . Based on the data quality results and security metrics a WorkflowEngine module may make a determination for triggering a workflow process and a Representation module may convert the data quality results into a representation according to the profile received from ProfileManager module .

If the application decides to update the profile the user may first set customizing rules security rules and rules for process configuration and then update the profile database by either creating a new profile or updating an existing profile with new rules. At the new profile may be stored in the profile database for future reuse. After the update or if the application determines that the profile does not need update at the application may choose a profile containing rules for calculating data quality metrics based on user s request and make a connection to the MDM or directly to the MDM database for retrieving data for which the quality check is performed. Then based on the rules provided in the profile quality metrics for the retrieved data may be calculated . The calculation of some the quality metrics may additionally depend on the results of other quality metrics. The calculation of some quality metrics may further require retrieving information from external services . With the calculated quality metrics the application may determine whether to trigger a workflow process according to rules provided for in the profile or convert the results into a representation suitable for displaying to a user at user s terminal .

According to an embodiment of the invention the whole framework of the data quality assessment application may include on the one hand a rule engine for assessing the quality of the overall security related to that MDM data and on the other hand the data quality metrics application itself. The data quality metrics application itself may implement the calculation of all different metrics. Two additional engines may be embedded in this application one for customizing purposes and one for process configuration. The three rule engines may be linked to another engine for managing profile rules where different configurations of the other engines may be saved and combined as different assessment profiles. These profiles may provides the user with an easy tool for managing different types of assessments without having to perform unnecessary reconfiguration in the future.

Although many metrics may be customized it is for the user or another source e.g. a lookup table to decide which parameters fit best into a data model. Initially standard values may be provided for as default values. shows an example of rules that are customized for a specific data model with a set of attributes e.g. including Account Group Code Account Group Name Address Time Zone and City etc. The user may customize e.g. Rule for Validity by specifying requirements in the first and second columns e.g. for Account Group Code specifying Length is max. in the first column and Consists of Characters in the second column. The third column may specify the result of applying the rule e.g. for Account Group Code resulting Account Group Code is valid. Similarly the user may customize e.g. Rule for Completeness by specifying rules in the first column and results in the second column e.g. for Account Group Code specifying the rule as This attribute is essential to the record and resulting High importance. 

The module for metrics selection may select a subset of metrics to calculate because not all metrics must be calculated under every scenario. For some scenarios the application may require to choose only a combination of some of the metrics.

Sometimes it may be desirable not to perform a quality assessment on the complete set of data. The module for data segmentation may allow a user to apply quality assessment to only part of the whole set of data records according to data model metrics or predefined segmentation rules. In one example embodiment as shown in the data quality assessment application may first calculate all the metrics specified by the Metrics Selection module and according to the profile for a particular metric e.g. the General Completeness. For each record shows the resulting General Completeness metric in terms of percentiles. Based on the results the module for segmentation may segment the data records for those whose General Completeness is less than 97.5 as shown in . The criteria or dimensions for segmentation may be based on a single calculated metric as the above discussed General Completeness. In an embodiment it might be desirable to access only records originated from certain source systems data models attributes of data model or Business Information data. If the total number of records is so large that it is difficult to access all records due to performance or cost reasons only a random sub sample of the whole set may be accessed. The random sub samples may be randomly chosen from a defined number of records.

Some metrics may depend on the calculation of other metrics according to one embodiment of the present invention. Moreover there may be a ranking in terms of the importance of metrics. An order for processing may be decided based on the dependency and importance factor among metrics. A rule for a metric may be derived in dependency on the previous metrics results. Additionally ranking rules may be defined according to the rules set up for segmentation if they have been chosen.

In another example embodiment shows the ranking of measurement may also depend on the results of previously determined metrics. For example when the General Completeness metric shows that an address is incomplete the application may not validate the address. Or when General Completeness and Accuracy are very low the application may not check for duplicates.

The process configuration module may have different setups for different scenarios which may require different assessments. A user may define any scenario through the module for scenario . Furthermore the module may define sub scenarios to the regular assessment e.g. one small monthly assessment and one completely detailed annual assessment. In one example embodiment shows scenarios of basic contexts. For each scenario one or more rule may be generated for the scenario. For example for Vendor Search and Select scenario a rule of Do not evaluate cognitive accessibility may result. For Multi Stage Create Add Supplier scenario rules of Do not check value adding and currency Do not check trustability of source system and Do not evaluate cognitive accessibility may be generated. In another example embodiment shows additional contexts may be provided to the basic contexts of scenarios. For example in a scenario of Distribution Management Process an additional context of Distribute records to other system may be provided and a rule of Do not check accessibility may be generated. In another example a scenario of Regular Quality Assessment may include two sub scenarios each of which may have different contexts and generate different rules. For example the first sub scenario may include contexts of High timeliness of record and Last address validation has been performed within a certain period and generate a rule of Do not validate address. The second sub scenario may include a context of No major basic changes since last assessment and generate a rule of Do not evaluate cognitive accessibility. 

Each quality assessment may be associated with a cost e.g. time for user interaction or resources according to one example embodiment of the present invention. The cost may be within a predefined range and may be weighed against the benefit of the assessment. Cost factors may be direct cost factors or indirect cost factors. Direct cost factors may include performance factor e.g. time and resources processing cost factor e.g. automation vs. manual execution level of detail factor e.g. quantity vs. detailed and security factor. Indirect cost factors may include benefits e.g. missed out benefits due to wrong information additional cost factor and contract factor e.g. risk of losing a supplier. The indirect cost factors may also be viewed as risk factors. Failure of critical values for certain metrics e.g. address validity consistency etc. may lead to a warning for the user. In one possible case a purchaser may choose a supplier for a new transaction. During that selection the incompleteness of the banking information may be determined. Thus the purchaser may receive a warning that this supplier information has to be updated first or that there are no transaction possible.

In an example embodiment of the present invention shows that the direct cost rules may be influenced by ranking. For example when the test set of records is huge rules of Do not prompt user to confirm spelling errors and Do not request user interaction for finding duplicates may be generated. In another example embodiment of the present invention shows rules influenced by indirect cost factors. For example in the context of minimal incompleteness rules of Direct contact is not possible and Customer might be lost due to missing contact may be generated.

According to scenarios a user or other entity may need to receive results of the assessment in different ways e.g. for it may not always be necessary to provide him with a very detailed report. The representation may also depend on the quality of data. For example a data of low quality may require a detailed report for the user to find out why. According to an embodiment of the present invention show representation rules generated according to scenarios and or sub scenarios. For example the scenario of Import Management Process may include two sub scenarios of one single record and set of records. For the sub scenario of one single record a representation rule of Only prompt user to correct erroneous data for that record may be generated and for set of records representation rules of Bundle and group the correction requests and present them to the user after the whole import has been finished and Offer a detailed report containing all the quality results for that import may be generated.

Based on the results of assessment rules chosen and the present scenario the data quality assessment application may trigger different workflows. The selection of a workflow may depend on many factors e.g. weights selection of metrics scenario and result values etc. According to one example embodiment of the present invention show different workflow triggered under different scenarios and conditions. For example a workflow process of Warn user or request an update may be triggered under a scenario of Search and Select for a condition that specified metric is below a critical value. In another example workflows of Inform user and request correction and Data cleansing and enrichment process may be triggered under a scenario of Multi Stage Create Add Supplier for a condition that accuracy consistency duplication or accessibility problem occurs.

In an embodiment of the present invention security metrics may relate to users roles of users data models passwords and workflows. Rules for passwords may include e.g. must not be initial must not contain user name or full name neither the complete string nor any substrings must use at least three of the four available character types lowercase letters upper case letters numbers and symbols and minimum length 8 characters. Rules for roles may include e.g. at least one role has to have restricted access rights for both functions and fields and technical and business side administrators should be different technical administrator should not be able to see Vendor records . In an embodiment rules for users relate to questions such as which persons have administration right is there a way to link it to any employee function and what are the setup rules for that mapping. They may also relate to factors e.g. check validity and timeliness of role assignment cross check employee data for functional changes and time stamp of role assignment or whether user name is identical to its corresponding company user ID. Rules for workflow may relate to the specification of which attribute changes that require an approval approval responsibilities and approval process. Rules for data model may relate to whether Application Programming Interfaces APIs are protected and or whether it is possible to access and modify the data via APIs. In an example embodiment according to the present invention shows security aspects and high level practices for security. These practices may be further defined and or supplemented with additional rules e.g. those in regard to the organizational structure of the specific company.

Fully setting up above discussed rules may require significant efforts. Therefore it may not be efficient to repeat the setting up process for each assessment scenario. To reuse and streamline the setting up process a profile engine is configured in response to a user request to create profiles of settings for later reuse. To create a profile the first step may include configuring different rules for security customizing and the process configuration. Then those settings may be saved separately. Finally those settings may be combined e.g. one for each category to a profile. In this way both the single rule engine settings and the profiles are reusable and hence convenient to handle a set of different assessment without having to reconfigure everything for each new assessment. A profile may include aspects of assessment frequency e.g. small monthly check or detailed annual check source system and data model e.g. SAP ECC SRM and scenarios e.g. Vendor Search and Select Create Add Supplier Update Supplier Deactivate Archive Supplier Import Management Process Distribution Management Process Data Cleansing Enrichment and Refresh Process.

In an embodiment of the present invention the module for calculating accuracy calculates either syntactic accuracy and or semantic accuracy. For example shows a main table of a vendor who may have two names e.g. Owens Electric Solar and J J Owens Electric Inc. related to the company and thus have two records created for it. In one example embodiment the syntactic accuracy may be measured e.g. in terms of edit distance. The edit distance between string a and string b may be calculated based on the cost of converting from a to b. A cost of 1 may be associated with either change or deletion or insertion of a letter. For example the edit distance between Owens Electric Solar and J J Owens Electric Inc. as shown in is 9. The user may specify a rule that defines up to which cost in relation to the length of the longer string the data shall be regarded as similar. In an alternative example embodiment the comparison function may be an identity function. An identity function has a result value true only if two strings are identical. Otherwise the result value is false. 

In an embodiment of the present invention the accuracy may be measured in terms of semantic accuracy or record matching of whether Record A and Record B refer to the same real world object. A union of Record A and Record B may be represented as Record A Record B a b a Record A and b Record B. A subset of matching field s may be represented as M a b a b a Record A and b Record B. A subset of nonmatching field s may be represented as U a b ab a Record A and b Record B. The semantic distance is based on the ratio of U M where if U M 0 the Records A and B are semantically identical or if U M 0 and M 0 the Records A and B are not semantically identical.

In an embodiment of the present invention the Provenance metric may be calculated as an individual assessment by defining weighs for different data sources and establishing a ranking.

In an embodiment of the present invention an inconsistency may be the result of an incomplete update. For example shows that an incomplete update of the database may cause an inconsistency in the Regions and Time Zones attributes.

In an embodiment of the present invention the calculation of the Time metric include determining Currency and Timeliness factors. The Currency may relate to the frequency of change of an attribute. The frequency of change may be calculated for data with stable change frequency or with flexible change frequency by calculating an average. In an embodiment a change of a company s address e.g. the city may be traced from the metadata of the database. Rules may be applicable to the Currency e.g. the city of a company may change within an average of five years but it may not change three times a year. The Timeliness may be related to availability of a data item. In an embodiment of the present invention the module for Time metric checks currency and then check if the attribute DataCreationTime less than TimeDataNeeded. If so the module may search for time stamp that shows when accessing the data has been tried for the first time. The timestamp TimeDataNeeded may be an indication when the user might have tried to access the data item for the first time e.g. when the user tried for the first time to read the address of a certain record. The timestamp may be created even during the initiation of a field.

In an embodiment of the present invention the calculation of metric for Cognitive Accessibility may measure how easy it is for a user to understand the data. shows an example Vendor main table where one field e.g. Account Group may be ambiguous because different users enter totally different data. For situation where there is a lookup table behind the field the module for Cognitive Accessibility may check editing rights for that table to look for persons who are responsible. In an embodiment if a lookup table is used it may not be possible for the user to enter any data as the user understands. For example one user may enter numerical values while other users may enter alphanumerical values. In a case like this the right to editing may be examined to ensure that only users with responsibilities may edit the lookup table.

In an embodiment of the present invention the metric of Value Adding is calculated based on frequency of use. For example shows high frequency of use of the e mail address field and low frequency of use of the train station field.

In an embodiment of the present invention the metric of Completeness is calculated for general completeness and minimum completeness . The general completeness may be related to the completeness of all data fields. However some data fields may be more important than others. Therefore the minimum completeness may be related to a minimum set of important data fields. For example in the phone number of a company may be considered more important than fax number or e mail address. Therefore the metric for minimum completeness may require a determination of the completeness of phone number and the general completeness may require a determination of the completeness of phone number fax number and e mail address of the company.

In an embodiment of the present invention for address validation the Data Quality Metric Calculation module residing on the server may first check for completeness to determine whether all necessary fields e.g. Name 1 Street House Number City City Postal Code Country and Phone Number are ascertained. Next the module may check for consistency to determine e.g. whether the city and the related city postal code are consistent against database with city information or whether the city exists in the country. Then the module may check for the timeliness and concurrency to determine e.g. when has the last update on the address taken place and the time stamps against the average change frequency. Finally the module may check accuracy to determine e.g. whether the data is semantic and syntactic correct or whether all data entries are in valid formats. shows an example table of data entries and their corresponding format specifications. shows an example result of applying the above discussed data quality metric modules to data in an enterprise database. In this example a check for general completeness may determine that the fields for House Number and Phone Numbers are incomplete. A check for consistency may determine that the fields for City City Postal Code and Country are consistent. A check for accuracy may determine that the fields for Name 1 and Street are not accurate. Finally a check for time may determine that the last update on address was two and half years ago.

In another example embodiment of the present invention the quality metrics may be provided with a default weighting through a survey and calculated with a weighting system. An example survey is herein attached in Appendix 1. A checkbox table shown in the survey may be provided to a user who may be in a role as e.g. a data collector a data custodian or a data consumer to fulfill the survey. The user may elect a weight for each attribute based on his view e.g. a 75 weight on Validity No Duplicate which may be used for further calculation. The survey may also seek for user inputs on the level of importance for quality metrics e.g. consistency and completeness.

Based on the weights derived from surveys a target value of overall data quality may be calculated from a weighted assessment of each individual quality metric. In one example embodiment of the present invention the accuracy metric may be evaluated as a weighted average of validity duplicates and proper spelling attributes from the survey e.g. R 75 150 R 50 150 R 25 150 R 0.5 R 0.33 R 0.17 R where the total weight X Validity Average Weigh No Duplicates Average Weigh Proper Spelling Average Weigh 75 50 25 150.

The provenance metric may be evaluated as a weighted average of DUNS Number Trustable Source System Timely Data attributes from the survey e.g. R 62.5 150 R 37.5 150 R 50 150 R 0.42 R 0.25 R 0.33 R and R Trustable Vendor Record R Trustable Source System R 0.75 R 0.25 R where the total weight Y Valid DUNS Number Average Weighting Trustable Source System Average Weighting Timely Data Average Weighting 62.5 37.5 50 150.

Similarly the accessibility metric may be evaluated as an weighted average of cognitive accessibility physical accessibility e.g. R Cognitive Accessibility R Physical Accessibility R 0.25 R 0.75 R. Based on the number of levels of importance the consistency and completeness may be evaluated as weighted averages of different level of importance. For example for a survey of two consistency levels a weighted average consistency may be evaluated as e.g. 0.75 a 0.25 b where a and b represent consistencies at each level and for a survey of four completeness levels a weighted average completeness may be evaluated as e.g. 0.4 a 0.3 b 0.2 c 0.1 d where a b c and d represent completeness at each level.

The overall data quality value target may be a weighted average of all targets of each metric evaluated as R 60 300 R 30 300 R 70 300 R 60 300 R 35 300 R 45 300 R 0.2 R 0.1 R 0.23 R 0.2 R 0.12 R 0.15 R where the total weight may be X Accuracy Average Weighting Provenance Average Weighting Consistency Average Weighting Completeness Average Weighting Time Average Weighting Accessibility Average Weighting 60 30 70 60 35 45 300.

The various computer systems described herein may each include a storage component for storing machine readable instructions for performing the various processes as described and illustrated. The storage component may be any type of machine readable medium i.e. one capable of being read by a machine such as hard drive memory flash memory floppy disk memory optically encoded memory e.g. a compact disk DVD ROM DVD R CD ROM CD R holographic disk a thermomechanical memory e.g. scanning probe based data storage or any type of machine readable computer readable storing medium. Each computer system may also include addressable memory e.g. random access memory cache memory to store data and or sets of instructions that may be included within or be generated by the machine readable instructions when they are executed by a processor on the respective platform. The methods and systems described herein may also be implemented as machine readable instructions stored on or embodied in any of the above described storage mechanisms.

Although the present invention has been described with reference to particular examples and embodiments it is understood that the present invention is not limited to those examples and embodiments. Further those embodiments may be used in various combinations with and without each other. The present invention as claimed therefore includes variations from the specific examples and embodiments described herein as will be apparent to one of skill in the art.

