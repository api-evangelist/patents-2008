---

title: Local collections of tasks in a scheduler
abstract: A scheduler in a process of a computer system includes a local collection of tasks for each processing resource allocated to the scheduler and at least one general collection of tasks. The scheduler assigns each task that becomes unblocked to the local collection corresponding to the processing resource that caused the task to become unblocked. When a processing resource becomes available, the processing resource attempts to execute the most recently added task in the corresponding local collection. If there are no tasks in the corresponding local collection, the available processing resource attempts to execute a task from the general collection.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08566830&OS=08566830&RS=08566830
owner: Microsoft Corporation
number: 08566830
owner_city: Redmond
owner_country: US
publication_date: 20080516
---
Processes executed in a computer system may include task schedulers that schedule tasks of processes for execution in the computer system. These schedulers may operate with various algorithms that determine how tasks of a process are to be executed. The algorithms however may not take full advantage of the underlying hardware topology of the computer system. For example the algorithms may not fully exploit memory locality effects in a computer system with a memory hierarchy and multiple processors. As a result a scheduler may not optimize the execution of a process in a computer system.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

A scheduler in a process of a computer system includes a local collection of tasks for each processing resource allocated to the scheduler and at least one general collection of tasks. The scheduler assigns each task that becomes unblocked to the local collection corresponding to the processing resource that caused the task to become unblocked. When a processing resource becomes available the processing resource attempts to execute the most recently added task in the corresponding local collection. If there are no tasks in the corresponding local collection the available processing resource attempts to execute a task from the general collection or a local collection of another processing resource.

In the following Detailed Description reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration specific embodiments in which the invention may be practiced. In this regard directional terminology such as top bottom front back leading trailing etc. is used with reference to the orientation of the Figure s being described. Because components of embodiments can be positioned in a number of different orientations the directional terminology is used for purposes of illustration and is in no way limiting. It is to be understood that other embodiments may be utilized and structural or logical changes may be made without departing from the scope of the present invention. The following detailed description therefore is not to be taken in a limiting sense and the scope of the present invention is defined by the appended claims.

It is to be understood that the features of the various exemplary embodiments described herein may be combined with each other unless specifically noted otherwise.

Runtime environment represents a runtime mode of operation in a computer system such as embodiments A and B of a computer system shown in and described in additional detail below where the computer system is executing instructions. The computer system generates runtime environment from a runtime platform such as a runtime platform shown in and described in additional detail below.

Runtime environment includes an least one invoked process a resource management layer and a set of hardware threads M where M is an integer that is greater than or equal to one and denotes the Mth hardware thread . Runtime environment allows tasks from process to be executed along with tasks from any other processes that co exist with process not shown using resource management layer and hardware threads M . Runtime environment operates in conjunction with resource management layer to allow process to obtain processor and other resources of the computer system e.g. hardware threads M .

Runtime environment includes a scheduler function that generates scheduler . In one embodiment the scheduler function is implemented as a scheduler application programming interface API . In other embodiments the scheduler function may be implemented using other suitable programming constructs. When invoked the scheduler function creates scheduler in process where scheduler operates to schedule tasks of process for execution by one or more hardware threads M . Runtime environment may exploit fine grained concurrency that application or library developers express in their programs e.g. process using accompanying tools that are aware of the facilities that the scheduler function provides.

Process includes an allocation of processing and other resources that host one or more execution contexts viz. threads . Process obtains access to the processing and other resources in the computer system e.g. hardware threads M from resource management layer . Process causes tasks to be executed using the processing and other resources.

Process generates work in tasks of variable length where each task is associated with an execution context in scheduler . Each task includes a sequence of instructions that perform a unit of work when executed by the computer system. Each execution context forms a thread that executes associated tasks on allocated processing resources. Each execution context includes program state and machine state information. Execution contexts may terminate when there are no more tasks left to execute. For each task runtime environment and or process either assign the task to scheduler to be scheduled for execution or otherwise cause the task to be executed without using scheduler .

Process may be configured to operate in a computer system based on any suitable execution model such as a stack model or an interpreter model and may represent any suitable type of code such as an application a library function or an operating system service. Process has a program state and machine state associated with a set of allocated resources that include a defined memory address space. Process executes autonomously or substantially autonomously from any co existing processes in runtime environment . Accordingly process does not adversely alter the program state of co existing processes or the machine state of any resources allocated to co existing processes. Similarly co existing processes do not adversely alter the program state of process or the machine state of any resources allocated to process .

Resource management layer allocates processing resources to process by assigning one or more hardware threads to process . Resource management layer exists separately from an operating system of the computer system not shown in in the embodiment of . In other embodiments resource management layer or some or all of the functions thereof may be included in the operating system.

Hardware threads reside in execution cores of a set or one or more processor packages e.g. processor packages shown in and described in additional detail below of the computer system. Each hardware thread is configured to execute instructions independently or substantially independently from the other execution cores and includes a machine state. Hardware threads may be included in a single processor package or may be distributed across multiple processor packages. Each execution core in a processor package may include one or more hardware threads .

Process implicitly or explicitly causes scheduler to be created via the scheduler function provided by runtime environment . Scheduler instance may be implicitly created when process uses APIs available in the computer system or programming language features. In response to the API or programming language features runtime environment creates scheduler with a default policy. To explicitly create a scheduler process may invoke the scheduler function provided by runtime environment and specifies a policy for scheduler .

Scheduler interacts with resource management layer to negotiate processing and other resources of the computer system in a manner that is transparent to process . Resource management layer allocates hardware threads to scheduler based on supply and demand and any policies of scheduler .

In the embodiment shown in scheduler manages the processing resources by creating virtual processors that form an abstraction of underlying hardware threads . Scheduler includes the set of virtual processors N . Scheduler multiplexes virtual processors onto hardware threads by mapping each virtual processor to a hardware thread . Scheduler may map more than one virtual processor onto a particular hardware thread but maps only one hardware thread to each virtual processor . In other embodiments scheduler manages processing resources in other suitable ways to cause instructions of process to be executed by hardware threads .

Scheduler includes a general collection of tasks and local collections of tasks N where local collections N correspond to respective virtual processors N . General collection may be organized into any suitable type number and or combination of sub collections of tasks. In one embodiment general collection may include a set of one or more schedule groups as shown in the embodiment of and described in additional detail below. In other embodiments general collection may be organized in other suitable ways.

The set of execution contexts in scheduler includes a set of execution contexts N with respective associated tasks N that are being executed by respective virtual processors N a set of zero or more runnable execution contexts and a set of zero or more blocked i.e. wait dependent execution contexts . Each execution context and includes state information that indicates whether an execution context and is executing runnable e.g. in response to becoming unblocked or added to scheduler or blocked. Execution contexts that are executing have been attached to a virtual processor and are currently executing. Execution contexts that are runnable include an associated task and are ready to be executed by an available virtual processor . Execution contexts that are blocked include an associated task and are waiting for data a message or an event that is being generated or will be generated by another execution context or .

The set of execution contexts in scheduler also includes sets of runnable execution contexts N in respective local collections N . Each execution context has an associated task that was unblocked by the execution of a task where the task was executed or is currently being executed on the virtual processor corresponding to the local collection that includes the execution context .

Each execution context executing on a virtual processor may generate in the course of its execution additional tasks which are organized in any suitable way e.g. added to work queues not shown in . Work may be created by using either application programming interfaces APIs provided by runtime environment or programming language features and corresponding tools in one embodiment. When processing resources are available to scheduler tasks are assigned to execution contexts or that execute them to completion on virtual processors before picking up new tasks. An execution context executing on a virtual processor may also unblock other execution contexts by generating data a message or an event that will be used by another execution context .

Each task in scheduler may be realized e.g. realized tasks and which indicates that an execution context or has been or will be attached to the task and the task is ready to execute. Realized tasks typically include unblocked execution contexts and scheduled agents. A task that is not realized is termed unrealized. Unrealized tasks e.g. tasks may be created as child tasks generated by the execution of parent tasks and may be generated by parallel constructs e.g. parallel parallel for begin and finish . Scheduler may be organized into a synchronized collection e.g. a stack and or a queue for logically independent tasks with execution contexts i.e. realized tasks along with a list of workstealing queues for dependent tasks i.e. unrealized tasks as illustrated in the embodiment of described below.

Upon completion blocking or other interruption e.g. explicit yielding or forced preemption of an execution context running on a virtual processor the virtual processor becomes available to execute another realized task or unrealized task . Scheduler searches for a runnable execution context or an unrealized task to attach to the available virtual processor for execution in any suitable way. For example scheduler may first search for a runnable execution context to execute before searching for an unrealized task to execute. Scheduler continues attaching execution contexts to available virtual processors for execution until all execution contexts of scheduler have been executed.

Local collections may allow scheduler to exploit memory locality effects that may occur with hardware threads . In executing process scheduler assigns each wait dependent execution context with a task that becomes unblocked to the local collection corresponding to the processing resource e.g. the combination of virtual processor and hardware thread that caused the task to become unblocked. Unblocked tasks with associated execution contexts become runnable tasks with associated execution contexts in response to being added to a local collection .

When a processing resource e.g. a virtual processor becomes available the processing resource attempts to execute the most recently added task associated with an execution context in the corresponding local collection i.e. the most recent task unblocked by the processing resource . By doing so scheduler increases the likelihood that each unblocked task will be able to take advantage of data stored high in the memory hierarchy of the processing resource caused the task to become unblocked. As a result the unblocked task may execute more efficiently in the processing resource than in another processing resource that did not already include such data stored high in the memory hierarchy.

For example if task on execution context unblocks a task with an execution context while being executed on hardware thread via virtual processor execution context likely produces at least some data that the task will consume. Because the production of the data by execution context is likely to have caused the unblocking of the task the data is likely high in the memory hierarchy of the hardware thread e.g. the data is hot within high levels of one or more caches accessible to hardware thread . In this example scheduler assigns the unblocked task and associated execution context to local collection to increase the likelihood that the unblocked task will be executed by the same hardware thread via virtual processor .

In one embodiment local collections are each implemented as workstealing queues to allow processing resources to steal tasks with runnable execution contexts from the local collections of other processing resources as described in additional detail below. In this embodiment a processing resource pops the most recently added task and associated execution context for execution when accessing the local collection corresponding to the processing resource. When accessing a local collection corresponding to another processing resource a processing resource steals the least recently added task and associated execution context for execution. By doing so scheduler allows local collections to be operated without locks or with minimal locking of local collections . In other embodiments local collections may be implemented as other types of collections.

Scheduler determines whether a task with a wait dependent execution context becomes unblocked as indicated in a block . Scheduler may perform this function continuously while causing process to be executed. To make the determination scheduler detects that data one or more messages and or one or more events that unblock the execution context have been generated by a virtual processor executing an execution context . Scheduler also identifies the virtual processor that caused the execution context to become unblocked.

In response to determining that a task with a wait dependent execution context becomes unblocked scheduler determines whether the local collection corresponding to the virtual processor that caused the execution context to become unblocked is full as indicated in a block . Scheduler may or may not limit the size of each local collection . For example scheduler may limit the number of execution contexts stored in each local collection to four.

If a local collection is currently storing the maximum number of execution contexts i.e. the local collection is full then scheduler moves the least recently added task and associated execution context from the local collection to general collection e.g. to the set of execution contexts as indicated in a block . Scheduler removes the least recently added execution context from the local collection and adds the execution context to general collection to make room for the newly unblocked execution context . When spilling an execution context over from a local collection to general collection scheduler operates the local collection as a FIFO first in first out buffer to spill the least recently added execution context in local collection to general collection .

In other embodiments scheduler may add an unblocked task and associated execution context to general collection when the local collection is full.

In embodiments where general collection includes two or more sub collections scheduler may add the execution context into a sub collection associated with the virtual processor corresponding to the local collection from which the execution context is being removed. The virtual processor may be associated with the sub collection by having most recently accessed the sub collection to obtain a runnable execution context .

After ensuring that space exists for the unblocked task in the local collection scheduler assigns the unblocked task and associated execution context to the local collection corresponding to the virtual processor that caused the task to become unblocked as indicated in a block . Scheduler adds the task and associated execution context into the local collection such that the task and associated execution context becomes a most recently added one of the set of tasks and associated execution contexts .

Scheduler determines whether a virtual processor becomes available as indicated in a block . Scheduler may perform this function continuously while causing process to be executed. Upon completion blocking or other interruption e.g. explicit yielding or forced preemption of an execution context running on a virtual processor the virtual processor becomes available to execute another execution context or and or another task .

When scheduler determines that a virtual processor becomes available scheduler begins a search for a runnable execution context to attach to the available virtual processor for execution. Scheduler first attempts to locate a runnable execution context in the local collection corresponding to the available virtual processor as indicated in a block .

If a runnable execution context is present in the local collection then scheduler causes the most recently added execution context in the local collection to be executed by the virtual processor as indicated in a block . When a runnable execution context is present in the local collection scheduler operates the local collection as a LIFO last in first out buffer to remove the most recently added execution context for execution. The runnable execution context is the most recently added execution context in the local collection and was unblocked by an execution context executing on the virtual processor . As a result the runnable execution context may have the highest probability of having data related to the wait dependency high in the memory hierarchy accessible to the hardware thread corresponding to the virtual processor .

If a runnable execution context is not present in the local collection then scheduler attempts to locate a runnable execution context in general collection as indicated in a block .

In embodiments where general collection includes two or more sub collections scheduler may attempt to locate a runnable execution context in the sub collection from which the available virtual processor most recently obtained a runnable execution context .

If a runnable execution context is present in the general collection then scheduler causes a runnable execution context from the general collection to be executed by the virtual processor as indicated in a block .

If a runnable execution context is not present in the general collection then scheduler attempts to locate a runnable execution context in a local collection corresponding to another virtual processor of scheduler as indicated in a block . In one embodiment scheduler accesses the local collections corresponding to the other virtual processors in a round robin order until a runnable execution context is located. In other embodiments scheduler accesses the local collections corresponding to the other virtual processors in other suitable orders.

If a runnable execution context is present in a local collection of another virtual processor of scheduler then scheduler causes the least recently added execution context in the local collection of the other virtual processor to be executed by the available virtual processor as indicated in a block . When a runnable execution context is found in another local collection scheduler operates the other local collection as a FIFO buffer to remove the least recently added execution context for execution. Scheduler thereby steals the least recently added execution context in the local collection and provides a mechanism for fairness and forward progress amongst the execution contexts in local collections of scheduler . In addition scheduler minimizes the interference with execution contexts most likely to benefit from running on the other virtual processors by popping the least recently added execution context for execution.

If a runnable execution context is not present in any of the local collections of the other virtual processors of scheduler then scheduler may search for a runnable execution context elsewhere as indicated in a block . For example scheduler may attempt to locate a runnable execution context by searching other sub collections of general collection in a round robin order in embodiments where general collection includes two or more sub collections. As another example scheduler may search one or more work stealing queues not shown of one or more sub collections of general collection to located unrealized tasks that may be runnable. When a runnable execution context or other runnable task is located scheduler causes the runnable execution context or other runnable task to be executed by the available virtual processor .

One embodiment of sub collections of general collection will now be described with reference to . is a block diagram illustrating an embodiment of sub collections configured as schedule groups P for use in scheduler by runtime environment .

Process may group tasks into schedule groups P such that each schedule group includes a grouping of related execution contexts or tasks and is used to provide a structure for locality of work fairness and or forward progress. The grouping may be due to logically related work e.g. a collection of tasks descending from a common root task hardware topology e.g. a non uniform memory architecture NUMA or a combination thereof. Schedule groups may allow scheduler to improve scalability locality and fairness.

Each schedule group includes a runnables collection a work queue and a set of zero or more workstealing queues . Each runnables collection contains a list of runnable execution contexts . Scheduler adds execution contexts to runnables collections when new runnable execution contexts are presented to scheduler by process or when runnable execution contexts are spilled over from a local collection into general collection as described above. Work queue contains a list of workstealing queues as indicated by an arrow and tracks the execution contexts that are executing tasks from the workstealing queues . Each workstealing queue includes one or more unrealized tasks .

The use of schedule groups in the embodiment of will now be described with reference to an example in . are block diagrams illustrating embodiments of executing execution contexts in scheduler with local collections .

In the example of virtual processors and are currently executing respective execution contexts and from schedule group as indicated by respective arrows and . Schedule group includes ten wait dependent execution contexts contexts A B C D E V W X Y and Z as shown in a box .

Execution context unblocks five of the execution contexts contexts A B C D and E by executing functions that produce data one or more messages or one or more events for the blocked execution contexts . The function A.PRODUCE produces data or a message for blocked execution context A B.PRODUCE produces data or a message for blocked execution context B and so on.

Similarly Execution context unblocks five of the execution contexts contexts V W X Y and Z by executing functions that produce data or a message for the blocked execution contexts . The function V.PRODUCE produces data or a message for blocked execution context V W.PRODUCE produces data or a message for blocked execution context W and so on.

As described above with reference to scheduler adds each execution context unblocked by virtual processor onto local collection and into the set of runnable execution contexts in the order of unblocking as shown in . Similarly scheduler pushes each execution context unblocked by virtual processor onto local collection and into the set of runnable execution contexts in the order of unblocking.

In the example of each local collection and is configured to store up to four execution contexts . When a fifth execution context is unblocked when four execution contexts are already in a local collection scheduler spills over the least recently added execution context into runnables collection of schedule group . In the example of scheduler spills over execution context A from local collection into runnables collection as indicated by an arrow to allow execution context E to be added to local collection . Likewise scheduler spills over execution context V from local collection into runnables collection as indicated by an arrow to allow execution context Z to be added to local collection .

An arrow indicates an order that execution contexts and were added to respective local collections and where a time t occurs before a time t i.e. t

When virtual processors and become available virtual processors and will first attempt to locate a respective runnable execution context and in respective local collections and as described above with reference to . In the example of virtual processor removes and executes execution context E i.e. the most recently added execution context and virtual processor removes and executes execution context Z i.e. the most recently added execution context . As illustrated by arrow execution contexts E and Z are most likely to have the hottest data in the respective memory hierarchies of respective hardware threads and . For example if the above execution contexts and operate on a large numeric matrix then a large amount of the matrix data associated with execution contexts E and Z is likely to be high in the respective memory hierarchies accessible to respective hardware threads and e.g. very hot in respective caches accessible to respective hardware threads and .

Eventually the runnable execution contexts and in local collections and are executed by virtual processors and or by other virtual processors that steal execution contexts and or from local collections and or as described above with reference to .

When an available virtual processor is unable to locate a runnable execution context in a corresponding local collection the virtual processor attempts to locate a runnable execution context in the following order until a runnable execution context is found. The virtual processor looks in the runnable collection in a corresponding schedule group then round robins through the local collections of other virtual processors and then round robins through the runnable collections in the remaining schedule groups .

If no runnable execution context is found in scheduler the virtual processor attempts to steal an unrealized task from a workstealing queue . Accordingly scheduler attempts a generalized steal only after failing to find a runnable execution context within a corresponding local collection the corresponding schedule group other local collections and the remaining schedule groups .

In the example of an available virtual processor not shown in that did not locate a runnable execution context within a local collection not shown or the runnables collection of a corresponding schedule group may steal execution context B from local collection i.e. the least recently added execution context or execution context W from local collection i.e. the least recently added execution context . If local collections and and the remaining local collections were empty then virtual processor may steal execution context V from runnables collection of a corresponding schedule group .

As shown in computer system A includes one or more processor packages a memory system zero or more input output devices zero or more display devices zero or more peripheral devices and zero or more network devices . Processor packages memory system input output devices display devices peripheral devices and network devices communicate using a set of interconnections that includes any suitable type number and configuration of controllers buses interfaces and or other wired or wireless connections.

Computer system A represents any suitable processing device configured for a general purpose or a specific purpose. Examples of computer system A include a server a personal computer a laptop computer a tablet computer a personal digital assistant PDA a mobile telephone and an audio video device. The components of computer system A i.e. processor packages memory system input output devices display devices peripheral devices network devices and interconnections may be contained in a common housing not shown or in any suitable number of separate housings not shown .

Processor packages include hardware threads M . Each hardware thread in processor packages is configured to access and execute instructions stored in memory system . The instructions may include a basic input output system BIOS or firmware not shown an operating system OS a runtime platform applications and resource management layer also shown in . Each hardware thread may execute the instructions in conjunction with or in response to information received from input output devices display devices peripheral devices and or network devices .

Computer system A boots and executes OS . OS includes instructions executable by hardware threads to manage the components of computer system A and provide a set of functions that allow applications to access and use the components. In one embodiment OS is the Windows operating system. In other embodiments OS is another operating system suitable for use with computer system A.

Resource management layer includes instructions that are executable in conjunction with OS to allocate resources of computer system A including hardware threads as described above with reference to . Resource management layer may be included in computer system A as a library of functions available to one or more applications or as an integrated part of OS .

Runtime platform includes instructions that are executable in conjunction with OS and resource management layer to generate runtime environment and provide runtime functions to applications . These runtime functions include a scheduler function as described in additional detail above with reference to . The runtime functions may be included in computer system A as part of an application as a library of functions available to one or more applications or as an integrated part of OS and or resource management layer .

Each application includes instructions that are executable in conjunction with OS resource management layer and or runtime platform to cause desired operations to be performed by computer system A. Each application represents one or more processes such as process as described above that may execute with scheduler that uses local collections N as provided by runtime platform .

Memory system includes any suitable type number and configuration of volatile or non volatile storage devices configured to store instructions and data. The storage devices of memory system represent computer readable storage media that store computer executable instructions including OS resource management layer runtime platform and applications . The instructions are executable by computer system to perform the functions and methods of OS resource management layer runtime platform and applications described herein. Examples of storage devices in memory system include hard disk drives random access memory RAM read only memory ROM flash memory drives and cards and magnetic and optical disks.

Memory system stores instructions and data received from processor packages input output devices display devices peripheral devices and network devices . Memory system provides stored instructions and data to processor packages input output devices display devices peripheral devices and network devices .

Input output devices include any suitable type number and configuration of input output devices configured to input instructions or data from a user to computer system A and output instructions or data from computer system A to the user. Examples of input output devices include a keyboard a mouse a touchpad a touchscreen buttons dials knobs and switches.

Display devices include any suitable type number and configuration of display devices configured to output textual and or graphical information to a user of computer system A. Examples of display devices include a monitor a display screen and a projector.

Peripheral devices include any suitable type number and configuration of peripheral devices configured to operate with one or more other components in computer system A to perform general or specific processing functions.

Network devices include any suitable type number and configuration of network devices configured to allow computer system A to communicate across one or more networks not shown . Network devices may operate according to any suitable networking protocol and or configuration to allow information to be transmitted by computer system A to a network or received by computer system A from a network.

In the embodiment of each processor package R and respective memory device R form a node. The nodes are interconnected with any suitable type number and or combination of node interconnections .

Each processor package includes a set of hardware threads where each hardware thread includes an L1 level one cache not shown . Each processor package also includes a set of L2 level two caches that correspond to respective hardware threads . Each processor package further includes an L3 level three cache available to the set of hardware threads a system resource interface a crossbar switch a memory controller and a node interface . System resource interface provides access to node resources not shown . Crossbar switch interconnects system resource interface with memory controller and node interface . Memory controller connects to a memory device . Node interface connects to one or more node interconnections .

With reference to the embodiments described above in scheduler may attempt to exploit memory locality effects in computer system B using local collections . For example when a task executing on an execution context on hardware thread via a virtual processor unblocks a task with an execution context at least some data that the task will consume is likely in the L1 cache not shown L2 cache and or L3 cache of processor package . By assigning the unblocked task to local collection scheduler increases the likelihood that the task will be executed by hardware thread via virtual processor and exploit the hot data in the L1 cache not shown L2 cache and or L3 cache .

The use of local collections in schedulers as described above may provide a scheduler with the ability to weight the execution of wait dependent execution contexts and maximize memory locality effects between wait dependent execution contexts. As a result the scheduler may increase the likelihood that wait dependent execution contexts will be executed on the same hardware resource.

In addition by including selected work stealing concepts into the above embodiments the scheduler may preserve fairness and forward progress amongst the execution contexts.

The local collections may also reduce contention between processing resources that are searching for execution contexts to execute. As a result the scheduler may also scale to computer systems with a large number of processing resources.

Although specific embodiments have been illustrated and described herein it will be appreciated by those of ordinary skill in the art that a variety of alternate and or equivalent implementations may be substituted for the specific embodiments shown and described without departing from the scope of the present invention. This application is intended to cover any adaptations or variations of the specific embodiments discussed herein. Therefore it is intended that this invention be limited only by the claims and the equivalents thereof.

