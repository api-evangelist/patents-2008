---

title: Machine translation using language order templates
abstract: Many machine translation scenarios involve the generation of a language translation rule set based on parallel training corpuses (e.g., sentences in a first language and word-for-word translations into a second language.) However, the translation of a source corpus in a source language to a target corpus in a target language involves at least two aspects: selecting elements of the target language to match the elements of the source corpus, and ordering the target elements according to the semantic organization of the source corpus and the grammatic rules of the target language. The breadth of generalization of the translation rules derived from the training may be improved, while retaining contextual information, by formulating language order templates that specify orderings of small sets of target elements according to target element types. These language order templates may be represented with varying degrees of association with the alignment rules derived from the training in order to improve the scope of target elements to which the ordering rules and alignment rules may be applied.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08150677&OS=08150677&RS=08150677
owner: Microsoft Corporation
number: 08150677
owner_city: Redmond
owner_country: US
publication_date: 20080626
---
Machine translation techniques involve a translation of a source corpus in a source language to a target corpus in a target language e.g. a source passage in the English language to a target passage in the Spanish language. Such machine translation techniques often involve choosing elements of the target language that match respective elements of the source corpus and may be facilitated by referencing a translation set such as a unidirectional or bidirectional dictionary.

Many types of machine translators may be devised by designing a learning algorithm such as an artificial neural network or an expert system and training the algorithm against a training data set such as many corpora of the source language associated with equivalent narrowly tailored corpora of the target language e.g. an English language passage and a word for word translation to a Spanish passage. By training against a sufficiently large training data set the machine translator may be equipped with a set of translation heuristics and or configured with a desirable selection of translation parameters that guide the searching and translating techniques.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

A significant challenge for many machine translation scenarios arises from the syntactic constraints of the source language and the target language. Specifically an accurate translation involves not only a selection of elements in the target language that are acceptably equivalent to the elements of the source language but also an ordering of the elements to satisfy the standards of the target language. Different languages may have different rules for correctly ordering the elements of the language so it may not be acceptable to order the translated elements of the target language according to the ordering of elements in the source language.

Many machine translation techniques attempt to derive translation and ordering heuristics together from the training data set and thereby formulate one or more rules that capture both features e.g. a rule that old man in English translates to hombre viejo in Spanish both in choice of words and ordering. However combined rules may be overly specific and may be difficult to generalize to cover many syntactic variations e.g. if similar ordering is a prerequisite of a rule for a translation of old man then old and very wise man may not detected by the same rule. 

An alternative technique for improving the applicability of translation rules and heuristics involves generating ordering rules from the training data set apart from a any element translation and b alignment rules generated therefrom. The ordering rules may be formulated as templates specifying an ordering of element types in the target language e.g. analyzing the Spanish phrase hombre viejo may result in an ordering template of noun adjective for the ordering of such word types as opposed to the adjective noun ordering in the analogous English phrase old man. The training may therefore result in a set of small ordering templates that may inform the ordering of elements translated from the source corpus into the target language. Moreover deriving small ordering templates may facilitate the combination of such templates to cover a wider range of linguistic structure in the source corpus. For example a first Spanish language ordering template specifying a noun adjective ordering and a second Spanish language ordering template specifying an adverb adjective ordering may be utilized to order the phrase very old man correctly as noun adverb adjective or hombre muy viejo. The ordering of elements may be performed in many ways and may be combined with other aspects of the translation such as the aligning of elements to provide additional improvements in machine translation.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

Machine translation techniques may be developed with a proficiency at translating from a source corpus specified according to a source language to a target corpus specified according to a target language. The corpora may comprise e.g. a human readable document such as a news article a computer readable document such as a programming language or a data set such as an image structured according to one language e.g. pixels in a two dimensional image representation and to be used as the basis for generating an image structured according to another language e.g. voxels in a three dimensional image representation. 

Machine translation techniques often involve the training of a learning algorithm such as an artificial neural network using training corpora such as a corpus in the source language and a semantically equivalent translation of the corpus in the target language. For example a Spanish to English machine translator may be trained using a set of Spanish sentences with semantically equivalent English translations. The machine translator may therefore be trained to recognize semantically equivalent aspects of the translation between the languages e.g. the rules for inserting the English articles a an and the in a target English sentence in view of the contents of the source Spanish sentence.

Syntax based machine translation techniques extend these concepts with the use of an external parser that breaks the source corpus into a sequence of elements annotates each element with an element type such as a part of speech e.g. noun verb or determiner and identifies another element in the corpus that is semantically superior to the element. This information is synthesized as a dependency tree representing the relationships between the elements of the corpus with the predominantly superior element positioned as the root node of the tree. A syntax based machine translator learns rules that involve a syntactic representation e.g. a pair of dependency trees representing the corpora. A syntax directed translator operates on a parsed representation of the source language. One approach for syntax directed translation involves the use of top down transduction rules which are formulated as a source language tree and a target language tree each comprising two types of nodes an element type node specifying an element type in the language represented by a tree and may have other children or a variable that corresponds to a variable in the other tree and has no child nodes. A transduction rule may be found to match a dependency tree at a given node if we can find a correspondence from each element of the of the transduction rule to a node of the dependency tree e.g. if the rule node has a lexical item then this lexical item matches that of the input tree node and all children of that input tree node have a correspondence with some lexical item node. Such rules can be applied to transduce the source tree into a target tree.

A translation technique based on the use of transduction rules may transform an input tree structure into an output tree structure using a tree transducer which is a set of small mappings that can transform trees by recursive application. For example we might start with an operator tree 2 3 4 to represent the mathematical expression 2 3 4 . Each operator and takes a list of children as arguments and represents the action of adding or multiplying their values. A tree transducer is composed of a set of rules each of which has a left hand side tree containing 0 or more distinct variables each of which has no children and a right hand side with an equivalent set of variables again with no children each such rule describes how a tree may be transformed. For example one such ruleset might be X Y Z X Y X Z 2 2 3 3 4 4 which distributes multiplication across addition. A rule matches a given input tree at a given node via a mapping from the rule left hand side nodes to the input tree nodes such that each input node is either a mapped to by a variable or b has the same label as the node mapped to it and all its children are also mapped to by some other rule node. To apply a ruleset to an input tree we find a rule that matches the root node then replace the input tree by the right hand side of the rule with each variable replaced by the result of recursively applying the transducer. Returning to the example ruleset from above we can transduce the input tree 2 3 4 into the output tree 2 3 2 4 . Often many rules may match at a given node. We can also associate a score with each rule in a transducers ruleset that represents the goodness of that rule.

Some techniques use treelet translation involving a treelet that comprises a connected set of subnodes of the dependency tree. Treelet translation extracts pairs of source and target treelets from the parallel training data. First the source training corpus is parsed into dependency trees and the target training corpus is separated into a sequence of elements. An alignment between the source elements and target elements is computed according to element alignment techniques. Based on this alignment candidate treelet translation pairs are evaluated if all of the elements of a candidate source treelet align to a at least one element in the target training corpus and that set of target elements is aligned only to the source treelet then the candidate treelet pair is extracted. This evaluation is performed across the training corpora and a set of pairs along with is compiled along with a frequency with which each treelet pair arises in the training corpora. Finally a probability for each source language treelet is computed given the source treelet is computed by dividing the count of times the pair occurred by the number of times that the source treelet arises. Given an input parse structure such as a dependency tree a treelet translation pair may contain sufficient information to translate a subset of the elements and specifies the relative order between them. However treelets are underspecified with respect to transduction rules because they do not specify the ordering of uncovered children. Therefore the process of finding the best translation is often much more computationally intensive than that of transduction approaches since a large number of potential reorderings are considered during the search.

To bridge the gap between treelet translation pairs and transduction rules while enabling a faster translation order templates may be devised which are simple single level transduction rules that specify the ordering of element types of the elements of the corpora and that specify the ordering of the children of a given node relative to its parent. According to this technique the training produces a language translation mapping set that serves to guide the translation of future source corpora into target corpora and or vice versa. The information embodied in the language translation rule set includes treelet translation pairs for translating lexical items from the first language to the second language e.g. for choosing the Spanish term hombre for the English term man and vice versa. In addition the language translation mapping set contains order templates that specify the ordering of target language child nodes with respect to their parent nodes given a match on element types in the source language.

One significant aspect of translation that may be involved in generating a correct target corpus is the ordering of translated elements. A machine translator may perform an element for element translation of the source corpus according to many techniques but assembling the resulting elements of the second language in an acceptable order may be difficult. For example the English language sentence a very old man may be correctly translated into the Spanish language sentence un hombre muy viejo but a word for word back translation to English produces the jumbled English language phrase a man very old. Different languages may involve different rules for the ordering of elements and a machine translation that does not select an adequate ordering of the elements may produce an incorrect jumble of elements. For example the ancient Latin language specified a subject object verb ordering and complex phrases of many words might separate the subject and object from the verb at the end of a sentence. Back translating an ancient Latin corpus such as alterius non sit qui suus esse potest to English correctly translated as let no man belong to another who can belong to himself without language based reordering might result in a jumbled phrase such as another not belong who to himself is able. 

Some techniques attempt to model translation ordering heuristics within the rules that also facilitate translation. For example a training algorithm may be devised to select fragments from a parallel corpus e.g. old man and to generate rules that both specify element translations into the target language e.g. old translates to viejo and man translates to hombre and also the ordering of the translated elements e.g. specifying an ordering of the elements selected for man followed by the elements selected for old . In this manner the training may produce a language translation rule set comprising rules that specify both translation of small phrases and the ordering of the translated elements. However the representation of both facets of the translation process in one rule may limit the generality of the rules. For example it may be difficult to extend the rule specifying an ordering and translating of the English phrase old man to other phrases such as old and wise man because the rule may be evaluated as adjective noun element types while the phrase to be translated comprises adjective conjunction adjective noun element types. In order to cover the full range of linguistic constructs in either language a language translation rule set may comprise a large number of such rules each applying only to a small set of fragments having very similar elements in a predefined order. The large number of rules therefore increases the duration of the search while parsing a first language corpus and also increases the potential for search error leading to less accurate translations.

An alternative translation technique involves a distinction between the selection of elements for translation and the ordering of elements in the resulting translation. According to this alternative technique from the parallel corpus old man hombre viejo two types of rules may be derived an alignment rule that translates the elements of the phrase old man as respectively viejo and hombre and an ordering rule that organizes adjective noun element types of the target Spanish corpus by ordering the noun before the adjective. Because these rules represent distinct types of linguistic information the rules gleaned from the parallel corpus may be generalized in several ways by specifying the selection of target language elements viejo and hombre for similar first language phrases e.g. very old man strong old and wise man and elderly man and by specifying the ordering of the adjective viejo after the noun hombre in phrases including the phrase old man e.g. hombre muy viejo and hombre fuerte viejo y sabio . The rules could also be extrapolated to inform similar phrases e.g. using a similar noun adjective ordering for the phrase young boy to produce muchacho joven . Thus this alternative technique involves a looser coupling of the alignment information of first language elements to second language elements and the ordering information of the second language elements so produced. However the alignment and ordering are not necessarily decoupled and applied in isolation. For example the alignment analysis may inform the ordering of elements such as by producing a dependency tree that defines the subordinate relationships of the elements which may facilitate selections of ordering rules that might otherwise be ambiguous. For example in the phrase old very wise man the alignment analysis may associate the adverb very with the adjective wise instead of the adjective old which may facilitate a selection of a correct ordering hombre viejo y muy sabio rather than the ordering hombre muy viejo y sabio which translates incorrectly to very old wise man. The representation of the ordering templates with respect to the translation and alignment rules may improve the context sensitivity of the application of the language translation rule set while preparing the target corpus.

According to this technique the training of the machine translator may produce ordering templates that indicate how certain element types are ordered in a target corpus that complies with the specifications of the target language. These ordering templates might be represented alongside the alignment and translating rules to include contextual information that may be utilized to produce more accurate translations while also not unduly restricting respective rules to a narrow set of linguistic constructs. This organization therefore imparts flexibility on the rules that reduces the number of rules covering the full range of lexical constructs in either language reduces the duration of the search during a translation of a corpus and reduces the possibility of search error.

In the exemplary training scenario of a training algorithm is directed to a parallel training data set which comprises a set of three parallel fragment pairs having a source training corpus and a parallel target training corpus . As illustrated in the source language is English and the target language is Spanish and the elements of the source training corpus and the parallel target training corpus comprise respectively words written in an English sentence and a word for word translation into an equivalent Spanish sentence. The exemplary training scenario illustrates a parse of the parallel training data set to produce parallel element aligned dependency trees for each corpus in the training data. From these parallel element aligned dependency tree is extracted a language translation rule set comprising at least two types of rules derived from the parallel training data set treelet translation pairs for selecting Spanish lexical items given English lexical items and order templates for selecting an acceptable ordering of Spanish elements given an English tree structure and element types. As illustrated in this exemplary training scenario the alignment rules are specified as dependency treelet translation pairs that specify a hierarchical relationship between various elements. The information represented by a dependency treelet translation pair includes only relative ordering between words included in the treelets as well as a superior and subordinate lexical relationship between elements which may facilitate the translation and parsing of the source training corpus . Moreover the dependency treelet translation pairs illustrated in are configured with a tree structure which may be handled in modular fashion and concatenated to produce a linguistic hierarchy of arbitrary depth and breadth.

As further illustrated in the exemplary training scenario of the language translation rule set also comprises language order templates each specifying an ordering of the direct children of a given target element relative to that element given a matching parent and child set on the source side. The ordering is based not on the ordering of specific elements such as particular Spanish words but rather on element types in the source language such as the parts of speech of the English language. The language order templates are inferred from parallel element aligned dependency trees by picking each pair of aligned source and target elements and tracking the order and element types of the source parent and all its direct children the order of the target parent and all its children and the correspondence between the two. The language order templates may identify the ordering of particular elements of the target language given a particular set of source side matches but may also be used to choose an ordering for similar elements e.g. a particular language order template may indicate that Spanish adverbs similar to muy and Spanish adjectives similar to importante may be ordered in adverb adjective order. In this manner each language order template may be generalized to specify an ordering of a large number of contextually similar elements of the target language. Moreover the breadth of generalization may be of many degrees between narrow e.g. only specifying ordering of synonyms of particular elements and broad e.g. specifying ordering of any words of the same parts of speech. The scope of generality therefore permits a preservation of the context in which the language order template is applicable while not unduly constraining the template to the elements of the target corpus fragment from which it is derived.

It may be appreciated that the inference of language order templates involves an evaluation of orderings among related elements. For example language order templates may be devised to represent the ordering in Spanish of the English words a and book and of the English Spanish words very and old because such words are lexically related however no language order template is generated for ordering a and sold or book and very because these words are not related. Thus the induction of ordering information that informs the generation of language order templates utilizes similar information used in the generation of the dependency treelet translation pairs . Accordingly the language order templates may be developed utilizing the relationship determinations made during the generation of the dependency treelet translation pairs . The language order templates may also be defined with reference to particular dependency treelet translation pairs e.g. the language order template defining an ordering of verb adjective may be defined with relation to the dependency treelet translation pair defining the relationships between es and importante. This definition of the language order templates in view of one or more dependency treelet translation pairs promotes the preservation of contextual information e.g. verb adjective may be a correct pairing for the intransitive verb es but other verbs may be associated with different orderings with respect to other element types. Moreover the language order templates may be modularly represented such that a series of language order templates may be selected to determine a correct ordering for a longer sequence of elements of the target language. In this manner the exemplary training scenario of illustrates the generation of translation and aligning rules such as dependency treelet translation pairs as well as language order templates based on the parallel training data set .

The techniques illustrated in may be implemented in many embodiments. illustrates one embodiment that incorporates some of the techniques utilized in the exemplary training scenario of illustrated here as an exemplary method of generating a language translation rule set comprising at least one language order template using at least one source training corpus in a source language aligned with a parallel target training corpus in a target language. The exemplary method begins at and involves evaluating respective parallel training corpora in the following manner. First the exemplary method involves parsing the source training corpus to identify element types for respective elements of the source training corpus such as the identifying of parts of speech of the words of the source training corpora . The exemplary method also involves generating a parse tree mapping the elements of the source training corpus to the elements of the target training corpus. The exemplary method then involves generating at least one candidate treelet translation pair based no the parse tree and generating at least one candidate order template based on the parse tree and the element types of the source training corpus. After evaluating the parallel training corpora the exemplary method generates the language translation rule set by selecting treelet translation pairs from the candidate treelet translation pairs and by selecting order templates from the candidate order templates. By generating an acceptable set of treelet translation pairs and order templates based on the analyses of the parallel corpora the exemplary method thereby achieves the generation of a language translation rule set and so ends at .

The techniques discussed herein may be devised with variations in many aspects and some variations may present additional advantages and or reduce disadvantages with respect to other variations of these and other techniques. Moreover some variations may be implemented in combination and some combinations may feature additional advantages and or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments e.g. the exemplary method of and the exemplary method of to confer individual and or synergistic advantages upon such embodiments.

A first aspect that may vary among embodiments of these techniques relates to the manner of building the language order templates and incorporating them in the language translation rule set. As discussed with reference to the language order templates define the ordering of various element types of various target elements and may be specified with reference to particular elements of the target language e.g. a particular language order template may indicate that adverbs similar to very and adjectives similar to important may be ordered in Spanish in adverb adjective order. The breadth of generalization may be adjusted to improve the heuristic fit with the target language. As one example the breadth of individual language order templates may be individually adjusted e.g. while evaluating the target training corpora a training algorithm may extend the breadth of a language order template that appears to be followed in many target corpora and may narrow the breadth of a language order template that only appears to apply to a small and well defined set of target language elements.

A second variation of the training may involve extending various language order templates to fit larger sets of target elements such as longer phrases of parts of speech in a target language. Where two or more language order templates are frequently utilized concurrently a composite language order template may be generated that combines the ordering of the elements. Accordingly techniques for generating language order templates may identify an ordering of target element types comprising at least one element type specified by a first language order template and at least one unspecified element type i.e. an element type that is not included in the first language order template where an opportunity exists to create a larger language order template. In this circumstance a second language order template may be generated comprising the first language order template and including in the ordering the unspecified element types and the second language order template may be added to the language translation rule set. illustrates an exemplary language order template updating scenario wherein a first language order template specifying a determiner noun ordering and a second language order template specifying a noun adjective ordering may be combined to produce a third language order template specifying a determiner noun adjective ordering. Such composite rules expand the size of the language translation rule set but may facilitate the machine translation by specifying the ordering of larger sets of element types while applying fewer rules to the target elements.

A third variation of the training involves deriving other types of information from the target training corpora while generating the language order templates which results in a language translation rule set comprising various types of information along with the ordering. The language translation rule set may include information for selecting aligned elements of the target language to match elements of the source language for identifying hierarchical relationships between elements and or for identifying element types such as parts of speech of the elements. As a first example in addition to generating the language order templates the training may also generate an alignment model of the source language and the target language according to the source training corpora and the parallel target training corpora which may be added to the language translation rule set . As illustrated in the alignment model may comprise at least one dependency treelet translation pair that aligns source elements with target elements and that defines superior subordinate relationships between such elements and element types. Moreover such additional rules may be related to the language order templates e.g. the language order templates may be specified with contextual reference to the elements of a particular dependency treelet translation pair .

As a second example the training may generate not only language order templates but also source language order templates that specify the contextual ordering of element types in the source language based on analyses of the source training corpora . These source language order templates may be derived in a similar manner to the generation of the language order templates i.e. by identifying element types for respective source elements of the source language generating source language order templates specifying an ordering of at least two element types according to the source training corpus and adding the source language order template to the language translation rule set. The source language order templates may be useful e.g. for creating a bidirectional language translation rule set that can also translate from the target language back to the source language and or for additionally informing the translation from the source language to the target language with linguistic information derived from a source corpus e.g. hierarchical relationships and element types defined among the elements of the source corpus. The source language order templates may also be useful where an ordering of language elements cannot be identified e.g. where two language order templates are in conflict or where the ordering is ambiguous. In this case a language order template may be generated based on the ordering of target elements aligned with source elements specified in at least one source language order template e.g. by specifying an ordering based on the ordering of analogous element types in the source language order template for the parallel source corpus. This might not be a completely accurate ordering but it may be preferable to have a somewhat accurate ordering of such elements in the target language than not having a language order template that can parse the combination of element types. Those of ordinary skill in the art may devise many types of rules and information that may be added to the language translation rule set in addition to the language order templates during the training of the machine translator on the parallel training data set in accordance with the techniques discussed herein.

A second aspect that may vary among implementations of these techniques relates to the translation of a source corpus to a target corpus using the orderings specified by the language order templates in the language translation rule set. The exemplary translation scenario of represents but one of many types and organizations of machine translation techniques and the techniques discussed herein relating to the use of language order templates may be incorporated in many aspects of the translation. A first variation relates to the use of an alignment model such as a set of dependency treelets for example the language translation rule set may include an alignment model of the source language and the target language and the selecting may comprise selecting target elements aligned with source elements of the source corpus according to the alignment model. The alignment model may be generated during the training whereby the language order templates are generated or may be generated through a separate training etc. Many types of alignment models may be generated and utilized in this manner e.g. the alignment model may comprise at least one dependency treelet aligning source elements with target elements. Accordingly and as illustrated in the selecting may comprise identifying at least one dependency treelet matching the source elements and selecting the target elements of the dependency treelet . Moreover if the language order templates are specified in relation to the dependency treelets the choosing may be performed by choosing at least one language order template specifying an ordering in the target language of at least two element types of the target elements and specifying at least one element type for respective target elements of the dependency treelet . As a second example of this variation the alignment model may specify an alignment probability between at least one source element and at least one target element e.g. dependency trees may be generated along with a weight that induces a preference for the selection of more common or useful dependency trees over less common or useful dependency trees. In this scenario the selecting may involve selecting target elements that are aligned with source elements e.g. via a dependency treelet that together present acceptable alignment probabilities according to the alignment model. Many variations in the generating and use of the alignment models and in the relationships of the alignment models to the language order templates may be devised by those of ordinary skill in the art while implementing the techniques discussed herein.

A second variation of the translating involves a continuation of the training and the refinement of the language translation rule set during the translation. As one example the language translation rule set may be supplemented with additional language order templates to cover newly encountered linguistic constructs e.g. where the machine translator identifies an ordering of target element types that is not specified by a language order template. In this circumstance the machine translator may generate a new language order template that specifying an ordering of the target element types in the target language and may add the new language order template to the language translation rule set. For example if the machine translator identifies a frequent pairing of language order templates e.g. a noun adjective language order template and an adverb adjective language order template during the translating it may generate a new language order template specifying the ordering e.g. noun adverb adjective ordering and add it to the language translation rule set. Many ways of updating the language translation rule set during the translating may be devised by those of ordinary skill in the art in accordance with the techniques discussed herein.

A third variation of the translating relates to the inclusion of source language order templates. Whereas the language order templates specify the ordering of elements of the target corpus based on the grammatic constraints of the target language the source language order templates specify the ordering of elements of the source corpus based on the grammatic constraints of the source language. The source language order templates may be generated and added to the language translation rule set based on analyses of the source training corpora and may contribute to the translating in many ways. As a first example of this third variation the source language order templates may be used to resolve ambiguities in the source corpus where two possible interpretations may be derived based on two different selections of source elements. For example English phrases involving the words man and walking may be parsed either as a noun verb combination the man is walking or as an adjective noun combination the walking man crossed the street and the ambiguity may be resolved with reference to source language order templates that indicate the more likely construction based on the ordering of the elements. Accordingly the source language order templates may be used to verify identified element types against at least one source language order template matching the element types of the source elements of the source corpus e.g. the aligning of elements according to the alignment model may be verified by checking the hierarchical relationships such as defined by dependency treelets against the source language order templates to verify a desirably accurate ordering.

As a second example of this third variation the source language order templates may be used to order elements of the target language that cannot be adequately ordered by the language order templates. For example an unusual linguistic construct such as an unusual turn of phrase may result in a selection of target elements that are not covered by the language order templates and the machine translator may fail to choose a language order template specifying an ordering in the target language of at least two element types of the target elements. In this circumstance the machine translator may choose an ordering of the target elements reflecting the ordering of the source elements in the source language by identifying source elements aligned with the target elements and choosing source language order templates that specify an ordering in the source language of at least two element types of the source elements. The ordering information may be used directly to order the elements of the target corpus or may be used to generate a new language order template that adequately specifies the ordering of the target elements. Those of ordinary skill in the art may devise many uses of source language order templates to facilitate the machine translation of a source corpus into a target corpus in accordance with the techniques discussed herein.

A third aspect that may vary among implementations of these techniques relates to the manner of performing the ordering. It may be appreciated that the modular representation of the language order templates may be applied to the set of aligned target elements which may be organized according to a dependency tree in many ways and that the sequence of applying the language order templates may lead to semantically different translations e.g. old and very wise man vs. very old and wise man. The choice of language order templates may therefore resemble an iterative search wherein a first language order template is chosen from the language translation rule set to order at least two target elements a second language order template is chosen to align at least one not yet ordered target element with respect to one already ordered target element etc. This iteration may continue until the chosen language order templates adequately cover the set of target elements such that a properly ordered target corpus may be generated. Moreover it may be desirable for any iteration to test multiple language order templates and to evaluate the remainder of the iterative process if respective language order templates are chosen. Thus the choosing of language order templates may be performed as a recursive search which may evaluate the search space of order templates for sequences of orderings that produce a desirable target corpus.

It may be appreciated that an exhaustively recursive search of this nature may be computationally intensive e.g. if the number of target elements is large if the types of the target elements are varied and or if the number and complexity of the language order templates are large. Therefore in many embodiments the recursive search may be adjusted to pare down the search space e.g. by omitting the evaluation of sequences that do not appear likely to produce favorable orderings and or by recursively evaluating more promising partial orderings before less promising partial orderings. One such example involves a formulation of the recursive search as a beam search wherein at any stage of recursion only a small number of promising candidates are chosen for evaluation at the next stage of recursion. A beam search may be advantageous due to the search parameters that may be adjusted to improve the speed and accuracy of the search. As a first example the beam search may be constrained for respective chosen language order templates by a maximum of recursively evaluated language order templates. As a second example where the language order templates comprising an ordering probability e.g. specifying that the noun adverb verb ordering is a more preferable or common ordering than an noun verb adverb ordering the beam search may be constrained by a minimum ordering probability for recursively evaluated language order templates and or a maximum of recursively evaluated language order templates before ordering the target elements according to the ordering specified by the at least one chosen language order template together having an acceptable ordering probability. Those of ordinary skill in the art may be able to devise many types of recursive searches and adjustments thereof that may be suitable for recursively evaluating the choosing of language order templates in accordance with the techniques discussed herein.

These and other variations of the aspects discussed herein may be incorporated in various embodiments such as the exemplary method of and the exemplary method of . Moreover such embodiments may include combinations of such variations which may operate independently to produce multiple advantages and or cooperatively produce synergistic advantages. For example the translation of a source corpus to a target corpus may be viewed as an end to end method involving both the training of the machine translator e.g. by generating a language translation rule set including target language translation templates from a set of source training corpora and parallel target training corpora and the translation of the source corpus using the target language translation templates for ordering the aligned target elements. Moreover the end to end method may generate an alignment model during the training such as a set of dependency treelets and may utilize the dependency treelets during the translation and ordering and or may generate a set of source language order templates which may be used e.g. to verify the dependency treelet and or to specify orderings of target element types that are not covered by the language order templates etc. Additionally the language order templates may be supplemented during the translating e.g. by generating new language order templates to specify orderings of newly encountered combinations of target element types etc. Many such combinations of the variations of the aspects discussed herein may be devised by those of ordinary skill in the art while implementing the techniques to achieve the translation and ordering of the source corpus according to the language order templates.

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply the techniques presented herein. An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to the principles set forth herein. In one such embodiment the processor executable instructions may be configured to perform a method of generating a language translation rule set comprising at least one language order template using at least one source training corpus in a source language aligned with a parallel target training corpus in a target language such as the exemplary method of . In another such embodiment the processor executable instructions may be configured to implement a method of translating a source corpus in a source language into a target language using a language translation rule set comprising at least one treelet translation pair and at least one language order template such as the exemplary method of . Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

