---

title: File format extensibility for universal rendering framework
abstract: Embodiments of the invention provide a method for extending a graphics rendering framework. A rendering application locates a first file that includes a first implementation involving a first graphics material and compares data associated with the first file to data associated with a second file that includes a second implementation involving a second graphics material. The rendering application compares data associated with the first and second files, determines that the first graphics material matches the second graphics material, and determines that the first implementation is different from the second implementation. The data associated with the first file and the data associated with the second file are then combined into a data structure. Advantageously, new graphics materials, and implementations for existing graphics materials, may be created without access to the source code of the original implementation of the graphics materials and may be installed at a later time without re-shipping the entire library of graphics materials and implementations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08212806&OS=08212806&RS=08212806
owner: AUTODESK, Inc.
number: 08212806
owner_city: San Rafael
owner_country: US
publication_date: 20080408
---
The present invention generally relates to computer software. More specifically the present invention relates to a rendering application configured to perform a renderer agnostic method for representing graphics assets independently from an underlying rendering engine.

The term computer aided design CAD refers to a broad variety of computer based tools used by architects engineers animators video game designers and other graphics and design professionals. CAD applications may be used to construct computer models or drawings representing virtually any imaginable two dimensional 2D or three dimensional 3D construct. A rendering application may then be used to generate an image from a CAD model. Rendering is also used to describe the process of calculating effects in a video editing file to produce a final video output.

A rendering application can simulate the appearance of real world textures colors surface shadows highlights and reflections by giving the final appearance to the models and animations. As a product rendering applications come in many forms. Some rendering applications are integrated into larger modeling animation simulation and CAD packages while others are stand alone applications. Functionally a rendering operation is based on a mixture of techniques related to light physics visual perception mathematics and software development.

Rendering applications can be implemented in hardware or software. In the case of software rendering frequently used for motion picture creation the actual rendering operation is a computationally intensive process. Typically animation software rendering is not done in real time because the time to render a single frame is longer than the time that frame is displayed. However software based rendering may produce very high quality images as the renderer is not constrained by frame rate requirements. In contrast real time rendering is frequently used in video games and is often implemented on graphics cards with 3D hardware accelerators.

Software based rendering engines include Maya StudioMax RenderMan Vray and Mental Ray among others. Similarly sophisticated 3D graphics APIs such as DirectX and OpenGL may be used to control hardware based graphics rendering pipelines. Given this assortment of available rendering tools each having unique advantages and disadvantages users often desire to use one rendering engine for certain purposes and another rendering engine for other purposes. For example Mental Ray provides a ray tracing rendering tool while RenderMan provides a scanline based rendering tool. Depending on the desired effect the user may favor one of these rendering approaches over the other.

Typically to switch between rendering engines the user must understand the interface and configuration for each rendering engine. For example to achieve a desired rendering effect using Mental Ray the user specifies a dynamic library to be loaded a Mental Ray file describing an interface to a shader and a set of parameters. Switching to a different rendering engine e.g. RenderMan may require the user to specify a completely different set of libraries files and parameters corresponding to that other rendering engine. Furthermore the users of these rendering tools oftentimes do not have a high degree of sophistication in computer programming. For example architects illustrators and engineers who may be familiar with the desired properties of rendered surfaces e.g. whether a painted wall surface should have a glossy or matte appearance or how graveled a concrete pathway should appear may nonetheless lack an understanding of the rendering interface and configuration needed to achieve these effects using a particular rendering engine.

Currently attempts at high level rendering frameworks do not allow for the implementation of different rendering engines. For example Autodesk ImageStudio makes use of user facades to make rendering more user friendly. However ImageStudio does not allow for the implementation of multiple renderers.

Also Mental Images MetaSL in conjunction with the Mental Mill application allows users to write a shader once and then translate the shader into an appropriate language for rendering using a particular rendering implementation. However Mental Mill requires users to implement the shaders in a meta language that is then translated into the rendering engine language. A further limitation of Mental Mill is that the source code for translating the meta language into the particular rendering engine language is stored in a single file that the original author users third parties and customers cannot edit easily. For example the original author cannot easily extend the shipped file. A third party or an end user typically cannot augment a file shipped by someone else. Thus once a MetaSL version is shipped by Mental Images the MetaSL file cannot be subsequently extended to provide support for additional materials or rendering engines without the user or customer being provided the source code.

Accordingly there remains a need in the art for a technique to efficiently extend rendering applications to enable additional materials to be rendered using an existing rendering engine or to enable existing materials to be rendered using a different rendering engine. Extending the rendering application is done after the rendering application has shipped and independent of third parties who would not normally coordinate their work.

Embodiments of the invention provide a method for extending a computer framework. An application locates a first file that includes a first implementation involving a first asset and compares data associated with the first file to data associated with a second file that includes a second implementation involving a second asset. The application compares data associated with the first and second files determines that the first asset matches the second asset and determines that the first implementation is different from the second implementation. The data associated with the first file and the data associated with the second file are then combined into a data structure.

Advantageously new assets and implementations for existing assets may be created without access to the source code of the original implementation of the assets and may be installed at a later time without re shipping the entire library of assets and implementations.

Additionally the components illustrated in may be implemented as software applications that execute on a single computer system or on distributed systems communicating over computer networks such as local area networks or large wide area networks such as the Internet. For example a graphical user interface may include a software program executing on a client computer system at one physical location communicating with rendering application at another physical location. Also in one embodiment rendering application and graphical user interface may be provided as an application program or programs stored on computer readable media such as a CD ROM DVD ROM flash memory module or other tangible storage media.

As shown a system includes without limitation rendering application graphical user interface scene file user input devices and a display device . Those skilled in the art will recognize however that the components shown in are simplified to highlight aspects of the present invention and that a typical rendering application and GUI interface may include a broad variety of additional tools and features used to compose and manage a design or drawing. Rendering application may be configured to allow users interacting with GUI interface to compose a graphical scene. Accordingly rendering application and GUI interface may include programmed routines or instructions allowing users to create edit load and save the scene file . User input devices may include a mouse pointing device a keyboard a joystick or a video game controller and the display device may be a CRT or LCD display.

As shown the scene file includes geometry and materials . Geometry defines the 3D structure or shape of elements included in a scene. For example the shape of a building or a human character. Typically the geometry is represented as a collection of polygons defined in a 3D space. As is known rendering applications frequently provide users with the ability to apply materials to the geometry in the scene file . A material is a set of reusable appearance attributes. Using pre defined materials from a library of materials allows users to quickly change the look and feel of the scene. Materials may be for example concrete brick wall paint or any other texture color or appearance. Materials are not limited to 2D and may also be volumetric such as noise and fog. Additionally materials may correspond to animation data or simulation data that is applied to geometry in the scene file .

Graphical user interface provides tools used to manipulate the scene file using rendering application including material parameter editing tools and rendering engine selection tools . Those skilled in the art will recognize however that the tools of GUI interface shown in are simplified to highlight aspects of the present invention and that a typical rendering application and GUI interface may include a broad variety of additional tools and features used to compose and manipulate the scene file .

Material parameter editing tools may provide graphical user interface elements that allow a user to edit the materials applied to a particular collection of geometry within a scene. The material parameter editing tools may allow the user to define and modify physical display animation simulation or meta properties of the material to be applied to the particular geometry in scene file generally referred to herein as material parameters. Examples of material display parameters include stroke weight overshoot spacing paper type hardness darkness angle arc transparency texture color color variation or any other parameters used to control the physical display animation simulation or meta properties of a material applied to the geometry within a scene. Different material parameters may be implemented based on the material being represented and the resulting application for which the scene is rendered. For example a material representing brick could include height width and grout thickness display parameters whereas a material representing wall paint could include color and finish display parameters. Additionally when using a simulation application rather than a rendering application physical properties of the material in addition to the display properties may be important to a user that desires the material to bend stretch or retain some other physical characteristics when the simulated geometry to which the material is applied is loaded into the simulation application. Physical properties of a material may include heat conductivity electrical conductivity how well the material responds to stress and the flexibility of the material and other physical characteristics.

In one embodiment the rendering engine selection tools may provide graphical user interface elements that allow a user to select a particular rendering engine implementation for rendering portions of the geometry from the scene file . For example assume that the rendering application is configured with three rendering engines each capable of rendering a particular material. Further each rendering engine may provide two implementations for rendering the material a first high speed low quality implementation and a second low speed high quality implementation. In this example there are a total of six implementations capable of rendering the particular material. In such a case the rendering engine selection tools allow the user to select which implementation to use for rendering a given image from a list of available implementations.

In another embodiment the rendering engine selection tools may automatically select which rendering implementation to use for rendering based on some user selected context preferences or profile. For example a user may select between high quality and low quality rendering and the rendering application determines which rendering implementation and which rendering engine is most appropriate for rendering the scene.

Each asset defines a framework for storing data to be used when executing an application program. Graphics assets define a framework for storing graphics data to be used when executing a rendering application. Graphics assets may represent graphics materials lights animation data or simulation data. Common examples of graphics materials represented by graphics assets include a painted wall material concrete materials metal materials glass materials and water materials etc. In one embodiment each object in a graphics scene is composed of one or more pieces of geometry e.g. a collection of triangles or polygons. Each piece of geometry may also be associated with a graphics asset to use in rendering that piece of geometry.

Each graphics asset may include strongly typed parameters representing the relevant characteristics of a given graphics asset. For example a graphics asset corresponding to a painted wall surface could include parameters for color application or brush type and finish. In a second example a graphics asset corresponding to a fluorescent light could include graphics parameters for light intensity or color temperature when rendering the asset. The fluorescent light asset could also include a physical parameter for wattage to be used by a simulation or animation application. Because the parameters of the graphics asset are strongly typed users can easily identify the characteristics to use in rendering or simulating a given graphics asset. The specific parameters for that graphics asset corresponding to an underlying rendering engine simulation engine or animation engine need not be known to the user.

In addition by strongly typing the parameters to the characteristics of the graphics asset the user interface objects may present the user with the appropriate user interface constructs regardless of the underlying implementation object or rendering engine implementations . For example continuing with the example of a graphics asset corresponding to a graphics material resenting a painted wall surface the user interface object may present the user the a color type parameter using interface elements that allow a user to specify an RGB color value a code reference to a manufacturer catalog or even sampled spectral values. Similarly the user interface objects may present the user with drop down lists for the application type and finish parameters. These drop down lists could present values for a painted surfed familiar to an architect or designer such as rolled sprayed brushed matte glossy satin etc. By decoupling the user interface from the graphics material the rendering framework enables different applications to adapt the user interface to the skills of the user. For example a typical Autodesk Revit user will prefer to enter colors from a catalog while an Autodesk 3ds Max user may prefer to enter RGB values.

Implementation objects provide an interface between a given graphics asset and a given rendering engine . Generally the implementation objects are configured to receive values for the strongly typed parameters and also to translate these values into an appropriate format for one of the rendering engine implementations to achieve a desired rendering effect. The translation may be a simple pass through such as in the case of passing of RGB color values but can also be a mapping from one value to another. That is depending on the desired rendering effect the underlying implementation object may generate multiple parameters from a single material parameter may indentify libraries files shader programs textures rendering parameters or any other values used by a particular rendering engine implementation to achieve a desired effect. By decoupling the rendering engine implementation from the graphics assets the rendering framework may be extended with additional rendering engine implementations by adding the appropriate implementation objects to each additional rendering engine to render existing graphics assets presented to the user through user object interface . Further the rendering framework is also designed to be easily extended with new materials for existing rendering engines as described in greater detail in below.

In addition to extending a rendering application to render graphics assets the framework applies to extending simulation or animation application. For example physical properties of assets may be matched to several simulation engines including multiple fluid simulators. A first fluid simulator may be optimized for speed and a second fluid simulator may be optimized for correctness.

As shown the method begins at step where the graphics application loads a graphics scene file containing geometry and graphics assets associated with the geometry. In one embodiment each object in a graphics scene is composed of one or more pieces of geometry e.g. a collection of triangles or polygons. Each piece of geometry may also be associated with a graphics asset to use in rendering that piece of geometry.

At step the rendering application displays editable graphics asset parameters for a first graphics asset. As discussed above each graphics asset may have different editable parameters based on the characteristics of the graphics asset.

At step the rendering application receives user input of graphics asset parameter values for the first graphics asset. The graphics asset parameter values may be input numerically chosen from a drop down menu or selected in another manner. Further in one embodiment the graphics asset parameter values may be pre set at default values for a given graphics asset and then modified by the user to achieve the desired effect.

At step the rendering application invokes a rendering engine implementation compatible with the first graphics asset and the graphics asset parameter values supplied at step . As described above multiple rendering engines and multiple rendering implementations for each rendering engine may be available for rendering the first graphics asset. In one embodiment the user may select the implementation and rendering engine to be invoked by the graphics application based on what implementations of the first graphics asset are available for a set of available rendering engines. Alternatively the rendering engine may be invoked by the graphics application based on a user selected context. For example the user may select high quality rendering or low quality rendering and the rendering application determines the appropriate rendering implementation to invoke when rendering.

In yet another embodiment the rendering application may invoke a different rendering implementation for each graphics asset to be rendered. Based on the context in which the user is rendering the rendering application may invoke an appropriate rendering engine and implementation. For example if rendering an interactive application and rendering into an interactive view then the rendering application may automatically invoke the fastest and lowest quality rendering implementation. Also if rendering offline the rendering application may invoke the highest quality implementation because rendering time may be less of a factor.

At step the rendering application translates the graphics asset parameter values into a format required for use with the rendering implementation selected at step . For example the implementation objects shown in may use a translation table that maps from the strongly typed graphics asset parameters values into the appropriate values used by the rendering implementation selected at step . At step the rendering application renders the geometry to which the first graphics asset is applied using the selected rendering engine. As described above each graphics asset specified for portions of a scene may be rendered using a different rendering implementation.

At step the user installs a first implementation file containing an implementation of a first graphics asset. In one embodiment the implementation corresponds to an additional rendering engine implementation of an existing graphics asset. For example a wall paint material may already be implemented in Mental Ray and the first implementation file contains an additional implementation for the wall paint material in a different rendering engine e.g. RenderMan. In another embodiment the implementation may correspond to an additional graphics asset for an existing rendering engine implementation. For example a granite tile material may already be implemented in Mental Ray and the implementation file may contain an implementation of a ceramic tile material also for Mental Ray.

In yet another embodiment the first implementation file may contain implementations for multiple graphics assets for the rendering engine implementation. For example the first implementation file may contain a series of implementations related to masonry materials including a granite material a ceramic material and a cement material where each such implementation may be configured to operate using the same rendering engine e.g. Mental Ray.

At step the rendering application locates the first implementation file containing the implementation of the first asset. Locating the first implementation file on disk may include searching a list of directories where implementations are saved searching default directories for the rendering application or searching the contents of an environment variable that the user can define.

At step the rendering application compares the user parameters of the first implementation file with the user parameters of a second implementation file. The second implementation file may contain a contract that the first implementation file should adhere to in order to be recognized as an additional implementation for the same graphics asset. For example the second implementation file may contain a contract for a wall paint material having three parameters color application type and finish. In one embodiment if the first implementation file contains an implementation for a material having parameters color application type and finish then the rendering application recognizes that the first implementation file contains an additional implementation for the wall paint material. The comparison may be performed in a variety of ways including without limitation a comparing an implementation ID of the first implementation file with an implementation ID of the second implementation file b comparing a name description of the first implementation file with a name description of the second implementation file c comparing user editable parameters of the first implementation with user editable parameters of the second implementation file or d comparing the types of the user editable parameters of the first implementation with the types of the user editable parameters of the second implementation file. These various approaches are described in greater detail below in .

At step the rendering application determines that the first implementation file and the second implementation file are different implementations of the same graphics asset. The determination is made based on the comparison performed at step .

At step after the first and second implementation files are determined to be different implementations of the same graphics asset the rendering application combines the first and second implementation files into a single database in memory. In one embodiment the database may be stored as a hash table that indicates that a first rendering engine corresponds to a first implementation a second rendering engine corresponds to second implementation and so on.

The steps may be performed at run time when a user invokes a rendering operation to be performed on a graphics scene file containing geometry with corresponding graphics assets. Furthermore steps may be repeated a number of times for each additional implementation located in the system as indicated by looping arrow .

In the rendering application compares an implementation ID of the first implementation file with an implementation ID of the second implementation file. For example a wall paint material may be associated with a numerical implementation ID. When comparing implementation files if the numerical implementation ID for the first implementation file matches the numerical implementation ID for the wall paint material then the first implementation file is determined to contain an additional implementation of the wall paint material.

In the rendering application compares a name description of the first implementation file with a name description of the second implementation file. The name description may be a string or characters. For example a wall paint material may be associated with a description wall paint1 . When comparing implementation files if the description for the first implementation file matches the description for the wall paint material i.e. wall paint1 then the first implementation file is determined to contain an additional implementation of the wall paint material.

In the rendering application compares user editable parameters of the first implementation file with user editable parameters of the second implementation file. In one embodiment each graphics asset may include strongly typed parameters representing the relevant characteristics of a given graphics asset. For example a graphics asset corresponding to a wall paint material may include parameters for color application type and finish. When comparing implementation files if the strongly typed parameters for the first implementation file match the strongly typed parameters for the wall paint material i.e. color application type and finish then the first implementation file is determined to contain an additional implementation of the wall paint material.

In the rendering application compares the types of the user editable parameters of the first implementation file with the types of the user editable parameters of the second implementation file. For example a graphics asset corresponding to a wall paint material may include parameters for color application and finish. The color parameter may include a numerical type and the application and finish parameters may include drop down menu types. When comparing implementation files if the types of the parameters for the first implementation file match the types of the parameters for the wall paint material i.e. color has numerical type and application and finish have drop down menu types then the first implementation file is determined to contain an additional implementation of the wall paint material.

Similarly the rendering framework is also extensible along the vertical rendering engines axis which represents support for newly implemented rendering engines for existing materials. For example assume the same twenty materials that shipped with the original product using Mental Ray implementations file are later implemented in hardware Opticore RenderMan or another rendering engine. Users or customers of the rendering framework may install the implementation files corresponding to these additional implementations of the masonry materials without knowledge of the source code for the original implementation file . As long as the additional implementation files adhere to the contract provided by the file for each of the materials then the rendering framework recognizes these new rendering options are available for these materials and presents the option to the user to render using these additional rendering engines in a common user interface.

As described each of the files represents separate files on disk that are installed individually. At runtime the rendering application identifies which materials and rendering engines are present in a given environment and the user does not need to know where all the implementations are coming from. Because the files are organized in a compartmentalized way each file may be shipped individually one after another which is especially important when the implementation file is created by a third party e.g. Pixar s Renderman implementation of a series of materials and not on a common release schedule with the original product containing the rendering framework .

However as also shown in there may be gaps in the matrix of materials and rendering engines. This results because a particular set of materials may not be implemented in a given rendering engine. The method described in may be configured to determine which materials are available in each rendering engine. For example if the selected rendering engine is RenderMan but a first material in the scene e.g. wall paint has no RenderMan implementation then there may be an explicit fall back material that is used. If no fall back material is specified a default fall back material may be applied instead i.e. a solid color . This functionality deals with incomplete definitions i.e. missing pieces in the matrix .

In an another embodiment an alternative technique for resolving missing implementations when rendering a given graphics scene is to flag each the materials that are not supported by the selected rendering engine remove or hide the objects with those materials from the scene and create a separate set of objects that is rendered separately in a second rendering pass. In such a case the user may manually resolve what material to apply to the separate set of objects during the second pass.

The material object acts like a contract. For example in order for a later installed material object to be compliant with the wall paint material object the implementation must include each of specific parameters of the wall paint material object. As shown the material object includes implementation object and default user interface object . Material object installed later does not include a corresponding user interface object. In one embodiment later installed materials object do not require a user interface object because the default user interface object is simply passed through to memory for that material object. In another embodiment a later installed material object may include an additional user interface object such that the rendering engine includes an override for the default user interface object for the material as well as the ability to define a unique user interface when creating the additional implementation.

Creating additional implementations for existing materials may be done using an Application Programming Interface API and scripting language. The API may allow content providers to query for existing material objects and parameters returning default values min max values user interface data order of parameters grouping of parameters dimming hiding logic for parameters etc. To create an additional implementation of a material creators may begin with the existing implementation object and simply modify the translation table to implement an additional renderer.

As described herein embodiments of the invention provide a renderer agnostic method for representing graphics assets independently from an underlying rendering engine. Advantageously graphics asset libraries may be extended with new graphics assets for rendering with an existing rendering engine and implementation. Also new rendering engines and implementations may be added for existing graphics assets. Thus at run time rather than limiting the rendering to being performed on a pre determined rendering engine the rendering application may efficiently and conveniently manage rendering a graphics scene on a plurality of rendering engines or implementations. Because of installation and release schedule issues the implementations may be installed in separate files and at a later time without access to the source code of the rendering framework or original material object implementations. Advantageously embodiments of the invention support third party material implementations without relying on a product release schedule of the third party. The library of available rendering implementations for materials can be updated any time by installing new implementation files that are combined at runtime into a single database. This extensibility is not possible with prior art systems like Mental Mill because the MetaSL code would need to be updated whenever an additional implementation was created and would require re shipping the entire MetaSL library.

While the forgoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present invention are embodiments of the present invention. Therefore the scope of the present invention is determined by the claims that follow.

