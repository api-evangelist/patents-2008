---

title: Method and system for linear processing of an input using Gaussian belief propagation
abstract: Methods and systems for processing an input. An input vector y is received that represents a noisy observation of Ax, where A is a data matrix and x is a data vector of unknown variables. Data vector x is recovered from the received input vector y via an iterative method. The recovering comprises determining an inference of a vector of marginal means over a graph G, where the graph G is of a joint Gaussian probability density function p(x) associated with noise in the received input vector y.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08139656&OS=08139656&RS=08139656
owner: The Regents of the University of California
number: 08139656
owner_city: Oakland
owner_country: US
publication_date: 20080925
---
This invention was made with Government assistance under National Science Foundation NSF Grant No. CCR 0514859. The Government has certain rights in the invention.

The invention relates generally to the field of signal processing. Embodiments of the invention relate more particularly to signal processing for communications.

In many areas of science and engineering such as but not limited to communications it is desirable to solve a system of linear equations e.g. to solve Ax b. Solving such equations using methods such as inverting matrix A that is to provide matrix A can be performed either directly or iteratively. However many conventional processes either require undesirable computational resources or may not arrive at a useful solution. Often such solutions are impractical in real world implementations.

As a nonlimiting example a signal may be received by a communications device where the signal corresponds to a data vector. This data vector in turn is based on at least a message vector a data matrix e.g. due to known communication techniques and an amount of noise. To determine the message vector from the received data vector a matrix inversion or similar method can be performed on the received signal. However for large sparse and or amorphous data matrices direct methods are impractical due to the need for excessive row reordering operations. Further the iterative approaches may converge asymptotically to the solution and thus may converge slowly or not at all.

Embodiments of the present invention provide among other things a method for processing an input. An input vector y is received that represents a noisy observation of Ax where A is a data matrix and x is a data vector of unknown variables. Data vector x is recovered from the received input vector y via an iterative method. The recovering comprises determining an inference of a vector of marginal means over a graph G where the graph G is of a joint Gaussian probability density function p x associated with noise in the received input vector y.

For a system of linear equations Ax b given the observation vector b n and the data matrix A a unique solution x x exists if and only if the data matrix A is full rank. For example consider the case where the data matrices A are also symmetric e.g. as in correlation matrices . Assuming a nonsingular symmetric matrix A the system of equations can be solved either directly or in an iterative manner. Direct matrix inversion methods such as but not limited to Gaussian elimination or band Cholesky factorization find the solution with a finite number of operations typically for a dense n n matrix on the order of n. The former is particularly effective for systems with unstructured dense data matrices while the latter is typically used for structured dense systems.

Iterative methods are inherently simpler requiring only additions and multiplications and have the further advantage that they can exploit the sparsity of the matrix A to reduce the computational complexity as well as the algorithmic storage requirements. By comparison for large sparse and amorphous data matrices the direct methods are impractical due to the need for excessive row reordering operations.

The main drawback of the iterative approach is that under certain conditions they converge only asymptotically to the exact solution x . Thus there is the risk that they may converge slowly or not at all. In practice however it has been found that they often converge to the exact solution or a good approximation after a relatively small number of iterations. A powerful and efficient iterative algorithm belief propagation BP also known as the sum product algorithm has been used very successfully to solve either exactly or approximately inference problems in probabilistic graphical models.

According to embodiments of the present invention an input represented by a linear system of algebraic equations can be solved as a probabilistic inference problem on a suitably defined graph. A more particular example method of the present invention Gaussian BP GaBP provides an efficient distributed approach to solving a linear system that circumvents the potentially complex operation of direct matrix inversion.

Preferred embodiments will now be discussed with respect to the drawings. The drawings include schematic figures that are not to scale which will be fully understood by skilled artisans with reference to the accompanying description. Features may be exaggerated for purposes of illustration. From the preferred embodiments artisans will recognize additional features and broader aspects of the invention.

Generally embodiments of the present invention provide systems methods and or devices for processing inputs from any system that can be modeled by y Ax where y is an n 1 vector of observations A is a data matrix for example square i.e. n n or rectangular i.e. m n and x is a n 1 vector of unknowns. Put another way embodiments of the present invention can process channels where y is a noisy observation of Ax.

The device includes an input for receiving a signal representing a data input vector. Example inputs include a suitable input signal path which may be configured to receive a processed signal via any suitable methods an unprocessed signal a partially processed signal a filtered signal a partially filtered signal an unfiltered signal or any combination thereof. Processing logic for performing methods of the present invention is provided and such logic may be as a nonlimiting example encoded into the signal processing device . The processing logic includes logic for recovering a message vector from the data input vector. An output provides a signal representative of a recovered message vector or as a nonlimiting embodiment a signal that can be further processed to provide a recovered message vector without performing matrix inversion . This output signal as nonlimiting examples can be displayed on any suitable display printed on any suitable medium stored to any suitable medium stored in memory e.g. physical or virtual memory delivered over a network used as an input for additional processing via any of the above methods etc.

Generally the processing logic receives an input vector e.g. receives a signal corresponding to an input vector that represents a noisy observation of Ax. A is a data matrix such as a two dimensional matrix either rectangular e.g. m n or square e.g. n n . This data matrix A is based on any of various origins as will be appreciated by one of ordinary skill in the art. Nonlimiting examples are provided herein. Data vector x represents data to be recovered by an example method according to the present invention. This vector x may represent as a nonlimiting example a message to be recovered a solution to a linear algebra problem or any of various other data vectors.

The input data vector y also includes noise which for example embodiments of the present invention is assumed to be Gaussian noise though the invention is not to be limited to this assumption. This noise may be incorporated into data matrix A and may be separately represented in nonlimiting examples by a noise vector n. Noise can originate from any of a variety of sources including but not limited to signal noise in communications or simply unknowns when generating a solution to a linear algebra problem. Thus it is to be understood that noise may be any type of data that may be represented as noise by the equations described herein.

The general goal of embodiments of the present invention is to recover the data vector x from input data vector y. In example embodiments of the present invention this is done by an iterative method that determines an inference of a vector of marginal means over a graph G where the graph G is of a joint Gaussian probability density function p x associated with noise in the received input vector y. Generally the graph G includes a set of continuous variable nodes that are in one to one correspondence with the vector of unknowns x and the set of undirected edges between variable nodes is determined by the non zero entries of the data matrix A. Example methods for recovering data vector x are referred to herein as Gaussian belief propagation GaBP methods.

A general description of example Gaussian belief propagation methods follows. In the description the following notation will be used the operator denotes a vector or matrix transpose the matrix Iis an n n identity matrix while the symbols and denote entries of a vector and matrix respectively.

First define an undirected graphical model i.e. a Markov random field G corresponding to the linear system of equations. Specifically let G x where x is a set of nodes that are in one to one correspondence with the linear system s variables x x . . . x and where is a set of undirected edges determined by the non zero entries of the symmetric matrix A. Using this graph one can translate the problem of solving the linear system from the algebraic domain to the domain of probabilistic inference as stated in the following theorem 

The computation of the solution vector x is identical to the inference of the vector of marginal means . . . over the graph G with the associated joint Gaussian probability density function

Proof Another way of solving the set of linear equations Ax b 0 is to represent it by using a quadratic form

Hence in order to solve the system of linear equations one needs to infer the marginal densities which must also be Gaussian p x N Ab P A where and Pare the marginal mean and inverse variance sometimes called the precision respectively. Generally speaking the mean is the average value that the vector of unknowns can get and the precision is the inverse of the variance fluctuation of these values.

According to the above theorem solving a deterministic vector matrix linear equation translates to solving an inference problem in the corresponding graph. The move to the probabilistic domain calls for the utilization of BP as an efficient inference engine.

To better illustrate an example GaBP algorithm according to embodiments of the present invention a belief propagation BP method will be first summarized. BP has been found to have outstanding empirical success in many applications e.g. in decoding Turbo codes and low density parity check LDPC codes. The excellent performance of BP in these applications may be attributed to the sparsity of the graphs which ensures that cycles in the graph are long and inference may be performed as if the graph were a tree.

Given the data matrix A and the observation vector b one can write explicitly the Gaussian density function p x and its corresponding graph G consisting of edge potentials compatibility functions and self potentials evidence . These graph potentials are simply determined according to the following pairwise factorization of the Gaussian function resulting in

The example BP algorithm functions by passing real valued messages across edges in the graph and includes two computational rules referred to as the sum product rule and the product rule . In contrast to some conventional applications of BP however an example graphical representation according to nonlimiting embodiments of the present invention resembles a pairwise Markov random field with a single type of propagating message rather than a factor graph with two different types of messages originating from either the variable node or the factor node.

Furthermore in most graphical representations used in the information theory art the graph nodes are assigned discrete values whereas example embodiments of the present invention deal with nodes corresponding to continuous variables. Thus for a graph g composed of potentials and as previously defined the conventional sum product rule becomes an integral product rule and the message m x sent from node i to node j over their shared edge on the graph is given by .

The marginals are computed as usual according to the product rule where the scalar is a normalization constant. The set of graph nodes N i denotes the set of all the nodes neighboring the ith node. The set N i j excludes the node j from N i .

Gaussian BP is a special case of continuous BP where the underlying distribution is Gaussian. Next example Gaussian update rules are derived by substituting Gaussian distributions into the continuous BP update equations.

An observation is made that the product of Gaussian densities over a common variable is up to a constant factor also a Gaussian density. Particularly let f x and f x be the probability density functions of a Gaussian random variable with two possible densities N P and N P respectively. Then it can be easily shown that their product x x x is up to a constant factor the probability density function of a Gaussian random variable with distribution N P where .

Looking at the right hand side of the integral product rule above node i needs to first calculate the product of all incoming messages except for the message coming from node j. Recall that since p x is jointly Gaussian the factorized self potentials x N P and similarly all messages m x N P are of Gaussian form as well.

As the terms in the product of the incoming messages and the self potential in the integral product rule are all a function of the same variable x associated with the node i then according to the multivariate extension of the product of Gaussians observation above x m x is proportional to a certain Gaussian distribution N P . Applying the multivariate version of the product precision expression above the update rule for the inverse variance is given by over braces denote the origin of each of the terms 

Next the remaining terms of the message m x are calculated including the integration over x. After some algebraic manipulation using the Gaussian integral exp ax bx dx square root over a exp b 4a it is found that the messages m x are proportional to a normal distribution with precision and mean . These two scalars represent the messages propagated in the example GaBP based algorithm.

Finally computing the product rule is similar to the calculation of the previous product and the resulting mean and precision but including all incoming messages. The marginals are inferred by normalizing the result of this product. Thus the marginals are found to be Gaussian probability density functions N P with precision and mean

For a dense data matrix the number of messages passed on the graph can be reduced from O n messages i.e. twice the number of edges down to O n messages per iteration round by using the following instead of sending a unique message composed of the pair of and Pfrom node i to node j a node broadcasts aggregated sums to all its neighbors and consequently each node can retrieve locally Pand from the aggregated sums

A well known alternative to the sum product BP algorithm is the max product a.k.a. min sum algorithm. In this variant of BP a maximization operation is performed rather than marginalization i.e. variables are eliminated by taking maxima instead of sums. For trellis trees as nonlimiting examples graphical representation of convolutional codes or ISI channels the conventional sum product BP algorithm boils down to performing the BCJR algorithm resulting in the most probable symbol while its max product counterpart is equivalent to the Viterbi algorithm thus inferring the most probable sequence of symbols.

In order to derive the max product version of an example GaBP solver the integral sum product rule is replaced by a new rule argmax .

Computing m x according to this max product rule one gets which is identical to the messages derived for the sum product case. Thus it can be shown that the max product and sum product version of the example GaBP solver are identical.

In ordinary BP convergence does not guarantee exactness of the inferred probabilities unless the graph has no cycles. Advantageously this is not the case with example GaBP solvers of the present invention. Its underlying Gaussian nature yields a direct connection between convergence and exact inference. Moreover in contrast to conventional BP the convergence of GaBP in example methods is not limited to acyclic or sparse graphs and can occur even for dense fully connected graphs adhering to certain rules.

For example one can use known probabilistic inferences in graphical models to help determine the convergence and exactness properties of the example GaBP solver. The following two theorems establish sufficient conditions under which GaBP will always converge to the exact marginal means.

However there are many examples of linear systems that violate these conditions for which the example GaBP solver nevertheless converges to the exact solution. As one nonlimiting example if the graph corresponding to the system is acyclic i.e. a tree the example GaBP yields the exact marginal means and even marginal variances regardless of the value of the spectral radius.

Further speed up of the GaBP solver can be achieved by adopting known acceleration techniques from linear algebra. Table 2 demonstrates the speed up of an example GaBP solver obtained by using such an acceleration method termed Steffensen s iterations P. Henrici Elements of Numerical Analysis New York John Wiley and Songs 1964 in comparison with the accelerated Jacobi algorithm e.g. as disclosed in O. Axelsson Iterative Solution Methods Cambridge UK Cambridge University Press 1994 diverged for the 4 users setup . This provides a unique setup using an acceleration method within the framework of message passing algorithms. Further the region of convergence of the example accelerated GaBP solver remains unchanged.

Having presented a general processing algorithm according to embodiments of the present invention more particular examples will be provided. However these examples are not intended to limit the methods and systems of the present invention to the particular methods or devices disclosed herein.

One such example application is communications. As explained above the underlying essence of estimation theory is to detect a hidden input to a channel from its observed noisy output. The channel can be represented as a certain graphical model while the detection of the channel input is equivalent to performing inference in the corresponding graph. However although particular examples described herein are directed to estimation theoretic problems and applications from the field of communications methods of the present invention are broadly applicable to problems of efficient distributed matrix inversion solution of systems of linear equations and determinant calculation and methods devices and systems for solving such problems are examples of embodiments of the present invention.

BP has been proven beneficial in various applications in communications. Applications of processing devices methods and or systems of the present invention include but are not limited to processing communication signals. shows an example communication device which may be any device portable or non portable which can perform methods according to the present invention. Nonlimiting examples include mobile telephones portable computing devices receivers servers clients network devices and or personal computers. The communication device includes at least one antenna for receiving wireless signals. One or more signal conditioners and analog digital converters may be used to process the received signal as is well known in the art. A processor controls functions of the communication device and suitable memory and input devices e.g. a keypad or touchscreen and output devices e.g. a display or transmitter may be provided for device use.

An input data signal is supplied to the processor which in a nonlimiting example is suitably configured to perform methods of the present invention. The processor may be one processor or may be several processors configured to perform particular methods of the present invention. In addition to logic for performing the data recovery as discussed above one or more filters e.g. matched filters may be provided depending on the type of wireless communication performed. A suitable power supply is provided and suitable coupled to the various components of the communication device .

One nonlimiting example of communication signal uses code division multiple access CDMA the details of which will be understood by those of ordinary skill in the art. For randomly spread code divisional multiple access CDMA in the large system limit a tractable BP based multiuser detection MUD scheme has been employed which exhibits near optimal error performance for binary input additive white Gaussian noise BI AWGN channels. This message passing scheme has been extended to the case where the ambient noise level is unknown. As for sub optimal detection the nonlinear soft parallel interference cancellation PIC detector has been reformulated as an approximate BP solution to the MUD problem.

CDMA may include e.g. K users and spreading codes of length N. In an example signal processing algorithm according to embodiments of the present invention the received signal can be represented by r Sx n where r is the N length vector of received samples at an antenna S is the N K spreading codes matrix in which each user has its own dedicated spreading code column in the matrix and n is the n length additive vector such as but not limited to a white Gaussian noise vector.

A matched filter S e.g. at a front end of a receiver as will be understood by one of ordinary skill in the art can be used to filter the samples to get y S r S Sx S n Rx z. In this example S indicates a conjugate transpose operator of S. In this equation y is the K length vector of observations R is the spreading code s cross correlation matrix K K matrix and z is the K length colored noise vector. This corresponds to the general GaBP model above where A R and n K.

An example embodiment of the present invention can be used for efficient and distributed implementation of a detector Ay a decorrelator . Other example detectors provided under embodiments of the present invention include detectors that are implemented via matrix inversion such as but not limited to linear minimum mean squared error MMSE detectors.

Another example system according to embodiments of the present invention is a multiple input multiple output MIMO system. For example consider a system with l transmitting antennas and m receiving antennas for example the communications device may have multiple receiving antennas . Here r Hx n where r is the m length vector of symbols received in m antennas H is the m 1 matrix of channel paths where each entry denotes the gain of the effective channel between a certain Ttransmitting antenna out of the l antennas and a certain Rreceiving antenna out of the m receiving antennas and n is a noise vector such as but not limited to an m length additive white Gaussian noise vector.

As with the CDMA example above an example embodiment of the present invention uses a matched filter H which is a front end of MIMO receivers as will be appreciated by one of ordinary skill in the art. The matched filter provides y H r H Hx H n Rx z where y is the m length vector of observations R is the cross correlation matrix e.g. an m m matrix and z is an m length colored noise vector. Again the general Gaussian model above is applicable with A R and n m.

Yet another example system device and method according to embodiments of the present invention processes signals using orthogonal frequency division multiplexing OFDM . Processing this signal provides y Gx where x is a K length vector of information bits G is a K K system matrix and y is a K length observed vector. K as a non limiting example is between 512 8192 sufficiently large to allow an efficient matrix inversion algorithm.

Still another example system device and method according to embodiments of the present invention processes signals using intersymbol interference ISI equalization. Similar to CDMA ISI uses a correlation matrix R but these are interferences of time as opposed to interference among users. This signal processing method compensates for interference cause delayed replicas of the same transmitted symbol e.g. due to reflections from large objects such as but not limited to mountains buildings etc. .

In contrast to the dense fully connected nature of the graphical model of the non orthogonal CDMA channel a one dimensional 1 D ISI channel can be interpreted as a cycle free tree graph. Thus detection in 1 D ISI channels termed equalization can be performed in an optimal maximum a posteriori MAP manner via BP also known in this context as the forward backward or BCJR algorithm. Further an iterative BP like detection algorithm for 1 D ISI channels has been proposed that uses a parallel message passing schedule and achieves near optimal performance.

For the intermediate regime of non dense graphs but with many relatively short loops extensions of BP to two dimensional ISI channels have been considered and more recently the near optimality of a generalized version of BP for such channels has been demonstrated. Further BP has been proven to asymptotically achieve optimal MAP detection for sparse linear systems with Gaussian noise for example in CDMA with sparse spreading codes.

An important class of practical sub optimal detectors is based on linear detection. This class includes for instance the conventional single user matched filter MF decorrelator aka zero forcing equalizer linear minimum mean squared error MMSE detector and many other detectors with widespread applicability. In general linear detection can be viewed as the solution to a deterministic set of linear equations describing the original probabilistic estimation problem. The mathematical operation behind linear detection extends to other tasks in communication such as but not limited to channel precoding at the transmitter.

However in spite of its significant role in estimation theory linear detection has never been explicitly linked to BP in contrast to optimal MAP detection and several sub optimal nonlinear detection techniques.

Embodiments of the present invention use a general linear detection reformulated as a GaBP algorithm. This message passing framework is not limited to the large system limit and is suitable for channels with arbitrary prior input distribution. Revealing this missing link allows for a distributed implementation of the linear detector circumventing the necessity of potentially cumbersome matrix inversion via e.g. Gaussian elimination .

GaBP is shown to yield faster convergence than conventional methods of solving systems of linear equations. BP based MUD recently derived and analyzed for Gaussian input symbols is an instance of a larger overall framework. GaBP convergence can be further accelerated.

Consider a discrete time channel with a real input vector x x . . . xgoverned by an arbitrary prior distribution P and a corresponding real output vector y y . . . y fx an extension to the complex domain is straightforward. Here the function denotes the channel transformation. By definition linear detection compels the decision rule to be where b y is the K 1 observation vector and the K K matrix A is a positive definite symmetric matrix approximating the channel transformation. The vector x is the solution over to Ax b. Estimation is completed by adjusting the inverse matrix vector product to the input alphabet dictated by P accomplished by using a proper clipping function e.g. for binary signaling is the sign function .

For example linear channels which appear extensively in many applications in communication and data storage systems are characterized by the linear relation where n is a K 1 additive noise vector and R SS is a positive definite symmetric matrix often known as the correlation matrix. The N K matrix S describes the physical channel medium while the vector y corresponds to the output of a bank of filters matched to the physical channel S.

Note that due to the vast applicability of linear channels example experiments described herein are directed to such channels though the invention is not to be limited to this case. Assuming linear channels with AWGN with variance as the ambient noise the general linear detection rule in the equation above can describe known linear detectors. For example 

In general linear detection is suboptimal because of its deterministic underlying mechanism i.e. solving a given set of linear equations in contrast to other estimation schemes such as MAP or maximum likelihood that emerge from an optimization criterion.

Linear detection can be implemented in its general form in an efficient message passing fashion. Again the aim is to find x a solution to the linear equation Ax b i.e. x Ab without actually inverting the nonsingular matrix A. Another way of solving this set of linear equations Ax b 0 is to represent it using a quadratic form

Thus equating q x 0 gives the global minimum x of this convex function which is nothing but the desired solution to Ax b.

The formulation above allows the linear detection problem to shift from an algebraic to a probabilistic domain. Instead of solving a deterministic vector matrix linear equation example methods of the present invention solve an inference problem in a graphical model describing a certain Gaussian distribution function. Given the overall channel matrix A and the observation vector b one knows how to explicitly write p x and the corresponding graph G with edge potentials compatibility functions and self potentials evidence . These graph potentials are determined according to the following pairwise factorization of the Gaussian distribution p x 

The move to the probabilistic domain calls for the utilization of BP as an efficient inference engine. The sum product rule of BP for continuous variable required in this example case is given by where m x is the message sent from node i to node j over their shared edge on the graph scalar is a normalization constant and the set N i j denotes all the nodes neighboring x except x. The marginals are computed according to the product rule .

As stated above GaBP is a special case of continuous BP where the underlying distribution is Gaussian. The GaBP update rules are derived by substituting Gaussian distributions in the continuous BP equations.

According to the right hand side of the sum product rule node i needs to calculate the product of all incoming messages except for the message coming from node j. Recall that since p x is jointly Gaussian the self potentials x and the messages m x are Gaussians as well. The product of Gaussians of the same variable is also a Gaussian. Consider the Gaussians defined by N P and N P . Their product is also a Gaussian N P with .

As the terms in the product of the incoming messages and the self potential are all describing the same variable x this property can be used to demonstrate that x m x is proportional to a N P distribution. Therefore the update rule for the inverse variance is given by over braces denote the origin of these terms 

Now one can calculate the remaining terms of the message m x including the integration over x. After some algebraic manipulations the Gaussian integral exp ax bx dx square root over a exp b 4a can be used to show that m x is a normal distribution with mean and precision given by .

These two scalars are the propagating messages in this example GaBP scheme. Finally the computation of the product rule is similar to previous calculations but with no incoming messages excluded. The GaBP based implementation of the linear detection operation is summarized in Table 3 below.

The number of messages passes on the graph can be reduced significantly down to only K messages per round. Instead of sending a message composed of the pair and P a node can broadcast the aggregated sums tilde over .

Now each node locally retrieves the Pand from the sums by means of a subtraction tilde over . The rest of the algorithm remains the same.

Again if it converges this example GaBP method is known to result in exact inference. One sufficient but not necessary condition is that GaBP converges when the spectral radius satisfies I A A i in order for GaBP to converge.

As these conditions are not necessary one can find examples of channels for which the conditions do not hold yet GaBP still converges perfectly to the linear detection solution. For instance in the case of Gaussian input signaling i.e. Pis a normal distribution for which linear detection becomes optimal it can be easily shown that the example GaBP scheme boils down to the BP based MUD scheme disclosed in A. Montanari B. Prabhakar and D. Tse Belief propagation based multi user detection in Proc. 43Allerton Conf. on Communications Control and Computing Monticello Ill. USA September 2005. This BP scheme tailored for Gaussian signaling has been proven to converge to the minimum mean square error MMSE and optimal solution for any arbitrarily loaded

It can be shown that when it converges GaBP is substantially faster than alternative iterative methods. Two system setups of binary signaling synchronous CDMA were examined with cross correlation matrices

Table 4 compares the example GaBP algorithm with standard iterative solution methods as disclosed in O. Axelsson Iterative Solution Methods Cambridge UK Cambridge University Press 1994 using random initial guesses previously employed for CDMA MUD.

Multiuser detectors based on the algorithms of Jacobi Gauss Seidel GS and optimally weighted successive over relaxation SOR were investigated. The table lists the convergence rates for the two Gold code based CDMA settings. Convergence is identified and declared when the differences in all the iterated values are less than 10. Clearly the example GaBP yields faster convergence speed on both examined systems in comparison with the Jacobi and GS algorithms. The best convergence rate with respect to the conventional iterative methods including SOR is achieved for serial GaBP i.e. the example scheme with serial rather than parallel flooding message passing update rule.

Further speed up of GaBP can be achieved by adopting known acceleration techniques like Aitken s method and Steffensen s iterations for example as disclosed in P. Henrici Elements of Numerical Analysis John Wiley and Sons 1964 yet to be employed with BP schemes. Consider a sequence x e.g. obtained by using GaBP iterations linearly converging to the limit circumflex over x and x circumflex over x for n 0. According to Aitken s method if there exists a real number a such that a 

Steffensen s iterations encapsulate Aitken s method. Starting with x two iterations are run to get xand x. Next Aitken s method is used to compute y this value is replaced with the original x and GaBP is executed again to get a new value of x. This process is repeated iteratively until convergence. Table 5 demonstrates the speed up of GaBP using these acceleration methods in comparison with the modified Jacobi algorithm.

An interesting question concerns the origin of this convergence speed up associated with GaBP. Better understanding may be gained by visualizing the iterations of the different methods for the matrix Rcase. The convergence contours are plotted in the space of x x x in . As expected the Jacobi algorithm converges in zigzags towards the fixed point. The fastest algorithm is serial GaBP. GaBP convergence is in a spiral shape suggesting that despite the overall convergence improvement performance improvement is not guaranteed in successive iteration rounds. The spiral nature of GaBP convergence is better viewed in . In this case the system was simulated with a certain R matrix for which Jacobi algorithm and other standard methods did not converge. Using Aitken s method a further speed up in GaBP convergence is obtained.

Despite the fact that examples of small systems are described herein these illustrate typical behavior of various algorithms. GaBP has been exponentially shown to converge in a logarithmic number of iterations in the cases of very large matrices both dense e.g. with up to hundreds of thousands of dimensions and sparse e.g. with up to millions of dimensions .

Example embodiments of the present invention using GaBP for linear detection allow for a distributed implementation of the linear detector circumventing the need of potentially cumbersome direct matrix inversion such as via Gaussian elimination. Example GaBP methods can yield faster convergence than many conventional methods.

For particular example GaBP methods the input matrix R SS the chip correlation matrix is computed prior to running the algorithm. This computation requires nk operations. In the case where the matrix S is sparse the matrix R might no longer be sparse. Further an example GaBP method uses 2nmemory to store the messages. For a large n this could be prohibitive.

An alternative method according to embodiments of the present invention is provided to address these issues. In this alternative method given a non rectangular CDMA matrix S an MMSE detector x SS Sy is computed where is the AWGN diagonal covariance matrix. An example GaBP algorithm which is an efficient distribution algorithm is utilized. Construction according to this example embodiment uses only 2nk memory for storing the messages. When k

Again consider a discrete time channel with a real input vector x x . . . xgoverned by an arbitrary prior distribution P and a corresponding real output vector y y . . . y fx . Here the function denotes the channel transformation. By definition linear detection compels the decision rule to be where b y is the K 1 observation vector and the K K matrix A is a positive definite symmetric matrix approximating the channel transformation. The vector x is the solution over to Ax b. Estimation is completed by adjusting the inverse matrix vector product to the input alphabet dictated by P accomplished by using a proper clipping function e.g. for binary signaling is the sign function .

For example linear channels are characterized by the linear relation where n is a K 1 additive noise vector and R SS is a positive definite symmetric matrix often known as the correlation matrix. The N N matrix S describes the physical channel medium while the vector y corresponds to the output of a bank of filters matched to the physical channel S.

Assuming linear channels with AWGN with variance as the ambient noise the general linear equation rule can describe known linear detectors. For example 

In general linear detection is suboptimal because of its deterministic underlying mechanism i.e. solving a given set of linear equations in contrast to other estimation schemes such as MAP or maximum likelihood that emerge from an optimization criterion.

In the example method described above linear detection in its general form was implemented using an efficient message passing algorithm. The linear detection problem was shifted from an algebraic to a probabilistic domain. Instead of solving a deterministic vector matrix linear equation an inference problem is solved in a graphical model describing a certain Gaussian distribution function. Given the overall channel matrix R and the observation vector y one knows how to write explicitly p x and the corresponding graph G with edge potentials compatibility functions and self potentials evidence . These graph potentials are determined according to the following pairwise factorization of the Gaussian distribution p x 

The applicability of the example GaBP based solver can be extended for systems with symmetric matrices to systems with any square i.e. also nonsymmetric or rectangular matrix. First a new symmetric data matrix R is constructed based on an arbitrary non rectangular matrix S 

Next it is shown that solving the symmetric linear system tilde over R tilde over x tilde over y and taking the first k entries of the corresponding solution vector tilde over x is equivalent to solving the original not necessarily symmetric system Rx y. Note that in the new construction the matrix tilde over R is sparse again and has only 2nk messages instead of nin the previous example construction.

Writing explicitly the symmetric linear system s equations one gets 0 Thus and extracting circumflex over x provides 

A relation of this alternative method to a factor graph is provided. Given the inverse covariance matrix tilde over R defined above and the shift vector tilde over x one can derive the matching self and edge potentials

To show the relation of this construction is shown to a factor graph a factor graph is used with k nodes to the left the bits transmitted and n nodes to the right the signal received shown in . Using the definition

One of the benefits of this alternative construction is that a mechanism is provided for other convergence results. It is known that if the matrix tilde over R is strictly diagonally dominant then GaBP converges and the marginal means converge to the true means. Noting that the matrix tilde over R is symmetric one can determine the applicability of this condition by examining its columns. Referring to Efficient Bayesian inference for learning in the Ising linear perceptron and signal detection in CDMA Physica A. vol. 365 pp. 203 210 February 2006 it is seen that in the first k columns the k CDMA sequences are present. Random spreading binary CDMA sequences are assumed which are normalized to one. In other words the absolute sum of each column is square root over n . In that case the matrix tilde over R is not diagonally dominant DD . One can add a regularization term of square root over n to force the matrix tilde over R to be DD but there is a cost in changing the problem. In the next n columns of the matrix tilde over R the diagonal covariance matrix is present with different noise levels per bit in the main diagonal and zero elsewhere. The absolute sum of each column of S is k square root over n thus when the noise level of each bit satisfies k square root over n one has a convergence guarantee. Note that the convergence condition is a sufficient condition. It can also be determined e.g. see A. Montanari B. Prabhakar and D. Tse Belief propagation based multi user detection in Proc. 43th Allerton Conf. on Communications Control and Computing Monticello Ill. USA September 2005 that in the large system limit the example algorithm converges for binary signaling even in the absence of noise.

Again though this alternative algorithm is referred to herein using the example of CDMA multiuser detection it has wider applicability. As a nonlimiting example an algorithm according to embodiments of the present invention can provide an efficient iterative method for computing the Monroe Penrose pseudoinverse and it can also be applied to the factor analysis learning problem.

While various embodiments of the present invention have been shown and described it should be understood that other modifications substitutions and alternatives are apparent to one of ordinary skill in the art. Such modifications substitutions and alternatives can be made without departing from the spirit and scope of the invention which should be determined from the appended claims.

