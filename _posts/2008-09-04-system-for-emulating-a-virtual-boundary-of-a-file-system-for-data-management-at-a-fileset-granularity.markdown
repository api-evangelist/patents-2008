---

title: System for emulating a virtual boundary of a file system for data management at a fileset granularity
abstract: A file system boundary emulation system emulates a virtual boundary of a filesystem within an existing file system for data management at a fileset granularity, within the framework of a wide area filesystem federation. The system dynamically assigns a fileset ID to the file that belongs to that fileset. The system comprises a fileset defined by the virtual boundary of the file. The virtual boundary is less than and contained within the file system. The fileset identifies the file via the file ID and the fileset ID. The system maps the file ID to the fileset ID. The filesets are dynamically created and removed based on administrative instructions. Filesets are used for fine grained data management and namespace control in a filesystem federation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08255364&OS=08255364&RS=08255364
owner: International Business Machines Corporation
number: 08255364
owner_city: Armonk
owner_country: US
publication_date: 20080904
---
The present invention generally relates to file systems and in particular to federated file systems. More specifically the present invention relates to a system that emulates a filesystem boundary within a general purpose filesystem that is exported via a network file sharing NFS .

As enterprises move toward distributed operations spread over several remote locations multi site collaboration and joint product development becomes increasingly common. Although this technology has proven to be useful it would be desirable to present additional improvements. Distributed operations require data sharing in a uniform secure and consistent manner across the enterprise acceptable performance. While large amounts of data can be easily shared on a local area network LAN using standard file access protocols these mechanisms do not scale well when extended to remote offices connected over a wide area network. Moreover deployment of alternate solutions such as a wide area filesystems geared for global scalability is rarely chosen by enterprises the cost of maintaining and operating one or more filesystems and protocols for local and wide area access and integrating data between them can be prohibitive.

Data and file sharing has long been achieved through traditional file transfer mechanisms such as file transfer protocol FTP and distributed file sharing protocols such as network file sharing NFS and common Internet file system CIFS . The file sharing protocols tend to be chatty having been designed for local area network LAN environments where clients and servers are located in close proximity.

Data sharing can also be facilitated by a clustered filesystem. While clustered filesystems are designed for high performance and strong consistency they are neither inexpensive nor easy to deploy and administer. Other filesystem architectures attempted to solve the file sharing issues of a wide area network through a distributed architecture that provides a shared namespace by uniting disparate file servers at remote locations into a single logical filesystem. However these technologies incur substantial deployment expense and have not been widely adopted for enterprise wide file sharing.

One conventional approach comprises the Andrew file system AFS which is a globally distributed filesystem. AFS introduces the concept of a cell as an administrative domain and supports a global namespace. AFS also introduces the volumes as an abstraction for data management. AFS has extensive client side file caching for improving performance and supports cache consistency through callbacks. AFS further allows read only replication useful for improving performance.

Another conventional approach comprises most of the features of AFS but is also integrated with the Open Software Foundation OSF common desktop environment DCE platform. This conventional approach provides improved load balancing and synchronization features along with transparency across domains within an enterprise for easy administration. Other AFS related filesystems deals with replication for improved scalability while focusing on disconnected operations.

Recently there has been some work on leveraging the features of NFSv4 to provide global naming and replication support. One conventional approach focuses on providing a global namespace and read write replica synchronization. Other related efforts are geared toward improving performance by using parallel data access.

Orthogonal to the distributed file system work there have been a number of conventional approaches utilizing clustered filesystems. These conventional approaches are geared for high performance solutions using high speed network connections and tightly coupled servers.

Additional conventional technologies have explored grouping together servers for a common file service. One conventional approach decentralized the storage services across a set of cooperating servers in a local area environment. In contrast another conventional approach comprises an archival system aimed at storing huge collections of data using worldwide replica groups with security and consistency guarantees. Yet another conventional approach focuses on security and byzantine faults where a loose collection of untrusted unsecured servers are grouped together to establish a virtual file server that is secure and reliable. A further conventional approach couples islands of data for scalable Internet services.

The need therefore is not to build yet another globally distributed filesystem but to group together a set of heterogeneous multi vendor independent and distributed file servers such that the distributed file servers act as one. It is desirable that data remain where it is possibly in legacy filesystems or on a variety of single server filesystems. Instead a system is needed that allows clients to seamlessly navigate the data without additional client side software or configuration and manage the data at fine granularities for replication migration and caching. The data management in conventional methods is done at the whole filesystem granularity.

What is therefore needed is a system a computer program product and an associated method for emulating a virtual boundary of a file system for data management at a finer fileset granularity. The need for such a solution has heretofore remained unsatisfied.

The present invention satisfies this need and presents a system a service a computer program product and an associated method collectively referred to herein as the system or the present system for emulating a virtual boundary of a file system for data management at a fileset granularity providing flexible data management within a wide area filesystem federation. The present system dynamically groups a directory tree and all files and directories within it into a fileset and assigns a fileset ID to the fileset. The present system comprises a fileset defined by the virtual boundary of the filesystem. The virtual boundary is less than and contained within the file system and can be created without any support from the underlying filesystem. In this system a file or directory contained in a fileset is uniquely identified via the file ID and the fileset ID and the filesystem id. The present system can efficiently map the file ID to the fileset ID it belongs to. The filesets are dynamically created and removed based on administrative instructions. System uses the fileset to generate a virtual boundary for more efficient data management.

The present system provides distributed file access across Internet scale networks networks that exhibit limited bandwidth high latency and low reliability the present system provides the distributed file access by exporting filesets. The present system provides these services using a unified administration and security model. All administration of the present system can be performed from a single interface regardless of the scale of the implementation. The present system further comprises features found in conventional distributed filesystems that facilitate data management and provide a unified namespace further referenced herein as a server set Namespace and a root namespace to ease client access.

The following definitions and explanations provide background information pertaining to the technical field of the present invention and are intended to facilitate the understanding of the present invention without limiting its scope 

Fileset A unit of data management. A container of data which could range from a single leaf directory to a directory tree within a filesystem containing all the files and subdirectories within it.

A distributed computing system comprises the server sets . Each of the server sets may represent one server a cluster of servers or one or more server cells. At least some of the server sets may be co located or geographically dispersed. For example server set may be based in Tokyo Japan server set may be based in San Francisco Calif. and server set N may be based in Boston Mass.

Clients represented by client can access the distributed computing system through a network . Client is connected to network via a communications link such as a telephone cable or satellite link. Server set server set through server set N can be connected to network via communications link respectively. While system is described in terms of network client may also access the distributed computing system locally rather than remotely.

The primary organizational unit of system is a cell. System comprises objects such as filesets fileset locations and a root namespace further referenced herein as a namespace a server set Namespace and a shared namespace . Each of these objects is associated with a cell. Cells are independent and non interacting with each other so that a single organization can create cells in a way that best meets their business needs of security and performance. Cells can be as small as a workgroup or as large as an enterprise.

The cell is a logical construct. System allows one or more cells to be serviced by a single host server within each of the server sets . System maintains all the information necessary to manage filesets. Cells provide a range of other services comprising security and automation. Cell services maintain security by allowing the authorization of users and groups as well as adding and removing data servers. System provides automation services to facilitate maintenance of filesets such as for example the scheduled update of a fileset replica from a source fileset.

System organizes files in a hierarchical container structure such that files appear inside directories. Directories may comprise files and directories. To extend boundary crossings to include a fileset boundary without any underlying physical filesystem support system maintains a minimal state outside a physical filesystem support. System maintains a state of the fileset via an in kernel database of fileset directories indexed by the physical filesystem generated file ID .

System identifies a file within a filesystem via the file ID and the fileset ID. System further maps the file ID to the fileset ID using the in kernel database. System further maintains the state of the database by extending an opaque file system filehandle to contain a fileset ID . The database identifies specific directories and contents of the directories. The database further identifies one or more files or one or more additional directories within the specific directory.

By carrying the fileset information in the filehandle system does not need to crawl the filesystem to identify a fileset to which a file or directory belongs. When a directory is upgraded to be fileset an in kernel database records the entry in a table mapping the directory file ID to a fileset ID . This fileset ID is piggy backed with the filehandle and used for subsequent requests. The filehandle structure contains the filehandle as shown below 

The filehandle is opaque to client implying that any file can be identified by a tuple comprising the file system ID and the file handle. If client wishes to read a file the augmented file server gives the client filehandle. The augmented file server parses the filehandle to obtain the file ID and the fileset ID. The client does not have to retrieve the file system ID from the database this information is provided in the file handle.

An instance of the data management server and the fileset kernel services module operate on any server in the server sets that provide file services. The administration server communicates with the data management server . In one embodiment the administration server the administration user interface the administration client the data management server the kernel interface module the fileset kernel services module and the augmented file server may operate on a single server in each of the server sets .

System facilitates fault tolerance by making each data server in the server sets independent of each other. Inter server communication occurs via reliable queues that can hold messages in case a data server fails or a network partition occurs. When the data server is restored or the partition is healed the queued messages are sent bringing the data server back to full currency.

The administration server is not duplicated in system and can be run on a server configured for high availability for added reliability. System data services run independently of the administration server . If the administration server fails or a network partition causes communication with the administration server to be lost all data services are still available. However administration functions cannot be performed until the administration server is restored or the network healed.

The architecture of system supports one or more cells. System administers cells through the administration user interface . Each data server can hold filesets for additional servers and an administration server can be used to configure additional cells. Consequently cells can be relatively lightweight making the cells more useful and more configurable to application needs. Creating a new cell for administration and security purposes does not require new hardware.

Kernel services provided by the fileset kernel services module are generally implemented as loadable kernel modules. The fileset kernel services module implements functions for filesets e.g. create modify etc. These services are implemented via native filesystem calls for each operating system. These file services are generally called from a file system server and the data management server described as follows.

In one embodiment the file system server is a modified standard NFS server supporting version 4 NFSv4 of the NFS protocol. While system is described for illustration purpose only in relation to an NFS file server it should be clear that the invention is applicable as well to for example any type of file server. The file system server is modified to be fileset aware and to maintain the state necessary to implement fileset semantics comprising additional locations failover etc. in a manner invisible to client .

The file system server queries the fileset kernel services module to determine fileset information such as boundaries identifiers etc. The file server further queries the data management server via the kernel interface module to resolve client requests for fileset location information.

The data management server runs on each host in a cell providing file services. The data management server responds to requests from the administration server to execute fileset operations. In response the data management server maintains a small local database of configuration information and uses the fileset kernel services module via the kernel interface module to perform fileset operations. The data management server communicates with other instances of the data management server in a cell to perform fileset motion operations. The data management server further responds to a request generally from the file system server via the kernel interface module to look up locations for given filesets.

The administration server provides a point of coordination for administration functions performed by system . The administration server maintains a complete database of all configurations of a cell and information within the cell including servers filesets locations users groups automation jobs etc.

The administration server receives user requests and takes the appropriate action updating the local database of the administration server and forwarding commands to the associated data management servers in the cell. All communications by the administration server both with the administration client and the data management servers are implemented via a purpose built protocol.

Administrative action occurs via the administration client that communicates with the administration server . In one embodiment the administration client is implemented as a command line interface CLI that encodes and decodes user commands for processing by the administration server .

Storage management of system utilizes filesets in the context of distributed filesystems to sidestep limitations of storage management at the filesystem level. A fileset can be viewed as a storage abstraction somewhere between a filesystem and a directory. Like a filesystem a fileset owns its contents and therefore copying a fileset implicitly copies its contents. However unlike a filesystem a fileset does not own free space. Filesets allocate and free space for files and directories from one or more backing filesystems.

A fileset is a lighter weight object than a filesystem. The fileset is not tied to a particular operating system device and can be moved from one filesystem to another relatively easily. Whereas a server generally has a small number of filesystems the number of filesets a single filesystem can hold is limited only by the size of the filesystem and the sizes of the filesets themselves. A fileset can be as small as a single empty directory or as large as an entire filesystem.

Generally filesets are created to represent a semantic storage relationship. For example every user can have their home directory in a unique fileset regardless of size. Because filesets have low overhead there is little penalty for creating a large number of filesets. Filesets can also be easily created destroyed and moved. The analogous filesystem operations are heavy weight. Some operations on filesets i.e. promoting an existing normal directory to a new fileset have no filesystem analog.

System comprises filesets that are implemented as related objects. These related objects comprise a fileset object and a fileset location object as illustrated in . The data for a fileset is stored in one or more locations. In the simplest case a single location exists for a fileset thus the distinction between a fileset and its location is blurred. An example of this case is shown in fileset A has one location shown as fileset A location . However filesets can have additional identical locations as illustrated with a fileset B . Fileset B has two identical locations a fileset B location and a fileset B location . When a fileset comprises additional locations all locations are identical and can be used interchangeably.

Locations are usually spread across two or more servers. Having locations on two or more servers opens up opportunities for added value. For example the present system enables higher throughput. Adding servers can spread the client load spread across more computing and storage resources. The present system further reduces latency. If locations are placed on geographically distributed servers similarly distributed clients observe improved latency. The present system improves reliability. With two or more servers and automatic failover tolerance of machine crashes and regional disasters is achieved.

System comprises read write filesets and read only replica filesets. Read write filesets generally have a single location unless created in a clustered filesystem environment and can be read and written by additional clients in a manner similar to a conventional filesystem. A read only replica of a fileset is created through replication of another fileset at a particular point in time. Referring back to fileset B is created as a replica of fileset A . The contents of fileset B reflect the contents of fileset A when the replica is created. Subsequent changes to fileset A are not reflected in any location of fileset B until a replica update operation is requested either manually through the administration user interface or through automation provided by system .

Filesets become visible to clients once the filesets are mounted. Filesets are mounted on an existing directory in an existing fileset. When mounting a fileset system creates a special object called a referral .

Each server comprises a special filesystem that provides the root of the namespace of the filesystem for local file access. System provides a root namespace that serves a similar function for system services. Details of this namespace are described below.

Mount operations of system differ from conventional filesystem mounts. Mount operations of system are persistent i.e. mounts survive a system reboot. System is a distributed multi server system for which the impact of individual system failures is minimal. Filesets of system can be mounted more than once in additional places within the namespace. Since mount points of system are lightweight there is no penalty in allowing additional mounts.

Filesets are mounted rather than locations. It is the responsibility of the administration server and client to determine an optimum location for accessing data for a fileset with additional locations.

System further introduces a concept of an external mount point. The external mount point represents mounting a filesystem that does not comprise system within a fileset. System provides the services necessary to create and recognize the mount point that causes the client to attempt to fetch the data from the external server. System does not manage this external data in any way and cannot verify the availability or validity of the target data.

Once created and mounted filesets appear to clients as normal directories with some restrictions. For example a fileset cannot be destroyed via an rmdir command.

In addition to common filesystem operations system provides a number of operations specifically applicable to filesets. These operations comprise for example a place operation a promote operation a demote operation a migrate operation and a snapshot operation.

An existing fileset can have an additional location created through the place operation with the restrictions previously mentioned regarding read write filesets and cluster filesystems. The place operation indicates to the server where the new location is created. Additional locations for the same fileset can be placed on the same server which can in some cases improve performance.

An existing directory with existing content either within an existing fileset or not within an existing fileset can turned into a fileset via the promote operation. Similarly a fileset location can be demoted back to a normal directory using the demote operation.

Locations of filesets can be migrated from one server to another using the migrate operation. Migrating a location is similar to creating a new location and removing an old location but is performed in such a manner that no client disruption occurs.

The snapshot operation forms a snapshot of a fileset i.e. using the snapshot operation system generates a consistent copy at a point in time. System facilitates the snapshot operation but requires support from underlying filesystems. Otherwise all copies are not made consistently i.e. changes can occur during the time it takes services of system to walk the contents of a fileset.

System facilitates fileset organization by providing a common root namespace that all clients see. The root namespace contains no data and serves as a place to mount other user created filesets. All clients share the root namespace. The scope of the namespace as well as other objects generated by system are described below.

System provides added value to the infrastructure of a file system such as for example NFSv4 without enforcing additional requirements. For example an existing NFSv4 server can be added to a cell of system without disrupting any preexisting normal NFSv4 services that the NFSv4 server was providing.

When a file server is added to a cell system places a copy of the namespace of the cell on the added file server and exports the namespace as cellname . A client need only mount the cell or the root of the server pseudo filesystem if desired to access any data within the cell regardless of where the data resides.

System can fit within a global namespace i.e. a namespace that crosses all organizational boundaries such as for example a web URL managing data once a directory level suitable for a cell is traversed.

The data management framework of system seamlessly replicates migrates and navigates through filesets distributed across a federation of a wide area distributed network. In one embodiment the fileset abstraction of system is supported by an underlying physical filesystem. With native physical filesystem support a fileset appears as a filesystem from the client and server perspective except that the fileset masquerading as a filesystem can appear and disappear. In another embodiment adding a virtualization layer to system supports filesets. The virtualization layer requires support in the operating system for fileset management and hooks in the administration server to query the virtualization layer for fileset information.

As client traverses the server set Namespace client requires detection of filesystem transition crossing mount points to for example obtain replica locations and other meta data information. In the absence of filesets the client typically detects a filesystem boundary when the value of a file server ID fsid attribute returned by the administration server changes during traversal. Each filesystem returns a unique file server ID value that in most cases is based on the device major and minor numbers of the underlying device. Supporting fine grained filesets requires support from the underlying filesystem to return a unique file server ID value per fileset.

From a perspective of client fileset boundaries are defined by changes in values of the file server ID. System adds one or more hooks in the administration server to query system and returns a different file server ID per fileset. In one embodiment a simple mapping table between the fileset boundary and a virtual file server ID is used. Every object within the fileset returns the same file server ID on a client s get file attribute GETATTR request. In this approach system tracks every object in the mapping table and monitors the objects as the objects are created and deleted.

In another embodiment system walks up a directory tree by looking up . . . on each GETATTR request to determine if any ancestor directory is a fileset boundary. This approach works for directories with significant overheads but is not adequate for files. Given a filehandle in a request by client the administration server may be unable to determine the directory containing the file especially in the presence of hard links.

System is scalable and requires minimal state to be maintained while adding only nominal performance overhead. The fileset information of system is embedded in a filehandle exchanged between client and the administration server instead of maintaining the fileset information for object at the server.

If the client selects another node i.e. a child of the selected node decision step system determines whether the selected node is a root of a new fileset decision step . If yes system changes the filehandle returned to client to reflect the new fileset ID step . Otherwise the filehandle returned to client reflects the fileset ID of the prior node traversed by client step . The fileset ID passes through the successive filehandles that are exchanged between client and the administration server . Whenever client steps into a directory that is the root of new fileset the filehandle is changed to reflect the new fileset ID. On a GETATTR file server ID request by client the associated fileset ID is used to create a unique file server ID value that is returned to client .

Operations affected by system comprise GETFH PUTFH LOOKUP GETATTR LOOKUP SAVEFH RESTOREFH PUTROOTFH PUTPUBFH OPEN READDIR RENAME and LINK. The effect of supporting fine grained filesets on the handling by system of various file system operations is summarized as follows.

For operations such as SAVEFH RESTOREFH PUTROOTFH PUTPUBFH OPEN and READDIR system manages the fileset ID appropriately in a manner similar to previously discussed operations. For operations such as RENAME or LINK system returns an error such as for example the NFS4ERR XDEV error when a rename or hard link crosses a fileset boundary.

System provides the necessary support to handle fine grained filesets. System further determines when a fileset can be defined. In the simplest case filesets are managed in an administrative task before the administration server is online i.e. before filesystems are exported . In this case client does not have any state e.g. filehandles associated with the objects in a fileset and can be provided a virtual file server ID whenever client crosses a fileset boundary. The filesets can be static provided the server is online.

For an operational system with rare down times it is not always prudent to take the administrative server offline for any customer desired changes in fileset boundaries. Consequently system comprises a flexibility of dynamic filesets. New fileset boundaries can be established after the administration server is online and client has previously accessed data. An existing directory in an exported filesystem can be promoted to be the root of a new fileset. In this case it is desired that there are no existing hard links that cross the new fileset boundary. If a new directory is created and marked as a fileset the new directory is similar to a static fileset as the client has no state associated with it.

Dynamic promotion requires expiration of filehandles of objects that client has previously seen that now belong to a new fileset. System accomplishes expiration by for example returning a NFS4ERRYHEXPIRED error. To expire filehandles system relaxes the persistence attribute of filehandles. The administration server indicates to client that filehandles are volatile. Consequently client can prepare to maintain the necessary state required to rebuild the filehandles on expiration.

Filehandle expiration is generally expensive. Consequently the administration server determines which filehandles need to be expired to prevent expiring all filehandles. The fileset information is carried in the filehandle the administration server cannot determine which filehandles belong to the new fileset without traversing up the tree. To manage expirations system attaches a generation number to each fileset. Whenever a new fileset is promoted the generation number of an associated parent fileset is incremented. This generation number is also embedded in the filehandle along with the fileset ID. Whenever the administration server is presented with a filehandle that has a valid fileset ID the administration server checks the validity of the corresponding fileset generation. If the generation is not current the filehandle is expired. In this manner the filehandle expiration is contained within the outer fileset. A similar approach is taken when a fileset is demoted. In this case however expiration can be limited to the demoted fileset only.

Replica filesets are read only only the original fileset are read write. Any operation that results in a modification at the replica fileset further results in an error message. Replica consistency is administratively controlled i.e. an administrator can specify when and how often a replica needs to be updated. For example a replica can be a daily backup of the original fileset. In this case the replica update mechanisms comprise taking a snapshot of the source fileset at a specific time and updating all the replicas.

System manages replica updates. Although replicas are read only they need to be modified on an update while clients may be accessing the files of an update. For consistent updates system provides snapshot support. A snapshot based replica update requires that the filesystem snapshot be taken from the source fileset and then populated at the replica location. Clients such as client are then redirected to the new snapshot while preserving the filehandles. A snapshot based in place replica update requires that the filesystem not only support fileset level snapshots but also guarantee that namespace of the file ID be preserved across snapshots. This ensures that client sees the same filehandle and attributes for a given object that client was previously accessing.

Replication in system is useful for both load balancing and failure handling. For load balancing the administration server returns different server locations i.e. the fs locations attribute for the directory that is the boundary of a replica fileset. The locations returned can be based on the geographic or network location of client the load on the administration server or a combination of other factors. To enforce load balancing system can dynamically steer client to different replica locations. In such cases client handles volatile filehandles and different file ids for the same objects on a different administration server .

Additional replica locations are also useful to mask failures. When client detects that the administration server providing a replica is unresponsive or poorly performing client can connect to another administration server from the list of locations for that replica. Failover behaves somewhat similar to migration except that the administration server has failed and no state can be recovered.

A fileset of system can be physically migrated from one administration server to another. Protocol of system comprises a method of providing filesystem migration with the use of the special fs locations attribute. Migration is typically used for read write single copy filesystems and usually employed for load balancing and resource reallocation. For the purpose of migration a filesystem is defined as all files that share a given file server ID. This allows a fileset of system to be physically migrated from one administration server to another with no noticeable impact to client applications.

Fileset migration does not impact the location transparency of the namespace. Once a fileset is migrated the migrated fileset appears as a referral at the previous location of the fileset. All future accesses of the fileset on the original administration server result in client redirection to the new location. A client that did not previously communicate with the original administration server or did not have cached state pertaining to files from the migrated fileset encounters a referral when traversing the namespace of the administration server that includes the migrated fileset. Existing clients however potentially have outstanding state on the original administration server that are transferred between the participating servers.

In one embodiment no state is transferred to client . Client starts afresh at the new administration server . If client presents state information from the original administration server client receives stale errors. In this case client is expected to recover all state as in case of administration server failure. While this is a simple approach from a point of view of the designer it can be rather disruptive to client applications.

In another embodiment client sees a transparent migration in which all client states are transferred between instances of the administration server . Consequently client can continue to use the state assigned by the original administration server . Moreover clients can use persistent filehandles if the immigrating filesystems can recognize each filehandles of other clients .

In yet another embodiment client starts afresh at a new administration server except for files that client has open. All state pertaining to open files is migrated to the new administration server . While client expects filehandle expiration for other files client can continue to use existing filehandles for open files on the new administration server . This requires the administration server to recognize and service foreign filehandles specially. Other client state including client ID and lease information may also need to be migrated.

Apart from state management migration also requires data transfer in case of single copy read write file systems. In one embodiment a remote server acts as a proxy reading the data on demand and in the background. In this case client is instantaneously redirected to a new administration server . All reads writes and metadata operations occur at the new administration server . Apart from the performance concerns of client having to cross two instances of the administration server to get the data there are data integrity concerns. On a network partition between the two instances of the administration server neither of the instances of the administration server has a fully consistent copy of the fileset.

In another embodiment data transfer is complete before redirection of client occurs. However all the updates from client to the old administration server cannot be delayed before the data transfer completes. System uses a series of snapshots each with lesser data to be transferred. When the remaining updated data is sufficiently small clients such as client are paused until the data is moved over. Redirection of client occurs after the data is moved over maintaining data integrity.

The data management server manages server to server data operations. These services are responsible for maintaining the configuration state for all filesets within a cell and for transferring filesets between systems.

Most fileset data management operations occur as the result of an administrative action for example a request to create a new fileset or to place a new copy of a replica fileset on a new administration server . The data management server also supports the file system server in responding to requests for fs locations attribute. Since these attributes represent cell wide information they are the domain of the data management services.

Once a fileset exists on a host operating as an administration server the administration server uses the fileset services in responding to client requests. However these services do not encompass such functions as those necessary to actually create a fileset to migrate a fileset from one administration server to another or to make create a new location for a fileset. Fileset services of the data management server provide this functionality.

Data management fileset services on the data management server are implemented via a purpose built server to server protocol. An agent of the data management server is instantiated on every host comprising system . This agent is responsible for accepting requests from either an administrator or from other peer agents.

In addition to implementing fileset maintenance operations the data management server is responsible for managing fileset allocation to backing filesystem storage. When a fileset location is created it can be created at a specific location in the local filesystem hierarchy. Optionally allocation can be left to services of the data management server that maintain a list of pools of filesystems where filesets are created if not otherwise specified.

As part of the fileset services of the data management server a set of copy and replication services is provided. These copy and replication services are provided in a plug in library that anticipates instances of the administration server providing different combinations of these protocols.

A primary responsibility of the data management server is movement of filesets from one administration server to another administration server . This can happen for example in response to an administrative request to place a new fileset location to update existing replica locations from a source fileset or to migrate a fileset location from one administration server to another. When placing a new replica location or migrating a fileset a copy operation takes place. Different copy implementations exist that can provide optional compression for low bandwidth lines or no compression for higher performance where network bandwidth allows.

A data management operation is replica fileset update. In this case a higher performance protocol is available that only transmits fileset differences between instances of the administration server . The protocol selection process of the data management sever returns to a simple copy where an rsync protocol is not available.

To ensure that the data in a new or update replica is consistent with the state of the source at some point in time the fileset replication represents a point in time copy or snapshot. Without point in time copies the contents of the resulting fileset may not represent the contents of the source at any single time but rather a mixture of the contents of the source at different times. Whether this is acceptable or not depends on the use of the contents of the fileset.

System does not implement snapshot support but can utilize that support where provided by the underlying filesystem. For example when a fileset snapshot is requested for a fileset that exists within a filesystem providing snapshot functionality system can snapshot the entire filesystem that is sufficient but not necessary to snapshot the fileset location. This snapshot can then be used to populate or update a replica location. When the fileset snapshot is no longer required it can be destroyed at which point system releases the filesystem snapshot.

The data management server maintains and responds to requests for fileset location information. One source of this request is in response to a request by client for the fs locations attribute. While the kernel components of system maintain the necessary information to handle fileset requests for fileset locations on the current administration server the kernel does not maintain fileset information for locations not on the local administration server . The data management server maintains a small custom database of all locations for all filesets in the cell.

The data management server provides a service for requesting location data for a given fileset. This data location service is designed with a flexible interface for selecting among possible locations. The administration server has a complete list of all filesets locations and servers within the cell. This information can be augmented with status about server and network capacity and load maintained via intra cell services. The data management server ranks the list of candidate replica locations and returns an ordered list of the top n candidates where n is configured per cell. To facilitate this some information about a request by client for example client IP address is passed to the ranking function. From the list of locations returned to client client can select any of the locations in an implementation defined manner. Some existing client implementations select an initial location and only switch to another on failures by the administration server . Other client implementations use a round robin selection.

The data management server is responsible for maintaining the namespace of the cell in response to administrative mount and un mount requests. These services comprise maintaining a fileset representing the namespace and managing exports by administration server of all filesets including the namespace fileset.

To implement a namespace of a cell a read write fileset is created and maintained detailed description follows . This fileset exists on the administration server . A replica of this fileset is also created and a fileset location for this replica is placed on each data administration server in the cell. This read only replica thus becomes the root of the namespace. The data management server is responsible for modifying and updating both of these filesets in response to the various administrative operations.

System manages all exporting of fileset locations required for proper operation. Manual network file system exports are required. The primary export of system is that of the namespace. The local location of the namespace replica fileset is exported to cellname in a file system pseudo namespace. Thus any administration server in a cell can resolve the root of the namespace.

Each administration server also exports all the fileset locations it contains. A fileset mount operation results in creation of a mount point in the appropriate fileset representing the root namespace. This mount point triggers the administration server to respond to client with a moved error at which point client requests the fs locations attribute. System then responds with locations for this fileset including the fs root component. Because this component is not exposed to client system has complete freedom in where within the pseudo namespace it exports filesets as long as the exports and the data in the locations attributed is consistent. System exports fileset locations into a hidden directory nominally .hidden in the directory that implements the cell. This makes the directory available to client but not obvious to the user.

The data management server is responsible for managing all fileset related state whether the state is in kernel memory state or filesystem resident state. In particular the initializing services of the data management server are used to reload kernel information after a reboot or subsystem reset and to check for fileset consistency similar to fsck.

It is to be understood that the specific embodiments of the invention that have been described are merely illustrative of certain applications of the principle of the present invention. Numerous modifications may be made to the system and method for emulating a virtual boundary of a file system for data management at a fileset granularity described herein without departing from the spirit and scope of the present invention.

