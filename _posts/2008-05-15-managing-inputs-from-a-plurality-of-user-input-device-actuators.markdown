---

title: Managing inputs from a plurality of user input device actuators
abstract: A computing device and method for managing inputs from a plurality of user input device actuators are provided. The computing device may include code stored in memory for implementing, via a processor, an actuator input module configured to receive a first actuator input from a first user input device actuator, and a second actuator input from a second user input device actuator. The computing device may further execute code to implement a window selection module configured to select a first selected window to which the first actuator input is sent according to predetermined selection rules, to select a second selected window to which the second actuator input is sent according to the predetermined selection rules, and to send the first actuator input to the first selected window and to send the second actuator input to the second selected window.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08418076&OS=08418076&RS=08418076
owner: Microsoft Corporation
number: 08418076
owner_city: Redmond
owner_country: US
publication_date: 20080515
---
With larger monitors and more powerful processors becoming available in recent computing devices computer users increasingly engage in concurrent use of multiple application programs. Further each application program may include multiple windows to which user input may be directed. It is therefore a challenge for the user to switch between these multiple windows and efficiently enter user input to the appropriate application window. Before manipulating a scroll wheel of a mouse for example it can be laborious for a user with many windows open to bring a desired window into focus to receive a first scroll input and then bring another desired window into focus to receive a second scroll input. This can result in wasted time and frustration for the user.

A computing device and method for managing inputs from a plurality of user input device actuators are provided. The computing device may include code stored in memory for implementing via a processor an actuator input module configured to receive a first actuator input from a first user input device actuator and a second actuator input from a second user input device actuator. The computing device may further execute code to implement a window selection module configured to select a first selected window to which the first actuator input is sent according to predetermined selection rules to select a second selected window to which the second actuator input is sent according to the predetermined selection rules and to send the first actuator input to the first selected window and to send the second actuator input to the second selected window.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

Computing device may be configured to associate user inputs from a plurality of user input device actuators with one or more windows selected from a plurality of windows displayed in a graphical user interface on a display . To achieve this functionality computing device may include an actuator input module configured to receive a first actuator input from a first user input device actuator and a second actuator input from a second user input device actuator . The first user input device actuator and the second user input device actuator may be for example scroll wheels touch sensors or other user input device actuators configured to receive haptic input from a user. The haptic input may be processed by the actuator input module for example to be in the form of a scrolling input which in turn may be sent to a window of an application program for interpretation. The actuator input module may be configured to receive and process the first actuator input and the second actuator input inputs substantially concurrently so that the first user input device actuator and the second user input device actuator may be concurrently used by a user. While the first and second user input device actuators are discussed herein by way of example it will be appreciated that a larger number actuators may be provided as illustrated in by the Nth user input device actuator and that corresponding actuator inputs may be processed in parallel.

In some examples the first user input device actuator and or the second user input device actuator may be mounted in a housing of the computing device as indicated by dashed lines in . In other examples the first user input device actuator and or the second user input device actuator may not be mounted in a housing of computing device but rather may be incorporated into the housings of one or more external user input devices such as an external mouse keyboard touch pad graphics tablet game controller etc.

Continuing with computing device may further include a window selection module configured to select from among the plurality of windows a first selected window to which the first actuator input is sent according to predetermined selection rules . In addition the window selection module may select from among the plurality of windows a second selected window to which the second actuator input is sent according to the predetermined selection rules .

The predetermined selection rules may include for example one or more temporal predetermined selection rules spatial predetermined selection rules and predetermined user specified settings as discussed in more detail below. The temporal predetermined selection rules may be for example based on a chronological order of the first selected window and or the second selected window . The spatial predetermined selection rules may be based on a position of the windows within the GUI on display . The predetermined user specified settings may indicate a specific application window or frame within a window for example to send actuator input from a specified user input device actuator as described below.

Following selection of the first and second selected windows the window selection module is configured to send the first actuator input to the first selected window and to send the second actuator input to the second selected window . In this manner the window selection module applies the predetermined selection rules to map inputs from the different user input device actuators to appropriate windows promoting efficient user interaction with the computing device . Since the window selection module allows more than one window to be selected for receiving actuator input concurrently potentially cumbersome user input operations to change the window that is in focus for receiving user input may be reduced.

It will be appreciated that the actuator input module the window selection module and the selection rules may be implemented as an application programming interface API to facilitate communication between these modules application programs and an operating system of the computing device. Alternatively either or all of these modules may be implemented via application programs drivers etc. on computing device .

The computing device may further be configured to implement a settings interface module as part of API which is configured to generate a settings interface to be displayed on display . The settings interface may be configured to receive one or more user specified settings form a user which may be sent to the setting interface module for inclusion within selection rules . Via the settings interface a user may specify a particular window or frame within a window of an application to which a specific actuator s input should be mapped for example.

A rule generation module may also be provided to programmatically generate selection rules based on a variety of detected parameters such as user login the identity of application programs in use usage history and patterns etc. These programmatically generated selection rules may be stored with the other selection rules at a location accessible by the window selection module .

Display may be configured to be coupled to computing device and configured to display a multi window graphical user interface GUI generated by an operating system of the computing device . Within GUI a plurality of windows generated by one or more application programs may be concurrently displayed. By way of example in GUI is depicted to include a first window W a second window W a third window W and a fourth window W. Among these the first window W is illustrated as the first selected window and the second window W is illustrated as the second selected window . Of course it will be appreciated that other numbers of windows may be displayed and the first selected window and second selected window will vary based on the predetermined selection rules .

It will also be appreciated that more than one window may be associated with a particular application program and in such circumstances the window selection module may be configured to determine which among the various windows associated with the application program should be selected for delivery of incoming actuator input from each of the plurality of actuators . Further it will be appreciated that in some examples a window may further include a plurality of sub windows within its bounds also referred to as frames. Under such circumstances the window selection module may be configured to determine which sub window to which actuator input should be sent.

Continuing with window selection module may be further configured to encode the first actuator input and or the second actuator input to instruct the first selected window and or second selected window to perform an action based on the first actuator input and or second actuator input . Alternatively the actuator inputs may be passed in a raw form without encoding to the application programs via the selected windows and appropriate actions may be determined by the application programs . A variety of actions may be specified either by the window selection module or the application programs for performance in response to receiving the actuator input including tabbing list item selection scrolling mode changing window switching gadget switching zooming window sizing menu list access multiple desktop switching magnification panning rate change sensitivity adjustment and user re assignable actions. In this way desired actions may be carried out in different windows initiated by separate actuator inputs of the user without manually switching the window in focus.

Referring specifically to the spatial predetermined selection rule may specify for example that input from a first user input device actuator are to be sent to a leftmost positioned window and the input from the second user input device actuator are to be sent to a rightmost positioned window. In the illustrated example the horizontal variation between the first window W and the second window W may be detected by the window selection module and the leftmost window identified as the first selected window and the rightmost window identified as the second selected window . Thereafter input from the first user input device actuator may be assigned to the first selected window and input from the second user input device actuator may be assigned to the second selected window based on the detected horizontal variation. As discussed above the horizontal variation may be measured from a top left corner of each window or from another suitable point of reference such as the center of each window. It will be appreciated that temporal rules or user specified settings may be further applied in combination with the horizontal spatial predetermined selection rules to select target windows for actuator input. For example the leftmost and rightmost most recently accessed windows may be compared for horizontal position and mapped to the first and second actuator inputs or the left most and rightmost windows from one or more specified application programs specified by the user may be compared for horizontal position and mapped to the first and second actuator inputs.

Continuing with as an alternative to determining spatial position of the windows based on their position relative to the entire display the display may be divided into a plurality of spatial regions such as a left region and a right region and the position of each candidate window may be checked to determine whether it is in each of the spatial regions. In this example the horizontal spatial predetermined selection rule may be implemented as follows. First the horizontal position of the first window W and or the second window W is detected using a suitable point of reference as described above. Next it may be determined if the first window W and or second window is within the left region or the right region . Finally window W may be selected as the first selected window since it lies within the left region and the second window W may be selected as the second selected window since it is the located within right region . In this way the first selected window may be associated with the first actuator input from the first user input device actuator and the second selected window may be associated with the second actuator input from the second user input device actuator . It will be appreciated that where multiple windows are present in a spatial region additional temporal selection rules or user specified settings may be applied within each region to determine the first and second selected windows. For example the most recently used window in each region may be selected or a window of a user specified application program in each region may be selected.

Continuing with in another example rather than comparing the vertical positions of the windows relative to the entire visible area of display the vertical spatial predetermined selection rule may be implemented by dividing the display into a plurality of spatial regions such as an upper region and a lower region and assigning actuator inputs to a selected window in each of the upper region and lower region. To implement such a rule the window selection module detects a vertical position of one or more of the selected windows using a suitable reference point as described above. Based on the variation in detected positions the first window W may be selected as the first selected window and the second window may be selected as the second selected window and the first actuator input and second actuator input may be assigned accordingly.

In some embodiments as shown in and the first user input device actuator and the second user input device actuator are each mounted in a user input device having a common housing that is a housing that is shared by both the first and second user input device actuators. Further the common housing may be in the shape of a mouse. The mouse may have a right click button and a left click button and the first and second actuators may be positioned proximate to and in some embodiments intermediate the right click button and left click button . In other embodiments the housing of the user input device may be in the shape of a track ball a keyboard a numerical keyboard and various other user input devices.

Again referring to and the first user input device actuator and second user input device actuator may be provided in the form of scroll wheels configured for independent rotation. The first user input device actuator and the second user input device actuator may be mounted in and partially enclosed by the housing of the user input device may extend to be substantially perpendicular to a housing surface . While rotationally independent the actuators may be mounted along a common rotational axis. Additionally the first user input device actuator and the second user input device actuator may be positioned proximate to each other and in a substantially parallel orientation. The first user input device actuator and the second user input device actuator may extend longitudinally down the user input device allowing for ease of manipulation of the actuators. Alternatively the first user input device actuator and the second user input device actuator may be spaced apart from each other and or may not share a common rotational axis.

Furthermore as shown in the first user input device actuator and the second user input device actuator may be separated by a divider extending out of the housing of the user input device. The divider may have a profile that is substantially larger than the profile of the first user input device actuator or the second user input device actuator . The divider may serve to separate the first user input device actuator and the second user input device actuator providing a user haptic feedback to position digits on the actuators and allowing operation of each actuator to be carried out independently.

In some embodiments the first user input device actuator and the second user input device actuator may be constructed to be different from each other in material shape size texture and or color to enable the user to easily distinguish the actuators. Further each of the actuators may be equipped to provide a distinguishable haptic response to the user. For example each of the actuators may be equipped with clicking detents that provide haptic feedback during rotation and the first user input device actuator may be equipped with stronger and or differently spaced detents than the second user input device actuator or vice versa to thereby vary the rotational resistance haptic feedback pattern and or sound produced during use of each actuator. In this way a distinction can be made between the first user input device actuator and the second user input device actuator allowing the user to easily differentiate between the actuators.

Still in other embodiments the first user input device actuator and the second user input device actuator may be each mounted in separate user input devices having respective housings as schematically illustrated with dot dash lines in . For example the first user input device actuator may be mounted in a mouse and the second user input device actuator may be mounted in a keyboard. In another example the first user input device actuator may be mounted in a housing of a display and the second user input device actuator may be mounted in a housing of a computing device. It can be appreciated that the user input device actuators may be mounted in other suitable devices.

As illustrated at the method includes receiving a first actuator input from a first user input device actuator. At the method includes receiving a second actuator input from a second user input device actuator.

At the method further includes associating the first actuator input with a first selected window in response to one or more predetermined selection rules. As previously mentioned the predetermined selection rules may be based on factors selected from the group consisting of spatial position of the first and second selected windows temporal properties of the first and second selected windows and user specified settings.

At the method includes associating the second actuator input with a second selected window in response to the predetermined selection rules. According to these selection rules the first actuator input and the second actuator input may be assigned to various windows without a user manually adjusting the focus of the windows.

As shown at the method includes triggering a first action in the first selected window in response to a first actuator input. At the method further includes triggering a second action in the second selected window in response to a second actuator input. By way of example each of the first and second actions may be one or more of tabbing list item selection scrolling mode changing window switching gadget switching zooming window sizing menu list access multiple desktop switching magnification panning rate change sensitivity adjustment and user re assignable actions. Triggering the first action in the first window may include sending the first actuator input to the first selected window. Likewise triggering the second action in the second window may include sending the second actuator input to the second selected window. It will be appreciated that the method may loop to continue the mapping of actuator inputs to selected windows as desired.

As depicted in it will be appreciated that receiving the first actuator input at and receiving the second actuator input at may occur concurrently as may the downstream associating of each of these inputs with the first and second selected windows at and the triggering of corresponding actions in each of the selected windows at . With such concurrent processing a user may use the first user input device actuator and the second user input device actuator concurrently to send input to the different selected windows.

The above described systems and methods may be implemented to enable a user to efficiently map inputs from a plurality of user input device actuators to respective windows in a multiple window operating environment potentially enhancing the user experience. While two actuator inputs and two selected windows are illustrated by way of example it will be appreciated that multiple user input actuators may be mapped to multiple windows as desired. Thus for example three four or more user input device actuators may be provided and the systems and methods described above may be configured to process in parallel actuator input from the three four or more user input device actuators. Further while certain modules are shown as implemented in an application programming interface it will be appreciated that the functions carried out by these modules may be implemented by any number of modules and or may be implemented via an application program driver or as other code executable on the computing device.

It should be understood that the embodiments herein are illustrative and not restrictive since the scope of the invention is defined by the appended claims rather than by the description preceding them and all changes that fall within metes and bounds of the claims or equivalence of such metes and bounds thereof are therefore intended to be embraced by the claims.

