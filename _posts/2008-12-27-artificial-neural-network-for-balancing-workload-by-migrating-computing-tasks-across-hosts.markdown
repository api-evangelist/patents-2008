---

title: Artificial neural network for balancing workload by migrating computing tasks across hosts
abstract: Methods and apparatuses for balancing computing workload via migrating computing tasks are disclosed. An artificial neural network (ANN) is trained based on the workload distribution over time for a host. The ANN predicts the workload for the host, and an indication may be sent to migrate at least one computing task away from the host. The indication is sent when the method is operating in a proactive mode and when the predicted workload is outside of a desired operating range. Some embodiments monitor the workload; and automatically switch the method to the proactive mode, when a difference between the monitored workload and the predicted workload is small. Other embodiments monitor the workload; and automatically switch the method to a reactive mode, when the monitored workload is outside of a failsafe operating range for the particular host.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09384062&OS=09384062&RS=09384062
owner: VMware, Inc.
number: 09384062
owner_city: Palo Alto
owner_country: US
publication_date: 20081227
---
When a host executes a typical computer program also known as an application the application starts one or more computing tasks. At times it is desirable to migrate such computing tasks to another host for any one of a number of reasons. One such reason is that the source host otherwise known as a first host i.e. a host which will become the source of the migration may currently be overburdened with too many computing tasks. Another such reason is that the source host may be overburdened with even just a few computing tasks that consume substantial resources. Yet another such reason is that it may be desirable to shut down the source host either for maintenance or because it is only lightly used at the moment a result of which is that power can be saved by consolidating the current computing workload on fewer hosts.

Blade servers are examples of systems in which a number of servers also known as blades or hosts share resources including disk storage systems network and input output IO access power and cooling. The processors and main memory within each blade may be largely or totally interchangeable with those on the other blades. Blade servers are currently popular due to their cost effectiveness for a variety of computing tasks applied to many types of applications. The current popularity of blade servers is only one of the reasons to provide effective mechanisms to migrate computing tasks among compatible hosts.

A manual approach for migrating a computing task includes i the user of the program stopping its execution on the source host ii the user or the program automatically saving the current program execution state to one or more files on a disk shared by both the source host and the destination host and iii starting execution of the program on the destination host. One drawback of this approach is that each migration requires manual intervention. Another drawback is that not all programs include features that allow the user to stop execution and save enough information on the state of the program to disk files.

Automatic approaches for migrating a computing task include but are not limited to virtualization. Virtualization has become popular for a variety of reasons. One common use of virtualization is for host consolidation. Virtualization allows underutilized hosts i.e. physical machines to be consolidated onto a single host i.e. a single physical machine .

In a typical virtualization scheme a particular instance of an operating system and all of the applications that operating system executes form a virtual machine VM . Thus computing tasks may be encapsulated as part of a VM. A single host may execute multiple VMs. Typically each VM is unaware of the other VMs on the same host each VM usually has no access to information about other VMs on the same host and no VM can affect the operation of any other VM on the same host.

A VM can be migrated from a source host to a destination host automatically. While a VM may not need to be halted to migrate its performance may be reduced for a period of time during which the migration is in process. Further the performance of other computing tasks on both the source host and the destination host may be adversely impacted particularly in the case where the decision was made to migrate the VM because the source host currently has a high computing workload. Migrating a VM can require half a minute to several minutes to complete. See M. Nelson B H Lim and G. Hutchins Fast Transparent Migration for Virtual Machines Proceedings of USENIX 05 General Track Apr. 10 15 2005.

Plot line shows the computing workload on the source host assuming that no computing tasks are migrated away from the source host. As plot line shows there is essentially no computing workload on this host for the first few hours of the day. Starting around mid morning the computing workload exceeds 80 . By late morning the workload has maxed out around 100 . In the later part of the afternoon the workload declines to below 80 and in the late evening it declines to below 15 .

Plot line shows the computing workload on the source host assuming that a number of computing tasks are migrated away from the source host to a destination host when the computing workload exceeds a threshold of 80 . This migration can be done using VM technology.

Plot line assumes that the source host initiates computing task migration as soon as its measured computing workload exceeds 80 . The migration process forces the computing workload on the source host to go even higher due to the resources the migration consumes on the source host. That is there is a period of time during which peak of plot line is higher than plot line .

When a first set of computing tasks has been migrated away from the source host then plot line lowers peak ends and plot line forms trough . However in trough the computing workload measured on the source host is still above 80 . Thus the source host decides to migrate a second set of computing tasks.

This second migration results in peak in plot line . When the second set of computing tasks has been migrated away from the source host then plot line again lowers peak ends and plot line forms plateau . In plateau the measured workload is below 80 and thus no further migrations are needed.

Another limitation of the above mentioned prior art approaches is that they may trigger unnecessary migrations. An actual computing workload is very unlikely to be a smooth curve as shown by plot lines and . Rather an actual computing workload would likely include a jagged random offset to the plot lines as shown. Because of this a temporary spike in computing workload may trigger a migration of computing tasks however if the spike is short enough more computing workload may be consumed by the migration process executing on the source host and the destination host than would be consumed by the temporary spike itself.

One or more embodiments of the present invention are computer implemented methods and apparatus for balancing a computing workload adapted for use with at least two hosts that are configured to migrate computing tasks among themselves.

In accordance with one or more such embodiments there is a system for training a first artificial neural network ANN using the first ANN to predict a workload i.e. the predicted workload for a particular one of a number of hosts and sending an indication to at least one of the hosts to migrate at least one of a number of computing tasks away from the particular host. In accordance with one or more such embodiments training data for the ANN is based on a distribution over time of a computing workload for the particular host. In accordance with one or more such embodiments the indication is sent when the system is operating in a proactive mode and when the predicted workload is outside of a proactive operating range for the particular host.

Some embodiments include monitoring the computing workload for the particular host and automatically switching to the proactive mode when a difference between the monitored workload and the predicted workload is less than an autostart accuracy threshold. Other embodiments include monitoring the computing workload for the particular host and automatically switching to a reactive mode when the monitored computing workload is outside of a failsafe operating range for the particular host. When in the reactive mode the migration indication is sent based on the monitored workload.

Host and host each execute a single instance of a layer of virtualization support software which is called herein a VM kernel. The VM kernel supports the execution of virtual machines VMs such as for example VM that run guest operating systems GOSs and applications. Each VM kernel that is in system as shown in includes at least one artificial neural network ANN a workload controller and a VM migration engine .

Multiple VMs can execute on a single host supported by the VM kernel executing on that host. In the embodiment shown in i.e. VM system each VM includes a single instance of a GOS and each GOS supports the execution of one or more applications. A particular VM includes a particular GOS and all of the applications being executed on that GOS.

In VM system local network has a direct hardware connection to each of host host shared storage and other networks . Also host host shared storage and other networks communicate with each other via local network . Also local network provides a high speed connection among host host and shared storage . Also other networks are accessible to host and host via local network .

Each application communicates to the GOS that supports that application via known mechanisms that include but are not limited to application programming interfaces. The GOSs are generally unaware that they are running on a VM kernel but they communicate with the VM kernel each time they attempt to perform an activity that is restricted to the VM kernels an input output IO operation for example. Each VM kernel communicates with the host that supports it via known mechanisms including but not limited to issuing commands and setting machine specific registers MSRs .

Each particular GOS and the applications that it executes form a particular VM. A VM can be thought of as a virtual hardware platform including processors memory and devices. The virtual hardware platform is an abstraction that is largely independent of the underlying physical hardware. Thus a virtual machine can be configured identically even on different physical machines although in some embodiments processor features are passed through to the VM. Such embodiments support VMs taking advantage of faster and more sophisticated processors.

Each VM kernel is responsible for managing the resources of the physical hardware being used by the VMs that are supported by that VM kernel so as to enhance the performance and scalability of those VMs and to enhance the utilization of that physical hardware. The VM kernels schedule each of their VMs and allocate and manage the resources they need.

Host and host execute VM kernel and VM kernel respectively. VM kernel includes one or more ANNs workload controller and VM migration engine . Guest operating systems GOS to N execute on top of VM kernel . These GOSs form the lowest level within VM to N respectively. GOS executes application to application J. GOS N executes applications K and L. Thus host is currently being shared by N VMs each of which has its own GOS associated with it and each GOS is executing some number of applications.

VM kernel includes one or more ANNs workload controller and VM migration engine . Guest operating systems GOS M and P execute on top of VM kernel . These GOSs form the lowest level within VM M and P respectively. GOS M executes application M. GOS P runs applications P to Z. Host is currently shared by 2 active VMs each of which has its own GOS associated with it and each GOS is executing some number of applications. Host is also currently shared by the migrated version of VM N which however is not yet executing at the point in time shown in .

The embodiment shown in i.e. system performs a VM migration process indentified as VM migration process in for workload balancing. In the example shown in host is the migration source for VM migration process and host is the migration destination for VM migration process . During VM migration process there are temporarily instances of VM number N the version on host which is to be shut down and the migrated version on host which is to be started up.

VM migration process is shown in as a dashed arrow between the two instances of VM N. However all communication actually occurs between VM migration engine in VM kernel and VM migration engine in VM kernel . At the hardware level this communication goes to and from the VM kernels via host local network and host . The computing task migration process both for VM based embodiments and for other embodiments is further described herein with reference to .

In some embodiments host and host are blade servers based on an x86 microprocessor. In various embodiments shared storage is any combination of a storage area network SAN device a network attached storage NAS device or other mass storage devices that are capable of supporting multiple hosts.

Some embodiments are used in a system that includes one or more hosts for which the VM kernels on those hosts do not include an ANN or a workload controller. In such embodiments the present invention is used for some hosts within the system but not for those hosts without an ANN or a workload controller. In other embodiments an ANN and workload controller operate on a first host according to the present invention but handle workload prediction and proactive migration of computing tasks for one or more hosts in addition to the first host.

In various embodiments a typical GOS could be a version of MICROSOFT WINDOWS a version of Linux or a version of FREEBSD . In some embodiments a single VM kernel can support multiple types of GOSs executing at the same time.

As shown and described relative to various figures herein the multi host VM system predicts the workload on a host so that migration of computing tasks can be initiated on a proactive basis. In particular it is desirable that any needed migration begin early enough that the computing workload required to perform the migration does not compound any workload problem there might be on the source host.

Unlike the embodiment of system as shown in some embodiments use computing task migration techniques that are not based on virtual machines. The academic work on migrating computing tasks includes but is not limited to S. Osman D. Subhraveti G. Su and J. Nieh. The Design and Implementation of Zap A System for Migrating Computing Environments Proc. Of the 5th Operating Systems Design and Implementation December 2002.

As is known to those skilled in the art arcs between the nodes and indicate that prediction information generally flows among the nodes in the direction shown by the arcs. In particular prediction information generally flows from input nodes through one or more hidden layers of intermediate nodes and then from the intermediate nodes of a final hidden layer to output node .

As is known to those skilled in the art an ANN is a network of relatively simple processing elements also known as neurons or nodes . For example a particular node might compute k A j B where k and j are weights also known as parameters contained in the particular node and A and B are the output values of two nodes at input arcs of the particular node. Despite employing relatively simple processing elements an ANN can exhibit quite complex overall behavior as determined by the connections among the nodes the values of the parameters within each of the nodes and the adaptation also known as back propagation or training that the ANN receives. The process of training or retraining of an ANN includes adjusting the values of the parameters in each of the nodes.

Input node receives measured workload from other components within the VM kernel or within workload controller . In some embodiments the VM kernel keeps track of workload measurements that are directly suitable for use as measured workload . In other embodiments workload controller requests that the VM kernel track the information needed. In yet other embodiments workload controller periodically queries the VM kernel for workload measurements and aggregates or otherwise processes these measurements as needed to form measured workload .

In some embodiments measured workload is the average percentage of CPU utilization over the most recently completed 10 minute time period. In various embodiments the computing workload is selected from a variety of factors including but not limited to i a processor utilization indication ii a memory utilization indication iii an input output IO utilization indication or iv any combination average or weighted average thereof.

Input node receives time period from other components within the VM kernel. In some embodiments time period is a count of the 20 minute time periods that have elapsed since midnight.

In some embodiments that use optional input node it receives day category from other components within the VM kernel. In other embodiments day category is not used and ANN treats each day of the week equivalently. In yet other embodiments Monday through Friday are categorized into a first day category and Saturday and Sunday are categorized into a second day category.

In yet other embodiments multiple ANNs are used one for each day category but these ANNs do not receive day category as an input. Rather the day category that applies to the current day is used to select which one of the multiple ANNs is used for the duration of that day.

Input node receives predict only flag from workload controller as shown in . When operating in the predict only mode ANN does not update its training i.e. retrain itself. Predict only mode may be desirable to avoid oscillation that is repeated periods of retraining. For example predict only mode may avoid oscillation if one or more VMs have been migrated off the particular host but it is expected that these same VMs or other VMs that are equivalently resource intensive are likely to be migrated back.

When not in predict only mode ANN is in the training retraining mode. In training retraining mode ANN updates the parameters within its nodes based on its inputs and on the accuracy of its output predictions. These updates are performed according to a specific training methodology.

Some embodiments of the invention use a well known back propagation algorithm as the training methodology for the ANN. Back propagation can be summarized as entering a current set of input training values into the input nodes of an ANN entering a correct or training output value into the output node of the ANN. Then working from the output node back through each previous layer of the ANN adjusting the parameters of the nodes to obtain the training output value as the value of the output node based on the training input values. The exact algorithm and mathematics used in back propagation are as known to those skilled in the art more elaborate than the above summary.

Training retraining mode may be desirable after the measured workload changes due to changes in the activity level of the VMs on a particular host. Training retraining mode may also be desirable after the addition of a new VM to a host. Training retraining mode may also be desirable after one or more VMs have been migrated off a particular host especially i when inbound VM migration is not likely ii when ANN is further trained to base its predicted workload on whether inbound or outbound VM migration has recently occurred or iii when inbound migration occurs and oscillation between training retraining mode and predict only mode would not occur or would dampen quickly enough that such oscillation would not cause a significant performance impact .

Input node receives training workload from workload controller as shown in . ANN is trained by providing it with past data on the workload of a particular host as this workload varies with the time of day. In some embodiments described above the day category is also taken into account either by being a part of the training data or by having separate sets of training data for separate ANNs for each of the day categories.

Output node generates predicted workload for a particular host based on the information it receives from the intermediate nodes that are within the final hidden layer of the ANN. In some embodiments predicted workload is the average percentage of CPU utilization that ANN predicts will occur during the current 20 minute time period. In some embodiments time periods start with time period number 1 which lasts each day from midnight to 12 20 AM then number 2 which lasts from 12 20 to 12 40 AM and so on.

If a good set of training data is available then ANN can be rapidly trained by cycling time period training workload and day category if used though some number of days worth of workload measurements. Alternatively or additionally ANN can more gradually train itself based on measured workload .

In some embodiments ANN retrains itself based on measured workload while simultaneously generating predicted workload . In some embodiments that employ such simultaneous retraining and prediction the accuracy workloads predicted from ANN may be increased or ANN may be able to adapt itself to changing computing workloads or both.

In some embodiments ANN is implemented as shown in that is software that is contained within the VM kernel.

In other embodiments ANN is implemented as a software program also known as an application that executes on the particular host for which the ANN predicts the workload. For example the NeuroSolutions product from NeuroDimension Inc. of Gainesville Fla. may implement be used to implement the ANN of an embodiment.

In some embodiments a 3 layer ANN is used with three nodes in the first input layer 20 nodes in the second intermediate layer and one node in the third output layer. Back propagation is used as the training technique. The three input nodes receive respectively the day of the week the time stamp and the measured workload which is expressed as a number ranging from 0.0 to 1.0. The output is the predicted workload which is also expressed as a number ranging from 0.0 to 1.0.

At entry point the process of configuring a new ANN or reconfiguring an existing ANN starts. Then in step the user sees i a set of configuration settings for the method ii the monitored workload of the particular host over a period of time and or iii the predicted workload for the particular host over a period of time. Users of process are generally system administrators responsible for keeping the hosts involved in the migration process up and operating effectively.

In various embodiments the configuration settings may include but are not limited to whether the ANN is training retraining or predict only mode whether the ANN is in the proactive mode or the reactive mode whether workload controller is in an autostart mode an accuracy threshold for the autostart mode whether automatic migration of a particular VM is enabled or disabled whether a set of two or more VMs must be migrated together whenever any one of them is migrated a relative priority for migration processes versus other computing tasks a failsafe operating range a proactive accuracy range and a reactive accuracy range.

Step also optionally includes receiving from the user one or more new values for the configuration settings. In embodiments that use day category such commands may apply to a particular category of days or to all days.

At entry point the process of restarting a host starts. Decision step occurs after the restart process starts at entry point or after step . Decision step transfers control to step when workload controller is in the reactive mode. Decision step transfers control to step when workload controller is in the proactive mode.

During step workload controller operates in the reactive mode. In the reactive mode the predictions of ANN are not used to make migration decisions rather the measured workload is used. In the reactive mode ANN generally operates in training mode although the current configuration settings may make ANN dormant. The operation of workload controller in the reactive mode is described further herein with respect to .

Periodically during step decision step is performed. Decision step compares the recent history of predicted workloads for the particular host with the measured workload for the corresponding time periods. If ANN has converged that is if its training process is far enough along that its predicted workloads are sufficiently accurate then decision step transfers control to step and thus workload controller automatically enters the proactive mode. In order for this to occur the user must have enabled autostart and the errors calculated must be less than the autostart accuracy threshold set by the user.

There may be a particular host that has an unpredictable workload. In that case the training of ANN would not converge and the accuracy of its predictions would not become sufficiently accurate that workload controller ever enters the proactive mode. While this does not allow one or more embodiments of the present invention to be realized for such hosts they can continue to operate in reactive mode. In some embodiments ANN disables itself if it does not converge after a training period set by the user. In other embodiments ANN is disabled by the user when the user decides that training is unlikely to converge. In yet other embodiments ANN continues to train in case the workload on that host does eventually become predictable.

During step workload controller operates in the proactive mode. In the proactive mode the predictions of ANN are used to make migration decisions. In the proactive mode ANN may operate in training retraining mode or may operate in predict only mode according to the configuration settings. The operation of workload controller in the proactive mode is described further herein with respect to .

Periodically during step decision step is performed. Decision step compares the measured workload for the particular host with the failsafe thresholds. If the predicted workloads from the ANN have been sufficiently accurate then the measured workload should lie within the operating range set by the failsafe thresholds. In this case decision step transfers control to step and thus workload controller stays in the proactive mode.

On the other hand it is possible that the host is getting too busy or is not staying busy enough and that the predicted workload from ANN has not been accurate enough to correct these effects. In these situations the failsafe operating range should be exceeded or undershot in which case decision step automatically transfers control to step and thus workload controller enters the reactive mode. In some embodiments this advantageously provides a failsafe mode of operation when the accuracy of the ANN falls off. A typical cause of a fall in the accuracy of an ANN is because the workload of the host suddenly changes.

Some embodiments include in step providing a graphical display of the monitored workload of a particular host over a period of time versus the workload predicted by the appropriate ANN for the particular host over the same period of time.

Step may optionally include receiving from the user one or more new values for the configuration settings. The configuration settings may include but are not limited to one or more selected from a command for ANN to enter the training mode a command for ANN to enter the predict only mode a command for workload controller to enter the proactive mode a command for workload controller to enter the reactive mode a command for workload controller to enter the autostart mode a command to stay in the current mode a command to disable automatic migration of a particular VM a command to require that at least two VMs be migrated together whenever any one of them is migrated a priority for migration processes versus other computing tasks a command to set an autostart accuracy threshold a command to set a failsafe operating range a command to set a proactive accuracy range a command to set a reactive accuracy range a command that applies to a category of days or a command that applies to all days.

In various embodiments the steps of process as shown in may be reordered combined with each other and or altered in other ways as known to those skilled in the art.

During step workload controller operates in the reactive mode. Periodically during step decision step is performed. Decision step compares measured workload for the particular host with a high reactive threshold and with a low reactive threshold.

If measured workload is within the reactive operating range i.e. if it is between these two thresholds then control loops back to step . If measured workload is greater than the high reactive threshold then control is transferred to step . If the measured workload is less than the low reactive threshold then control is transferred to step .

In step workload controller sends an indication including an offload flag to one or more of the hosts to offload at least one VM from the particular host which will become the source host for migration process . Then control loops back to step .

In step workload controller sends an indication including a reduce power flag to one or more of the hosts to offload all VMs from the particular host and to put it into a reduced power mode. Then control goes to step during which ANN and workload controller are shut down or prepare to be shut down as the VM kernel of which they are a part is shut down. This ends process .

In some embodiments the reactive mode is used while ANN is initially being trained or as a failsafe mode to take over when the accuracy of the ANN falls off. Process starts with decision step and typically loops between decision step and step .

After workload controller decides to offload one or more VMs executing on a particular host due to a high computing workload on that host the workload controller must decide which VM s are to be migrated. In various embodiments this decision is constrained or influenced by one or more factors including but not limited to 

Once a VM is chosen to be migrated a decision must be made as to which host is to be the destination host for this migration. In some embodiments workload controller of the source host sends in steps and indications directly to one or more hosts which respond to the workload controller with information on their current status. Then workload controller of the source host selects the most suitable target host.

In other embodiments workload controller sends in steps and the indications to a central system monitor that executes on a particular host within the system rather than being sent directly to one or more hosts. The central system monitor determines a suitable target host for the VMs to be migrated and sends the indication on to that host.

In various embodiments this decision as to a suitable target host is constrained or influenced by one or more factors including but not limited to 

Unlike the embodiment of process as shown in some embodiments use computing task migration techniques that are not based on virtual machines. See for example Osman et al. cited herein in the description of . In various embodiments the steps of process as shown in may be reordered combined with each other and or altered in other ways as known to those skilled in the art.

During step workload controller operates in the proactive mode. Periodically during step decision step is performed. Decision step compares predicted workload for the particular host with a high proactive threshold and with a low proactive threshold. In contrast decision step of uses measured workload instead of predicted workload .

If predicted workload is within the proactive operating range i.e. if it is between these two thresholds then control loops back to step . If measured workload is greater than the high reactive threshold then control is transferred to step . If the measured workload is less than the low reactive threshold then control is transferred to step .

In step workload controller sends an indication including an offload flag to one or more of the hosts to offload at least one VM from the particular host. Then control loops back to step .

In step workload controller sends an indication including a reduce power flag to one or more of the hosts to offload all computing tasks from the particular host and to put it into a reduced power mode. Then control goes to step during which ANN and workload controller are shut down or prepare to be shut down as the VM kernel of which they are a part is shut down. This ends process .

In various embodiments steps and are performed by various tasks on various hosts within the system according to various factors. These tasks hosts and factors are described herein with respect to .

In the proactive mode and under some operating conditions the use of predicted workloads by workload controller to decide whether or not to migrate computing tasks advantageously causes such migrations to occur proactively and early.

Unlike the embodiment of process as shown in some embodiments use computing task migration techniques that are not based on virtual machines. See for example Osman et al. cited herein in the description of .

In various embodiments the steps of process as shown in may be reordered combined with each other and or altered in other ways as known to those skilled in the art.

Plot line shows the computing workload on the source host making the same assumptions as were made for plot line in . Plot line assumes that no computing tasks are migrated away from the source host. As plot line shows there is essentially no computing workload on this host for the first few hours of the day. Starting around mid morning the computing workload exceeds 80 . By late morning the workload has maxed out around 100 . In the later part of the afternoon the workload declines to below 80 and in the late evening it declines to below 15 .

Plot line shows the computing workload on the source host assuming that a number of computing tasks are proactively migrated away from the source host to a destination host. This migration is assumed to start when the predicted workload exceeds a threshold of 80 but prior to when the actual workload gets that high.

Plot line shows the computing workload on the source host assuming that the source host initiates computing task migration as soon as its predicted computing workload exceeds 80 . The migration process forces the computing workload of the source host to go even higher due to the resources that the migration consumes on the source host. That is there is a period of time during which peak of plot line is higher than plot line . Nevertheless due to starting earlier than the similar but reactive process illustrated in the measured computing workload never exceeds the desired threshold of 80 .

When a first set of computing tasks has been migrated away from the source host then plot line lowers peak ends and plot line forms trough . Plot line shows the computing workload on the source host assuming that during trough the predicted workload for the source host is still above 80 . Thus the source host decides to migrate a second set of computing tasks.

This second migration results in peak in plot line . When the second set of computing tasks has been migrated away from the source host then plot line again lowers peak ends and plot line forms plateau . In plateau the measured workload is below 80 and thus no further migrations are needed.

There is a third migration that results in peak in plot line . When the predicted workload falls below 15 of the capacity of the source host a third set of computing tasks is migrated away from the source host. This third set includes all tasks that are currently active on the host so that the host can be put into a low power state or shut down completely. At drop plot line goes to zero to enable this power savings.

VM migration process involves the following steps i decision selection and initiation ii pre copy memory state iii quiesce the VM and send the non memory state iv transfer control and resume the VM and v send remaining modified memory and or fault in missing pages . In each VM migration process these steps occur in the order listed and shown unless a particular VM migration process is initiated and subsequently aborted.

Step initiates VM migration process by deciding which VM to migrate and selecting the destination host to which this VM is to be migrated. During step source host sends prepare message to destination host which replies with OK to migrate message . During steps the VM being migrated is still executing on source host .

After step step pre copies the memory state of the VM directly from the source host to the destination host. The physical memory of the virtual machine is the largest state component of a virtual machine besides the virtual disks. Proper handling of the physical memory during migration is important for a VM migration that attempts to minimize the impact on the performance and the availability of the VM being migrated. During steps the VM being migrated is still executing on source host .

The physical memory is sent while the VM continues to run on the source which implies a probably iterative process of repeating pre copy process . That is the first iteration of pre copy process copies to the destination host the entire physical memory of the VM. Before each physical page is copied it is marked read only so that any modifications to the page can be detected by the VM kernel on the source host. When the first iteration of pre copy process is completed all of the memory has been copied. However because the VM was executing during the pre copy process some memory pages may have been modified after being copied. Thus pre copy process is repeated until either the number of modified pages is small enough or until insufficient forward progress has been made. In particular each iteration of pre copy process should take less time than the previous iteration. There can be cases where the VM modifies memory faster than it can be transferred and such cases should be detected and handled as exceptions.

Step may also include other optimizations such as data compression and or not sending indications but not full copies of memory pages that contain only zeros.

After step step quiesces the execution VM on source host after which the source host sends non memory state information to destination host . Non memory state information includes but is not limited to i the virtual device state including the state of the processor the motherboard network adapters disk adapters serial ports floppy disks and the super video graphics array SVGA or other video information ii the external connection state with devices including networks universal serial bus USB devices small computer system interface SCSI devices and iii the external connection state with removable media such as floppies compact disk read only memories CD ROMs and digital versatile disks DVDs . Non memory state information for a typical VM may be less than 5 megabytes with the largest of that being the SVGA frame buffer.

After step step transfers control of the VM to the destination host and resumes execution of the VM thereon. It is important that the same VM never be executing on two hosts at the same time. Thus when the migration is completed the source host sends resume message to the destination host. In acknowledgement the destination host sends resume started message . Once the source host receives resume started message it can no longer resume the migrated VM but otherwise source host can resume the VM. Up until the time that it receives resume started message the source host could decide to abort a VM migration process for example if the destination host stopped responding to the source host.

It is possible that the destination host sends resume started message but the source host never sees it. In this case both source host and destination host may try to resume the same VM. In order to guarantee that only one machine will resume the VM an atomic on disk lock for each virtual disk that is used by a VM arbitrates between the two machines.

In step all virtual computing tasks and processors begin execution where they left off. In addition any pending interrupts for things such as disk completions that occurred while the VM was quiesced are be delivered to the guest operating system GOS to be delivered to the VM that was migrated.

In some embodiments both the source host and the target host have access to the same disk storage such as shared storage as shown in and thus disk files need not be copied. In other embodiments step further includes sending disk files to a storage unit that is available to the target host.

In some embodiments during step source host sends any remaining memory state of the migrated VM as needed. In such embodiments any accesses to memory pages that are missing on target host are handled as page faults that are to be paged in from source host via response messages .

In other embodiments during step source host sends all of the VMs remaining memory state to destination host . This removes the dependency of the migrated VM on source host . The migrated VM is more robust if all information is transferred from the source host to the destination host because in that case the migrated VM is not impacted by failures or performance issues on source host .

In yet other embodiments source host does both that is it gives higher priority to sending pages needed to complete page faults and lower priority to sending all remaining pages.

Unlike the embodiment of VM migration process as shown in some embodiments use computing task migration techniques that are not based on virtual machines. See for example Osman et al. cited herein in the description of .

In various embodiments the steps of VM migration process may be reordered combined with each other and or altered in other ways as known to those skilled in the art.

In some embodiments VM migration takes a running virtual machine and moves it from one physical machine to another in a way that is transparent to the guest operating system applications running on the operating system and remote clients of the virtual machine. The only perceived change should be a brief slowdown during the VM migration and a possible improvement in performance after the migration because the VM was moved to a destination host with more available CPU disk or network bandwidth. In general in order for a migration to be transparent a migrated virtual machine can be unavailable for only a short time while being migrated. Thus it may be necessary to pre allocate to the VM migration any of all of i source host processor time ii destination host processor time or iii network bandwidth.

In other embodiments VM migration is allowed to compete with computing tasks from other VMs and from the VM kernel. These embodiments may be appropriate for a VM for which a relatively long pause in its availability is not an issue or for a situation in which the VM being migrated has low priority on computing workload relative to the other activities currently going on. In these embodiments the VM migration will have less impact on the computing workload on the source host and on the destination host.

In yet other embodiments a VM is quiesced then its memory state and non memory state information is written from the source host to a shared disk memory. When resources are available on the destination machine the state information of the VM is read from the shared disk memory to the destination host and then the VM is resumed on the destination host. In these embodiments the VM migration will have even less impact on the computing workload on the source host and on the destination host partly because the bandwidth of information transfer to and from a shared disk is likely to be significantly lower than via a network. Generally the bandwidth of a network transfer of information directly from host nation host is higher than the bandwidth of two transfers first from the source host to a disk and second from the disk to the destination host. Again these embodiments may be appropriate for a VM for which a relatively long pause in its availability is not an issue or for a situation in which the VM being migrated has low priority on computing workload relative to the other activities currently going on.

The inventor has discovered various embodiments that balance a computing workload as described herein. Some embodiments help solve the problem in modern multiprocessor systems of migrating computing tasks without first allowing performance to be compromised on the source host from which computing tasks will be off loaded. Various embodiments may advantageously increase overall performance of a multiprocessor system by proactively migrating computing tasks based on predicted workloads.

A variety of specific qualities quantities sizes and parametric values have been specified herein. It will be clear to those skilled in the art that these and other attributes can be varied widely without departing from the spirit or the scope of the present invention. Examples include but are not limited to i using a longer or shorter time period for measured workload and time period ii using various day categories for example categorizing Monday through Friday as a first day category Saturday as a second Sunday as a third and holidays as a fourth day category and iii using ANNs with varying numbers of nodes varying numbers of intermediate layers.

Although the present invention has been described in terms of specific embodiments it is anticipated that alterations and modifications thereof will no doubt become apparent to those skilled in the art. It is therefore intended that the following claims be interpreted as covering all such alterations and modifications for example structural functional usage parametric and other changes as falling within the true spirit and scope of the invention.

