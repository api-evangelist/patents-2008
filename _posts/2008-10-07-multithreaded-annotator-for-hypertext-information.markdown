---

title: Multi-threaded annotator for hypertext information
abstract: The present invention relates to a system for handling client/server traffic and communications pertaining to the delivery of hypertext information to a client. The system includes a central server which processes a request for a web page from a client. The system operates by receiving a request for a web page from a client. If information for the requested web page is available in a cache, it is forwarded to the client. Otherwise, the relevant information for the requested web page is retrieved from the pertinent server and processed to generate additional relevant information for creating an annotated version of the requested web page which includes additional displayable hypertext information. In handling its communications with various processing/storage entities, the operating system running behind the central server utilizes a pool of persistent threads and an independent task queue to improve the efficiency of the central server.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08307364&OS=08307364&RS=08307364
owner: General Electric Company
number: 08307364
owner_city: Schenectady
owner_country: US
publication_date: 20081007
---
This application is a continuation of U.S. patent application Ser. No. 10 672 236 filed Sep. 25 2003 now U.S. Pat. No. 7 437 725 which is a continuation of U.S. patent application Ser. No. 09 524 046 filed Mar. 13 2000 abandoned and this application is also related to 1 U.S. patent application Ser. No. 09 021 331 filed Feb. 10 1998 and allowed to issue on Jul. 18 2000 U.S. Pat. No. 6 092 074 and 2 U.S. patent application Ser. No. 09 476 758 filed Jan. 3 2000 entitled AUGMENTING INFORMATION BY DYNAMIC INSERTION OF HYPERTEXT LINKS now abandoned which claims the benefit of priority from U.S. Provisional Patent Application Ser. No. 60 114 712 filed Jan. 4 1999 all of which are hereby incorporated by reference as if set forth in full in this document.

The present invention generally relates to processing techniques for a server handling client server traffic and communications. More specifically the present invention utilizes persistent threads and an independent task queue to improve the efficiency of servers. This invention is particularly suitable for use with servers handling client server traffic and communications in a computer network such as the Internet.

The predominant way to access information on the Internet is through the use of a browser. A browser is a software program that allows a web surfer to view web pages accessible on the Internet. In order to properly display a web page on a computer screen the underlying script which represents the web page must be written in a language that can be interpreted by the browser. Hypertext languages which may include Hypertext Markup Language HTML Extended Markup Language XML or other forms of Standard Generalized Markup Language SGML are often used to accomplish this purpose. Put in simplified terms the browser interprets a hypertext script which essentially contains text and formatting commands and displays the web page on the screen in accordance with those text and formatting commands. The web page as displayed may or may not contain any hypertext links to other web pages.

Many web users currently find a large number of existing web pages to be lacking in hyperlinks. Therefore in addition to retrieving the hypertext script for a desired web page it would be desirable to provide the capability to modify the original hypertext script to offer additional hyperlinks and functionality. One such invention which provides the foregoing desired capability is disclosed in the co pending U.S. patent application Ser. No. 09 021 331. As disclosed therein that particular invention is a method and apparatus for automatically providing additional hypertext anchor codes and destination addresses for a pre existing web page. That invention among other things modifies the underlying hypertext script to produce an annotated version of the pre existing web page that includes additional hypertext links and other functionality.

Since web pages are retrieved and viewed by web users during every second of every day at an astronomical rate the task of generating an annotated web page each time a web page is accessed could become quite burdensome. From an efficiency standpoint it is more efficient to retain a copy of the annotated web page for subsequent use. Otherwise every time an annotation request is received from an user regardless of the request frequency all the processing steps have to be repeated starting from retrieving the original web page from the content server to producing the annotated web page. Therefore it would be desirable to provide a system that can efficiently process and handle annotation requests.

By processing and handling the annotation requests in a more efficient manner valuable time can be saved thereby allowing the web users to view their desired web pages more quickly.

Furthermore under current practice a web user usually subscribes for Internet access and other subscription services through an Internet service provider ISP . is a simplified block diagram showing a conventional configuration for Internet access. The ISP acts as a gateway to allow a web user using a browser residing on a user computer to access the Internet . When access to the Internet is needed the web user using the user computer contacts the ISP to have the ISP assign a temporarily IP address to the user computer . With the assigned IP address the user computer is then able to communicate with other computers on the Internet. For example if a web user desires to retrieve a particular web page the user computer contacts the server where the desired web page is located and the pertinent hypertext script for that web page is retrieved to the web user s browser on the user computer to allow that web page to be displayed.

Since the use of a browser is the most preferred way to access information on the Internet it would be safe to conclude that a high percentage of this Internet communication traffic is attributable to transfers of hypertext information. With the use of the Internet increasingly growing more popular among the general public heavy Internet communication traffic is becoming a significant issue in connection with managing and hosting web servers. Therefore it would be desirable to provide a system that can help reduce Internet communication traffic during the processing of annotation requests.

In addition there is a constant need to improve the efficiency of a server servicing requests from a client over a computer network. An operating system running behind a server generally uses a pool of threads to control the number of executable requests. Such threads are spawned or generated by the server when a request requires execution and are terminated upon a request s completion. A thread represents an authorization without which a particular request cannot be executed by the server. The thread is a signal given by the operating system to ensure that there are sufficient resources from the system to allow a request to be executed.

Typically a thread is assigned to a request exclusively until the request reaches its conclusion. Such exclusive assignment is often very wasteful when a request further comprises a number of sequential tasks. When one or more tasks within a request cannot be initiated or completed due to other system constraints an assigned thread is occupied but not efficiently used thereby rendering the server inefficient as well. Therefore it would be desirable to provide processing techniques that are capable of improving the efficiency of a server servicing requests from a client.

The present invention relates to processing techniques for servers handling client server traffic and communications pertaining to the delivery of hypertext information to a client. A system which is capable of processing annotation requests may include a central server for processing a request for a web page from a client a cache for storing information relating to requests previously received from clients and an annotation module for annotating the requested web page. The central server further includes a querying module for querying the cache to determine whether information relating to the request is present in the cache and an updating module for populating the cache with annotated information generated by the annotation module.

The system operates by receiving a request for a web page from a client. The cache is then queried by the querying module to determine whether information for the requested web page is available. If such information is available it is forwarded promptly to the client for display. Otherwise the central server directly retrieves the necessary information for the requested web page from the pertinent server connected to the Internet. The web page information is then processed by the annotation module to generate additional hypertext information which can be used to create an annotated version of the requested web page which includes additional displayable hypertext information. The central server then relays the additional hypertext information to the client to allow the client to generate an annotated version of the requested web page for display. In addition the central server can also update the cache with the additional hypertext information.

In order to optimize the performance of the central server a pool of persistent threads and an independent task queue are used to expedite the processing of the annotation requests. Optionally an additional independent I O queue can also be used to further enhance the performance of the central server.

Reference to the remaining portions of the specification including the drawings and claims will realize other features and advantages of the present invention. Further features and advantages of the present invention as well as the structure and operation of various embodiments of the present invention are described in detail below with respect to accompanying drawings like reference numbers indicate identical or functionally similar elements.

The present invention generally relates to processing techniques for a server handling client server traffic and communications. More specifically the present invention utilizes persistent threads and an independent task queue to improve the efficiency of servers capable of processing annotation requests from a client to a server over a computer network such as the Internet.

The annotation process takes place as follows. An Annotator first parses the text of the original web page and identifies certain keywords or character strings for subsequent annotation. The Annotator then matches the keywords or character strings in the web page text with predefined words in a database. Additional hyperlinks and other related information associated with these keywords or character strings are then retrieved from a database and passed onto a user computer in particular a browser on the user computer to allow the user computer to incorporate and display the additional hyperlinks and related information in a modified web page. An important end product generated by the Annotator is additional hypertext information that can be incorporated to form a modified hypertext script which allows a browser to display the annotated web page having the added hyperlinks and functionality. In a preferred configuration the Annotator does not directly access the databases containing the predefined keywords or character strings and their associated additional hyperlinks and other related information. Instead during startup of the Annotator copies of those databases are loaded into a memory storage area which can be more efficiently accessed by the Annotator. Those databases are updated on a regular basis by computer programs designed to crawl the Internet for the latest contents and information. The process of annotating a pre existing web page to provide additional hyperlinks and functionality is further described in detail in co pending U.S. patent application Ser. No. 09 021 331.

In order to process the annotation request the central server is in communication with various different processing storage entities for example the Annotator a cache a user ID server a session ID server a request ID server a product serial number server a search engine search and a third party server .

Generally a server or file server refers to a computer system with data storage that allows different users to access the data storage via a computer network. In a client server interaction a client forwards a request. The server accepts the client s request performs the associated operation e.g. open close read write or find etc. and returns a response to the client.

As previously mentioned the Annotator is a software program that is capable of providing hyperlinks for a web page on a dynamic basis. The Annotator may receive as input a hypertext script preferably in HTML format which can be used to accordingly generate the original web page. The hypertext script is then modified by the Annotator to include hyperlinks which are displayable in the annotated web page. The modified hypertext script may be outputted in XML format. The details regarding the features and operations of the Annotator may be found in the co pending U.S. patent application Ser. No. 09 021 331.

The cache is generally a storage area where the relevant computer information such as modified hypertext scripts and destination page information e.g. URLs for the annotated versions of previously requested web pages are kept for quick retrieval. Preferably the contents of the cache are indexed by URLs. Such relevant computer information may be organized using the XML format and syntax. Using conventional relational database techniques the cache may also be implemented in the form of a database.

Since the size of the cache may be limited the cache may be updated periodically to include the relevant computer information for only selected annotated versions. The contents of the cache may be updated based on a number of different criteria including but not limited to the most recently requested entries the most frequently requested entries and the stale entries etc. For example if the cache is updated based on a most recently requested basis i.e. a first in first out basis then the relevant computer information for the last requested web pages is retained in the cache based on a reverse chronological order if the cache is updated based on a most frequently requested basis then the relevant computer information for the most frequently accessed web pages is retained and if the update is done on the basis of stale entries then the obsolete relevant computer information determined based on a preset time expiration is removed from the cache . Various other updating criteria are well known in the art.

The session ID server the request ID server the user ID server and the product serial number server are databases for respectively storing session IDs request IDs user IDs and product serial numbers. These different types of IDs and numbers are assigned by the central server for various purposes as will be described further below.

Preferably in order to improve efficiency the central server retrieves a large number of available IDs numbers for example in blocks of one thousand every time one of these servers or is accessed for purposes of retrieving the next available IDs numbers. The retrieval of large blocks of available IDs numbers per access reduces the number of times the servers or have to be accessed. The central server can exhaust the blocks of IDs numbers before the servers or need to be accessed again for purposes of retrieving available IDs numbers.

The central server maintains a number of logs for each of these IDs numbers to separately keep track of the available IDs numbers retrieved and the IDs numbers already assigned. Periodically the central server interacts with the servers and to synchronize their information.

The central server can also retrieve information in a number of ways. For instance when a user desires to search for information on a particular term the central server can first look to the memory storage area not shown being used by the Annotator as mentioned above to determine if any information is available from such area. Alternatively if no information is available from the memory storage area the central server can contact a search engine not shown which resides on the search engine server and automatically provide the search term to the search engine to have it conduct the search.

It should be understood that the physical location of the various different processing storage entities mentioned above may vary depending on the particular configuration desired and system constraints imposed during implementation. For example the central server and a number of the processing storage entities such as the Annotator the cache the session ID server the request ID server and the user ID server may reside on the same machine. It should also be understood that these various different processing storage entities may be combined or further divided into additional components depending on the design or constraints of the system.

It should be further understood that the central server the user computer and each of the various processing storage entities are individually scalable. In other words there may be multiple instances of each one of the elements shown in the overall system architecture in . For example a single central server may communicate with a large network of user computers on a continual basis depending on the needs of the web users and the bandwidth of the communication network a single central server may also communicate with one or more Annotators or alternatively one Annotator may be called upon by various central server at different times to perform the necessary annotation.

For example an annotation request issued by a web user via the user computer is processed as follows. illustrates a process flow for a central server in accordance with the present invention.

At step the central server receives from the client the destination page information preferably a URL for a desired web page. The client also fetches a copy of the desired web page from the traditional web server . Generally such destination page information can be transmitted from the client to the central server and the traditional web server in a number of formats commonly known in the art.

At step using the URL provided the central server queries the cache to determine whether the corresponding relevant computer information such as additional hypertext information associated with the specified URL for the requested web page is available in the cache .

At step if the corresponding relevant computer information is found in the cache such information is retrieved by the central server and then forwarded to the client . The client in turn integrates such information with information received from the traditional web server and subsequently relays the integrated information in the form of a modified hypertext script to the browser to allow the annotated web page to be displayed in the proper format.

If the computer information associated with the specified URL is not found in the cache at step the central server contacts the traditional web server which has the web page referenced by the URL provided by the client . The computer information such as the hypertext script for that particular web page is then sent back to the central server .

At step the central server forwards the computer information for the specified URL generally in HTML format to the Annotator for annotation.

At step the Annotator performs the intended annotation resulting in additional relevant computer information that can be incorporated to form a modified hypertext script which contains displayable additional hyperlinks. The Annotator then transmits the additional relevant computer information preferably coded in the XML format to the central server .

At step the central server relays the additional relevant computer information to the client . The client then integrates the additional relevant computer information with information received from the traditional web server to form a modified hypertext script. The modified hypertext script is then forwarded to the browser . Since the input to the browser is a modified hypertext script an annotated web page having additional hyperlinks is now shown to the web user.

At step the cache is populated and updated with the additional relevant computer information associated with the specified URL. Alternatively not shown the step of populating and updating the cache can be performed concurrently with or before step above.

In accordance with the present invention the use of the cache expedites the processing of requests received from the client . When the relevant computer information for a specified URL is available in the cache such information is promptly forwarded to the client by the central server . Therefore a web user is able to view the desired annotated web page with minimal processing delay.

Furthermore there is no need to always contact the server containing the requested web page to retrieve the needed information and the Annotator is not always called upon to produce the desired modified hypertext script for every requested web page. This clearly reduces communication traffic and frees up the central server to allow it to perform other necessary tasks thereby rendering the central server more efficient.

Additional features and functionality of the present invention will now be described. These additional features and functionality generally relate to the assigning and collecting of identifying information.

Each client located on a user computer contains certain identifying information. This identifying information is generally used by the central server to monitor the usage and security of the system. In one embodiment the client contains a distribution tag a product serial number and a user ID.

The distribution tag contains information on the identity of the source which distributed the client to the user computer . This information is used mainly to track the distribution of clients for marketing purposes.

The product serial number is a unique number specific to each user computer . This number is assigned to a particular user computer during the first communication between the client and the central server after the initial installation of the client onto the user computer . As mentioned before a new product serial number is assigned from a block of available product serial numbers previously retrieved from the product serial number server and kept by the central server .

The user ID is an identification number assigned to each user. The user ID is both machine specific and user specific. This two level specificity permits different users to access and use the client on the same user computer . Similarly the user ID is assigned to a particular user during the first communication between the client and the central server after the initial installation of the client onto the user computer . Thereafter each time a client establishes a connection with the central server the user ID is transmitted by the client to the central server together with other pertinent information. Likewise a new user ID is assigned from a block of available user IDs previously retrieved from the user ID server and kept by the central server .

At step the central server determines whether the user ID provided by the client is valid. If the user ID is not valid at step a new user ID is generated by the user ID server and issued to the client . At step the user ID log is updated to reflect the new activity.

A session ID is issued by the central server to a client when the client initiates contact to establish a session with the central server . Thereafter all communications exchanged between the client and the central server during that session are marked with that assigned session ID. Similarly a new session ID is assigned from a block of available session IDs previously retrieved from the session ID server and kept by the central server .

In the event that a particular session has remained idle for a predetermined period time i.e. there is no communication between the client and the central server for an extended period of time for example twenty minutes despite the client maintaining a connection to the central server the client may invalidate the currently assigned session ID and not include this invalidated session ID in future communications with the central server .

Since a currently assigned session ID may be invalidated by the client due to inactivity during a session the central server may want to confirm the presence of a session ID. illustrates the process flow for checking a session ID. At step each time a communication is sent from the client a session ID if it has not been invalidated is also transmitted to the central server together with other pertinent information. At step upon receiving the communication from the client the central server checks to see if there is a session ID associated with that communication. At step in the event that the session ID is not present due to for example invalidation because of inactivity the central server assigns a new session ID to the client and at step the session ID log is updated to reflect the new activity.

Furthermore the central server may assign a unique request ID for each annotation request made by the client . In other words each time a client supplies the central server with a URL associated with a web page for annotation purposes a request ID is assigned to that URL. A new request ID is assigned from a block of available request IDs previously retrieved from the request ID server and kept by the central server .

By maintaining a list of issued request IDs for a particular client a history of activity can be established. The request IDs already assigned may be stored in a batch file for subsequent processing. Periodically the central server may transfer the data in the batch file together with other identifying information to a request ID server for storage and other purposes.

As described above the central server is the central point for coordinating the performance of various functions. In order to optimize the efficiency of the central server the present invention utilizes a pool of persistent threads and an independent task queue to expedite the processing of requests from the user computer . The pool of persistent threads is maintained by the operating system running on the central server at all times i.e. these threads are not spawned or generated only at the time when they are needed and are not terminated when they are no longer needed. By eliminating the thread generation and termination process the operating system is better able to allocate its resources to perform other functions for the central server .

The operating system uses an independent task queue and the persistent thread pool to reduce any thread utilization inefficiency. As mentioned above the operating system of the central server maintains a pool of persistent threads. Whenever a thread from the thread pool is available the available thread is assigned to a task only when such task is ready for execution. The thread pool and the task queue are independent of one another in other words an available thread is assigned to an execution ready task without regard to the nature of such task.

The independent task queue is made up of tasks that need to be executed in order to carry out the various functions of the central server . For example in processing an annotation request from the user computer the request is broken down into its constituent tasks. Some tasks might include retrieving the relevant computer information such as the URL for the desired web page checking the cache for availability of relevant computer information retrieving hypertext information for the desired web page and annotating the desired web page etc.

The order of execution for the tasks within the task queue is generally sequential i.e. first in first out FIFO . This FIFO order however is subject to contingent and other execution conditions. It should be understood that many requests can be broken down into their respective constituent tasks and that these tasks can be channeled into one or more task queues for processing. A task located at the beginning of the task queue but is not ready for execution due to other constraints for example the unavailability of certain pre requisites such as the results from the completion of another task is bypassed until it is ready to run. Alternatively a task that is not ready to be executed may be re prioritized to await its turn for execution.

It should be understood that is merely illustrative of the operation of a single thread and that many threads can be performing their respective functions concurrently in cooperation with the independent task queue.

By grouping tasks into a task queue and maintaining a thread pool which is independent from the task queue the operating system is able to improve its utilization of system resources thereby allowing the central server to perform its functions more efficiently. A thread is no longer tied up unnecessarily due to unexecutable tasks within a request. For example if one thread is assigned to a request for the entire duration of the request s execution valuable system resources would be wasted if any one of the constituent tasks such as the step of retrieving the hypertext information of the desired web page involves an excessive amount of idle time. Under the present configuration by assigning a thread to an executable task excessive amounts of idle time can be avoided. Therefore a higher percentage of time is spent by a thread in executing tasks rather than sitting idle.

To further improve the efficiency of task execution the present invention may also include an independent input output I O queue. The I O queue functions as follows. When a task is identified as performing strictly input and or output functions this I O task is put on the I O queue to wait for execution. Since the tasks in the I O queue only perform input and or output functions they are usually executed at a much higher rate due to their relatively few dependencies on other parameters. Furthermore the tasks in the I O queue are generally executed in a parallel or concurrent manner.

Once a task in the I O queue has been executed the task queue is notified and tasks in the task queue which require the results of the executed I O task become executable. Based on empirical data it has been shown that I O tasks are often the bottlenecks in task execution. Therefore by implementing a separate I O queue the efficiency of a server is likely to improve.

It should be understood that the number of thread pools task queues and I O queues may vary individually based on the design and constraints of the system. It will also be appreciated by those skilled in the art that various elements of the present invention such as the central server the cache and the Annotator as described herein are scalable and that the number of each element may be increased individually depending upon the needs of the system.

Conventional techniques and hardware which will be apparent to those skilled in the art may be used for communicating data between and within the server and the client. Moreover the invention may be adapted for use with various software programming systems. For example while the use of XML has been mentioned in an example embodiment other programming languages and tools may be used.

Additionally while the invention has been described for use in connection with the Internet the invention may be adapted or use with virtually any computer network including but not limited to intranets local areas networks and wide area networks.

Although the invention has been described in connection with various specific embodiments those skilled in the art will appreciate that numerous adaptations and modifications may be made thereto without departing from the spirit and scope of the invention as set forth in the claims.

The scope of the invention is indicated by the appended claims and not the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.

