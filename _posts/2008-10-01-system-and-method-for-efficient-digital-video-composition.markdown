---

title: System and method for efficient digital video composition
abstract: An efficient method of compositing planes onto a target surface using a computing device with graphics processing capability is disclosed. The method includes partitioning the target surface, on which planes are composited, into partitions. Each one of the partitions contains connected pixels to be formed by compositing an identical subset of the planes to be composited. Each partition is associated with a corresponding subset of the planes. Each partition and its corresponding set of associated planes are then provided to a graphics processor for composition, using exemplary software components including an application programming interface, a library and device driver software. An image is formed on the target surface by compositing each partition. Using the disclosed method, a single pass through stages of the graphics pipeline for the graphics processor is sufficient to composite multiple planes to form an image on the target surface.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08159505&OS=08159505&RS=08159505
owner: ATI Technologies ULC
number: 08159505
owner_city: Markham, Ontario
owner_country: CA
publication_date: 20081001
---
The present invention relates generally to digital video processing and more particularly to digital video composition.

Digital video in general and high definition digital video in particular are becoming widely used in a variety of display devices for educational business and consumer entertainment applications. The cost of digital video processing continues to fall and as a result the benefits of digital manipulation of video signals over analog alternatives have become more compelling. Digital processing of video signals relies on a variety of techniques related to sampling and quantization compression encoding modulation error correction post processing and the like which are often used in complementary ways to achieve high quality video transmission or storage at reduced overall bandwidth or storage capacity requirements.

As a result digital video is now fairly ubiquitous and can be found in a variety of computing devices such as personal computer workstations and laptop computers and even in handheld devices such as cellular telephones personal digital assistant devices and portable music and video players.

In most digital devices that display images a circuit responsible for graphics processing such as a graphics processing unit GPU an integrated graphics processor IGP a digital signal processor DSP or even a central processing unit CPU is used. When available dedicated graphics processing circuits such as GPUs are often utilized by application software to process composite and render digital images to interconnected displays. This is typically accomplished by providing graphics data and associated instructions to a graphics processing circuit through an application programming interface API defined for that purpose. The use of a graphics API enables relatively high level application programs to take advantage of processing capabilities typically available on a graphics processor.

A graphics processor manipulates received graphics data which may be representative of a three dimensional scene and outputs a two dimensional image for viewing using a sequence of stages collectively called a graphics pipeline. In some devices these stages may include an input assembler various shaders such as a vertex shader and a pixel shader and an output merger. Each stage may read write its input output data respectively into buffers formed inside a video memory or frame buffer memory accessible to the graphics processor.

In a typical computing device various stages of the graphics pipeline may have an associated API that exposes capabilities of the graphics processor that are suited for the stage to application software. As a result multiple APIs are typically used by application software to render graphics.

Modern video data sources such as high definition digital television HDTV video sequences stored on Blu ray or HD DVD discs often require video processing using a graphics processor. For example Blu ray discs typically contain multiple multi layer video that requires blending or compositing multiple planes to form composited images for display. This typically requires multiple passes through the pipeline to compute the contributions of each plane in order to form the image to the target surface.

Unfortunately such multi stage multi pass compositing may be inefficient leading to multiple read and write operations that often result in the need for increased video memory bandwidth. In addition multi pass compositing often requires larger video memory sizes associated with intermediate buffers and increased shader processing abilities to meet time constraints imposed by a particular output frame rate. Moreover multi stage multi pass compositing increases the power consumption of the graphics processor and often requires a more complex application programming model involving difficult synchronization schemes to be implemented across stages.

A method of compositing planes onto a target surface is disclosed. The method involves the use of a processor equipped to handle graphics processing such as a computing device that includes a graphics processor. The method includes partitioning the target surface on which planes are composited into partitions. Each one of the partitions contains connected pixels to be formed by compositing an identical set of planes. That is each pixel in a given partition is to be composited from the same planes. Each partition is associated with its corresponding subset of associated planes. Pixels in each partition are then formed by compositing corresponding pixels from the subset of planes associated with the partition. A graphics processor may be used for composition. Exemplary software components including an application programming interface a library and device driver software may be used to transfer the planes and the partitions to the graphics processor. A final image is formed on the target surface by compositing each partition. A single pass through a graphics pipeline of the processor may accomplish the composition of multiple planes to form an image.

In accordance with one aspect of the present invention there is provided a method of compositing a plurality of planes including at least a first plane and a second plane onto a target surface. The method includes dividing the surface into partitions each partition made up of connected pixels to be composited from the same subset of the plurality of planes associated with the each partition. The partitions include at least a first partition to be composited from at least both the first and second planes a second partition to be composited from at least the first plane but not the second plane and a third partition to be composited from at least the second plane but not the first plane. The method also includes compositing pixels for each of the partitions from corresponding pixels of the associated subset of planes to render an image on the target surface.

In accordance with another aspect of the present invention there is provided a computer readable medium storing processor executable instructions for forming an image on a surface by compositing a plurality of planes. The instructions include instructions for dividing the surface into partitions. Each partition made up of connected pixels to be composited from the same subset of the plurality of planes associated with the each partition. The partitions include at least a first partition to be composited from at least both the first and second planes a second partition to be composited from at least the first plane but not the second plane and a third partition to be composited from at least the second plane but not the first plane. The processor executable instructions further include instructions for compositing pixels for each of the partitions from corresponding pixels of the associated subset of planes to render the image on the target surface using the graphics processor.

In accordance with another aspect of the present invention there is provided a device including a processor in communication with memory. The memory stores processor executable instructions including instructions causing the processor to receive a plurality of planes to be composited to form an image on a target surface and to divide the surface into partitions. Each partition is made up of connected pixels to be composited from the same subset of the plurality of planes associated with the each partition. The partitions include at least a first partition to be composited from at least both the first and second planes a second partition to be composited from at least the first plane but not the second plane and a third partition to be composited from at least the second plane but not the first plane. The processor executable instructions also include instructions to composite pixels for each of the partitions from corresponding pixels of the associated subset of planes thereby rendering the image on the target surface.

Other aspects and features of the present invention will become apparent to those of ordinary skill in the art upon review of the following description of specific embodiments of the invention in conjunction with the accompanying figures.

Integrated interface circuits and are sometimes referred to as North Bridge and South Bridge respectively and are used to facilitate data communication between processor peripheral units and memory .

The North Bridge interface circuit may interconnect processor with a graphics processor a block of system memory and the South Bridge interface circuit . The South Bridge interface circuit in turn may interconnect lower speed peripheral devices such as a network interface card NIC a drive audio adapter i.e. a sound card and other lower speed peripherals not specifically illustrated .

A high speed expansion bus such as the Peripheral Component Interconnect Express PCIe may be used to interconnect the North Bridge interface circuit with processor graphics processor memory and the South Bridge interface circuit .

Graphics processor may be an application specific integrated circuit ASIC formed on a graphics adapter expansion card such as a PCIe graphics card. Alternately graphics processor may be formed on a motherboard of computing device . In some embodiments graphics processor and the North Bridge interface circuit may be integrated. In other embodiments the North Bridge interface circuit and the South Bridge interface circuit may be combined into a single circuit or ASIC on the motherboard of device . Yet other embodiments may combine processor the North Bridge integrated interface circuit and graphics processor into a single integrated circuit. Other variations are possible.

Drive may be an optical disc drive such as a Blu ray DVD or HD DVD drive capable of reading a Blu ray DVD or HD DVD disc containing multi layer or multi stream video. As may be appreciated decoding and displaying multi stream video involves decoding of each of the streams or layers from the disc to form individual planes and compositing the planes together to form a final image for display.

Software applications such as application that are designed to take advantage of graphics hardware often utilize graphics runtime through a specific application programming interface API . The API provides interfaces to routines in graphics runtime that interact with device driver . As will be appreciated device driver is typically specifically written for the underlying graphics processor .

Several graphics runtimes and associated APIs have become widely popular over the last few years. Two of the most common are the OpenGL cross platform API developed by Silicon Graphics Inc. and DirectX developed by Microsoft Corp. and typically used in the Windows family of operating systems. Others will be known to those of ordinary skill in the art.

Application software does not typically communicate directly with graphics hardware. Instead application software calls routines in a graphics library using a predetermined API. The graphics library communicates with a lower level device driver code which in turn performs actual data exchange with the graphics processor hardware.

As may be appreciated standardized graphics library commands allow application software developers to take advantage prewritten functions without knowledge of the specific underlying graphics processor. This allows programmers to write significantly less code.

Graphics processor hardware may be abstracted by a particular graphics pipeline model. Graphics APIs and associated runtime libraries are generally designed to take the abstraction into account. depicts a simplified block diagram of one graphics pipeline model representative of graphics processor in the computing device of .

As depicted a graphics pipeline may include multiple stages including a vertex shader a rasterizer a pixel shader and an output merger . Other embodiments of a graphics pipeline may also include input assembler geometry shader and stream output stages.

Various buffers formed in memory which may be frame buffer memory may be used to store indices and texture data and to transfer data between the different stages in the pipeline. Accordingly a vertex buffer an index buffer and constant buffer may provide inputs to vertex shader . Texture buffer and constant buffer may be used to provide input to pixel shader . A render target buffer may be used by output merger to output rendered pixels. These buffers may be formed inside the same physical memory or may be formed in different blocks of memory accessible to graphics processor . In particular vertex buffer index buffer and constant buffer need not be adjacent in memory. Similarly texture buffer and constant buffer may not be adjacent in memory. The illustration is thus only exemplary. Individual buffers may reside in different parts of a memory block or may even be spread out across physically separate blocks of memory.

Pipeline may be compliant any hardware architecture including but not limited to known architectures such as shader model shader model shader model or the like.

Buffer may be used to store intermediate buffers when multiple passes through pipeline may be required. Pixel shader may store its output data into buffer for re use in a subsequent pass. This is often observed in conventional plane composition operations as detailed below.

Graphics applications such as video players often take advantage of the abstraction provided by various stages in pipeline to utilize graphics processor for hardware acceleration. For example video player applications for presenting video on a Blu ray disc or an HD DVD disc must often deal with a multiple streams of video. Each stream may be used to form individual planes or layers that are composited to form the final frame for display. Individual planes may correspond to a background plane a main video sub video also called picture in picture a subtitle plane user interface plane graphics planes a cursor plane and the like.

Each plane may have an associated transparency value which may be specified for the entire plane or on a per pixel basis. For example the RGBA or ARGB color format provides the red green and blue sub pixel values in R G and B as well as an alpha value A which determines how transparent the pixel is. The alpha value may indicate the degree to which any background pixel is visible. An alpha value of 0 may indicate complete transparency while an alpha value 1 indicates complete opacity. The value may be scaled and specified as an 8 bit value by multiplying the value in the range 0 1 by 255 and rounding or truncating to the nearest integer. In alternative representations R G and B may be pre multiplied by their corresponding alpha value A.

Conventional video compositing by video player application executing in a computing device such as device typically involves calling appropriate graphics routines in graphics runtime through its associated application programming interface. The graphics runtime provides interfaces to conventional driver routines defined in driver for graphics processor .

Conventional video compositing requires multiple passes through a graphics pipeline such as pipeline . Conventional methods for compositing multiple planes typically composite the first two planes to form an intermediate composited plane. The intermediate plane is then composited with another plane to form an updated intermediate plane. Each composition requires a pass through pipeline . Finally the last plane is composted to the last updated intermediate plane to form the final composited image. Specifically conventional plane composition of the planes depicted in may initially start by compositing a background plane layer 0 and the next higher plane layer 1 . Thus background plane layer 0 and the next plane layer 1 are provided to pipeline as inputs along with transparency values. This conventional process is illustrated in a flowchart S depicted in . Pipeline initially accepts a background plane S and stores it a composition buffer S . It then receives the next higher plane S and forms and stores the intermediate composited plane in the same composition buffer S . If there are more planes to composite S the next higher plane is received again S and composited onto the intermediate frame in a subsequent pass through pipeline . The process terminates when there are no more planes left to composite S .

Alpha blending may take place in the pixel shader and output merger stages of pipeline . In a first pass plane and plane i.e. layer 0 and layer 1 may be composited or alpha blended to form an intermediate layer X. The intermediate layer may be stored in an intermediate composition buffer in memory. As may be appreciated significant memory size and bandwidth requirements may be imposed on the graphics processor to store the intermediate composition buffer.

In a subsequent pass the next higher layer layer 2 may then be provided to pipeline as input to be blended with the intermediate layer X already stored in buffer memory. The composition operation will form an updated intermediate image in the composition buffer containing contributions from layer 0 layer 1 and layer 2. This process may be repeated until the highest layer is blended onto the preceding layers to form a final rendered image or frame ready for display.

In the ARGB format when a pixel P A R G B from background plane and another P A R G B from foreground plane e.g. plane are composited the corresponding an intermediate image pixel P a r g b may be computed as follows. Note that P P Preside at the same pixel location within the render target and A A and aare each between 0 and 1.

Using the red component for illustration in the initial pass through pipeline the first intermediate pixel ris computed as r 1 A R AR. On the second pass the red component in the intermediate buffer is updated as r 1 A r AR. Thus after the npass to composite n planes and the background the intermediate buffer red component value may be given as r 1 A r ARwhere ris the red component value in intermediate buffer value after the previous n 1 pass. The same holds for the green and blue components.

Many disadvantages can be identified with this conventional method of compositing planes. First a large memory footprint is often required to store the intermediate planes formed from compositing a subset of the layers. This clearly requires a large video memory size.

In addition large video memory bandwidth is required to ensure that all composition operations are finished before the next frame is displayed. This may mean that multiple passes and associated memory read and write operations through pipeline must be completed within a frame period which may be 1 24of a second or less especially if further processing is required on the composited frame.

To overcome these disadvantages and simplify the programming model exemplary embodiments of the present invention in the form of a new API a graphics library and device driver software for use in computing device will be described below.

Application software may be a video player application and may include a library that is either statically or dynamically linked to the application. Application software may interact with graphics processor through an API defined in static library which provides an interface to dynamically linked library which in turn provides an interface to driver routines defined in device driver and or other kernel routines in a graphics kernel subsystem .

Device driver may include a user mode driver A and a kernel mode driver B. As depicted application software static library dynamic graphics library and user mode driver A may operate in user space A of operating system . Conversely kernel mode driver B graphics kernel subsystem may operate in kernel space B of operating system .

Application software dynamically linked graphics library and device driver may all be in the form of processor executable instructions or CPU instructions to be executed on processor . Accordingly processor executable instructions in driver may include kernel mode instructions kernel mode driver B as well as user mode instructions user mode driver A . In addition processor executable instructions in driver may include driver code for execution by a CPU e.g. processor and graphics processor instructions shader code for execution by graphics processor .

Furthermore in some embodiments graphics processor may form part of processor . Thus instructions in driver may include graphics processing instructions shader code for execution on the same processor having graphics processing capability.

In operation to achieve the plane composition as depicted in exemplary application software initializes dynamic library and supplies the required plane data using the software interface or API specified in static library . Individual planes and associated data may be obtained for example by decoding a Blu ray video stream such as the main video graphics stream or sub video stream using processor . The video stream from which individual planes are obtained may read from an optical disc e.g. HD DVD or Blu ray disc hard disk or other digital storage media. Alternately the video stream may be received by way of a network a video cable an optical cable and the like.

The exemplary API may specify or include data structures for encapsulating a collection of planes in the form of memory addresses linked lists arrays pointers or other collection classes for representing planes. Other attributes such as position and size plane type source data buffers or buffer pointers destination data buffers or pointers and flags indicative of various attributes e.g. full screen mode display alpha values color format and the like may be specified by the application using data structures defined in static library .

Application software may populate data structures with a list of planes for composition. These data structures may take the form of an array a linked list a collection class or similar representation in memory. Each plane may have its own color format that is a plane may be specified in one of RGB ARGB YCbCr sometimes called YUV 4 2 0 YCbCr 4 2 2 formats and the like.

After receiving a list of planes to be composited from application software dynamic library provides the plane data specified by application software to device driver . To do so dynamic library may use a number of methods including the use of a defined surface format. The surface format may be a 4CC surface identified by a unique four character code. Alternately an extension of an existing API may be used to selectively tag a surface so that driver can distinguish calls from library for passing planes from other calls that do not originate in library . Other methods include the use of a de interlacing and sub stream compositing call e.g. VideoProcessBlt for Windows Vista with a private globally unique identifier GUID passing compressed buffer of planes to a DirectX Video Acceleration DXVA defined decoding routine with a private GUID or using version 2 of the DXVA interface called DXVA2 when the operating system is Widows Vista . As will be appreciated by those skilled in the art DXVA and DXVA2 are standard software application programming interfaces including corresponding driver interfaces for using hardware acceleration to speed up video processing using a graphics processor. However DXVA2 differs from DXVA as it includes standalone APIs for decoding processing and capturing video.

Conveniently dynamic library shields an application programmer from details of how plane data is actually passed to driver for composition or the subsequent partitioning described below. After device driver receives data representative of planes to be composited it may partition or divide the target surface into distinct partitions each of which may be provided to pipeline to be composited individually.

The overall operation is outlined in a flowchart depicted in . In the depicted example three planes are provided to a graphics pipeline for composition in a single pass. Each plane may require different types of processing steps. For example for an interlaced plane e.g. Plane in a de interlacing step may be required. A scaling step and a color conversion step may also be required for the interlaced plane. A progressive plane Plane in however does not require a de interlacing step but may require a scaling step and a color conversion step . Similarly a graphics plane input Plane in may similarly only require scaling step and a color conversion step . The color conversion steps may convert pixels from one color space e.g. YCbCr to another color space e.g. RGB . After all input planes to be composited are appropriately scaled and color converted to a common format the target surface may be divided into partitions using methods that will be detailed below. Once the target surface is divided into partitions each partition may be selected step using its coordinates and luma keying alpha blending step may be performed on the selected partition. Optional color conversion step may be performed if needed. The composited partition is then provided as output. This may be repeated for all partitions to form and output the final image.

In one specific exemplary embodiment depicted in driver divides surface which may overlap or be coextensive with background plane . Each plane may be specified using a common coordinate system so that all planes have a common reference coordinate system. The common coordinate system may be the window coordinate system of surface . However in other embodiments the screen coordinate system may be used. Accordingly each plane s coordinates define the boarders and placement of the plane on a target surface.

Driver may initially identify the top and bottom boundaries of each plane and form corresponding horizontal edges or lines spanning the width of the surface as depicted. Each horizontal edge corresponds to either the top or bottom boundary of a plane. In other words each horizontal line along which the top or the bottom of any plane may lie may be designated or marked as a horizontal edge by driver . For example as depicted in a horizontal edge marks the top boundary of plane . Another horizontal edge marks the top boundary of plane . Horizontal edge marks the top boundary of plane while horizontal edge marks the bottom boundary of plane . Horizontal edge marks the bottom boundary of plane . Horizontal edge marks the bottom boundary of plane .

The horizontal edges thus divide surface into multiple horizontal strips as shown. As may be appreciated the edges may be easily computed from the corner coordinates of each plane.

Subsequently driver may form vertical edges that correspond to vertical boundaries of each plane. The horizontal strips formed above may thus be subdivided along the vertical edges so formed to define the partitions depicted in .

As may be appreciated the use of horizontal and vertical edges as depicted allows device driver to form partitions as contiguous regions of connected pixels that would be composited from the same subset of source planes. The partitioning operation depicted in results in a number of regions or partitions. A partition is a set of connected pixels in which each pixel is to be composited from corresponding pixels of the same subset of planes. A given pixel at location x y is said to be connected or specifically 8 connected to its eight neighboring pixels at locations x 1 y 1 x 1 y x 1 y 1 x y 1 x y 1 x 1 y 1 x 1 y and x 1 y 1 . A pixel P is thus connected to another pixel Q if P is 8 connected to Q or if there is a path of interconnected pixels from P and Q on which each pixel is 8 connected to the next pixel. For the purposes of the present disclosure two pixels may be considered to be connected if they are 8 connected.

A partition is thus a set of connected pixels sharing a common identical subset of planes from which each pixel is to be composited. At least two pixels are contained in each partition and every pixel is connected e.g. 8 connected to at least one other neighboring pixel within the partition.

Unlike conventional edge based image segmentation techniques no image analysis or edge detection step is required to form partitions in embodiments of the present invention. In the exemplary embodiment depicted in the edges used to form partitions simply correspond to boundaries each plane to be composited. Using horizontal and vertical edges corresponding to the boundaries of planes to be composited a surface such as surface may be divided into multiple such partitions.

In alternate embodiments to identify partition boundaries the first plane may be overlaid on top of the background plane and the region of intersection may be identified as a partition. Subsequently the next plane may be overlaid on top of existing partitions to further identify new regions of intersections to form new partitions. This process may be repeated until all planes are overlaid and all partitions are identified.

Driver divides a target surface so as to form a complete partition that is a target surface such as surface depicted in is tessellated so that when the partitions are assembled back together they would completely fill the target surface without gaps or overlaps. In other words generally if a target surface is divided into N partitions denoted p p . . . peach partition being a set of connected pixels then the intersection of any two partitions p pis the empty set i.e. p p for 1 i N and 1 j N and i j while the union of all partitions forms the original target surface.

Each partition s coordinates along with an identifier of its corresponding subset of planes may be provided to pipeline of graphics processor for composition. As will be appreciated the size and position of any rectangular partition may be completely specified by its coordinates relative to the coordinate system of the target surface e.g. window coordinates .

Different subsets of the planes to be composited may be associated with different partitions. For example partition is associated with only background plane while for partition the corresponding subset of planes includes planes and . That is pixels of the final image in partition are simply corresponding pixels in plane while pixels in partition are composited from corresponding pixels in planes and .

Although the depicted partitions are rectangular in shape in alternate embodiments the partitions may take on other shapes. Partitions may for example be formed in the shape of other polygons such as triangles squares or other combinations of shapes that may result from regular semi regular or other tessellation techniques. For example partitions may have shapes formed from one or more triangles.

As may be appreciated pixels of a given plane may be specified in the RGB YCbCr or another color format along with transparency values. Per pixel transparency alpha values may be used to specify planes having non rectangular shapes e.g. ARGB color format . A pixel may thus be designated as invisible by setting its corresponding per pixel alpha value to indicate complete transparency. Invisible pixels of a plane may however still be considered part of the plane for the purposes of forming horizontal and vertical edges in the partitioning described above.

After horizontal strips are formed each strip is subdivided S into rectangular partitions vertically along the left and right boundaries of each plane within the strip. The partitioning algorithm or logic in driver may then identify and record S the layers or subset of planes associated with each partition. For the exemplary partitioning depicted the corresponding planes or layers that are associated with each partition are given in a table depicted in .

Each partition may be associated with a corresponding subset of planes that may be composited to from a portion of the image corresponding to the partition. To reduce the number of such partitions partitions with identical associated subset of planes may be merged into a single larger partition. The resulting larger partition would still be a set of connected pixels to be composited from the same subset of planes. Thus optionally driver may merge partitions that have the same layer stack or associated subset of planes S . Partitions that may be merged together may be adjacent. As a specific example partitions and in may be merged into a single partition as they have an identical subset of associated planes.

Finally graphics processor may be provided with the partition data i.e. coordinates of the partition and identifier of the subset of planes to graphics processor which may composite the final image a single pass S through its pipeline . The shaders in pipeline may form the final image in a frame buffer in a single pass without first storing intermediate images to be composited with each one of the individual planes. Each formation of an intermediate image in a conventional composition scheme requires a pass through graphics pipeline . Accordingly multiple passes would have been required in conventional uses of a graphics pipeline for digital image composition. However exemplary embodiments of the present invention require only one pass. In other words each partition may be processed using a single shader code to output its corresponding final pixels in the final image. That is intermediate pixel values need not be stored for later processing. Shader code may be executed for one partition after another sequentially. However in embodiments containing multiple shader execution units multiple shader codes may be executed in parallel.

Planes to be composited may include a background plane e.g. plane a first plane e.g. plane a second plane e.g. plane and potentially many more planes like plane . As noted above exemplary methods for compositing planes onto a target surface involve identifying contiguous regions of connected pixels to be composited from the same subset of planes. The partitions so formed may include at least one partition e.g. partition within an area of the target surface covered by both the first and second planes a second partition e.g. partition within another area of the surface covered by the first plane but outside of the second plane and a third partition e.g. partition within yet another area of the surface covered by the second plane but outside the first plane. Each one of the partitions is then associated a corresponding subset of planes that are composited to form the partition. A given partition and its associated plane regions actually used during composition would have the same coordinates or size and position on the target surface.

For each partition graphics processor may be provided with partition coordinates and an identifier of the associated subset of planes to be composited. Graphics processor may also be provided with the order of composition for the subset of planes. The identifier for the associated subset of planes and their order of composition may be provided in the form of memory or buffer addresses pointers arrays linked lists or buffer identifiers and the like indicating memory locations storing pixels of each plane in the subset of planes to be composited. As will be appreciated by those of ordinary skill in the art the order of planes may be easily communicated to graphic processor . For example memory addresses corresponding to planes associated with a given partition may be specified in their order of composition starting with the bottom plane and ending with the top plane or vice versa. Similarly linked lists arrays or other structures used to transfer individual planes as inputs to processor may be ordered or arranged to conform to the order of plane composition.

Graphics processor may then composite image pixels for each of the partitions from corresponding pixels of the associated subset of planes to render an image on the target surface. The image on the target surface may be formed by a single composition pass through the graphics pipeline as each partition has corresponding plane regions for its composition which may all be supplied to of graphics processor .

In another alternate exemplary embodiment the order of edge formation may be reversed for the partitioning operation. That is partitioning logic in driver may first divide the target surface into vertical strips by finding vertical edges spanning the height of the target surface along which the left or right boundaries of each plane may lie. Subsequently each vertical strip may be subdivided into rectangular partitions along horizontal boundaries corresponding to the top and bottom boundaries of each plane. Optional merging of adjacent partitions having the same subset of planes may also be performed.

In some embodiments certain partitions may include transparent layers. As transparent layers do not affect the final pixel color of the image corresponding to a partition they may be removed from the list of planes for compositing associated with a given partition. As an optimization step among the subset of planes associated with a given partition those that are behind or underneath or blocked by an opaque plane may be removed from the subset of planes without processing. As can be appreciated any pixel that is behind an opaque completely non transparent pixel would not contribute to the final image.

In some applications a clear rectangle may be specified and pixels of one or more of the planes to be composited that lie within the clear rectangle may be made transparent to expose a particular plane of choice. For example in HD DVD applications a clear rectangle may be defined to expose the main video plane. To expose the main video plane pixels of all other planes in front the main video plane that lie within the clear rectangle are made transparent. An HD DVD video player application may specify which particular plane the clear rectangle exposes. Typically the clear rectangle is used to make either a main video or a sub video plane visible in the foreground. As may be appreciated clear rectangle processing may be included in the plane composition logic in exemplary embodiments of the present invention.

In addition to alpha blending shaders may also be used to perform luma keying. In luma keying a pair of minimum and maximum luma values are used to determine the transparency of a pixel. For example the alpha value may be set to a value of 0.0 if the pixel luminance value i.e. Y in the YCbCr color space is either greater than the maximum or smaller than the minimum value. Conversely the alpha value may be set to 1.0 if the pixel luminance value is in between the minimum and the maximum values. In other words pixel values above a given maximum or below a given minimum value may be made transparent during compositing.

Conveniently the partitions may be grouped by their shader setup requirements prior to being transferred or provided to a graphics processing unit such graphics processor . This allows a graphics processor to process a group of partitions that require a common shader type before switching to another type of shader which may improve efficiency. Techniques for proper selection and programming of shaders in pipeline to accomplish the composition would be known to those of ordinary skill in the art.

Generally performance improvements may be realized by rearranging the partitions to match the specific hardware architecture employed by the graphics processor used. For instance partitions that are to be composited from the same subset of planes may be grouped together for processing using the same shader code. The same shader code may be used to composite partitions that are grouped together. Partitions that are grouped together need not be adjacent to each other in order be grouped together. Nonadjacent partitions may be grouped together for processing using the same shader code if they are to be composited from an identical subset of planes. Partitions that are grouped together may be processed sequentially after one another to avoid shader code switching.

To further reduce shader code switching in some embodiments smaller partitions to be composited from different subsets of planes but having at least one plane in common may also be grouped together for processing. For example a first partition to be composited from two planes e.g. plane 1 and plane 2 may be grouped together with a second partition to be composited from the same two planes as well as a third e.g. from plane 1 plane 2 and plane 3 . The first and second partitions which are grouped together may be processed immediately before or after one another. This permits a shader to composite the two partitions without switching shader code but at the cost of a small pre processing overhead. Pre processing may be required to discard a small number of unused pixels from planes that are not common to all partitions that are grouped together e.g. the third plane . That is pixels from plane 3 corresponding to the first partition may be read but are discarded without being used. This helps to reduce the overhead involved in shader code switching.

The software interface or API specified in static library may be used to provide data to driver . A software component such as application software may provide data using the interface in library to another software component such as driver so as to allow a final image to be formed in a single pass through pipeline . Data provided to driver may include video plane data de interlacing method e.g. BOB de interlacing scaling factors from video source to a window on screen color conversion requirements e.g. format of source planes and the destination color format and luma keying related data. The software interface allows communication of all required data to form the final image from individual planes so that a single pass is sufficient for graphics processor to render the final image. In other words the software interface in library permits provision of all data required to render the final image in a single pass without the need to store an intermediate image and retrieving additional data from application software in subsequent passes.

Each partition may have its own graphics processor instructions or shader code that may be specified using a suitable shader language e.g. shader assembly HLSL and GLSL and compiled for execution on graphics processor .

As noted above each of source planes may be associated with a layer in a Blu ray disc or HD DVD disc. Planes may also be decoded from a disc such as DVD VCD Blu ray disc or HD DVD disc. Alternately source planes may be received from a broadcast source via digital TV Internet TV satellite receiver set top box and the like. For example when decoding a Blu ray disc plane may correspond to a background plane while plane may correspond to the main video plane. Planes may correspond to java plane graphics plane sub video PiP plane user interface plane subtitle plane or the like. In some embodiments all the planes may be present. The format of the planes may also be different for embodiments of the present invention. For example a main video plane may be specified in the YCbCr sometimes called YUV 4 2 2 format for Blu ray sources while the background plane may be provided in RGB format.

Color formats of all planes may be converted to the same format such as the ARGB format prior to compositing. Shader code for compositing planes may also perform color format conversion to a common format for composition. The common color format to which all planes may be converted for composition need not be the ARGB format other formats may also be used in alternate embodiments.

Embodiments of the present invention may include a computer readable medium such as a compact disc CD hard disk or the like on which processor executable instructions i.e. CPU instructions representing static library dynamically linked graphics library and device driver including shader code are stored. For example driver software package containing static library dynamically linked graphics library and device driver including related graphics processor instructions may be distributed as a CD or DVD. Such software packages may also be downloaded onto a hard disk a removable disk or similar computer readable media on a computing device from a server by way of a network connection.

Embodiments of the present invention may also include a computing device such as device having processor executable instructions or CPU instructions representative of static library dynamically linked graphics library and device driver including shader code are stored in a computer readable medium such as its memory its hard disk or the like.

As noted above in alternate embodiments processor may have graphics processing capabilities obviating a separate graphics processor such as graphics processor . Processor executable instructions executing on a processor having graphics processing capabilities thus need not be separated into static libraries dynamic libraries driver code and shader code.

Of course the above described embodiments are intended to be illustrative only and in no way limiting. The described embodiments of carrying out the invention are susceptible to many modifications of form arrangement of parts details and order of operation. The invention rather is intended to encompass all such modification within its scope as defined by the claims.

