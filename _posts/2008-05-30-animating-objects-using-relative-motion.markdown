---

title: Animating objects using relative motion
abstract: Input is received that selects an animation aspect associated with an object within an animation. The animation involves the object and an original frame of reference through which the animation is displayed, and the selected animation aspect is one that changes over time with respect to the original frame of reference. The animation is displayed through a new frame of reference defined by holding the selected animation aspect constant over time. During the animation display through the new frame of reference, input is received that manipulates the object to create a new animation aspect associated with the object. The new animation aspect associated with the object is recorded in the animation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08508534&OS=08508534&RS=08508534
owner: Adobe Systems Incorporated
number: 08508534
owner_city: San Jose
owner_country: US
publication_date: 20080530
---
Computer animation allow users to create animated content for display on various platforms e.g. web sites mobile displays etc. . Some systems allow users to build animations by recording motions of objects e.g. graphical characters for subsequent playback. For example a user can click on an object displayed in a user interface and drag it around while the animation tool records the motion. This recorded motion can then be played back when the animation is run.

Animating an object can involve simply adding one type of movement to the object such as rotation. But it can also involve adding a combination of movements e.g. translation and rotation . Adding such combined motion to an object can be challenging especially as the complexity of the object and the number of different desired movements increases.

This specification describes technologies relating to animating objects in a computing environment using relative motion.

In general in one aspect a computer implemented method is provided. The method includes receiving input that selects an animation aspect associated with an object within an animation the animation involving the object and an original frame of reference through which the animation is displayed and the selected animation aspect being one that changes over time with respect to the original frame of reference. The method includes displaying the animation through a new frame of reference defined by holding the selected animation aspect constant over time during the animation display through the new frame of reference receiving input that manipulates the object to create a new animation aspect associated with the object and recording the new animation aspect associated with the object in the animation. Other embodiments can include corresponding systems apparatus and computer program products.

Implementations can include one or more of the following features. For example the method can include receiving input that generates the object in an animation environment the animation environment defining a coordinate system. Receiving input that generates the object can include receiving input that defines a two dimensional graphic in a two dimensional animation environment. Displaying the animation through a new frame of reference can include accessing a data structure that maps the object and the coordinate system to a region on a user interface and modifying the data structure to orient the new frame of reference to the selected animation aspect such that the selected animation aspect is held constant over time.

Receiving input that manipulates the object during the animation display can include receiving input that effects at least one of a rotation of the object a translation of the object and a scaling of the object.

Receiving input that selects an animation aspect can include receiving a selection of an animated aspect of the object. The animated aspect of the object can include at least one of an object size an object orientation and an object location. Displaying the animation through a new frame of reference can include displaying the animation through a new frame of reference defined by holding at least one of the object size the object orientation and the object location constant over time such that the selected animation aspect is displayed as a change to an animation environment over time through the new frame of reference. The change to the animation environment can include a change to at least one of a size an orientation and a location of at least one other object in the animation environment displayed over time through the new frame of reference.

Receiving input that selects an animation aspect can include receiving a selection of a region on the object. Receiving input that selects an animation aspect can include receiving the selection of the region on the object in combination with a selection of a reference point other than the selected region on the object.

Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following and or other advantages. For example in some animations previously recorded motion of an object can be played back while new motion is being added. Because the object is moving when the new motion is being added it can be difficult to control the motion. Implementations consistent with this disclosure can allow users to more easily record successive motions to build up an animation.

Implementations consistent with this disclosure can provide advantages in situations in which users control complex movement of an object by acting directly on the object with a mouse or other similar input device. For example a mouse can be used to control two dimensional translation grab object and move or one dimensional rotation through two dimensional movement grab object and use circular motion . However it can be difficult to accurately and smoothly control both of these movements at the same time using a mouse. These movements can be controlled for example using specialized input devices with more degrees of motion e.g. a mouse like translation device with a rotating knob control on top or using awkward keyboard input e.g. for rotation simultaneous with the mouse e.g. for translation . Although encompassing arbitrary and arbitrarily complex input devices implementations consistent with this disclosure can allow users to control complex movements with simple and familiar devices such as a mouse already in the user s possession. Implementations consistent with this disclosure can allow a user to control any number of movement types by using successive recordings of simple motions. This can allow the user to build animations with familiar input devices e.g. a mouse rather than specialized input devices or awkward combinations of inputs. In addition complex motions can be built up using simple gestures rather than requiring programming skills.

Additionally implementations consistent with this disclosure can provide advantages in situations in which an animator wants one object to follow in relation to another object a peer object within a more complex scene. Consider for example a dog object chasing a cat object within a moving train object. Implementations consistent with this disclosure can allow a user to isolate to a frame of reference in which motion can be relative to other peers in the scene. For example if the animator isolates to the motion within the train the animator can record the cat running around and then record the dog chasing the cat within the relative context of the train s frame of reference.

The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features aspects and advantages will become apparent from the description the drawings and the claims.

In some implementations an animation tool enables the creation and playback of animations. An animation can include an animation environment one or more objects e.g. a figure that exhibit motion within the environment and a view camera through which the animation is viewed. The camera can determine the projection of the animation onto a display device such as a computer monitor.

Objects can themselves be composed of sub objects. For example a figure can be further refined to sub objects that represent the head torso arms and legs. These can be further divided to the fingers toes etc. These in turn can be further refined to the individual vertices or other elements describing the shapes.

Each object can have a location within the animation environment defined as a function of time. The location can include translational rotational and scale components. An animation can be achieved by rendering through the camera the objects at their location according to successive time increments.

In some examples a user or animator can construct an animation through one or more repetitions of the following four stages. At the first stage the animator specifies a set of parameters that vary over time and that are to define the camera projection as the animation is played. The set of parameters can be any combination of x y position orientation angle and scale factor. The projection is determined from these parameters by causing the x y position to be projected to a fixed point the angle to be projected to a constant angle and the scale factor to a constant length.

The animator can choose parameters that are derived from changing properties of objects in the animation. By so doing the animator can cause those properties or derived properties to remain fixed as the animation is played.

The position parameter can be specified by any of a the position of a single object b the position of a point relative to the bounding box of a single object and c a weighted average of some combination of a and b for a subset of objects in the animation for example the mid point between two objects . The orientation can be specified by any of a the orientation of a single object and b the orientation within the animation environment of a line connecting two points those two points being specified by any of the same methods as may be used for position. The scale can be specified by any of a the scale of a single object and b the length within the animation environment of a line connecting two points those two points being specified by any of the same methods as may be used for position.

At the second stage the animation is displayed by the animation tool. The parameters specified in the first stage are used to determine the camera projection over time as the animation is displayed. At the third stage as the animation is being displayed the animator can modify parameters of one or more objects in the animation environment. For example the animator might modify the position rotation or color of one or more objects. At the fourth stage the animation tool records the new object parameters as they are being manipulated by the animator. The example stages described above are not intended to be restrictive. Other stages and variations can therefore be used.

As noted above an animation can involve an animation environment one or more objects that exhibit motion within the animation environment and a view camera through which the animation is viewed. As used herein the term object refers to any type of presentation that can be visually or otherwise rendered to an observer. Examples include graphics e.g. figures shapes text illustrations images etc. that can be displayed on an interactive medium such as a user interface of a personal computer e.g. a Web site or mobile device or other platform. Objects can be two dimensional or three dimensional raster or vector based and colored or monochromatic. Objects can be represented by data stored in various formats. In some examples objects can be represented using various models such as a wire frame model.

The animation environment or stage defines a space in which objects can be situated. The animation environment can define a world coordinate system in which the origin and axes can be arbitrarily located . The positions of objects can be described with respect to these world coordinate axes. The animation environment can also include or define other coordinate systems. For example each object involved in an animation can also have a local coordinate system e.g. a set of axes that is defined relative to the object and moves with object as it animates or objects can be collected into a group and the group assigned a coordinate system. A position given with respect to one coordinate system can be translated to a position with respect to another. In particular objects can be described in terms of their position in world coordinates. The motion of an object can be described in terms of transformations over time of the object or parts thereof with respect to a coordinate system. Such transformations can include but are not limited to translations rotations and scaling.

In some examples animation environments can include graphical elements displayed on an interactive medium such as a user interface of a personal computer e.g. a Web site or mobile device or other platform. Animation environments can be two dimensional or three dimensional raster or vector based and colored or monochromatic. Thus an animation environment can be another object in an animation. As an example an object can include an automobile and the animation environment can include a graphical representation of a background setting e.g. a road in which the automobile moves. The animation environment can be stationary or include stationary elements and or it can be moving or include moving elements . In some examples the animation environment can include a background of a website.

Animating an object can involve causing the object to exhibit some type of motion within the animation environment. As used herein object motion or object movement refers to any perceivable change of an object with respect to an animation environment. Examples of object motion include translation e.g. movement of an entire object or a rigid part of an object in a specified direction and rotation e.g. substantially circular or elliptical movement around a point or axis . In some examples object motion can include various visual effects such as morphing e.g. transitioning one object to another object fading stretching color changes etc.

Animating can involve recording object motions that when played back generate an animation of the object. A user can manipulate an object through a user interface so that the object exhibits a certain motion and the manipulation can be recorded for subsequent use in building an animation. For example an animator can manipulate an object e.g. a cloud so that it moves from left to right across an animation environment e.g. a sky displayed on a computer. This manipulation can be recorded and then played back to create an animation. In some examples the recorded manipulation can be mixed with other motion and effects which can include other recorded user manipulations and or other system generated motions and effects to generate an animation. Animators can build animations involving multiple objects by separately recording manipulations for each of the objects.

Animators can successively or iteratively add and record object manipulations to create compound motion. A compound motion refers to for example at least two motions of the same object that overlap in at least one point in time. Animations can be built on the compound motion of one or more objects. An example of a compound motion is an object e.g. a cloud rotating and simultaneously moving across e.g. left to right an animation environment e.g. the sky . Another example is a human figure standing on a moving train while simultaneously trying to catch a ball. As a particular component e.g. rotation of a cloud of a compound object motion is being recorded the animation tool can play back previously recorded motions of that object i.e. translation of the cloud or other objects e.g. birds in the environment so that the animator can view the new motion being recorded in context.

The view camera defines how an animation is projected onto an intended display area such as a display area e.g. a display screen of a computer mobile device handheld device or other platform. The view camera can define or be associated with a viewer s frame of reference. For example it can be thought of as aligning with a viewer s eye or line of sight. The view camera itself can act as an object that moves in the animation environment. The view camera can be positioned at various points in the animation environment. In some examples the view camera defines a coordinate system in which the origin is located at the camera viewing point. Thus the viewer s eye point can be thought of as being at the origin of this coordinate system.

In some examples the view camera can include or utilize a view matrix which maps the animation environment and objects in the environment to the intended display area. The view matrix can specify and control the manner in which objects and animation environments are displayed e.g. the orientation and location of the objects on the screen . The view matrix can be composed of translation scale and orientation. In some examples the view matrix can map objects and the animation environment to the display area using one or more coordinate systems. For example the view matrix can define objects and environments relative to a display using a coordinate system based on screen pixels. In some examples the view matrix can map world coordinates of the animation environment to coordinates of the view camera.

The animation tool facilitates animation of objects based on relativity. This can involve allowing the animator to specify a frame of reference through which an animation is displayed such that a selected aspect of the animation appears to be held fixed over time. The selected aspect of animation can include object position object orientation and or object scale. The animator can specify that at least one aspect should be fixed by selecting a frame of reference that locks or orients on that aspect while the animation plays and new motion is recorded relative to that frame of reference or any other frame of reference. Choosing a frame of reference can entail choosing an object and a particular subset of its motions e.g. translation rotation etc. that define the frame of reference such that the object will appear stationary within that frame of reference.

To select a frame of reference the animator can specify that the view camera through which animation is viewed should track or follow an animated aspect of an object. In two dimensional animations for example the view camera can have three parameters x y position angular orientation and scale or zoom . The animator can specify that the camera should track one or more of these aspects. For example the animator can choose to track the rotation of an object by selecting an object and indicating that its rotation should be tracked by the view camera. Because the camera tracks the animated aspect of the object the animation tool can cause that aspect to appear stationary when the animation is viewed.

The animator can choose to specify that the camera tracks any combination of position orientation and scale and the animation aspects being tracked need not be defined by the same object. In some examples the animator can track just the position the position and scale position and rotation rotation and scale etc. Both position and rotation can be defined by a single object or position can come from one object and rotation from another.

In some examples the animator can specify a frame of reference based on a group of objects object peers . Consider for example a bag of marbles. The animator may wish to animate the individual marbles within the bag or animate the motion of the bag itself. To animate the individual marbles for example the animator can specify a frame of reference that allows the animator to individually manipulate each marble within the bag without having to deal with motion of the bag.

Fixing an aspect of animation during recording of a manipulation of an object can be especially useful in creating animations based on compound motion. Continuing with the train example noted above the animator can specify that the camera should track the position of the figure on the train. The animator can then play the animation. When the animation is played back the figure can appear stationary on the intended display area. During this play back the animator can position the figure s hand and record its motion as it reaches to catch the ball. This can allow the animator to add the new motion without having to deal with other movement of the figure i.e. the figure moving with the train .

In addition or as an alternative to selecting a frame of reference that keeps an animation aspect held constant or fixed the animation tool can allow the animator to specify that at least one aspect of an object being animated should be disabled stand still while other motions in the animation environment remain active. The specified aspect includes an aspect e.g. its position that changes during animation of the object. The animator can choose for example to hold the object completely fixed disable all object motion or to hold some combination of its position orientation and scale fixed.

In the example configuration shown in the data processing system can include various hardware and or firmware components such as a network interface a processor an output device an input devices supplementary devices and a storage device . One or more system buses not shown can interconnect these components. The data processing system can also include an operating system e.g. WINDOWS MAC UNIX LINUX and the like and applications . The number identity and arrangement of these elements are not limited to what is shown and additional and or different elements can be contained in or coupled to the elements shown. Further the data processing system can include fewer components than what is shown.

The network interface may facilitate connectivity with a network such as the network . Network interface can be any appropriate wireline e.g. IEEE 1394 USB etc. or wireless e.g. IEEE 802.11 BLUETOOTH IrDA etc. mechanism for facilitating unidirectional or bidirectional transmission of data between the data processing system and the network . The network interface can include one or more network cards and or data and communication ports.

The network can include any element or system that facilitates communications among and between various network nodes. The network can include one or more telecommunications networks such as computer networks telephone or other communications networks the Internet etc. The network can include a shared public or private data network encompassing a wide area e.g. WAN or local area e.g. LAN . In some implementations the network can facilitate data exchange by way of packet switching using the Internet Protocol IP . The network can facilitate wired and or wireless connectivity and communication.

The processor can execute instructions from storage e.g. computer programs such as applications route information among components of the data processing system and or perform various operations on data. Although shows a single processor the system can include any number of general and or special purpose processors which can operate collaboratively or independently. In some examples the processor can include one or more application specific integrated circuits ASICs and or various other circuitry. The processor can include various logical elements and architectures e.g. the von Neumann architecture parallel architectures etc. and can perform various types of computational operations such as sequential computation and parallel computation.

The output device can present text images video audio or any other type of information. Examples of the output device include video display devices audio display devices printers and the like. The output device can display user interface information for various software applications running on the data processing system as well as the operating system programs necessary to operate the system. The output can present information by way of a cathode ray tube liquid crystal liquid crystal on silicon light emitting diode gas plasma laser or other type of display mechanism. The output can also be configured to receive generate and or present holographic or other visual representations. The output can be configured to audibly present information and it can include suitable components for receiving and presenting audio signals. Although shows a single output the system can include any number of similar or different output devices.

The input device can include components such as a keyboard a mouse a stylus a pointing device a joystick and or a touch screen. The input device can also include audio or video capture devices e.g. video cameras microphones etc. and or various sensors for capturing and processing emissions e.g. thermal motion sound etc. . It can also include one or more information reading devices e.g. scanners disk drives etc. and or input ports. Although depicts the input as a single discrete element the system can include any number of similar or different input devices. For example the system can include a keyboard and a mouse as well as a video capture device a scanner and several disk drives.

Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

A user of the data processing system can input commands to control and operate functionality of the system by way of the output device s and the input device s . These commands can for example be input by way of user manipulation of physical controls such as a keyboard or mouse. The user can input commands to select and manipulate objects presented on the output device .

The data processing system can include various interfaces not shown for facilitating bidirectional or unidirectional communication between the system and one or more of the input and output devices or other devices. The interfaces can include a combination of hardware software and or firmware components. The interfaces can include various connection ports such as USB RS 232 RS 485 Fibre Channel Ethernet IEEE 1394 RG 6 and or TOSLINK .

The supplementary devices can be included in or attached to the data processing system . The supplementary device can include for example various devices used for video and film editing. Examples include video controllers video recorders audio recording systems backup power supplies etc. Moreover the supplementary devices can include any digital print engine or marking engine display monitor or other raster output device capable of producing color or gray scale pixels on paper film display screen or other output medium. Additionally for displaying animations a playback media player e.g. the A F Player software incorporated in devices such as mobile phones set top boxes handheld devices or other display devices can be used.

The storage can provide mass storage working e.g. cache memory and or buffer space for the system . The storage can be implemented using a variety of suitable memory elements. The memory elements can include for example solid state elements optical elements polymer elements magnetic elements and or organic elements e.g. crystals . The memory elements can be volatile or non volatile and can be randomly or sequentially accessed. The storage can include random access memory RAM flash RAM read only memory ROM erasable programmable read only memory EPROM and electrically erasable programmable read only memory EEPROM . The storage can include one or more fixed disk drives e.g. a hard drive RAID storage etc. and one or more removable disk drives e.g. a CD ROM drive DVD drive etc. . The storage can also include one or more data repositories e.g. relational distributed and or object oriented databases which can be local and or remote to the data processing system . In some examples the storage can include one or more local and or remote network based storage architectures such as a storage area network SAN . Although a single storage element is shown in the data processing system can include or interact with any number of individually configured storage elements .

The storage can store program code for various applications the operating system an application programming interface application routines middleware components and or other executable instructions. The storage can include program code and information for communications e.g. TCP IP communications middleware components kernel and device drivers invariant low level systems code data for basic input and output and various configuration information.

In some implementations the storage includes at least one computer readable medium which tangibly embodies one or more computer programs. The computer programs can contain instructions that when executed by a processor implement various methods such as those described below and or systems. Computer readable medium refers generally to any type of computer program apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a processor. Computer readable media suitable for storing computer programs and data can include forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks.

The applications refer to computer programs having some defined purpose appreciable by a user. The applications can include various computer programs also referred to as programs software software applications software modules or code which contain instructions executable by the processor . In some examples the applications can be transferred to the storage device e.g. by way of network transmissions e.g. an Internet download and or removable disks a CD ROM or DVD . Computer programs consistent with this disclosure can be implemented in various programming languages such as high or mid level procedural and object oriented programming languages e.g. C C Java JavaScript PHP Visual Basic etc. low level assembly languages Intel 80x86 ARM etc. and or various other languages.

The animation tool can be implemented as application software within the data processing system . A user of the data processing system can interact with the animation tool e.g. through output and input devices and to perform various tasks such as creating objects and object animations. The animation tool can be built on an application support platform which can include the operating system and a runtime library that operates in conjunction with the operating system to provide support for applications on the data processing system .

In some examples the animation tool can be implemented as an independent monolithic application that runs on the data processing system . Other implementations are also within the scope of this disclosure. For example the animation tool can be configured as an applet that runs in conjunction with a Web application. In some examples the animation tool can be implemented as a plug in type component that provides various functionality to and extends the feature set of one or more host applications . The data processing system can include various host applications e.g. that use such a plug in component. The host applications can provide services to the plug in to allow the plug in to interact with the host application. The host applications and or the operating system on the data processing system can include APIs application programming interfaces not shown that allow plug ins to be added and interact with the host applications . In some implementations the animation tool itself can include its own API which can be used for accepting plug ins. Non limiting examples of APIs include the A AE API and the A F Media Interactive Server Plug in API available from Adobe Systems Incorporated of San Jose Calif.

The animation tool can connect and provide services to one or more components such as a remote processor which can include a Web server over the network . For example the animation tool can run on the data processing system and interact with Web servers and sites that display animations such as Flash based web sites hosted by systems external to the data processing system .

The animation tool is not limited to application level software and in some examples can interact and or be integrated into various system level elements of the data processing system . For example the animation tool can include a system level software component used by the operating system to provide various user interface or other features.

Additionally although depicted as software in the animation tool can include and or be coupled to various hardware elements within or external to the data processing system . In some examples the animation tool can include and or use one or more embedded systems such as microcontrollers routers etc.

In some examples aspects of the animation tool can include or be incorporated into animation software for creating multimedia content e.g. A F software available from Adobe Systems Incorporated of San Jose Calif. and or software for creating motion graphics and visual effects e.g. A AE software available from Adobe Systems Incorporated . Additionally or alternatively aspects of the animation tool can include or be incorporated into software for images and or video e.g. A P and A P software both available from Adobe Systems Incorporated . Other examples are also within the scope of this disclosure.

The animation tool can include various functional modules such as an authoring module and an animation module . These discrete modules are used herein for purposes of explanation only and various other arrangements are within the scope of this disclosure. For example the authoring and animation modules and can be distributed across multiple data processing systems . Moreover the various functionality of the modules and can be distributed or exist in more or less modules than what is shown in the figure. Additionally the animation tool can include more or less functionality than what is described in connection with modules and . In some examples the animation tool can include components that reside in other applications and or components. The particular configuration arrangement and feature set of the animation tool will be flexible and will depend on the particular operating environment.

The modules and can include and or use one more data structures as well as one or more computational algorithms that can operate on various data. The modules and can include sets of instructions for performing various tasks and the modules can output information for use by users or other systems. In some implementations the modules can include one or more engines which can output code that serves as input to other systems engines or processes. The modules can include and or use various hardware and firmware elements.

To facilitate user interaction one or more of the modules and can generate and present various user interfaces. These interfaces can include any physical or virtual mechanisms by which a user can input information and or by which a user can perceive information. In some examples the modules and can generate visual interfaces such as graphical user interfaces. Other types of interfaces can also be used. The interfaces can include one or more physical or virtual elements or widgets e.g. buttons sliders windows menus lists toolbars navigation elements etc. that allow a user to view navigate and or input e.g. select information.

The authoring module can include functionality for allowing users to create objects animation environments and or other content. The authoring module can be used to create such content for various interface platforms such as for web sites mobile communication displays handheld displays set top box displays and other interactive media. The authoring module can therefore include website authoring components.

In some examples the authoring module can allow users to design objects and animation environments through a user interface that provides access to various graphical design tools which can be provided by the module or some other module application or system . In addition or as an alternative the authoring module can allow user to select predefined objects or assemble objects from predefined object components. In some examples the authoring module can present a palette of predefined and pre generated objects and components from which users can make selections. The authoring module can also allow users to import objects from files accessible to the data processing system and or upload the object from a source accessible to the data processing system .

Objects and animation environments which can be created by the authoring module can be created and stored in various formats. The formats can employ various compression schemes e.g. lossy and or lossless compression and various data structures e.g. raster graphics and or vector graphics . In some examples objects can be represented as SWF Shockwave Flash data. Other example formats include SVG Scalable Vector Graphics X3D VRML Virtual Reality Modeling Language XMT extensible mpeg 4 textual format HTML HyperText Markup Language FlashPix AQ AVI Audio Video Interleave PICT Animated GIF Graphics Interchange Format MAM AP and AI and the like. Alternative formats include PDF Portable Document Format TIFF Tagged Image File Format JPEG Joint Photographic Experts Group GIF ZIP etc. The authoring module can allow users to create and animate objects using the various formats which can be selectable by users. In some examples the animation tool can include an API that accepts plug ins for supporting one or more of the various formats.

The animation module can include functionality used for animating objects created with the authoring module . The animation module can receive and record object manipulations input from users. One or more data buffers or other temporary or permanent storage mechanisms of various capacity e.g. 1 MB to 32 MB can be used by or included in the animation module for recording. The animation module can allow users to successively input and record manipulations to create compound motion. The animation module can present various user interface elements that allows a user to input manipulations and control the recording of manipulations.

In some examples the animation module can generate and present a timeline for use in animating objects. The timeline can divide time into segments or frames and graphically represent these segments. The animation module can allow a user to store object manipulations at various points on the timeline in order to build an animation. The animation module can allow a user to select points on the timeline to begin and end recording.

The animation module can build or assemble animations based on the compound motion of one or more objects. For example the animation module can generate an animation involving multiple objects by assembling and running recorded manipulations for each of the objects involved in the animation. In some examples the timeline can be used in building animations. In addition the animation module can employ various animation techniques such as tweening fading etc. For example with tweening a user can insert motion at certain key frames in the timeline and the animation module can interpolate and fill in the frames between those key frames with additional motion and or visual effects to achieve smooth transitions.

In some implementations the animation module can infer object motion when building animations. For example the objects themselves can include links with inverse kinematics used to infer additional motion from a user manipulation. As an example a human figure can be represented as an object with several rigid members connected by joints. The animation module can be configured to determine positions and angles of the jointed members associated with a specific pose of the human figure. When a user manipulates one of the rigid members e.g. moves the figure s arm the animation tool can infer movements of other jointed members of the figure and animate those members to effect a certain pose or to ensure that the animation of the figure is consistent with the animation environment e.g. the human figure s arm is positioned in proximity to a ball .

The animation module can include or utilize a view camera to define how animations are projected onto an intended display area. The animation module can include or utilize one or more data structures for mapping the animation environment and objects in the environment to an intended display area such as a display area of the output device . These data structures can include a view matrix that specifies and controls the manner in which objects and animation environments are displayed e.g. the orientation and location of the objects on the screen . The view matrix can be composed of translation scale and rotation. These can be specified in some example implementations using matrices vectors and affine transformations between vector spaces.

The view matrix can map objects and the animation environment to the display area using one or more coordinate systems. For example as noted above the view matrix can define objects and environments relative to a display using a coordinate system based on screen pixels. In some examples the view matrix can include one or more transformation matrices for transforming object coordinates from one coordinate system e.g. 3D world coordinates to another e.g. 2D screen coordinates .

The view matrix can contain various properties of objects and the animation environment as well as associations between those properties and aspects of the intended display area. The view matrix can be implemented for example using various tables or other structures. In some implementations the view matrix can include or utilize standard object modules. The view matrix can also be implemented in hardware.

The animation module can render animations. This can involve assembling and presenting animations on a display such as output device . The animation module also provide services for rendering animations on one or more components over the network . For example the animation module can interact with Flash based web sites hosted by web servers remote to the system . The animation module can also interact with various service providers for example to render animations on mobile devices.

The animation module can provide functionality for creating animations based on relativity. As described above this can involve allowing the animator to specify that certain motion should be relative to the object being animated during recording of a manipulation of the object. For example that animator can specify that the view camera should track at least one aspect of an object being animated e.g. its position . In addition or as an alternative the animator can specify that at least one aspect of an object being animated should stand still while the environment moves relative to that aspect. The animator can then add and record additional motion to the object while the at least one aspect is fixed. The recorded motions can build an animation of the object. The animation module can present various user interface elements that allows user to utilize this functionality.

To animate the object the animation tool can allow the user to add motion to the object while the motion is recorded. Adding motion can involve for example translating the object and rotating the object. To add motion the user can manipulate the object using an input device. For example a pointer or cursor associated with a mouse or other input device can be used to select and manipulate the object . In this example the user selects object using the cursor and adds translational motion M to the object by dragging it across the environment from a position A to a different position B. The animation tool records this manipulation as it occurs for example using the animation module .

The animation tool allows the user to select an aspect of animation that will remain fixed during recording of additional object manipulations. Doing so can define a frame of reference that is tracked by the view camera thus causing the projection of that frame of reference to remain fixed in the display. A frame of reference can be defined by an origin point an orientation angle and a scale factor. These parameters can be determined from a subset of the aspects of the animating objects specified by the animator. For example the user can specify that the origin point be determined from the position of a selected object as that object translates in the animation environment during the animation.

Referring to element the user can fix the positional aspect of the object animation by fixing the view camera so that it tracks the x y position of the object in the animation environment . Fixing the view camera to track position can cause the object to appear stationary at an x y position C in the animation environment . Because the camera tracks the object the other objects objects and in the animation environment can appear to move against the motionless object .

The user can input the selection to fix an aspect of animation in various ways and the selection can involve a single user action selection or several actions selections. In some examples the user can fix an aspect of animation by simply selecting anywhere on the object or by selecting a particular region or point on the object . In these scenarios the animation module can prompt the user to select the object or a particular region on the object in order to fix the object.

In some examples the animation module can present various menus and options which can be hierarchically arranged for fixing aspects of the object . For example to select the entire object the user can select a Fix Object option followed by an Entire Object sub option. The user can then select from a menu of motions. For example the user can select a Position option. The user can also select from a menu of previously recorded motions. For example the user can select a Last Recorded Motion option to fix the horizontal position of the object .

In some examples the animation module can allow the user to fix an aspect of animation by selecting a region or point on the object in combination with a selection of some other reference point. This technique can be used for example to fix an aspect of animation e.g. the position of the object relative to some reference in the animation environment. For example the user can select the object and a point near or at object to fix the position of the object relative to the position of the selected point near or at object . As another example consider a bicycle object moving across the stage with the bicycle wheels rotating on the ground. The user can select an arbitrary point on one wheel and another arbitrary point on the other wheel and choose a frame of reference that keeps those two points stationary. Playing back the animation with this frame of reference can show a complex scene where the bicycle appears to buck around and the camera appears to zoom in and out.

In some examples the user need not explicitly define a point fixed relative to some other object. Continuing with the train dog and cat example from above two groups can be created in addition to these three individual objects. For example a world group and a train group can be created. The train group can contain the train the dog and the cat whereas the world group can contain the train group. The objects in the train group would move all together through the world or animation environment. As the train group moves the train the dog and the cat would all be stationary with respect to one another. Additional dog and cat motion can then be added relative to the train group s position and not relative to the train itself.

In some examples the tracking of the view camera can be defined by one or more reference points on one or more objects. As described above in the 2D case the view camera can have three parameters x y position angular orientation and scale or zoom . In one example the animator can specify that the camera should track an object by selecting an object to indicate that the x y position of the camera should track the position of the object. If the x y position is not well defined e.g. the object is changing in shape however the user can choose to track a region of the object e.g. center top left etc. or a specific point on the object e.g. a vertex point of a vector object .

Position can be defined by an average of several points. For example the animator can specify that the camera position should be fixed at the mid point between two objects or the point equidistant from three other points. These new points can be used to define rotations or scales. With two pairs of balls being animated for example the rotation angle can be defined by the line connecting the mid points of the pairs.

As another example the animator can choose to track the rotation of an object. This can be accomplished by selecting an object and indicating that its rotation should be tracked by the view camera. The animator can also choose to track the rotation angle defined by multiple objects. For example if the animation involved two rotating balls a line between the center of the two balls will be at some angle with respect to the ground plane. The animator can specify that the view camera should track this rotation by selecting the two objects and indicating that the camera should track the angle between them.

An animator can also choose to track the scale of an object based on one or more reference points. If the object being animated is changing size the animator can select the object and indicate that the camera should track its scale. For example the scale of an object can be defined by the distance between two points. The user can track object scale by selecting these points.

The animation tool can allow users to fix an animated aspect of particular object being animated with varying degrees of granularity which can depend on the complexity and structure of the object being animated. For example the animation tool can allow the user to simply fix the position or some other animated aspect of the entire object . In addition or as an alternative the animation tool can allow the user to fix the position or some other animated aspect of a component of the object e.g. the wheel . If the object were a character e.g. a human figure having various rigid members connected by joints for example the animation tool can allow the user to fix the position of one or more of the rigid members while allowing other members of the character to move relative to the fixed aspect of the selected member.

In some examples the animation tool can fix an aspect of animation that involves multiple objects. For example the user can choose to fix the position of a point that is half way between the object and the object .

In some examples the selected aspect of animation to be fixed can include a relationship between among multiple objects or object components members . As an example if two soccer ball objects were animated in an animation environment such they both simultaneously rotate around an axis while maintaining a constant distance from each other the animation tool can fix the positions of both of the soccer balls so that the rotation of the balls is displayed as rotation of the background environment rather than rotation of the balls. This can allow the user to add additional motion to the soccer balls such as increasing and decreasing the distance between the balls in an oscillating manner. When the animation is eventually played back the distance between the two soccer balls can vary as the balls rotate around each other.

To fix the selected aspect of the animation e.g. the position of the object the animation module can access and modify the view matrix data structure that maps the objects e.g. the object and or the animation environment to the intended viewing space. For example to hold the selected aspect fixed the animation module can modify a translation property in the view matrix by performing a transformation. As another example to hold the selected aspect fixed the animation module can modify a scale property in the view matrix.

Once the user selects an aspect of animation to hold fixed the user can record an new aspect of animation. The animation tool can play back the previously recorded animation such that the selected aspect remains fixed and the animation environment and other objects move relative to the selected aspect. For example in element the translation of the object is held fixed while other aspects of the animation environment e.g. the objects and move relative to the object . During this playback the user can add additional motion to the object by further manipulating the object. For example as shown the user can add rotational motion M to the object . The animation tool records this additional manipulation while playing back the other aspects of the animation relative to the object. Playing back the other aspects of animation while the new manipulation is being recorded allows the user to view the new motion in context.

In some implementations the animation tool can play back movement of the animation environment and other objects relative to the selected aspect in slow motion or fast motion or with other time based effects. For example the translation of the object can be held fixed while other aspects of the animation environment e.g. the objects and move relative to the object in slow motion.

In some implementations the animation tool can play back movement by displaying visual cues e.g. lines similar to graph paper or some other background element in the animation environment. The visual cues can be displayed for example to display motion relative to an object in an animation environment that is monochromatic and lacking any other objects. The visual cues can be part of the authoring environment but need not be part of the produced animation itself.

As an example consider an object recorded to move across the stage the default frame of reference with a blank monochromatic background. Changing the frame of reference to the object and playing the animation would make it appear that nothing is changing over time since the frame of reference can be defined by the object and no other objects features are in motion relative to it. If the frame of reference were fixed to the object s translation but not to its rotation the object can appear to rotate in place. If the frame of reference included all aspects of the object then a time indicator can progress forward or some visual cue can be presented to show motion.

The animation tool can then animate the object by playing back or running the recorded manipulations without holding any aspect of the animation fixed. This is shown in element . As shown the object is animated with compound motion that is with both translational motion M and rotational motion M.

To further illustrate aspects of animating based on relative motion consider another example in which an inclined ramp object is placed on the animation environment which is defined and fixed . A multi colored beach ball object is placed at the top of the ramp. The animator then desires the beach ball to move down the ramp and translation of the beach ball is recorded with it moving sliding down the ramp no rotation .

The animator then desires the beach ball to rotate as it moves down the ramp. To achieve this the animator can choose to change the frame of reference from the animation environment to the beach ball so that the beach ball is the new frame of reference. Playing back the animation with the new frame of reference causes the beach ball to appear stationary and the ramp appears to slide upward against the beach ball which is motionless within this its own frame of reference. During the play back the animator records rotation of the beach ball as the ramp slides against it e.g. by grabbing the edge of the beach ball and moving it in a circular motion . The animator can then change the frame of reference back to the stage. Playing back the animation now shows the beach ball rolling both translating and rotating down the ramp.

The animator then desires the beach ball to bounce as it rolls down the ramp. Once again the animator can change the frame of reference from the stage to the beach ball. In this situation the animator then temporarily disables the rotation motion of the beach ball. Playing back the animation with this aspect disabled shows the ramp sliding upward against the non rotating beach ball. The animator then records the up and down bouncing motion. The animator can then re enable the beach ball s rotation and change the frame of reference back to the stage. Playing back the animation now shows the beach ball rotating and bouncing down the stationary ramp.

The animator then desires for a bug to run along the top of the beach ball as if it were on a treadmill. The animator can choose the frame of reference as the bouncing beach ball but can choose that rotation should not be included in the frame of reference. All motions are enabled but only some motions are fixed as part of the frame of reference. Playing back the animation now shows a rotating non translating beach ball with the ramp moving past it. The animator places a bug object on top of the beach ball and records the bug running on top of the beach ball using small translation movements forward and backward. The animator can then change the frame of reference back to the stage. Playing back the animation now shows the bug running on top of the ball is it rolls and bounces down the ramp.

For purposes of explanation only certain aspects of this disclosure are described with reference to the discrete elements shown in . However the number identity and arrangement of elements are not limited to what is shown. For example the environment can include any number of geographically dispersed data processing systems which can themselves be discrete integrated modules or distributed systems.

Furthermore additional and or different elements not shown can be contained in or coupled to the elements shown in and or certain elements shown can be absent. In some examples the functions provided by the elements shown can be performed by less than the number of components shown or even by a single element. The elements shown can be implemented as individual processes that run on separate machines or a single process running on a single machine.

The data processing system need not include all of the elements shown in . Rather in some implementations the data processing system can include only one or more processors for performing instructions and one or more memory devices for storing instructions and data. Moreover the data processing system can itself be embedded in another device or system such as a mobile communications device e.g. a mobile phone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver and the like.

The process receives a selection of an animation aspect associated with an object. An animation aspect can include any feature of the animation that is associated with the object or any attribute of an object that changes when an animation of the object is displayed. Such changes can result from recorded user manipulations of the object or indirectly as a result of manipulation of some other element.

An animation can include the object an animation environment and an original frame of reference. The original frame of reference can include the frame of reference associated with e.g. fixed to the animation environment. The original frame of reference can be a frame of reference through which all aspects of the animation are displayed from one vantage point. The original frame of reference can represent what is seen through the view camera which can be aligned with a viewer s eye or line of sight when the view camera is fixed or tracking the entire animation environment.

The animation aspect can include any attribute of the object that changes over time with respect to the original frame of reference when the object animation is displayed. For example the animation aspect can include object position object scale or object orientation with respect to the animation environment. Other attributes are also within the scope of this disclosure. In some examples the animation aspect can include a relationship e.g. a distance between among multiple objects or object components . The animation aspect can be used to determine a view matrix or camera discussed above which maps the animation to an intended display area. In some examples the selected animation aspect can include an aspect that was previously recorded.

Receiving a selection of an animation aspect associated with an object can include receiving a selection of a single animation aspect or receiving a selection of a combination of animation aspects. For example object position can be selected or a combination of object position and object scale be selected.

Receiving a selection of an animation aspect associated with an object can include receiving a selection of an animated aspect of an object component or member. If the object includes various rigid members connected by joints for example the process can receive a selection of one or more animated aspects e.g. position scale of one or more of the rigid members.

Receiving a selection of an animation aspect can include receiving input that selects an animation aspect. This can involve receiving from a user of the data processing system one or more selections input by way of the input device . The selections can include selections of various elements presented in a user interface generated by the animation tool . Selecting an animated aspect can be accomplished by a single operation or by multiple operations by the user. In some examples the user can select the animated aspect by simply selecting a region on the object either alone or in combination with some other reference point. In some examples the user can select the animation aspect by navigating through and selecting various menu options. A combination of these techniques and other techniques can also be used to select an animation aspect.

The process displays the animation through a selected frame of reference which can include a frame of reference different from the original frame of reference associated with the animation environment. Displaying the animation can involve playing back previously recorded object manipulations. The selected frame of reference can be defined based on the selected animation aspect e.g. by holding the selected animation aspect constant over time. The selected frame of reference can be one that follows the selected animation aspect. Displaying the animation through the selected frame of reference can cause the selected animation aspect e.g. its x y position to appear to remain constant over time while the rest of the environment outside of the selected frame of reference moves relative to that selected aspect.

The displaying can involve holding the selected aspect fixed by adjusting the view matrix or view camera so that it tracks the selected aspect. By tracking the selected aspect that aspect can appear to be remain stationary relative to the animation environment. For example if the camera tracks x y position of the object then the x y position can appear stationary. The selected aspect of animation e.g. the object position can be displayed in the selected frame of reference as changes to other elements in the animation environment e.g. changes to the positions of other objects .

If the selected aspect is object position for example the object can appear to stand still at a fixed position in the animation environment while everything else in the environment e.g. other objects moves relative to the object. If the selected aspect includes an aspect of an object component the selected component of the object can be held fixed while other components of the object move relative to the fixed animated aspect of the selected object component.

The process can fix the selected aspect by modifying one or more data structures that associate the selected aspect with a viewing space. For example the process can fix the selected aspect by modifying a data structure maintained by the animation module such that the coordinates e.g. pixel coordinates of the object are held fixed.

In some implementations the displaying can involve disabling the selected animation aspect and enabling other aspects. That is the animation can be displayed such that the selected aspect of the object is fixed while other elements in the environment are allowed to move. This can be optional.

At stage the process receives during the animation display a new animation aspect associated with the object. In some examples the new animation aspect can include an aspect of the object other than the aspect selected at stage . For example the selected aspect can be object scale whereas the new animation aspect can include translation of the object. Receiving a new animated aspect can involve receiving user input that manipulates the object. For example the process can receive an input that rotates the object around a point or axis. Such input can be received from a user by way of the input device .

At stage the process records the new animation aspect associated with the object. The recording of the new animation aspect associated with the object can occur simultaneously with the receiving of the new animation aspect. That is as the user inputs a manipulation the process can record the manipulation. Recording the new animation aspect can involve storing the recorded information for example in the storage for subsequent retrieval.

As shown in the process can be an iterative process to allow user to add compound motion to objects. For example after the new animation aspect is recorded the process can receive a selection of another animation aspect. At this iteration the selected animation aspect can be the aspect that was recorded at stage during the previous iteration of the process. The process can continually receive selections of animation aspects and record new aspects for a number of iterations sufficient to build the desired animated. That is a user can build a desired animation by successively recording manipulations selecting aspects to hold fixed and recording new manipulations. This can allow users add compound motion to objects which can be used to build animations.

In some examples the process can be used to add motion to and animate multiple objects. For example receiving a selection of an animation aspect can involve receiving animated aspects of more than one object in an animation environment and or receiving a selection of a relationship e.g. a distance between among multiple objects. The process can display the animation through a selected frame of reference so that the selected aspect appears fixed by defining the frame of reference based on the multiple objects or their relationship . The process can then receive and record new animation aspects .

Continuing with the soccer ball example from above the process can fix the positions of the two soccer ball objects in the animation environment so that the two balls remain fixed relative to the animation environment and or relative to each other. For example the animation tool can fix the positions of both of the soccer balls relative to each other so rotation of the balls around an axis is displayed as rotation of the background environment rather than rotation of the balls. The process can also fix for example the position of an insect object sitting on one of the soccer balls. The process can then receive a new manipulation by receiving motion to the insect object that causes it to jump back and forth between the two soccer balls. When the animation is eventually played back the two soccer balls can be rotating and translating with the insect jumping back and forth between the two balls.

Turning now to a flow diagram depicting another animation process will be discussed. The process can be performed by one or more elements in the data processing system . The process can be performed by the processor executing one or more instructions from the animation tool .

The process can involve presenting a timeline. This can involve dividing time into various segments and graphically displaying these increments. For example the process can present a graphical user interface element that displays a time scale and various markings that break the time into segments. In some examples the timeline can represent the duration of an animation. As an example the animation of an object can last two minutes and the timeline can divide this duration into various increments such as one second increments.

In some examples the timeline can correspond to frames that can be played back in sequence. Each frame can represent a visual picture or effect e.g. position of an object. When the frames of the timeline are played back in sequence the object can appear to be animated. Some implementations can include key frames which can be used by the process for tweening and or other animation techniques.

The process can receive a selection of a starting point. This can involve receiving a user selection of point or frame on the graphical timeline. For example the user can select a starting point that is 15 seconds into the animation. In some examples the user can input a selection by clicking or otherwise selecting one or more points on a graphical timeline.

The process can receive a selection of an animation aspect associated with an object. This stage of the process can be similar to stage of process . The process can receive for example a user selection of object position or a combination of object position and rotation.

The process can then initiate recording . This can involve initiating the recording of new motion for the object such a rotational motion. The process can initiate recording in response to a user selection such as a selection of the object itself a selection of a particular key and or a selection of a particular user interface element e.g. a record button .

During the recording the process can display an animation of the object in context with the selected aspect held fixed . Displaying the animation of the object in context can include displaying recorded events for other objects so that the new motion being recorded can be seen in context. Displaying the animation with the selected aspect held fixed can involve displaying the animation through a selected frame of reference as discussed above. The frame of reference can follow the selected animation aspect so that the selected animation aspect appears to remain constant over time while the rest of the environment outside of the selected frame of reference moves relative to that selected aspect. In some examples movement of the environment relative to the selected aspect can be displayed in slow motion or fast motion.

During the recording the process can receive a manipulation of the object. This can involve for example a user clicking or otherwise selecting on the object and moving the object around the animation environment. In some examples the process can allow the user to manipulate the object in response to some user input e.g. holding down a particular key selecting an interface option etc. . The received manipulation can include for example object rotation and or translation within the animation environment. The user can input the object manipulation by way of the input device .

The process can then stop the recording . In some examples the process can stop the recording in response to a user command such as a selection of a particular key and or a selection of a particular user interface element e.g. a stop button . In addition or as an alternative the process can automatically stop recording after a certain amount of time which can correspond to a recording buffer capacity. In some examples the process can stop the recording in response to the user releasing control of or de selecting the object being manipulated e.g. the user stops dragging the object around the animation environment or releases some key or mouse button .

The process can then decide whether the animation is complete. This can involve determining whether there are any additional manipulations to be recorded by the user for example by presenting various prompts to the user or evaluating various user selections. In some examples the decision can be made based on a user selection that indicates the animation is complete such as a user selection of an interface element e.g. an animation done button .

If the animation is not complete the process can receive a selection of another recording starting point and a selection of another animated aspect . The process can then proceed through the various other stages . The process can continue for a number of iterations sufficient to build the desired animation.

When the animation is complete the process can run the animation . Running the animation can involve playing back frames of the timeline in sequence as well as performing various tweening interpolation and other animation techniques. With tweening for example the user can insert motion at certain key frames in the timeline during previous stages of the process and the process can interpolate and fill in the frames between those key frames with additional motion when the animation is run at stage . In some examples running the animation can involve inferring motion of objects based on inverse kinematics discussed above .

Running the animation can involve playing back recorded manipulations without any aspect of animation being held fixed. In some examples this stage can involve assembling various manipulations to build an animation based on compound motion. Continuing with the soccer ball example from above running the animation can involve assembling and playing back an animation in which two soccer balls are independently rotating and translating in an animation environment while an insect jumps back and forth between the two moving balls.

The sequences of events shown in are examples and not intended to be limiting. Other processes can therefore be used and even with the processes and depicted in events can be re ordered added and or removed. Furthermore the elements of the processes can overlap and or can exist in fewer stages than the number shown in the figures. In some examples processes can be re arranged and configured to accommodate and or exploit multitasking and parallel processing techniques and or other aspects of various system architectures.

Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter effecting a machine readable propagated signal or a combination of one or more of them. The term data processing apparatus encompasses all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver to name just a few. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user embodiments of the subject matter described in this specification can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described is this specification or any combination of one or more such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN e.g. the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

While this specification contains many specifics these should not be construed as limitations on the scope of the invention or of what may be claimed but rather as descriptions of features specific to particular embodiments of the invention. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a subcombination or variation of a subcombination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

Thus particular embodiments of the invention have been described. Other embodiments are within the scope of the following claims. For example the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition embodiments within the scope of this disclosure can encompass various contexts. As an example embodiments within the scope of this disclosure can include a machine vision system that interprets real world actions e.g. real paper puppets and translates what it sees e.g. via a live video stream into computer world virtual manipulations. Other contexts are also possible.

