---

title: Sound capture system for devices with two microphones
abstract: The perceptual sound quality of desired audio signals (e.g., human voice) captured by an electronic device (e.g., cell phone) are improved by reducing ambient noise according to an algorithm that acts upon audio signals captured from a front and rear direction. More particularly, audio signals captured by two directional microphones pointing in opposite directions (e.g., a front microphone which receives audio signals from a forward direction and a rear microphone which receives audio signals from a rear direction) are classified and subsequently enhanced (e.g., unwanted signals are suppressed) according to a probability of their source (e.g., front, rear, or noise) thereby providing an improved perceptual sound recording than each microphone individually. The resultant signals provide decreased noise since the contribution of the front and rear microphones are taken into consideration and the signal from the more relevant (e.g., in the direction from which sound is coming) microphone is utilized.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08503694&OS=08503694&RS=08503694
owner: Microsoft Corporation
number: 08503694
owner_city: Redmond
owner_country: US
publication_date: 20080624
---
Small electronic devices such as web cameras or cellular phones need to capture sounds in severe noise conditions or when a talker is at some distance from the device. In general mobile or hand held electronic devices are engineered to make the signal e.g. speaker s voice to noise e.g. everything from the outside world besides the speaker s voice ratio high. This happens when the device is hold close to the mouth. A high signal to noise ratio provides a high perceptual sound quality without requiring any additional processing. When the device is moved away from the mouth the signal to noise ratio becomes low leading to lower perceptual audio quality.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

The perceptual quality of desired audio signals e.g. human voice captured by an electronic device is improved by reducing ambient noise according to an algorithm that acts upon audio signals captured from a front and rear direction. More particularly audio signals captured by two directional microphones pointing in opposite directions e.g. a front microphone configured to receive audio signals from a forward direction and a rear microphone configured to receive audio signals from a rear direction are classified and subsequently enhanced according to the probability of their source e.g. front or rear thereby providing an improved quality sound recording than each microphone individually.

Essentially signals captured from a front and a rear microphone are enhanced by increasing the suppression of the opposite signal e.g. rear signal in a front channel and front signal in a rear channel . A set of features e.g. the level difference for a whole frame feature the time of arrival for a whole frame feature the level difference per frequency bin feature and the time of arrival per frequency bin feature is extracted based on the difference between the suppressed audio signals in the front and rear channels for each frame and frequency bin. A probability that the captured audio signal is from the front or from the rear is calculated for respective features of the set of features. The respective probabilities are combined to form an overall probability. The front and rear suppressed audio signals are enhanced e.g. unwanted signals further suppressed based on the overall probability of a front or rear source. The resulting enhanced audio signal provides decreased noise since the contribution of the front and rear microphones are taken into consideration and the audio signal from the more relevant microphone is utilized e.g. microphone in the direction from which the sound is coming .

The real time execution of the above method depends on a certain number of parameters minimal gains prior probabilities etc. . These parameters are estimated off line and optimized for achieving improved perceptual sound quality using wide range of test recordings.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

Most electronic devices use a single microphone integrated into the devices. However a single microphone does not work well in situations where the speaker s mouth is not near the single microphone because the microphone captures larger amounts of ambient noise and reverberation therefore making the captured sound unusable e.g. with a low signal to noise ratio . To address this problem and thereby increase the signal to noise ratio people may use headsets if they need good sound quality or incorporate microphone arrays configured to perform beamforming into their devices. Headsets are awkward and limit mobility while microphone arrays needed for beamforming require a significant amount of space and do not easily fit into today s small sized electronics.

The problem of increased signal to noise ratio of captured sound will further increase with the approach of fourth generation communication systems 4G which will offer increased broadband access to internet and video phones capabilities. In video phones users will hold the device one to two feet from their face. This increased distance between the microphone and the speaker s mouth will increase the ratio of signal to noise ratio since the microphone will capture the same noise signal but the voice signal from the speaker s mouth will be ten times weaker since it has further to travel. Another similar situation occurs when a video phone is used as a camcorder. The screen acts as a viewfinder while the camera is on opposite side. Microphones placed on the screen e.g. viewfinder side will result in a poor sound quality on the camera side and microphones placed on the camera side will result in a poor sound quality on the screen side. Therefore there is a need to have reliable sound capturing capabilities in these and similar situations.

The present techniques and systems provided herein relate to a method by which the perceptual quality of desired audio signals e.g. human voices captured by an electronic device e.g. cellular phone are improved by reducing ambient e.g. background noise according to an algorithm that acts upon audio signals captured from a front and rear direction. More particularly audio signals captured by two directional microphones pointing in opposite directions e.g. a front microphone configured to receive audio signals from a forward direction and a rear microphone configured to receive audio signals from a rear direction are classified according to the probability of their source e.g. front source rear source side source etc. . The audio signals are then enhanced according to their source effectively suppressing audio signals coming from an unwanted direction and resulting in an improved audio signal that uses only the audio signal from the more relevant microphone e.g. the audio signal from the front .

At an electronic device e.g. cellular phone video camera web camera etc. captures a sound from an external source. Two directional microphones facing in opposite directions front and rear microphones receive the sound. In one example sounds are captured by at least one front microphone e.g. a microphone facing in a forward direction from the electronic device and one rear microphone e.g. a microphone facing in a backward direction from the electronic device and are converted to audio signals e.g. electrical signals .

The audio signals are classified according to a probability of their source at . An audio signal can be classified as either coming from a front source e.g. direction coming from a rear source e.g. direction or as noise. Classification of the audio signals can be dependent upon a set of features extracted from a difference between captured signals from the front and rear microphones. For each feature of the set of features a probability of a source e.g. from the front from the rear noise of its associated signal is calculated. A combination of the probabilities of all the features in a set overall probability is determined taking into consideration that for a given signal a probability of one feature may be more reliable than a probability of another. The overall probability may be enhanced e.g. optimized and used to classify the audio signals by source.

The audio signals are enhanced according to the overall probability of their source e.g. front source or rear source for a plurality of frequency bins and time frames at . Enhancement of an audio signal provides an improved perceptual sound quality than each microphone could individually provide. Enhancement of the audio signals suppresses signals which have been classified as noise e.g. signals which have a high probability of being noise for respective frequency bins and time frames. Likewise signals that are classified as coming from an unwanted direction e.g. signals that have a high probability of coming from a direction with a low probability will also be suppressed for respective frequency bins and time frames. Therefore the enhanced audio signals will have undesirable signals removed and thereby improve the captured sound quality.

At captured audio signals are converted from the time domain to the frequency domain. A sound is captured by two microphones a front microphone and a rear microphone . The front microphone and rear microphone input captured audio signals x t and x t respectively to the analog to digital converter ADC and conversion to frequency domain block . The captured audio signals x t and x t go through analog to digital conversion e.g. convert an analog audio signal to a digital audio signal . The captured audio signals are also segmented into a plurality of audio frames n e.g. 256 samples and converted to the frequency domain denoted X f and X f by using a fast Fourier transform FFT or Modulated Complex Lapped Transform MCLT or any other method for conversion to frequency domain. The frequency domain audio signals X f and X f are a spectra of complex numbers which arrive every single audio frame n e.g. a 20 mS sample of the signal .

The frequency domain audio signals X f and X f are input into a front filter and a rear filter respectively where they are combined and the opposite frequency domain audio signal is suppressed e.g. X f is suppressed for the front channel and X f is suppressed for the rear channel at . The front filter receives X f and X f which are filtered in a certain way to achieve the suppressed audio signal Y f . The rear filter also receives X f and X f which are filtered in a different way to achieve the suppressed audio signal Y f . The filtering performed by both the front filter and the rear filter increases the maximum contrast e.g. difference between front and rear audio signal X f and X f . For example the suppressed audio signal Y f has as much as possible from the front audio signal and as little as possible from the rear audio signal while the suppressed audio signal Y f has as much as possible from the rear audio signal and as little as possible from the front audio signal.

At voice activity detection is performed. Voice activity detection can be performed by a feature extractor . Voice activation detection is a method by which the algorithm can determine whether or not a suppressed audio signal e.g. Y f or Y f is speech or noise. If the voice activity detection determines a suppressed audio signal is a noise frame the parameters of the ambient noise may be updated. If the voice activity detector determines a suppressed audio signal is a speech e.g. voice frame the method proceeds to find the probability that the suppressed audio signal is from a front source a rear source or a side source.

A set of features are extracted from the difference between the front and rear audio signals e.g. suppressed audio signals Y f and Y f frequency domain audio signals X f and X f and a probability is calculated for respective features at . In Y f and Y f together with X f and X f are input into the feature extractor . The feature extractor extracts a set of features from the difference between the front and rear audio signals. Two probability vectors pand p e.g. probabilities that we have signal from the front or rear direction for every time frame and frequency bin are calculated for each of the features.

In one example a set of four features are extracted. The first feature is level e.g. energy differences between the front and the rear suppressed audio signals Y f and Y f for a whole frame e.g. a 20 mS sample of the signal . If the suppressed audio signal has a higher front level e.g. energy than rear level it indicates that someone is talking from the front. If the suppressed audio signal has a higher rear level than front level it indicates that someone is talking from the rear. If the suppressed audio signal has a substantially equal signal level from the front and rear it indicates that someone is talking from the side. The second feature is the time of arrival difference between the front and the rear frequency domain audio signals for a whole frame. The time of arrival difference estimates the time of arrival difference for a frequency domain audio signals X f and X f between the front and rear microphones. The third feature is the level e.g. energy difference between the front and rear suppressed audio signals Y f and Y f per frequency bin e.g. each of 256 frequencies . The fourth feature is the time of arrival difference per frequency bin which determines the difference in time of arrival between the front and rear frequency domain audio signals X f and X f for each frequency bin.

At the probability of respective features of a set of features are combined together to provide an overall probability that an audio signal is from a front or a rear source. For example the four features are cumulatively combined to form a probability model providing the probability of an audio signal s location e.g. calculate an overall probability that the signal is a front or a rear signal . The overall probability for the k th frequency bin of the n th frame can be estimated for both front and rear probabilities e.g. using the front and rear probability vectors pand pfor each of the features as 1 1 1 1 Where p p pare probabilities associated with the front or rear audio signal of the four features respectively level difference for a whole frame time of arrival difference for a whole frame level difference per frequency bin and time of arrival difference per frequency bin and G G G and Gare time and frequency independent minimal gains. The minimal gains determine how much a corresponding feature e.g. belonging to a set of features can be trusted. For example a gain value close to 1 means that a feature has a low level of trust e.g. the feature has a small contribution to the overall probability relative to other features of the set and a gain value close to 0 means that a feature has a high level of trust e.g. the feature has a large contribution to the overall probability relative to other features of the set .

The suppressed audio signal in the front channel or rear channel is enhanced based on the overall probability at . Enhancement is of the front suppressed audio signal Y f may be performed by a front estimator and enhancement of the rear suppressed audio signal Y f may be performed by a rear estimator . Enhancement according to the front and rear estimators and use the suppressed audio signals output of by the front and rear filters Y f and Y f and the overall probability provided by the feature extractor pand p to provide an improved estimate of an audio signal that has just front source components or just rear source components. Accordingly audio signals that have a high probability of coming from an unwanted direction will be suppressed resulting in an enhanced audio signal Z f or Z f with improved captured sound quality.

At amplification of the enhanced audio signals Z f and Z f are automatically adjusted by a process known as automatic gain control AGC . As is well known in the art AGC can be performed by an adaptive system wherein an average output signal level is fed back to adjust the gain to an appropriate level for a range of input signal levels. In a first adaptive system and a second adaptive system automatically adjust the incoming enhanced audio signals Z f or Z f based upon their strength. For example weaker enhanced audio signals receive more gain and stronger enhanced audio signals receive less gain or none at all.

A mixer mixes the front and rear adjusted enhanced audio signals Z f and Z f with each other based on the operation mode at . For example in the case of a cellular phone only a front signal mode is needed when a person is talking on a phone which is either closely positioned to the mouth or held in a way that the person can see the screen in a video phone mode. Alternatively a rear signal mode may be used when the phone or the small device is used to capture video e.g. when the camera is on the opposite side of the screen . Both the front and rear signal modes can be used when a user wants to use the phone as a camcorder in addition to recording her voice. There could also be a conference call mode when the phone lays on the table in which both front and rear signals are suppressed since sound is only coming from the sides and noise comes from up and down. Once the adjusted enhanced audio signals are mixed a reverse Fourier transformation is performed to return the mixed audio signals to the time domain.

The real time execution of the method of depends on a certain number of optimization parameters e.g. minimal gains prior probabilities etc. . These optimization parameters are estimated off line during the design process where they are optimized for achieving best perceptual sound quality using wide range of test recordings. For example a set of files comprising samples of clean speech are played through a speaker and recorded with ambient noise by a device. The files are processed offline and the perceptual quality is measured e.g. by MOS . The optimization is then run to determine parameter values which are stored in the program.

Once the optimization parameters are estimated they are stored in the device performing the method. Optimization of the optimization parameters can be achieved using a wide range of optimization programs. illustrates an example of one possible optimization method that can be used to determine e.g. optimize the optimization parameters e.g. minimal gains which determine the impact that each feature of a set has on the overall probability . In method a non constrained optimization equation is formed from a constrained equation comprising the unknown optimization parameters and additional constraints e.g. a punishing factor that gives boundaries of the permitted value of the non constrained optimization equation . The non constrained optimization equation can be enhanced using numerical methods e.g. gradient descent method to solve for the unknown optimization criteria e.g. inter alia minimal gains . More particularly method serves to enhance the front frequency domain audio signal X f to maximize the energy captured from the front direction e.g. 30 from the direction the front microphone is pointing and to enhance the rear frequency domain audio signal X f to maximize the energy captured from the rear direction e.g. 30 from the direction the rear microphone is pointing .

At the front frequency domain audio signal X f and the frequency domain audio signal X t are combined according to a plurality of unknown filter functions. The operation the front and rear filters perform the enhancement can be determined by information stored in a plurality of unknown filter functions e.g. unknown variables in vector form . The unknown filter functions are initially unknown but are determined e.g. enhanced during the enhancement process. Once the unknown filter functions are determined they become enhanced filter functions and information is extracted from them and used to operate filters according. For example the enhanced Yare Ydefined in relation to the filter functions e.g. known or unknown W W W Waccording to the following equations where n is the frame of the audio signal. Wand Ware filter functions related to the front filter and Wand Ware related to the rear filter . The filter functions W W W Ware vector comprising scalar values that relate to the operation of the front and rear filters and on the incoming signals X f and X f .

At a constraint equation is defined. The constraint equation is a mathematical relation comprising the unknown filter functions that can be enhanced e.g. optimized in a non constrained optimization equation to determine enhanced e.g. optimized values of the unknown filter functions. For example constraint equations Qand Qcan be defined as the ratio of the average energy captured in front e.g. 30 of the microphone to the average energy captured in rear e.g. 150 of the microphone as shown in the following equation for Q Q is the ratio of the average energy captured in the rear of the microphone to the average energy captured in the front 

At additional constraints are defined. The additional constraints can be defined according to the needs of the user. In one particular example the additional constraints require the maximums of the constrained equation to be searched for under the constraint of unit gain and zero phase shift.

A non constrained optimization equation is formed at . The non constrained optimization equation is formed from the constraint equation Q Q and the additional constraints. The unknown filter functions of the constrained equation are part of the non constrained optimization equation and once the equation is enhanced they provide the front and rear filters and with information to enhance e.g. optimize the suppression of the opposite channel e.g. signal .

At the non constrained optimization equation is enhanced and the filter functions W W W Ware extracted. The non constrained optimization equation can be enhanced using numerical methods e.g. gradient descent method . The extracted filter functions are utilized to act on the incoming signals X f and X f thereby resulting in the suppressed audio signal Y f which has as much as possible from the front audio signal and as little as possible from the rear audio signal and the suppressed audio signal Y f has as much as possible from the rear audio signal and as little as possible from the front audio signal.

At a root mean square RMS signal level for the front and rear suppressed audio signals are computed for a limited frequency band range. The RMS signal level provides an estimation of the level e.g. energy of the sound for the front and rear suppressed audio signals. A limited frequency band range is used because the lower part of the frequency band comprises too much noise energy while the higher part of the frequency band comprises too low speech energy. The limited frequency band range may be between 300 and 6500 Hz for example.

A noise floor level e.g. energy is estimated at . The noise floor level is a measure of an audio signal created from a sum of all noise sources and unwanted signals within a system. For example the noise floor level can be estimated according to the following equations 

At the ratio between the RMS signal level and the noise floor level is computed. The ratio is computed respectively for the front and rear suppressed audio signals Y f and Y f . The resultant ratio can be used to determine whether a captured signal is a voice or not a voice according to an activity flag criteria. For example an activity flag V can be set according to the following equation 

At the audio level e.g. energy difference between the front and rear suppressed audio signals are calculated for a current frame n. Differences between the front and the rear suppressed audio signals may occur due to manufacturing tolerances for example.

The audio level difference is used to update values in probability models by updating the parameters of the probability density function of speech and noise at . In general the probability density function uses probabilistic models with certain distribution which can be the same or different for the speech and noise signals for the difference between the front and the rear suppressed audio signals. In one example a non Gaussian distribution e.g. Gamma distribution or Laplacian distribution can be used as the probability density function for speech to correspond to the captured difference between the front and the rear suppressed audio signals. In such an example the difference between front and rear audio signals can be modeled according to a Gamma distribution or Laplace distribution while the noise can be modeled according to a Gaussian distribution. In a more sophisticated example a Gaussian distribution may be used for modeling noise but for speech if the level e.g. energy difference between the front and rear signals is greater than 0 a one sided Gamma distribution may be used for adjustment and if the level difference between the front and rear signals is less than 0 a Gaussian distribution may be used for adjustment. The same model can be applied for the opposite case just by changing the sign of the difference.

At the probability a suppressed audio signals is from a front or a rear source is calculated from the probability density functions. The probability distributions of the front signal the rear signal and the noise can be used to build a probabilistic model. The probabilistic model allows a probability that a signal is from a front or a rear source to be calculated given different L. For example the probability that a suppressed audio signal is from a front or a rear source can be given by 

The probabilities are time averaged at . Time averaging is performed using a two time constant approach similar to that used to determine the noise floor above. For example time averaging equations can be written as 

At a delay estimate is calculated. In one example the delay is estimated as the maximum of a Phase Transform PHAT weighted and band limited cross correlation function of the two input channels e.g. front and rear . The resultant delay estimate between front and rear frequency domain audio signals can be used to distinguish signals coming from the front rear and ambient noise. A difference in an average time of arrival is due to manufacturing tolerances such as phase mismatch in microphones or preamplifiers.

The delay estimate is modeled according to the probability density function of speech amplitude at . This adjustment compensates for difference in time caused by manufacturing tolerances. In one example a Gaussian probability density function can be used to adjust the delay estimate for the front signal the rear signal and noise.

At the probability a frequency domain audio signals is from a front or a rear source is calculated from the probability density functions. The probability distributions of the front signal the rear signal and the noise are used to build a probabilistic model. For example the probability that a frequency domain audio signal is from a front or a rear source can be given by 

The probabilities are time averaged at . As in the level difference approach of time averaging is performed using a two time constant approach similar to that used to determine the noise floor above. For example the time averaging equations can be written as 

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply one or more of the techniques presented herein. An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to one or more of the principles set forth herein. In one such embodiment the processor executable instructions may be configured to perform a method of such as the exemplary method of for example. In another such embodiment the processor executable instructions may be configured to implement a system configured to improve the relevance rank of web searches for a query. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

