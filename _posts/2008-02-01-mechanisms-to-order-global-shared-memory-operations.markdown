---

title: Mechanisms to order global shared memory operations
abstract: A method and data processing system for performing fence operations within a global shared memory (GSM) environment having a local task executing on a processor and providing GSM commands for processing by a host fabric interface (HFI) window that is allocated to the task. The HFI window has one or more registers for use during local fence operations. A first register tracks a first count of task-issued GSM commands, and a second register tracks a second count of GSM operations being processed by the HFI. The processing logic detects a locally-issued fence operation, and responds by performing a series of operations, including: automatically stopping the task from issuing additional GSM commands; monitoring for completion of all the task-issued GSM commands at the HFI; and triggering a resumption of issuance of GSM commands by the task when the completion of all previous task-issued GSM commands is registered by the HFI.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08214604&OS=08214604&RS=08214604
owner: International Business Machines Corporation
number: 08214604
owner_city: Armonk
owner_country: US
publication_date: 20080201
---
This invention was made with United States Government support under Agreement No. HR0011 07 9 0002 awarded by DARPA. The Government has certain rights in the invention.

The present application is related to the following co pending U.S. patent applications filed on even date herewith and incorporated herein by reference in their entirety 

The present invention generally relates to data processing systems and in particular to distributed data processing systems. Still more particularly the present invention relates to data processing systems configured to support execution of global shared memory GSM operations.

It is well known in the computer arts that greater computer system performance can be achieved by harnessing the processing power of multiple individual processing units. Multi processor MP computer systems can be designed with a number of different topologies of which various ones may be better suited for particular applications depending upon the performance requirements and software environment of each application. One common MP computer architecture is a symmetric multi processor SMP architecture in which multiple processing units each supported by a multi level cache hierarchy share a common pool of resources such as a system memory and input output I O subsystem which are often coupled to a shared system interconnect.

Although SMP computer systems permit the use of relatively simple inter processor communication and data sharing methodologies SMP computer systems have limited scalability. For example many SMP architectures suffer to a certain extent from bandwidth limitations especially at the system memory as the system scale increases.

An alternative MP computer system topology known as non uniform memory access NUMA has also been employed to addresses limitations to the scalability and expandability of SMP computer systems. A conventional NUMA computer system includes a switch or other global interconnect to which multiple nodes which can each be implemented as a small scale SMP system are connected. Processing units in the nodes enjoy relatively low access latencies for data contained in the local system memory of the processing units respective nodes but suffer significantly higher access latencies for data contained in the system memories in remote nodes. Thus access latencies to system memory are non uniform. Because each node has its own resources NUMA systems have potentially higher scalability than SMP systems.

Regardless of whether an SMP NUMA or other MP data processing system architecture is employed it is typical that each processing unit accesses data residing in memory mapped storage locations whether in physical system memory cache memory or another system resource by utilizing real addresses to identifying the storage locations of interest. An important characteristic of real addresses is that there is a unique real address for each memory mapped physical storage location.

Because the one to one correspondence between memory mapped physical storage locations and real addresses necessarily limits the number of storage locations that can be referenced by software the processing units of most commercial MP data processing systems employ memory virtualization to enlarge the number of addressable locations. In fact the size of the virtual memory address space can be orders of magnitude greater than the size of the real address space. Thus in a conventional systems processing units internally reference memory locations by the virtual or effective addresses and then perform virtual to real address translations often via one or more intermediate logical address spaces to access the physical memory locations identified by the real addresses.

Given the availability of the above MP systems one further development in data processing technology has been the introduction of parallel computing. With parallel computing multiple processor nodes are interconnected to each other via a system interconnect or fabric. These multiple processor nodes are then utilized to execute specific tasks which may be individual independent tasks or parts of a large job that is made up of multiple tasks. In these conventional MP systems with separate nodes connected to each other there is no convenient support for tasks associated with a single job to share parts of their address space across physical or logical partitions or nodes.

Shared application processing among different devices provides a very rudimentary solution to parallel processing. However with each of these systems each node operates independently of each other and requires access to the entire amount of resources virtual address space mapped to the local physical memory for processing any one job making it difficult to productively scale parallel computing to a large number of nodes.

Disclosed are a method and data processing system for performing fence operations within a global shared memory GSM environment having a local task executing on a processor and providing one or more GSM commands for processing by a host fabric interface HFI window allocated to the task. The HFI window has one or more registers for use during local fence operations. A first register tracks a first count of task issued GSM commands and a second register tracks a second count of GSM operations being processed by the HFI. The processing logic detects a locally issued fence operation and responsive to the detection of the locally issued fence operation performs a series of operations including automatically stopping the task from issuing additional GSM commands monitoring for completion of all the task issued GSM commands at the HFI and triggering a resumption of issuance of GSM commands by the task when the completion of all previous task issued GSM commands is registered by the HFI.

In another embodiment the HFI and task performs global fence operations within the GSM via local host fabric interface HFI windows allocated to each local task on a node. The HFI window has at least one registers allocated for use during global fence operations. The at least one register tracks a count of GSM operations issued by the local HFI to the network fabric. The HFI processing logic detects a globally visible fence operation and responds to the detection of the globally visible fence operation by performing a series of operations including automatically stopping the HFI window from issuing any additional GSM operations to the network fabric monitoring for completion of all the GSM operations issued by the HFI and triggering a resumption of issuance of GSM operations by the HFI when the completion of all previous HFI issued GSM operations is registered by the HFI.

In one embodiment the HFI processing logic also performs one or more of the functions of signaling the completion of all local GSM operations issued by the fabric monitoring for a global acknowledgement of the completion of the global fence operation generating and issuing the global acknowledgement to the network fabric when the local node is the originating node for the global fence operation and has received confirmation of a completion of all GSM operations from each other node in the GSM environment.

In yet another embodiment the HFI processing logic triggers the task to stop issuing GSM commands when the globally visible fence is detected. Both the task level and HFI level issuance of GSM commands and HFI level issuance of GSM operations then resumes when the global fence operation completes.

The above as well as additional objectives features and advantages of the present invention will become apparent in the following detailed written description.

The illustrative embodiments provide a method and data processing system for generating and processing global shared memory GSM operations that complete parallel job execution of multiple tasks on different physical nodes with distributed physical memory that is accessible via a single shared global address space GAS . Each physical node of the data processing system has a host fabric interface HFI which includes one or more HFI windows with each window assigned to at most one locally executing task of the parallel job although multiple windows may be assigned to a single task. The HFI includes processing logic for completing a plurality of operations that enable parallel job execution via the different tasks each of which maps only a portion of the effective addresses EAs of the shared GAS to the local real or physical memory of that node. Each executing task within a node is assigned a window within the local HFI. The window ensures that issued GSM operations of the local task are correctly tagged with the job ID as well as the correct target node and window identification at which the operation is supported i.e. the EA is memory mapped . The window also enables received GSM operations with valid EAs in the task to which the window is assigned to be processed when received from another task executing at another physical node while preventing processing of received operations that do not provide a valid EA to local memory mapping.

In the following detailed description of exemplary embodiments of the invention specific exemplary embodiments in which the invention may be practiced are described in sufficient detail to enable those skilled in the art to practice the invention and it is to be understood that other embodiments may be utilized and that logical architectural programmatic mechanical electrical and other changes may be made without departing from the spirit or scope of the present invention. The following detailed description is therefore not to be taken in a limiting sense and the scope of the present invention is defined only by the appended claims.

Within the descriptions of the figures similar elements are provided similar names and reference numerals as those of the previous figure s . Where a later figure utilizes the element in a different context or with different functionality the element is provided a different leading numeral representative of the figure number e.g 1xx for and 2xx for . The specific numerals assigned to the elements are provided solely to aid in the description and not meant to imply any limitations structural or functional on the invention.

It is understood that the use of specific component device and or parameter names are for example only and not meant to imply any limitations on the invention. The invention may thus be implemented with different nomenclature terminology utilized to describe the components devices parameters herein without limitation. Each term utilized herein is to be given its broadest interpretation given the context in which that terms is utilized. Specifically the following terms which are utilized herein are defined as follows 

As further described below implementation of the functional features of the invention is provided within computing nodes and involves use of a combination of hardware and several software level constructs. The presented figures illustrate both hardware and software components within an example GSM environment in which two physically separate nodes interconnected via respective HFIs and an interconnect provide a data processing system that executes a parallel job as individual tasks that utilize a GSM. The presentation herein of only two nodes i.e. an initiating sending node and a target receiving node is provided solely to simplify the description of the functionalities associated with GSM operations and the HFI. It is appreciated that this GSM functionality enables scaling to a much larger number of processing nodes within a single data processing system.

With specific reference now to the figures and in particular to there is illustrated a high level block diagram depicting a first view of an exemplary data processing system configured with two nodes connected via respective host fabric interfaces according to one illustrative embodiment of the invention and within which many of the functional features of the invention may be implemented. As shown data processing system includes multiple processing nodes A B collectively for processing data and instructions. Processing nodes are coupled via host fabric interface HFI to an interconnect fabric that supports data communication between processing nodes in accordance with one or more interconnect and or network protocols. Interconnect fabric may be implemented for example utilizing one or more buses switches and or networks. Any one of multiple mechanisms may be utilized by the HFI to communicate across the interconnect . For example and without limitation HFI may communicate via a proprietary protocol or an industry standard protocol such as Inifiniband Ethernet or IP Internet Protocol .

As utilized herein the term processing node or simply node is defined as the set of computing resources that form the domain of a coherent operating system OS image. For clarity it should be understood that depending on configuration a single physical system may include multiple nodes. The number of processing nodes deployed in a given system is implementation dependent and can vary widely for example from a few nodes to many thousand nodes.

Each processing node may be implemented for example as a single integrated circuit chip e.g. system on a chip SOC a multi chip module MCM or circuit board which contains one or more processing units e.g. processing units A B for processing instructions and data. Further each processing unit may concurrently execute one or more hardware threads of execution.

As shown each processing unit is supported by cache memory which contains one or more levels of in line or lookaside cache. As is known in the art cache memories provide processing units with low latency access to instructions and data received from source s within the same processing node and or remote processing node s . The processing units within each processing node are coupled to a local interconnect which may be implemented for example with one or more buses and or switches. Local interconnect is further coupled to HFI to support data communication between processing nodes A B.

As further illustrated in processing nodes typically include at least one memory controller which may be coupled to local interconnect to provide an interface to a respective physical system memory . In alternative embodiments of the invention one or more memory controllers can be coupled to interconnect fabric or directly to a processing unit rather than a local interconnect .

In addition to memory controller each processing unit also includes a memory management unit MMU to translate effective addresses to real or physical addresses. These MMUs perform EA to RA translations for tasks executing on processing nodes e.g. node A of data processing system . However the invention also uses a separate MMU which is coupled to the local interconnect . MMU performs EA to RA translations for operations received from tasks operating on remote processing nodes e.g. node B of data processing system . In one implementation of processor configurations MMU may be integrated with HFI so as to support EA to RA address translations required by HFI and or tasks utilizing HFI to complete GSM operations.

The HFI A and functional components thereof which are described below enables the task s executing on processing units to generate operations to access the physical memory B of other nodes that are executing other tasks of the parallel job using EAs from a shared global address space GAS and a GSM. Likewise HFI B enables access by the task s on initiating node A to access physical memory B when certain criteria are met. These criteria are described below with reference to

Those skilled in the art will appreciate that data processing system of can include many additional components which are not illustrated herein such as interconnect bridges non volatile storage ports for connection to networks or attached devices etc. Because such additional components are not necessary for an understanding of the present invention they are not illustrated in or B or discussed further herein.

The above described physical representations of nodes of an example data processing systems with HFIs supports the distribution of tasks associated with a parallel job across multiple nodes within a larger system with a GSM. illustrates a high level view of processing multiple tasks of a parallel job within an exemplary software environment for data processing system in accordance with one embodiment. In the exemplary embodiment data processing system includes at least two physical systems and which respectively provide processing nodes and of coupled by interconnect fabric . In the depicted embodiment each physical system includes at least two concurrent nodes. That is physical system includes a first node corresponding to operating system and a second node corresponding to operating system . Similarly physical system includes a first node corresponding to operating system and a second node corresponding to operating system . The operating systems concurrently executing within each physical system may be homogeneous or heterogeneous. Notably for simplicity only one node of each physical system is utilized in the descriptions of the GSM and HFI functions herein although the features of the invention are fully applicable to tasks executing on any one of multiple nodes on a single physical system accessing physical memory of other nodes on other physical system s .

Each physical system may further include an instance of a hypervisor also referred to as a Virtual Machine Monitor VMM . Hypervisor is a program that manages the full virtualization or para virtualization of the resources of physical system and serves as an operating system supervisor. As such hypervisor governs the creation and destruction of nodes and the allocation of the resources of the physical system between nodes.

In accordance with the present invention the execution of parallel jobs in data processing system is facilitated by the implementation of a new shared memory paradigm referred to herein as global shared memory GSM which enables multiple nodes executing tasks of a parallel job to access a shared effective address space referred to herein as a global address space GAS .

Thus under the GSM model employed by the present invention data processing system can execute multiple different types of tasks. First data processing system can execute conventional individual Tasks C F G K L P Q T V and W which are independently executed under operating systems . Second data processing system can execute parallel jobs such as Job with tasks that are confined to a single node. That is Tasks D and E are executed within the node corresponding to operating system of physical system and can coherently share memory. Third data processing system can execute parallel jobs such as Job that span multiple nodes and even multiple physical systems . For example in the depicted operating scenario Tasks A and B of Job execute on operating system Tasks H and J of Job execute on operating system Tasks M and N of Job execute on operating system and Tasks R and S of Job execute on operating system . As is illustrated tasks of multiple different jobs e.g. Job and Job are permitted to concurrently execute within a single node.

With standard task to task operation tasks running on a same node i.e. tasks homed on the same physical device do not need to utilize the HFI and resolve EA to RA mapping beyond the standard page table. The HFI and or MMU components are thus not utilized when exchanging operations across tasks on the same physical node. Where tasks are running on different physical nodes however the use of the MMU and HFI is required to enable correct EA to RA translations for tasks homed at the specific node when issuing and or receiving GSM operations.

Additional applications can optionally be executed under operating systems to facilitate the creation and execution of jobs. For example depicts a job management program such as LoadLeveler executing under operating system and a runtime environment such as Parallel Operating Environment POE executing under operating system . LoadLeveler and Parallel Operating Environment are both commercially available products available from International Business Machines IBM Corporation of Armonk N.Y. LoadLeveler and POE can be utilized as a convenience to the user but are not required. However the described embodiment provides for the availability of a privileged program to both bootstrap non privileged executables on the cluster nodes and to enable the non privileged executables to request and use node resources.

In the following descriptions headings or section labels are provided to separate functional descriptions of portions of the invention provided in specific sections. These headings are provided to enable better flow in the presentation of the illustrative embodiments and are not meant to imply any limitation on the invention or with respect to any of the general functions described within a particular section. Material presented in any one section may be applicable to a next section and vice versa.

The method for generating and distributing the tasks of a job e.g. Job illustrated in are described in . The executable of the program is supplied to the job management program with user supplied execution attributes in a job command file. These attributes include the number of nodes on which the job needs to execute. The job management program generates a job ID that is unique system wide and selects a set of nodes in the system on which to execute the parallel job. The job management program then invokes the runtime system for parallel jobs e.g. POE . The runtime system in turn spawns the user executable on the set of nodes that the job management program allocated for the parallel job and the runtime system sets up state that permits each task to determine the task s unique rank ordering within the parallel job. For example in a job with N tasks exactly one task will have the rank order i where 0

In order to complete the processing by the HFI and other functional features of the invention a system level establishment or system allocation of the global shared memory is required. illustrate two embodiments of assigning tasks to address spaces within the global address space during setup establishment of the GSM environment. The complete description of this process is presented within co pending patent applications Ser. Nos. 11 958 668 and or 11 958 956. Relevant content of those applications are incorporated herein by reference.

During initialization of the tasks of a parallel job each task issues a system call to set up the global address space. In addition to reserving effective address space the system call also accomplishes two additional tasks. First the call initializes a HFI window hardware structure in preparation for usage in the global shared memory model. Second the system call creates a send FIFO and a receive FIFO which allow the task to send active messages to one another via the node s HFI.

Once the global address space has been initialized individual tasks can allocate physical memory that can be globally addressed by all tasks of the job. Memory allocation on each task is achieved through a second system call which specifies the amount of memory to be allocated as well as the effective address within the already reserved global address space GAS where the allocated memory must appear. All allocations are done locally with respect to the task issuing the second system call. Once allocation is completed all threads within the locally executed task can access the allocated memory using load and store instructions.

In order to use the GSM feature each of the group of tasks for the job has to communicate the results of the first system call and co ordinate amongst each other the arguments to the second system call invocation. described below illustrates the method by which these inter task coordination of system calls are completed.

Referring now to there is depicted a representation of an exemplary effective address space of tasks of a parallel job following the establishment of the GAS. In the exemplary embodiment parallel job comprising ten tasks labeled Task though Task . Each of the ten tasks is allocated a respective one of effective address EA spaces A by its operating system . These effective address spaces are allocated to each task independent of the existence of the other tasks. After each task issues an initialization system call a portion of the effective address EA space on that task is reserved for use exclusively for performing global shared memory GSM allocations as illustrated at reference numerals A 

With reference now to there is illustrated a representation of an exemplary effective address space of tasks comprising a parallel job following the allocation of memory in the GAS A . In the depicted example the allocation for a shared array X distributed across the GAS A is shown. In particular region A is allocated to X 0 X 9 in GAS A of Task region B is allocated to X 10 X 19 in GAS B of Task and so on until finally X 90 X 99 is allocated in region of GAS . The portions of X allocated to the GAS of a task are homed on the node executing that task. Physical memory A is further allocated on each task s node to back the portion of X homed on that node.

For the allocations in the operating system of the node on which each task executes only allocates backing memory for those portions of the task global address space that are homed on that node. Elements through in each figure show how the physical memory may be allocated to store the portion of the array x homed at that node. As shown for tasks and the allocation in takes seven physical pages while that in takes six physical pages. Every access to a shared variable in a GSM application must be translated into a tuple of the form where EA is the effective address on task T where the location is homed.

Practicality in data structure placement is a very important consideration since practicality can have a huge impact on the amount of physical memory required to support the allocation. For instance if the programmer specifies that the shared array x should be distributed in a cyclic manner an extensive amount of fragmentation and wasted physical memory will result if the array were to be allocated such that the array can be contiguously addressed within the global address space. For such an allocation savings in the amount of physical memory required to back up the homed portions of x would be achieved by compacting the data structure. The GSM feature described herein thus provides applications with considerable flexibility in deciding how to map global data structures. As B show simplicity in determining where a shared element is homed can be traded off against the fragmentation costs of the chosen mapping scheme.

Using the above allocation of GAS to tasks of a job the embodiments of the invention enables a job to be scaled across a large number of nodes and permits applications to globally share as large a portion of the application s effective address space as permitted by the operating system on each node. Also no restrictions are imposed on where the tasks of a job must execute and tasks belonging to multiple jobs are allowed to execute concurrently on the same node.

Referring now to there is illustrated another more detailed view of the data processing system of with the hardware and software constructs required for generation transmission receipt and processing of GSM operations across physical nodes within the GSM environment. First computer node initiating or sending node and second computer node target or receiving node includes HFI respectively. HFI is a hardware construct that sits on the coherent fabric within a processor chip. Each HFI provides one or more windows and see allocated to a particular executing task of a parallel job.

When an executing task of a parallel job issues an initialization system call the operating system OS of that node attempts to establish a dedicated window on the HFI for that task. If the operation succeeds a portion of the allocated HFI window is first mapped into the task s address space. The memory mapped IO MMIO space includes a command area and FIFO pointers. After the appropriate portion of the task s effective address space is reserved i.e. mapped to the physical memory the operating system sets up the window to point to the page table for that task so that effective addresses within inbound i.e. from the interconnect GSM commands can be translated.

In processing system first node represents the sending initiating node and is illustrated with send FIFO within memory that is accessible via a MMIO . Second node represents the receiving or target node and is illustrated with receive FIFO within its memory . It is understood that even though an asymmetric view is shown both processing nodes and are similarly configured having both send FIFO and receive FIFO and each node is capable of performing both send and receive functions. Within processing system the HFI is the primary hardware element that manages access to the interconnect . The interconnect is generally represented by links routing switch and a series of switch elements A B and . HFI A thus enables a task executing on sending node to send GSM operations with a destination or target identified by the job ID node ID and window ID to a receiving target node

As further illustrated in processing nodes include at least one memory controller which is coupled to local fabric to provide an interface between HFI and respective physical system memory DIMMs . Processing nodes also include MMU which is coupled to fabric bus . MMU may be a part of i.e. integrated into HFI and provides the EA to RA translation required for GSM operation processing by the HFI . Coupled to fabric bus is processor cache which is in turn connected to processing units of the central processor. Also illustrated is form the perspective of the executing task a view of the mapping of EAs to physical memory space allocated to the executing task. Within this virtual view of the physical memory is a send FIFO which is used to store commands and data generated by the task prior to being processed by HFI to generate GSM operations. Also illustrated is HFI doorbell which is a mechanism that tracks the number of operations within send FIFO and is utilized to alert the HFI when to retrieve operations from the send FIFO . Similarly receive FIFO of target node is located within physical memory in which an EA mapping location is also identified for reference.

The HFI window and provide a task level view into the node s hardware that enables GSM commands to be launched with regards to a particular task s effective address space and for the effective addresses EA contained within commands to be appropriately translated. HFI windows are basic system constructs used for GSM operations. Each HFI may contain multiple windows and each window is allocated to a single task of the one or more tasks executing on the computer node .

Further functional characteristics of example HFI windows are illustrated by which is now described. As shown by HFI consists of a plurality of windows window through windowN of which HFI window is selected as the example window. Each HFI has a fixed number of windows each of which can belong to exactly one task although more than one window may be assigned to a task. The window assigned to a task is used by the HFI to both launch GSM messages originating from the task as well as handle incoming messages accessing that task s effective address space. HFI window is accessible by task generated commands which may be generated at different functional levels including by a user an OS and or a hypervisor .

HFI window consists of a plurality of functional entries such as command entries credentials entry an address translation entry and data structures used by the HFI to control message transmission and reception. Specifically as illustrated window comprises the following entries without limitation HFI command count send FIFO EA SEND RDMA FIFO EA receive FIFO EA epoch vector EA credentials and fence counters . In the illustrative embodiment credentials includes the job ID also referred to herein as a job key process ID LPAR logical partition ID and EA key. The HFI references the credentials to correctly authenticate an incoming GSM transaction as being authorized to perform an operation on the associated task s effective address space. It is appreciated that the different components of credentials may also be represented with its own entry within HFI window . Each of the above entries are registers providing a value of a memory location at which the named entry is stored or at which the named entry begins i.e. a start location within the effective address space of the task. These effective addresses are translated by MMU into corresponding real addresses that are homed within the physical memory . HFI forwards one of the effective addresses of Window contents to MMU and MMU translates the effective address into a real address corresponding to the physical memory to which the EAs of the task identified by the credentials are mapped.

HFI window also comprises one or more fence counters for tracking completion of GSM operations during a local fence operation and a global fence operation. The fence counters referenced by the EAs in map to fence counter within the real memory location assigned to the task. In order to assist with local task issued fence operations the RA space assigned to the task also includes a send op counter to track the completion of task issued commands which are initially stored in send FIFO before passing to HFI window for processing.

Thus as further illustrated send FIFO EA holds the start effective address for the task s send FIFO which address can be translated by MMU to point to the start real address of send FIFO in physical memory . Likewise receive FIFO EA holds the start EA of the task s receive FIFO which address is translated by MMU and points to the start address in physical memory of the receive FIFO of the task. The SEND RDMA FIFO EA and epoch vector EA similarly can be translated by MMU to point to the start real addresses of the SEND RDMA FIFO and Epoch vector respectively. Note that while the send FIFO and receive FIFO may be contiguous in the effective address space of the task to which that window corresponds these FIFOs may be discontiguous in real physical memory .

Each HFI window contains key resources including the pointer to the address translation tables that are used to resolve the effective address with respect to a particular task into a real address. The window number within the HFI that is allocated for the GSM initialization operation is returned back to the user as an opaque handle which may contain an encoding embedding of the node and window number along with the effective address where the global address space is reserved within that task s effective address space. The language run time takes on the responsibility for communicating each task s window identity to all other tasks that wish to issue GSM commands to that task. If a task has multiple threads of control atomicity to the HFI window has to be ensured either through normal intra task locking primitives or by assigning each thread its own distinct HFI window. Finally HFI performance counters for all traffic based on that window are also mapped into the task s address space. This permits the task to easily monitor statistics on the interconnect traffic.

HFI windows may be shared amongst one or more logical partitions. If a single node is partitioned the operating system running on a partition may only have access to a subset of the total number of supported windows. The OS may further reserve a subset of these windows for kernel subsystems such as the IP device driver. The remaining windows may be available for use by the tasks executing within that partition.

When a window is allocated on the HFI the operating system tags the window with the identity of the job to which the task belongs. During issuance of GSM operations all outgoing packets are automatically tagged by the HFI with the job id. Outgoing packets also specify a particular window on the destination target node s HFI B in whose context the GSM effective address must be translated. The HFI compares the job ID contained within the GSM packet against the job id contained within the window. If the job ID s do not match the packet is silently discarded. Statistics that count such packets can be used to gently dissuade system users from either unintentionally or maliciously flooding the system with such packets.

Thus unauthorized access to a task s effective address space is not permitted during the course of global shared memory operations. A task is able to send a GSM operation to any task belonging to any job running anywhere in the entire system. However the HFI will perform the GSM operations on the targeted task s effective address space if and only if an incoming GSM command belongs to the same job as the task whose address space the command manipulates. A further granulation of job IDs is also possible whereby a task can give specific authorization to only a subset of the tasks executing within the job. This can be done by a subset of the tasks requesting a different job ID to be associated to them causing that job ID to be installed into the HFI window associated with these tasks.

In order to fully appreciate the functionality of each of the above listed entries and the entries use during GSM operation to retrieve values from within physical memory a description of the process of assigning a window to support a task of a parallel job is now provided. This process is illustrated by which is now described. Generally is a flow chart of the method of initiating a job within the GSM environment and allocating the various tasks of the job to specific nodes and assigning a window within the HFI of those nodes to a task according to one embodiment of the invention.

The process begins at block and proceeds to block at which an application generates and issues a GSM initialization operation to launch a parallel job. Initialization of the job leads to allocation of a plurality of tasks to certain nodes across the distributed network as shown at block . At block mapping of these nodes with allocated tasks is generated and maintained at each node. At each local node with one of these tasks before using global shared memory the task establishes or is assigned a dedicated window on the HFI for that task as provided at block . A portion of the allocated HFI window including a command area and FIFO pointers is first mapped into the tasks effective address EA space as shown at block . The mapping of EA to RA for the task is provided to the MMU for later use by the HFI during GSM processing. Additionally the unique job key or job ID is embedded into the HFI window assigned to the task.

At block the HFI window assignments for the various tasks are linked to a generated node mapping for the job and then at block the runtime library communicates task window identity to other tasks in the job. This enables each task to be aware of the location of the other tasks and permits subsequent software operations that allocate memory to determine on which node a certain variable allocated in the global address space should be homed. After the appropriate portion of the task s effective address space is reserved the operating system sets up the HFI window pointer s page table pointer to point to the page table for that task so that effective addresses within inbound i.e. from the interconnect GSM commands can be translated at the node as indicated at block . Send and receive pointers are also established within the HFI window that are translated to specific physical memory locations by MMU .

At decision block the OS determines if the task has multiple threads. When a task has multiple threads of control the OS ensures atomicity to the HFI window through normal intra task locking primitives as shown by block . Alternatively a task may request a separate window for each of its threads. At block the window number within the HFI that is allocated during the GSM initialization operation is returned back to the user space task as an opaque handle along with the effective address where the global address space is reserved within that task s effective address space. Finally at block HFI performance counters for all traffic based on that window are also mapped into the tasks effective address space. This setup of performance counters permits the task to easily monitor statistics on the interconnect traffic. The process then ends at termination block .

After a global address space is established and memory allocated as generally described above each task is able to perform the following basic operations 1 Reads or gets to memory 2 Writes or puts to memory and 3 Restricted atomic operations such as those belonging to the set ADD AND OR XOR COMPARE AND SWAP FETCH AND OP. Ultimately all GSM operations are relayed by interconnect messages to and from the nodes where a memory location is homed. The basic GSM operations listed above therefore need to be converted into interconnect messages that are processed at the appropriate home node. Furthermore any response messages also need to also be processed at the sending node i.e. the node receiving a response from a target node for a previously sent GSM operation . The HFI and specifically the HFI window allocated to the particular task is utilized to provide the hardware support for these and other GSM related functions. GSM commands are transmitted by a task to the HFI by simply writing to the memory mapped address space.

The below described embodiments enables different tasks in a parallel job to perform operations efficiently on the global address space of the parallel job by using a HFI to issue GSM operations across the fabric of the GSM environment. Among the operations that are performed are reads writes certain types of atomic operations and higher level operations that can be constructed using one or more of these basic operations. Within GSM task execution all operations refer to effective addresses within the constituent tasks of the GSM job. GSM operations are non coherent can be issued by an application from user space code and have a simple API application programming interface that they can be used by the compiler library or end user.

In one embodiment GSM task execution does not provide support load store access to a location within the global address space that is homed on a remote node. That is when a particular global address space location is homed on example target node a task executing on a different node is not able to access the location using a load or store instruction. Rather with GSM task execution a GSM operation such as a read write or atomic operation must be employed in order to access the location. However the executing task utilizes load and store instructions from the PowerPC ISA instruction set architecture to access GSM locations that are homed on the node where the task is executing.

Turning now to which provide flow charts illustrating the methods by which the HFI and the HFI window are utilized to enable GSM operations across different physical nodes of a processing system. Although the methods illustrated in may be described with reference to components shown in it should be understood that this is merely for convenience and alternative components and or configurations thereof can be employed when implementing the various methods. Key portions of the methods may be completed by the task executing within data processing system DPS and controlling access to a GSM location of on a target node and the methods are thus described from the perspective of either both the executing task and or the HFI and HFI window. For example referring to a GSM operation is initiated by a task on node A to a location that is homed in the effective address space of a task on node C

GSM commands issued by a task are in the form of operations on locations within another task s effective address space. Consequently the effective address embedded in a GSM command is meaningless without knowing the specific task with reference to which the effective address must be translated into a real address. The HFI evaluates received GSM commands from a local send FIFO before generating the corresponding GSM message packets . HFI and HFI window functionality provides the ability to launch GSM commands i.e. interconnect messages through user space commands.

In the following description the terms GSM packets GSM messages GSM operations and GSM data are interchangeably utilized to refer to any component that is transmitted from a first HFI window of an initiating task to a network fabric and or is received from the network fabric at a second HFI window of a target task. GSM command refers simply to any task issued command that is intended to be processed by the HFI and issued to the network fabric. The task also provides non GSM or standard commands that are executed on the local processing node.

Referring to as part of the command structure the task on node A creates the GSM command. The command structure includes the identifier ID of the destination target node and the window on the destination node against which the message must be examined. Specifying the window on the destination node versus specifying the task executing on the destination node simplifies the hardware implementation. For put operations that involve long memory transfers the task also includes the start effective address and range information as part of the command.

Returning to the flow chart as provided at block the task writes the command describing the operation into the send FIFO. These commands accumulate in initiating task s cache FIFO as the commands are created. At block the task s initiator triggers requests the HFI transmit the stored commands by updating the command count location register which is physically resident on the HFI window. As previously described the command count location is memory mapped into the tasks address space of physical memory. This action constitutes ringing the HFI doorbell.

Referring again to as the task creates GSM commands the task keeps updating the number of operations that need to be handled by the HFI. Commands are created in the send FIFO which is backed by local physical memory and can be resident in the cache . The send FIFO resides in physical memory but is mapped into the task s address space and is cacheable by the task. After assembling one or more commands the task writes the number of assembled commands to the HFI window door bell location . In one embodiment the door bell location is physically resident on the HFI but is memory mapped into the task s effective address space. The commands at the doorbell location are retrieved by the HFI and utilized by the HFI to generate a GSM packet containing GSM operations data or messages that the HFI transmits to a target task via the network fabric.

In order to transmit a GSM operation the HFI needs certain buffer resources. As these buffer resources become available the HFI retrieves commands from the send FIFO. Thus at decision block HFI logic determines if HFI resources are available to transmit the command using the task assigned window. When HFI resources are not currently available the task may continue to place new commands if any in the send FIFO as shown at block . However if there are HFI resources available the HFI creates packet headers from the command information and generates the GSM packets as shown at block . For long put operations the HFI also translates the start address and fetches DMAs data from the local node. The retrieved data is used to create a GSM message. HFI data structures in the window assigned to the task are also referenced updated. The HFI window tags the job ID of the task to the GSM message as shown at block . The job ID is maintained in the send window and is included as part of every GSM message issued by the HFI window. At block the HFI routes the message as GSM packets through the interconnect switch. Then the process of generating the GSM packets using the HFI ends at termination block .

The HFI identifies the window associated with the task generating the commands placed in the task s send FIFO as shown at block . The HFI logic then determines at block if the command is a legal GSM command. A legal GSM command includes the required target node and window identifiers and an operation that is supported via GSM processing e.g. a get put or atomic operation and any other parameter s for generating a GSM packet. When the command is not a legal GSM command the HFI window discards the command as not supported by GSM as provided at block and the HFI window provides an appropriate response notification to the executing task at block .

However when the command is legal the HFI completes a series of operations to generate the GSM packets from the command as indicated at block . Among these operations performed by the HFI are one or more of a creating a packet header from the command information b potentially fetching via DMAs data from the local node and c generating the packets. The HFI window then tags the packet with the job ID at block and the HFI window transmits the packets over the interconnect at block . The process ends at termination block . In a system where the individual nodes execute operating systems that do not trust one another the installed job ID can also be encrypted or hashed to make it tamperproof.

In order to appreciate the generation and issuing of a GSM message i.e. a GSM operation transmitted via multiple GSM packets with sequence number and count tuples an example GSM command and corresponding example GSM packet are illustrated by . The GSM command includes without limitation the following entries shown without regard to actual order an operation type which defines whether the operation is an atomic operation or a GET or PUT operation for example the source effective address EA of the operation which is mapped to the memory of the initiating local task the target effective address EA which is mapped to a real address in the local memory of the target task the number of memory locations affected by the GSM operation immediate data or the EA of the locally stored data and flags indicating whether and or what type of notification the receipt completion of the operation requires. As shown other entries may also be included within the command and these entries are utilized to create corresponding entries within the GSM operation generated by the HFI.

When the message reaches the destination hardware support provided by PERCS retrieves the data and sends the response back as a message. The response message is also handled by the HFI of the initiating node causing the retrieved data to be written to the memory location of the initiating task. On the receive side of a GSM operation the job ID in the packet is compared with the job ID in the target window. If the IDs match the GSM command specified in the message is carried out.

For get operations the effective address is translated on the target HFI through the use of MMU . Data is fetched from the memory location of the translated real address and the data is embedded into a composed message and sent back to the initiating task node . For put operations the appended data is written to the physical address obtained by translating the specified effective address where the data is to be written at the target node. In one implementation GSM atomic operations are carried out by the memory controller on board the processor chip such as a Power7 chip. The processor s internal bus is designed to support special transaction types for the atomic operations that are initiated by the HFI.

In one embodiment the HFI may also evaluate the window and or task ID to ensure that the packet has arrived at the correct destination node. As with the job ID the message is discarded if the window ID information does not match that of the target window that is specified in the message. Also in one embodiment a threshold number of false requests may be established for each HFI window. When the number of received GSM operations that do not have the correct jobID meets of surpasses the pre established threshold number an error condition is registered which triggers issuance of an administrative notification.

Returning to decision block if the job IDs match the HFI determines at decision block if a translation exists for the EA within the page table pointed to by the page table pointer within the HFI window. The translation is provided by MMU which is accessed by the HFI to complete the check for whether the EA to RA translation is homed on the local node. When no valid translation exists for the EA received in the message the local task associated with the window is interrupted as shown at block . Several alternatives are possible. One alternative is to send an error response to the initiating node which could then send a non GSM message to request a valid translation to be installed. Another alternative is for the interrupted task to install the required translation in turn sending an error to the initiating task if the requested mapping does not exist on the target task. When a translation does exist within the page table the HFI via the page table translates the effective address in the received message into the corresponding real address as shown at block . The translation is performed by referencing the page table that is pointed to within the HFI window. When the address is successfully translated the operation specified by the message is carried out performed as shown at block .

The operation is first presented on the internal fabric bus in the chip. The memory controller performs the operation on the memory DIMMs. If the locations being modified reside on any cache the cache locations are updated in place with the contents being injected into the cache. At block the HFI window via the task generates and transmits a response packet if such a response is required. The HFI also writes notifications to the receive FIFO either writing the notification to memory or injecting the notification into the cache as shown at block . These notifications are visible in the target task s effective address space. The target task can also access the locations that were modified by directly accessing the appropriate location in the target task s address space.

The message flows are similar for GSM atomic operations and GSM get operations. In an atomic operation the memory controller can perform the atomic operation. Cache injection does not take place for atomic operations. For a get operation the HFI does not perform the DMA operation and instead retrieves DMAs data requested by the operation. The retrieved data is assembled into a message that is then sent back to the initiating node. The HFI on the requester performs the functions required to store the retrieved data into the initiating task s effective address space.

As described above a GSM job comprises a large number of tasks spread across multiple nodes that are connected via the network fabric. With this configuration of the nodes during normal execution of the GSM job any task may issue a GSM operation to the network fabric in any sequence and at any time. Further the network fabric provides a large number of different routes between any two nodes in the distributed data processing system. That is each HFI is able to utilize more than one route to send messages between any pair of nodes. Consequently there is no intrinsic ordering guarantee amongst messages exchanged between two tasks. While certain programming models have very lax ordering and coherence requirements other programming models such as global arrays have strict requirements. Also even within some single programming environments such as UPC these ordering and coherence requirements may differ depending on how the program is executed or even compiled.

Thus one embodiment provides message ordering mechanisms to enforce message ordering amongst the distributed tasks. Specifically as described below two forms of fences i.e. barrier operations are utilized to enforce ordering in the GSM environment. The first fence is a locally performed fence issued by the local task and performed by the local HFI which ensures that all previously issued GSM operations commands have been locally performed i.e. changes to local memory will not affect these operations before completion of the fence itself. The second fence is a globally visible fence which ensures that all previously issued GSM operations have been globally performed before completion of the fence itself. The program can continue execution only after the fence returns.

A decision is made at block depending on whether the HFI retrieves a command from the send FIFO to generate a corresponding GSM operation for the task If the HFI retrieves a command from the send FIFO to generate a GSM operation the send operation counter is decremented as shown at block . Also at block HFI increments HFI processing counter fence counter .

When the HFI has previously retrieved a GSM command and after incrementing the fence counter and decrementing the send operation counter the process moves to block at which a next determination is made whether the HFI window has completed processing of a GSM operation of a task. If the HFI has begun but not yet completed processing of a GSM operation of the task the HFI maintains the processing counter at the current number. In an alternate embodiment however a third counter is utilized to track in progress operations such as operations that are issued to the network fabric but for which no acknowledgment of completion has been received. For simplicity in the present description the number of operations that has been received from the send FIFO and are not yet completed are tracked by a single counter regardless of whether the HFI has processed the operation and is simply awaiting confirmation. Returning to the flow chart if the HFI has completed local processing of the GSM operation the HFI decrements the HFI processing counter at block . The GSM message issues and as shown at block the HFI increments the waiting for notification counter. A determination is made at block whether a made visible at target notification is received by the HFI. The made visible at target notification indicates a receipt of the operation by the target node i.e. the operation has been performed by the HFI window of the target task . When the made visible at target notification is received the waiting for notification counter is decremented as shown at block . The process for updating the various counters repeats until the task and HFI completes all pending operations and or the node is removed from processing tasks of the job.

The locally performed fence is provided by the HFI which maintains two counters that physically reside on the HFI window but are memory mapped into the associated task s effective address space. described above illustrates these HFI fence counters . In one embodiment a first counter of the HFI fence counters contains the number of GSM operations that the task has asked the HFI to perform but which the HFI has not yet picked up from the send FIFO . The second counter contains the number of GSM operations that have been picked up by the HFI but which have not yet been completed. Non completion of a GSM operation by the HFI refers to any stage of processing of operation until further operations by the task will not affect GSM operations that have yet to be remotely performed. Depending on the implementation final completion may entail a receipt of an acknowledgment of the completion receipt from the target node or b receipt and final MMU processing of data returned by the operation or c copying the GSM operation and relevant data into a dedicated buffer where it will lie undisturbed until the specified operation is performed.

A locally performed fence blocks the task from issuing new commands to the send FIFO and or the HFI from processing any more task issued GSM commands until both counters go down to zero. In a multi threaded task the threads in the multi threaded task can independently block further operations or the threads may co ordinate and pick one designated thread to complete the fence operation.

The process of begins at block and proceeds to block at which processing of GSM operations is initiated and performed by the task and HFI. At decision block processing logic processing at the local task determines whether a local fence e.g. synchronization or barrier operation issued by the local task has been detected. If a local fence operation has been issued the task is naturally prevented from issuing new commands to the send FIFO for HFI processing as shown at block since the fence is currently executing .

Notably this local fence not only stops further GSM operations from being issued but also other locally performed operations i.e. non GSM operations . Thus the local fence operation is synchronous such that no further operations GSM or otherwise e.g. loads and stores are permitted to be executed by the program on the local node. Additionally the local fence is not queued inside the send FIFO for subsequent processing by the HFI. The local fence actions are performed by the task itself.

While the task executes the local fence operation the previously issued GSM commands are allowed to be processed by the HFI until the send FIFO is empty or the operations have completed processing at the HFI. At decision block the task checks whether the value of both counters send op counter and HFI processing counter equal zero indicating that there are no task issued commands waiting for processing by the HFI and no unfinished GSM operations being processed at the HFI. If the counters are not both equal to zero the suspension of issuance of new GSM commands by the task continues . However once this condition counters 0 is registered the process moves to block at which point the local fence operation returns control back to the task indicating completion of the fence and the task can resume executing other operations including placing new GSM commands in the send FIFO. According to one embodiment in order to enable this resumption of command issuance certain pre specified conditions must be met in addition to the counters both equaling zero at . These conditions may involve successful completion of certain operations within the local node.

With the globally visible fence the mechanism implements the globally visible fence by blocking new operations from being issued by the local HFI until every previously issued GSM operation has received a made visible at target notification. In one implementation the language run time library implements the globally visible fence utilizing the software guaranteed reliability model. In the following description the implementation of the globally visible fence is explained with reference to a uni threaded task.

Turning now to the process begins at block and proceeds to block at which HFI processing and issuing of GSM operations to the fabric is initiated and or performed by the HFI. At decision block HFI processing logic determines whether a global fence e.g. synchronization or barrier operation issued by a local task to stop network level issuing of GSM operations has been detected. The globally visible fence may be locally generated and issued to the GSM environment or may be generated from the external environment and received on the network fabric by the HFI window of the tasks within the job to which the global fence is directed. However global fences are only valid from the point of view of the issuing task. In other words the global fence ensures that all GSM operations issued previous to before the global fence are globally performed before the fence operation is determined to have completed. Thus the global fence does not return to the issuing task until all previously issued GSM operations are globally performed. During the performance of the global fence until completion thereof the task does not issue any more GSM operations. If a global fence operation has been detected the task naturally stops issuing new GSM operations packets to the network fabric as shown at block .

At block the HFI tracks the completion of all previously issued GSM operations on the fabric. The completion of all previously issued GSM operations is determined at decision block by receipt of the corresponding made visible at target notifications for all issued operations as indicated by a zero in the value of the waiting for notification counter. When all previously issued GSM operations have received made visible at target notifications the process transitions to block at which point the global fence completes. The task is then free to resume issuing GSM operations to the HFI.

In a multi threaded task the threads in the multi threaded task can independently block further operations or the threads may co ordinate and pick one designated thread to complete the fence operation.

Thus the above embodiments provide a method and data processing system for performing global fence operations within a global shared memory GSM environment having a plurality of local tasks of a single job distributed across multiple nodes connected within a GSM environment via local host fabric interface HFI windows allocated to each local task on a node. The HFI window has a register allocated for use during global fence operations. The register tracks a count of GSM operations issued by the local HFI to the network fabric. The HFI processing logic detects a globally visible fence operation and responds by performing a series of operations including automatically stopping the HFI window from issuing any additional GSM operations to the network fabric monitoring for completion of all previously issued GSM operations and triggering a resumption of issuance of GSM operations by the HFI when completion of all previous HFI issued GSM operations is registered by the HFI.

In each of the flow charts above one or more of the methods may be embodied in a computer readable medium containing computer readable code such that a series of steps are performed when the computer readable code is executed on a computing device. In some implementations certain steps of the methods are combined performed simultaneously or in a different order or perhaps omitted without deviating from the spirit and scope of the invention. Thus while the method steps are described and illustrated in a particular sequence use of a specific sequence of steps is not meant to imply any limitations on the invention. Changes may be made with regards to the sequence of steps without departing from the spirit or scope of the present invention. Use of a particular sequence is therefore not to be taken in a limiting sense and the scope of the present invention is defined only by the appended claims.

As will be further appreciated the processes in embodiments of the present invention may be implemented using any combination of software firmware or hardware. As a preparatory step to practicing the invention in software the programming code whether software or firmware will typically be stored in one or more machine readable storage mediums such as fixed hard drives diskettes optical disks magnetic tape semiconductor memories such as ROMs PROMs etc. thereby making an article of manufacture in accordance with the invention. The article of manufacture containing the programming code is used by either executing the code directly from the storage device by copying the code from the storage device into another storage device such as a hard disk RAM etc. or by transmitting the code for remote execution using transmission type media such as digital and analog communication links. The methods of the invention may be practiced by combining one or more machine readable storage devices containing the code according to the present invention with appropriate processing hardware to execute the code contained therein. An apparatus for practicing the invention could be one or more processing devices and storage systems containing or having network access to program s coded in accordance with the invention.

Thus it is important that while an illustrative embodiment of the present invention is described in the context of a fully functional computer server system with installed or executed software those skilled in the art will appreciate that the software aspects of an illustrative embodiment of the present invention are capable of being distributed as a program product in a variety of forms and that an illustrative of present invention applies equally regardless of the particular type of media used to actually carry out the distribution.

While the invention has been described with reference to exemplary embodiments it will be understood by those skilled in the art that various changes may be made and equivalents may be substituted for elements thereof without departing from the scope of the invention. In addition many modifications may be made to adapt a particular system device or component thereof to the teachings of the invention without departing from the essential scope thereof. Therefore it is intended that the invention not be limited to the particular embodiments disclosed for carrying out this invention but that the invention will include all embodiments falling within the scope of the appended claims. Moreover the use of the terms first second etc. do not denote any order or importance but rather the terms first second etc. are used to distinguish one element from another.

