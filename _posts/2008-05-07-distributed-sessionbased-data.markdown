---

title: Distributed session-based data
abstract: Session-based data, such as call detail accounting information, is tracked and distributed to a plurality of servers in a distributed telephony environment. One type of session is a telephone call between participants. Session-based data includes information about a session provided by the switches along the media path. Session-based data further includes information related to the session obtained from the application layer (e.g., user input metadata). A network proxy maintains a participant list to which the session data is distributed. The network proxy sends updates to the participants and determines the network status to implement fault tolerance of data distribution.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08107612&OS=08107612&RS=08107612
owner: ShoreTel, Inc.
number: 08107612
owner_city: Sunnyvale
owner_country: US
publication_date: 20080507
---
The present application is a continuation of U.S. patent application Ser. No. 10 754 424 filed Jan. 8 2004 now U.S. Pat. No. 7 386 114 entitled Distributed Session Based Data the contents of which are herein incorporated by reference in its entirety.

This invention relates generally to distributed telephony and more particularly to fault tolerant tracking and distribution of session based data.

Enterprises often have several offices or call centers that are located in a plurality of locations. To interconnect all of these sites enterprise telephony systems have been developed. Enterprise telephony systems consist of a distributed set of voice switches. This distributed hardware platform enables increased reliability and system capacity. Enterprise telephony systems also offer enterprise applications enabled by the integration of computer systems with telephony services. Call detail accounting is one example of such enterprise applications. Call detail accounting enables an enterprise to for example track allocate and document calls in a database.

While the underlying hardware in enterprise telephony systems is distributed the software that supports the computer integrated functionality is typically centralized. The software is generally implemented as a client server environment in which the participants or clients distributed telephony users communicate directly with the server. For example in a customer relationship management CRM application a customer service representative may create a log about a customer interaction that is meant to be stored on a primary server. In many cases the data reported by a participant is subsequently provided to another participant. For example the log mentioned above may be concurrently presented to a customer service supervisor. Centralized computer integrated features rely not only on a central server s application platform but also on the availability of the network that connects the switches central server and application services.

A centralized approach to providing computer integrated features or functionality has a number of limitations. One problem is that centralized systems have very limited scalability. As more sites are added to an enterprise telephony system the demand on the central server or logical cluster increases. In order to meet this increased demand the central server must be upgraded regularly. While upgrading servers can be expensive the alternative is far worse. If the server is not upgraded users of the telephony system will experience severely decreased levels of service due to bottlenecks at the server and other problems.

Another problem with centralized systems is that they lack resilience. Computer integrated features need to be fault tolerant and highly available. When these features rely on a central server however they are affected whenever the central server experiences a problem. One possible solution is to use both a primary server and a backup server. When the primary server is working correctly it handles all incoming requests. The backup server is used only when the primary server confronts a network outage or computing problem. In other words the backup server is used for failover redundancy. While this configuration is better than one containing a central server alone recovery of session based data during a failover transition can still be challenging. If the primary server failed while a user was trying to create session based data that was meant to be stored on the primary server the backup server may not be able to capture the call state accurately.

What is needed is a system and method for providing session based data to participants in a distributed manner that provides high reliability and high availability to a plurality of participants. What is further needed is a system and method that uses peer to peer interactions to exchange session based data.

Session based data such as call detail accounting information is tracked and distributed to a plurality of Call Data Servers CDSs in a distributed telephony environment. One type of session is a telephone call between participants. Session based data includes information about a session provided by the switches along the media path. Session based data further includes information related to the session obtained from the application layer e.g. user input metadata . A network proxy maintains a list of participants to which the session data is distributed. The network proxy sends updates to the participants and determines the network status to implement fault tolerance of data distribution.

Further features of the invention its nature and various advantages will be more apparent from the accompanying drawings and the following detailed description.

The present invention is now described more fully with reference to the accompanying figures in which several embodiments of the invention are shown. The present invention may be embodied in many different forms and should not be construed as limited to the embodiments set forth herein. Rather these embodiments are provided so that this disclosure will be thorough and complete and will fully convey the invention to those skilled in the art.

One skilled in the art will recognize that methods apparatus systems data structures and computer readable media implement the features functionalities or modes of usage described herein. For instance an apparatus embodiment can perform the corresponding steps or acts of a method embodiment.

The illustrated embodiment includes a first site a second site a third site and a fourth site . As used herein a site represents a grouping of resources. In the illustrated embodiment each of the four sites are communicatively coupled via a network . One skilled in the art will note that sites can be physically distinct from each other or merely topology related groupings that are not in physically distinct locations. The system architecture in is used only by way of example. While illustrates four sites the present invention applies to any system architecture containing two or more sites.

The first site includes an edge router a first switch a second switch and a first server . An edge router may be used for for example providing local area connectivity between multiple switches providing security establishing a VPN or guaranteeing quality of service. In the illustrated embodiment the edge router couples the first site to the network and provides local area connectivity for the first and second switches . The first and second switches represent telephony switch devices to which a number of endpoints can be coupled. Switch endpoints may be analog digital or Voice over Internet Protocol VoIP and may take the form of servers clients or devices. Note that the first and second switches may be implemented as softswitches. A softswitch is similar to a hardware switch except that it runs on a server instead of on a device. In this embodiment the first server would also include a softswitch entity.

Further the second switch provides connectivity to the public switched telephone network PSTN via an analog or digital trunk line e.g. a T1 or E1 interface . In the illustrated configuration the second switch provides an interface for calls originating from or terminating on the PSTN . One skilled in the art will recognize that numerous configurations of switches and communications links are contemplated. For example PSTN links can be coupled to multiple switches at several points within the topology.

The first server includes a processor and a memory . The processor can be a conventional processing device such as a general purpose microprocessor. The memory includes program instructions or functional modules that implement features of the present invention. The functional modules are described in further detail below and with reference to .

In one embodiment of the present invention one or more servers e.g. the first server are configured to implement features or functions of the present invention described below. More specifically the first server can execute an instance of telephony management software TMS as well as provide call data services CDSs . A TMS instance presents a computer telephony integration CTI view of the switch or switches managed by the TMS instance. A TMS instance can manage zero or more switches. Note that switches can operate without an associated TMS instance if CTI features are not being used. CDSs provide distributed access to session based data such as call detail records. Further details of the structure and function of TMS and CDS are provided below.

The second site similarly includes a first switch a second switch and an edge router to which the first and second switches are communicatively coupled. An edge router may be used for for example providing local area connectivity between multiple switches providing security establishing a VPN or guaranteeing quality of service. In the illustrated embodiment the edge router is further coupled to the network to provide the first and second switches connectivity to the other sites . Although for convenience of illustration the exemplary system architecture of does not include endpoints one skilled in the art will recognize that each of the first and the second switches are capable of having a number of endpoints communicatively coupled thereto. First and second switches can be implemented as for example switch devices or softswitches.

The configuration of the second site demonstrates that a server is not required for each site. Although embodiments of the present invention exchange data between servers the first and second switches of the second site can be managed by a TMS instance running on for example the first server that is illustrated in the first site . A call can involve more than one switch. For example a call that originates from the PSTN and terminates on an endpoint that is communicatively coupled to first switch of the second site involves two switches the second switch of the first site and the first switch of the second site . In addition each switch can be managed by a different server.

The third site similarly includes a switch and a second server . The switch can be implemented as for example a switch device or a softswitch and is communicatively coupled to the PSTN in a manner that is similar to the second switch of the first site . By being coupled to the PSTN the switch provides additional capability for endpoints to receive calls from or terminate calls to the PSTN . The switch is also coupled to the network to communicate with the other sites . In addition the switch may be coupled to a number of endpoints. While the illustrated embodiment does not contain an edge router a different embodiment may contain an edge router for providing security establishing a VPN or guaranteeing quality of service. Since only one switch is present an edge router would not be used to provide local area connectivity between multiple switches. As with the first server the second server comprises a processor and a memory . As further described below the second server executes processes or instances of TMS and CDS.

The fourth site includes a switch and a third server . The third server likewise includes a processor and a memory . Similar to the third site the fourth site includes a single switch . The switch can be implemented as for example a switch device or a softswitch. While the illustrated embodiment does not contain an edge router a different embodiment may contain an edge router for providing security establishing a VPN or guaranteeing quality of service. Since only one switch is present an edge router would not be used to provide local area connectivity between multiple switches. One skilled in the art will appreciate that additional networking devices can be added to the fourth site for example if needed to support additional endpoints servers or other systems.

In one embodiment of the present invention the network is a partially public or a wholly public network such as the Internet. The network can also be a private network or include one or more distinct or logical private networks e.g. virtual private networks or wide area networks . Additionally the communication links to and from the network can be wireline or wireless i.e. terrestrial or satellite based transceivers . In one embodiment of the present invention the network is an IP based wide or metropolitan area network.

The first server also includes a CDS instance running in conjunction with the TMS process . CDS is an application layer communication that is capable of peer to peer interaction. As illustrated in each of the servers can exchange session data or call data via the CDS mechanism. Call data includes information that is gathered from the switches involved in handling a call i.e. the media path . For call detail accounting purposes call data may include among other things the origination telephone number the destination telephone number and the duration of the call. Call data may also include information about a call that is provided by applications . For example a CRM user may wish to include notes about a call in the call data.

The CDS instance where a call originates is called the owning CDS and is the repository of the call data associated with that call. At the end of the call the owning CDS sends the call data to the database for persistent storage. The contents of the call data can be dynamic during the call. Each switch provides call data to the owning server i.e. the server that is configured to manage that particular switch . For each server to have a complete picture of the call data for a given call or session the servers exchange messages to ensure that each server has consistent call data. More specifically the owning CDS can receive call data from and send call data to a remote participant. As described below timestamps are used to ensure consistency to minimize event message size and to eliminate duplicate entries. One advantage of this configuration is fault tolerance if one or more servers should fail. The TMS processes can monitor network health and update other participants call data as required.

In one embodiment CDS instances are implemented as dynamically linked library functions that are called by the TMS processes . That is the CDS instances may execute in the same process space as the TMS processes . Communication or data exchange between the TMS processes and the CDS instances is further described below and with reference to .

First server may also include one or more softswitches. As described above a TMS process communicates with zero or more switches. For example with reference to the TMS process executing on the first server may manage the switches and as desired. That is the switches can operate without an associated TMS process if CTI features are not being used. Although applications are illustrated as executing on the first server the applications may be distributed among computing devices as is known to one of skill in the art.

Likewise the second server and the third server include TMS processes and respectively. The TMS processes also have associated CDS instances. Second server and third server may also include one or more softswitches.

The network proxy registers as a client with the local CDS store . The network proxy also registers and interfaces with remote CDS instances for example those running on the second and third servers . The network proxy receives updates from remote CDS instances and sends updates to remote CDS instances. Call data from the switch is passed to a TMS SWITCH module . The TMS SWITCH module registers with the local CDS store in order to exchange data.

The local CDS store also includes a control data interface that offers several functions. An initialize function initializes the CDS instance when the associated TMS process starts. A finalize function shuts down the CDS instance when the associated TMS process stops. A register function registers interest in a particular call identifier callID at a particular TMS CDS location. A callID is a unique identifier e.g. a token or GUID that is assigned by the switch at which a call originates. The callID is passed from switch to switch in order to uniquely identify the call within the media path. Passing the callID between switches is done using a call signaling protocol. The protocol may be standards based such as Session Initiation Protocol SIP Media Gateway Control Protocol MGCP or H.323 or proprietary. The callID is also passed to the TMS process for call management and integration purposes. An unregister function unregisters interest in a particular callID. An update function updates the call data for a particular callID. A callback function is called to report changes in the call data and registration information.

The modules include program instructions that can be executed on for example processor to implement the features or functions of the present invention. The modules are typically stored in a memory such as memory . For the servers the program instructions can be distributed on a computer readable medium or storage volume. The computer readable storage volume can be available via a public network a private network or the Internet. Program instructions can be in any appropriate form such as source code object code or scripting code.

The registration monitor module handles registration and unregistration of remote participants. The registration monitor module receives a registration request including a particular callID when a remote participant is interested in receiving call data updates for that callID. The registration monitor module also interfaces with the local CDS store to register the network proxy as a client that is interested in all callIDs. The registration monitor module builds a participant list for each callID from the registration unregistration requests received. The participant list enables the network proxy to send call data updates to the remote CDS instances that are participating i.e. interested in the call .

The remote update module manages the sending and receiving of call data to and from remote participants. When the network proxy is registered as a local participant the remote update module emulates a local participant to store and to retrieve information from the local CDS store . The processes associated with the remote update module are described in additional detail below.

The network health monitor module includes functions to determine the status of remote CDS instances and general network availability. The network health monitor module can periodically poll the servers or the TMS processes within the servers to determine whether the TMS processes are still alive. In another embodiment the network health monitor module regularly receives I m alive messages from CDS instances. If the message is not received within a predetermined amount of time e.g. 30 seconds the network health monitor module informs the server that a network outage has potentially occurred. If the remote participant does not re register its interest in the callID within a specified time frame e.g. 5 minutes the registration monitor module unregisters the remote participant.

The timestamp module coordinates the time base for the remote participants. The timestamp used for a particular call is based on the server time where the owning CDS instance is running. For a remote participant the timestamp of the owning CDS is simulated. On each interaction between a client and the owning CDS the current Coordinated Universal Time UTC of the owning CDS is returned to the client. The timestamp module at the client computes the difference between the UTC time of the local client server and the UTC time returned from the owning server. The difference is stored at the client and added to the local UTC time whenever a local client needs a timestamp. One skilled in the art will appreciate that the timestamp module keeps track of the latest timestamp received from the owning CDS instance.

The modules include program instructions that can be executed on for example processors to implement the features or functions of the present invention. The modules are typically stored in a memory such as memory . For the servers the program instructions can be distributed on a computer readable medium or storage volume. The computer readable storage volume can be available via a public network a private network or the Internet. Program instructions can be in any appropriate form such as source code object code or scripting code.

The registration module manages local client connections to local CDS store . The CDS network proxy registers with the registration module as a local client. The initialize finalize module interacts with the local TMS process to start stop the associated CDS instance. The update module processes call data to update the data store and to retrieve data from the data store. The update module provides call data to the participants of the local CDS instance that are interested in the particular callID. Of course the CDS network proxy can be registered as one of the local participants that is interested in all callIDs. The update module provides call data entries e.g. properties and logs depending on the type of event. For example in response to a registration event the call data includes all of the entries. For an update the call data contains only those entries that have been changed since the last update. The update module coordinates with the timestamp module to determine whether an entry has already been processed to eliminate redundant messages being sent to the CDS participants. At the end of a call the call data contains all entries.

The timestamp module controls the assignment of timestamps to call data entries. One skilled in the art will appreciate that timestamps are used to ensure data consistency throughout the distributed system. When a client registers for a callID it sends the timestamp if any of call data it may currently be holding e.g. due to a reconnect network outage or other failure . At registration time the update module of the CDS instance sends call data it is holding for the callID back to the registrant. Of course if the registrant is a remote CDS instance the network proxy sends the call data. The timestamp module also enables the update module to perform filtering of incoming call data to avoid storing redundant information in the storage module .

The storage module provides data storage services for the other functional modules . The storage module processes data storage and retrieval requests for call data entries and objects. At the end of a call the owning TMS process the TMS process associated with the switch that originated the call accesses the storage module to retrieve the call data entries associated with the callID to write the call data to the database for archiving or other processing. For example a call accounting process may later retrieve information from the database to generate a cost report.

The owning TMS process then receives call data from the switches or the application layer as described above. Alternatively the owning TMS process may receive call data from participant CDS instances. The owning TMS process sends the received call data to the local CDS instance to store the call data and capture the call state. The local CDS instance then sends call data to local participants one of which may be the network proxy in order to distribute the call data see .

The TMS process then determines whether an end of call event has been received. If an end of call event has not been received the TMS process returns to steps to receive additional call data. If an end of call event has been received the owning TMS process writes the accumulated call data to the database and then ends.

The process determines whether an end of call event has been received. If an end of call event has not been received the process returns to steps to receive additional call data. If an end of call event has been received the process ends.

Alternatively the process may receive an unregistration from a remote participant and determine whether any remote participants are remaining for the call. If unregistrations have been received for all of the remote participants the CDS network proxy unregisters with the local CDS store . Otherwise the process returns to the beginning to perform additional tasks.

When the process receives call data from a remote participant it sends the call data to the local CDS store . When the process receives call data from the local CDS store it sends the call data to the remote participants on the participant list. The process continues to handle registrations unregistrations and call data until it is determined that an end of call event has been received. The process ends responsive to the end of call event message.

Alternatively the process may receive an unregistration from a local participant and determine whether any local participants are remaining for the call. If unregistrations have been received for all of the local participants the CDS network proxy unregisters with the owning CDS instance. Otherwise the process returns to the beginning to perform additional tasks.

When the process receives call data from a local participant it sends the call data to the owning CDS store . When the process receives call data from the owning CDS store it sends the call data to the local participants on the participant list. The process continues to handle registrations unregistrations and call data until it is determined that an end of call event has been received. The process ends responsive to the end of call event message.

If the last unregistration has been received then the process sets end of call status. In one embodiment the process delays a predetermined amount of time e.g. 30 seconds to wait for additional registrations before setting end of call status. This behavior is advantageous because in a networked environment it is possible that all currently registered participants will unregister e.g. due to unexpected connection difficulties while the call is still active. In this case the owning CDS instance will keep the call data active in case another participant re registers.

When the end of call status is set the process sends the end of call event message to interested local participants. Otherwise call data continues to be received from local participants including the CDS network proxy . When the process receives call data the process determines whether it has seen the particular call data before. As described above the determination uses timestamps to compare the call data to that which has already been received. One skilled in the art will appreciate that the most recent modification of a property i.e. entry replaces an earlier modification of the same property. If the call data has been seen before it is disregarded and the process returns to the beginning . If the call data has not been seen before it is stored in the local CDS store and then sent as a call data update to other local participants including the CDS network proxy for distribution to remote participants .

When the process receives call data from a local participant the process determines whether it has seen the particular call data before. As described above the determination uses timestamps to compare the call data to that which has already been received. If the call data has been seen before it is disregarded and the process returns to the beginning . If the call data has not been seen before it is stored in the local CDS store and then sent as a call data update to other local participants including the CDS network proxy for distribution to remote participants .

The process then determines whether any local participant remains. If it does the process returns to the beginning . If it does not the process ends.

Having described embodiments of distributed session based data which are intended to be illustrative and not limiting it is noted that modifications and variations can be made by persons skilled in the art in light of the above teachings. It is therefore to be understood that changes may be made in the particular embodiments of the invention disclosed that are within the scope and spirit of the invention as defined by the appended claims and equivalents.

