---

title: Multi-core processors for 3D array transposition by logically retrieving in-place physically transposed sub-array data
abstract: A method and system for transposing a multi-dimensional array for a multi-processor system having a main memory for storing the multi-dimensional array and a local memory is provided. One implementation involves partitioning the multi-dimensional array into a number of equally sized portions in the local memory, in each processor performing a transpose function including a logical transpose on one of said portions and then a physical transpose of said portion, and combining the transposed portions and storing back in their original place in the main memory.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07979672&OS=07979672&RS=07979672
owner: International Business Machines Corporation
number: 07979672
owner_city: Armonk
owner_country: US
publication_date: 20080725
---
The present invention relates generally to multi dimensional data processing applications and in particular to transposing three dimensional 3D arrays for multi core processors.

Transposing three dimensional 3D arrays is a fundamental primitive operation used in many multi dimensional data processing applications. Examples include seismic medical imaging media industry for 3D TV biomedical and 3D Fast Fourier Transform FFT applications. 3D FFT in turn is used in solving many mathematical problems including Poisson s equation in cylindrical coordinates partial differential equations and x ray diffraction data processing. Conceptually 3D transpose simply changes the order of axis along dimensions for example given 3D data ordered in XYZ axis order one 3D transpose operation would be to change the order to ZXY. However with large data sets as typical in above applications such operation is challenging even for a massively parallel computing system. The operation is memory bound rather than computation bound it involves much data communication and displacement rather than processing.

Conventional approaches to 3D transpose operations may be grouped into two approaches The first approach physically reorders the data while the second approach performs reordering logically without moving any data. The latter approach does not require any data movement operation however it is not necessarily as efficient as the first approach especially when memory is organized in a hierarchical structure. Memory hierarchy favors accessing data in blocks thereby decreasing communication latencies. Moreover usually the transposed data are later stream processed which again require accessing data in blocks. Logical transpose accesses data in small granular level at element level fashion which does not interface well with the underlying memory and processing architecture. Further there is an associated mapping overhead. Therefore physical transpose is usually preferred.

Performing physical transpose however has several shortcomings. One shortcoming involves the fact that it is usually sought to have the data transposed in place to conserve memory given large data size . This introduces complexity on the order of transpose and may limit the effective memory bandwidth especially on shared memory parallel systems. A second shortcoming involves the fact that all the data is transposed even if only a small subset is required that will be the case if data access later on is sparse .

The invention provides a method and system for transposing a multi dimensional array for a multi processor system having a main memory for storing the multi dimensional array and a local memory. One embodiment involves partitioning the multi dimensional array into a number of equally sized portions in the local memory in each processor performing a transpose function including a logical transpose on one of said portions and then a physical transpose of said portion and combining the transposed portions and storing back in their original place in the main memory.

Partitioning the multi dimensional array into a number of equally sized portions in the local memory may include partitioning the multi dimensional array into a number of equally sized portions wherein the number of portions is equal to the number of processors in said multi processor system.

Partitioning the multi dimensional array into a number of equally sized portions in the local memory may further include partitioning the multi dimensional array into a number of equally sized rows wherein the number of rows is equal to the number of processors in said multi processor system.

Partitioning the multi dimensional array into a number of equally sized portions in the local memory further may further include associating each row with a processor among the processors of said multi core processor system.

Performing a transpose function in each processor may include partitioning each associated row into plural matrices in the local memory and transposing each matrix in the local memory.

Combining the transposed portions and storing back in their original place in the main memory may further include combining the transposed matrices into a new row in said local memory and storing back the new row from local memory to its original position in the main memory. The multi dimensional array may comprise a three dimensional 3D array.

Other aspects and advantages of the present invention will become apparent from the following detailed description which when taken in conjunction with the drawings illustrate by way of example the principles of the invention.

The following description is made for the purpose of illustrating the general principles of the invention and is not meant to limit the inventive concepts claimed herein. Further particular features described herein can be used in combination with other described features in each of the various possible combinations and permutations. Unless otherwise specifically defined herein all terms are to be given their broadest possible interpretation including meanings implied from the specification as well as meanings understood by those skilled in the art and or as defined in dictionaries treatises etc.

The invention provides a method and system for in place multi dimensional transpose for multi core processors with software managed memory hierarchy. One embodiment provides a three dimensional 3D transpose operator for multi core multi node processors with software managed memory hierarchy for target domain of shared memory architecture in a multi core paradigm.

The 3D transpose operator performs logical transpose on sub parts e.g. cubes of the 3D array rather than the entire 3D array. The operator then performs a physical transpose on each cube. Such two level decomposition matches the requirements of logical and physical transpose approaches. Utilizing cubes as logical access units removes a substantial amount of logical mapping and performing transposes only when needed i.e. lazy transpose decreases on chip memory communication bandwidth requirements. Physical transpose of intra cube elements allows for high memory access bandwidth and properly orders data for single instruction multiple data SIMD stream processing.

Preferably said transpose levels logical and physical are processed in parallel wherein each processor core is associated with a cube in which a physical transpose is performed. An application programming interface API function is then responsible for the logical mapping which in turn is executed in parallel. Transposing performed on multi core processors with software managed memory hierarchy. Transpose is performed lazily wherein transposing the entire 3D array is not performed when the array is sparsely accessed. This reduces on chip memory bandwidth requirements. Transpose operations occur at the intra cube level providing efficient memory access and allowing for streaming SIMD processing. Further transpose operations occur in place which contrasts with conventional physical transpose approaches where parallel in place operation is complex.

An implementation is now described for a Cell Broadband Engine BE processor manufactured by IBM. An example multi core processor with software managed memory hierarchy is a Cell BE processor by IBM A version of the Cell BE processor is described in IBM Cell BroadBand Engine Architecture Hand book Version 1.01 October 2006 incorporated herein by reference . The Cell BE processor includes a multi core chip comprising a 64 bit Power Architecture processor core and eight synergistic processor cores capable of massive floating point processing optimized for compute intensive workloads and broadband rich media applications. A high speed memory controller and high bandwidth bus interface are also integrated on chip. The Cell BE software managed parallel processing system is typically used in the application domains where 3D transpose operation is significant. The Cell BE is a multi core processor that provides for a large centralized shared memory off chip and small local memories for 8 synergistic processing elements SPEs . Such architecture as well as similar software managed memory hierarchies provide for memory transfers and process computation to operate in parallel.

An example 3D transpose operation on such a processor involves transposing a 3D array 3D matrix as a cuboid according to an embodiment of the invention. A cuboid has the dimensions of L M N corresponding to the axes X Y and Z respectively. The values L M N need not be the same. As shown by example transpose in a transpose operation changes the order of the cuboid axes X Y and Z. The axes X and Y of the cuboid before the transpose are in the plane of the drawing page while the Z axis is perpendicular to the plane of the drawing page. The axes X and Z of the cuboid after transpose are in the plane of the drawing page while the Y axis is perpendicular to the plane of the drawing page.

A three letter string is used herein to specify the sought axes order. For example the transpose YZX operation exchanges axis Y and Z in original ZYX order. To avoid confusion from original and desired axis names a distinction is made between cuboid axis and baseline axes. The latter are fixed and labeled as major middle and minor corresponding to the original cuboid X Y Z axes order respectively. shows the use of such naming while performing an YZX transpose.

A cuboid includes multiple rows. The cuboid is divided into plural small cubes 3D matrix each of dimension p p p. As such the cuboid dimensions L M N are divisible by p. A row in the minor axis direction of each cuboid is referred to as a bar . The cuboid is assumed to be stored in the processor computer main memory in major middle minor axes order. Middle minor planes for cuboid bars and cubes are qualified as faces . As noted cube comprises a 3D matrix smaller than the 3D array e.g. for a 3D matrix of size 256 128 64 a possible cube size may be 4 4 4 thus the 3D array would be decomposed into 32768 cubes . Each element of the cube or 3D matrix is a scalar number value .

A process for transposing a cuboid 3D array in a multi core processor system according to an embodiment of the invention is now described. The multi core processor system includes a main memory for storing the 3D array and a local memory. Generally the process involves partitioning dividing the 3D array into a number of equally sized bars rows wherein the number of bars is equal to the number of processors cores in said multi core processor system. Each bar is associated with a given processor among the processors of said multi core processor system. Each given processor is programmed to partition divide each associated bar into plural matrices e.g. cubes in the local memory transpose each cube combine the transposed cubes into a bar in said local memory and to store back the bar from local memory to its original position in the main memory.

Table 1 below shows an example pseudo code process for said transpose operation. The 3D array is in main memory and bars are moved to local memory step 5 of Table 1 and cubes are extracted from local stores.

Each processor transposes its share of bars. In block each bar is loaded from main memory and stored into the local memory of the corresponding processor. The loading operation is rapid due to bar organization as mentioned above. In block the processor then chops the bar into cubes. The chopping into cubes occurs in local memory and in parallel each processor is performing the same for its corresponding bar . Moreover memory transfer and processor processing occurs in parallel thus chopping and loading bars may be overlapped. Therefore the chopping operation does not introduce overheads. In block each processor now has a current bar chopped into cubes and proceeds to transpose each cube in local memory. In block each processor combines transposed cubes into bars then in block stores back the bar into its original position. Operations in blocks and are the opposite to the bar reading and chopping operations in blocks and respectively.

Upon completion data inside each cube is transposed but not cube locations. Post transpose programs that access the cuboid may utilize a logical mapping to access a particular cube. Such mapping is trivial merely require reordering cube coordinates as per transpose string and may be provided by a simple cube mapping function or coded directly by a programmer. Moreover the programmer may use the same bar access step defined above for accessing many cubes at once saving memory transfer time if access pattern permits .

An example cube transpose operation for the cuboid transpose operation above is now described. The cube transpose operation is useful with all possible transposes that may be performed on a p p p cube. Vectorization is used to achieve high performance of element displacement. For a p p p ZYX cube cube elements for all x values for x 1 to p for a given z and y are to be defined as yz cube row. Only two adjacent axes are swapped at each single step i.e. swap is either between major and middle or between middle and minor axes . Thus a maximum of three swap operations are required for any cube transpose.

Major middle swapping is performed by reordering of the cuboid rows. As such each yz row is swapped with zy row. This swapping is performed by simple out of place memory copying from the source to a temporary destination for the Cell BE computer this memory copy and swap process is performed using SPU C intrinsics load store to achieve the highest performance .

Middle minor swapping comprises a 2D transpose for one face of the p p p cuboid to be performed p times for the p faces of the cube. Any efficient 2D transpose algorithm may be used for the Cell BE computer the transpose matrix function from the SDK library may be used . In order to achieve 3D transpose of a cube a transpose process shown in involves 

Steps and may or may not involve major middle axis swapping depending on the requested transpose which is one out the five possibilities described further below . Further steps may or may not be performed based on the requested transpose. Possible transposes for a cuboid are the following note that the trivial no transpose case is omitted 

Referring to the graphical example in and example process in clockwise rotation i.e. cw ZYX XZY involves the following 

After performing the transpose process on all p p p cubes and the destination bar is built the process is reversed and the bar is written back in place in its original cuboid location into main memory. As such a preferred embodiment of the invention divides the steps of transpose operations among multiple processing units that process independently along all axes until transpose is completed without inter process communications. Further the 3D transpose is performed in place based on a hybrid integrated 3D transpose approach including logical and physical processing.

Increasing a cube dimension size cubically increases volume and hence local memory allocated space whereas decreasing the cube size decreases cube read write speeds and ultimately the degree of SIMD processing possible. One approach to choosing cube dimension is to choose a suitable size with respect to efficient SIMD processing for the underlying architecture. The sizes should allow for efficient vectorization of the transpose and possibly the post transpose operations. We then rely on bars to achieve high communication speed.

As discussed above there are two main operations according to one embodiment of the invention the first is to physically transpose small 3 D portions on the 3 D array the second is to make a logical transpose on each access to the said 3 D array resulting in returning the correct transposed data. The logical transpose merely requires changing the order of the element coordinates for access. In more concrete terms suppose that we have a 3 D array of N N N dimensions. Suppose that the dimensions of the small portions are M M M such that N is an integer multiple of M. Also suppose that the transpose is to change the axis of the N N N array from XYZ to YZX. In one embodiment of the invention all M M M portions are physically transposed from XYZ to YZX. For an application to access element a b c in the N N N array the following steps will be performed 

For ease of understanding the following example is presented as follows. Take N 4 and M 2. The elements of the 3 D array is indexed by the tuple i j k where 0 i 0 0 j 3 0 k 3.

The terms computer program medium computer usable medium and computer readable medium computer program product are used to generally refer to media such main memory secondary memory removable storage drive a hard disk installed in hard disk drive and signals. These computer program products are means for providing software to the computer system. The computer readable medium allows the computer system to read data instructions messages or message packets and other computer readable information from the computer readable medium. The computer readable medium for example may include non volatile memory such as a floppy disk ROM flash memory disk drive memory a CD ROM and other permanent storage. It is useful for example for transporting information such as data and computer instructions between computer systems. Furthermore the computer readable medium may comprise computer readable information in a transitory state medium such as a network link and or a network interface including a wired network or a wireless network that allow a computer to read such computer readable information. Computer programs also called computer control logic are stored in main memory and or secondary memory. Computer programs may also be received via a communications interface. Such computer programs when executed enable the computer system to perform the features of the present invention as discussed herein. In particular the computer programs when executed enable the processor multi core processor to perform the features of the computer system. Accordingly such computer programs represent controllers of the computer system.

As is known to those skilled in the art the aforementioned example embodiments described above according to the present invention can be implemented in many ways such as program instructions for execution by a processor as software modules as computer program product on computer readable media as logic circuits as silicon wafers as integrated circuits as application specific integrated circuits as firmware etc. Though the present invention has been described with reference to certain versions thereof however other versions are possible. Therefore the spirit and scope of the appended claims should not be limited to the description of the preferred versions contained herein. Those skilled in the art will appreciate that various adaptations and modifications of the just described preferred embodiments can be configured without departing from the scope and spirit of the invention. Therefore it is to be understood that within the scope of the appended claims the invention may be practiced other than as specifically described herein.

