---

title: Content analysis simulator for improving site findability in information retrieval systems
abstract: A system and method including a simulator operating in conjunction with a search-engine, for improving document and site findability. Users input their content (pages or sites) and the simulator will analyze the site in terms of structure and content. It will then give the user a ranked list of suggestions about how the user might improve his/her site's findability. The user will then be able to apply some or all of these suggestions, or any other changes, by virtually modifying the site, and then immediately receive feedback both on how the pages look and a sense of the degree of findability improvement. The interactive process allows users to simulate modifications in their site structure and content in order to improve its findability. When the user completes the modifications and is satisfied with the new findability of his site, the user will be able then to replace his/her current site in the repository with the modified one.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08285702&OS=08285702&RS=08285702
owner: International Business Machines Corporation
number: 08285702
owner_city: Armonk
owner_country: US
publication_date: 20080807
---
The present application relates to commonly owned U.S. patent application Ser. No. 11 461 464 filed Aug. 1 2006 now U.S. Pat. No. 7 792 830 the entire content and disclosure of which is incorporated by reference as if fully set forth herein.

The present disclosure relates generally to information retrieval systems and more particularly to a simulator implemented as part of or operating in conjunction with a search engine for improving document and site findability.

Content Management also known as CM is a set of processes and technologies supporting handling of digital information. This digital information is often referred to as digital content. Currently people managing content have very few tools to tell them a priori if users will be able to locate their content.

 Findability is the term used to refer to the quality of being locatable or the ability to be found. Findability has become highly relevant with the expansion of the World Wide Web. However findability is not limited to the web and can equally be applied to other environments. The structure language and writing style used for content description all have a huge effect on the findability of content by users searching for information encapsulated in that content.

Currently content providers who write content for Intranet and Internet web sites find it very difficult to make the pages they write findable by potential consumers. The main reason is the difficulty to describe their content in optimal ways from the search engine perspective. This means that while the content itself may suffice it is written and formatted in such a way that the search engine employed to find the site e.g. in response to a query or user input ranks it low compared to other pages which may be of lesser interest to people who search for specific content.

Currently the main solution to this problem is either experience of the people who generate the content or more commonly experts in the field of Search Engine Optimization SEO who reformat pages to be better valued by the search engine based on their knowledge and experience.

However both these approaches rely on experience rather than on objective measures. SEO experts usually do not have access to the search engine ranking methodology hence their recommendations are mostly based on experience and common assumptions. Moreover due to the complexity of the ranking algorithms used by state of the art search engines it is extremely difficult to predict in advance the effect of modifications in content and structure on the ranking of the web pages pages in the set of results for specific queries.

In the patent literature US Patent Publication No. 2003 0046389A1 describes a standard SEO system where web site improvements are based on user behaviour in the web site. While US Patent Publication No. 2003 0046389 talks about the possibility that an Human SEO will recommend how to improve the site by discussing how SEO professionals may advise an owner of the Web site on how to write strategic and relevant copy i.e. text for a given Web page or Web site there is no teaching or disclosure as to how to do it automatically based on a findability analysis without human expert intervention.

Japanese patent JP2001319129A2 refers to a general system which is based on comparing the behaviour of different search engines on the same web site.

European Patent application WO 07143395A2 refers to a system which proposes improvements based on general rules generated by an expert that would generally benefit the performance of a web page however not specific to any one website.

Other non patent literature refers to the generation implementation of simple heuristics e.g. analysis of log files analysis of incoming links to suggest improvements to web pages.

It would be highly desirable to provide a system and method that operates in conjunction with a search engine for automatically analyzing a web site or web page and making recommendations for improving document e.g. web page and web site findability.

The present invention is directed to a methodology system and computer program product for improving document e.g. web page and web site findability.

In one aspect of the invention there is provided a simulator operating in conjunction with a search engine for improving document and site findability. Users input their content pages or sites and the simulator will analyze the site in terms of structure and content. It will then give the user a ranked list of suggestions about how the user might improve his her site s findability. The user will then be able to apply some or all of these suggestions or any other changes by virtually modifying the site e.g. using a text editor or HTML editor and then immediately receive feedback both on how the pages look and a sense of the degree of findability improvement. The interactive process allows users to simulate modifications in their site structure and content in order to improve its findability. When the user completes the modifications and is satisfied with the new findability of his site the user will be able then to replace his her current site in the repository with the modified one.

In one aspect of the invention there is provided a computer implemented method for improving a web site s content comprising 

for each web page performing a meta data extraction to obtain features of the site pages related to its findability 

for each important term found for this site implementing via the search engine a search query using this term and retrieving the returned results of web pages having the term 

identifying based on the query results the place of the current site s web page in the rank of the returned results 

providing recommendations for improving the web site based upon the web pages results ranking the recommendations directed to improving the web site s findability.

In a further aspect of the invention there is provided a system for improving a web site s content comprising 

a simulator device operable for receiving the document and for analyzing the document set to determine the site page s important terms 

a search engine for searching for each important term found for this site a search query using the site s important terms and retrieving the returned results of web pages having the term the search engine further identifying based on the query results a ranking of the current site s web page in a list of the returned results and 

the simulator device generating an interface to provide recommendations directed to improving the web site s findability based upon the web pages results ranking.

means for performing for each web page a meta data extraction to obtain features of the site pages related to its findability the performing means determining from the features the web site s important terms wherein the important terms includes the most important concepts in the web site content the simulator means determining for each web page a set of terms from the terms of the document set that minimizes a distance measurement from the given set of documents.

Advantageously in accordance with the principles of the invention dominant competitors can be determined and analyzed to determine the differences between a given site s page s and the competitors sites which differences may be suitably emphasized or flagged for a user via a client device. Such determination is valuable as the user may learn the reasons that cause their competitors to dominant a given site s page s .

Thus in a further aspect the invention can be applied to obtain information about an entity s Dominant Competitors by performing a top k dominant competitor analysis for determining any web page in the domain not belonging to the given site that is ranked higher than all the site pages for at least k important terms.

Further to this aspect in accordance with the system and method of the invention the simulator performs the top k dominant competitor analysis by 

determining a ranking of the second web site based on the second site s important terms from the features and 

performing a count of how many important terms this page is ranked higher than all the given site pages

if the count is greater than the threshold k identifying the second web site count as a top k dominant competitor.

The computer implemented method further determines the differences between a given site s page s and the competitors and informs a user the differences wherein the differences can be used to modify the given web site.

In a further aspect of the invention a service is provided that operates in conjunction with a search engine by enabling receipt of user content e.g. a web page or site analyze the page or site content in terms of structure and content and generate a ranked list of suggestions as to how to improve the page or site s findability i.e. improve the likelihood that the page or site will be ranked high by the search engine if the suggestions are implemented.

Advantageously the findability simulator permits a user to modify his her web site pages. Those modified pages replace the original pages in the mirror index of the search engine. The simulator then analyses the findability of the modified site using the mirror index with the new modified pages . When modification is completed the user may complete the task by saving the modified site in the main index.

Thus via an interactive process the simulator enables the user to modify his her web site and simulates how these modifications affect its findability. The search engine holds a separate mirror index where the site modifications are handled. After modifications has been applied the findability analysis is invoked over the modified site. After the user is satisfied with his her modifications and is satisfied with the new findability of the site the new modified site will be re indexed by the search engine i.e. the user will be able then to replace his her current site in the repository with the modified one.

Advantageously a search service may be provided that includes the simulator operating in conjunction with a search engine for improving document and site findability.

The present invention is directed to a methodology system and computer program product for improving document e.g. web page and web site findability. A document includes textual content. For example a set of textual documents such as web pages belonging to a specific web site Intranet or Internet web site s . Content in this case is referring to the textual content of these pages and to the anchor text of hyper links pointing to these pages. Textual content may also be retrieved in the form of a single document or related documents from a database or other repository.

A user finds relevant documents by using query terms which are submitted to a search engine. It is therefore important to ensure that documents are found by the most appropriate query terms.

Referring to an example embodiment of a search engine system as known in the art is shown. A server system is provided generally including a central processing unit CPU with an operating system and a database . A server system provides a search engine including a crawler application for gathering information from servers via a network an application for creating an index or catalogue of the gathered information in the database and a search query application .

The index stored in the database references URLs Uniform Resource Locator of documents in the servers with information extracted from the documents.

The search query application receives a query request from a search application of a client via the network compares it to the entries in the index stored in the database and returns the results in HTML pages. When the client selects a link to a document the client s browser application is routed straight to the server which hosts the document.

The search query application keeps a query log of the search queries received from clients using the search engine . In conventional methods the query log is often used to analyze users queries to provide search engine optimisation of a document.

There are many search engines on the Internet each with its own method of operating to located web pages within the web. Internet technology is also used to create private corporate networks call Intranets. Intranet networks and resources are not available publicly on the Internet and are separated from the rest of the Internet by a firewall which prohibits unauthorised access to the intranet. Intranets also have search engines which search within the limits of the intranet. In addition search engines are provided in individual web sites for example of large corporations. A search engine is used to index and retrieve the content of only the web site to which it relates and associated databases and other resources.

As further shown in according to the invention is a simulator device comprising computer implemented processing instructions and application programming interfaces operating under control of the server system or like computer device for generating a list of recommendations for improving the findability of a document.

In the embodiment depicted in the simulator may be integral with the server device co located in an area with or or remote from but otherwise operable in conjunction with a search engine that may comprise any private or publicly available search tool designed to search the World Wide Web or network for web pages images and other types of information. Internet or Intranet search engines gather information by accessing web sites and indexing their content e.g. by crawling . Google for example is a well known search engine but other similar types that initiates a search and provides links to information matching the input are include e.g. Yahoo Ask.com Wikia etc. .

More particularly the inputs to the simulator are in one embodiment a list of web pages or a web site containing several pages which is referred to herein as the content . The simulator provides an interface to the search engine in a manner such that the simulator may provide the following functionality 1 run a query on the search engine and retrieve the returned results 2 obtain a list of indexing terms for a specific page as extracted by the parsing devices provided with the search engine parsers . The list of terms is checked to determine if they are identical to the list of terms that were actually used for indexing that page in order to verify that the terms used to represent the page within the search index are indeed the terms who represent the current content of page on the Web. For example it might be a case that a page which has been modified on the Web has not been modified within the search index. By comparing the terms extracted from the page and the terms that are used to index that page a modified site that has not been updated within the index may be identified. The list might include terms extracted from the page content from the page meta data and from any other available sources used by the search engine such as anchor text data user tags as extracted from a collaborative bookmarks system etc. and the terms should be identical to the list of terms that were actually used for indexing that page and 3 obtain any other features of the page used by the search engine ranking function to identify any of the page features that are used by the search engine to index the pages. For example the time of indexing or the number of in links of a page and the number of pages who link to the site is used by most search engine as an important feature for scoring. The simulator uses the feature extraction tools of the search engine to extract all features used to index the page in order to extract those feature from the input pages to be analyzed.

Once these inputs are provided to the simulator the simulator executes programmed instructions to identify one or more important features of the site pages related to its findability. This set of features includes but is not limited to finding the following 

The simulator will then generate output results including a list of recommendations for improving the findability of the content. This list will include recommendations for modifying the format of the content modifying titles emphasis etc adding keywords adding in links simulating what will happen if more external pages will link to your site and modifying content. The list may be ranked according to effectiveness that is the highest ranked recommendation is the one which will have the greatest effect on findability.

An example of a list of recommendations provided by the simulator of the present invention for a given web site is provided with reference to .

The user will then be able to apply one or more recommendations apply any other modification the user might consider to be useful see the effect on the web page and the effect on ranking of the list of important concepts. Note that each modification will be applied by the simulator to simulate the search behavior of the search engine as if the original site would have been replaced by the modified one.

The search engine will simulate the replacements of the current pages in its indices and other data structures with the modified ones and re evaluate the site findability. The simulation of page replacements are performed on a mirror index of the search engine where page modifications immediately affect the site findability. When the user is satisfied with the findability results the simulator will save the modified pages for upload to the search engine.

The simulator can be used as stand alone or integrated with an HTML editor or like editing device to ease the modifications of the Web site and enable textual content and any scripts or functionality to be modified or updated.

A detailed description of the processes performed by the simulator is now described with respect to the flow chart of depicting simulator operations . The simulator works as follows 

A data structure representing a web site input to the simulator at step . This input may include for example a data structure and set comprising textual content of a given site s Web pag e . The simulator in response executes a process including the following functionality as shown in the loop beginning at step and ending at step for each web page of the site performing at step a meta data extraction set to extract a number of in links extract a number of out links extract a meta data page title page keywords last index update date extract user annotations if exist tags comments etc. Then at step the simulator provides all the extracted data to a location in memory storage e.g. in one database table where the data is organized and stored. depicts exemplary interface provided of the extracted data at an output page of the findability simulator.

Then at step the simulator provides an identification step to identify the most important N terms of the site. It is understood that N is a configurable parameter having for example a default value of 10 but not at all limited. Identifying the most important N terms of the site can be performed in several ways. For example in the way as described in commonly owned U.S. patent application Ser. No. 11 461 464 filed Aug. 1 2006 now U.S. Pat. No. 7 792 830 of identifying the most important terms in a web site . This published patent is incorporated by reference as if fully set forth herein. The algorithm includes determining a set of terms from the terms of the document set that minimizes a distance measurement from the given set of documents. The method includes using a greedy algorithm to build the set of terms incrementally at each stage finding a single word that is closest to the document set. The set of terms is evaluated to assess the ability to find the document set. The set of terms are compared with expected terms to evaluate the ability to find the document set. A measure of the ability to find a document set is provided by computing a distance measure between a document set and an entire collection.

Referring to an entire document collection is shown schematically including a document or a document set to be analyzed. The document or document set may be a web site an intranet site a web page an intranet page a web domain an intranet domain a database document etc. This is referred to herein as a document set although it will be appreciated that the set may include a single document. The document collection may be the entire web one or more web sites an intranet a database etc. The document collection may be dispersed across a network or within a database etc. The document set is retrieved from the document collection by users using search queries.

A content manager is shown which provides and or manages a document set . For example the content manager may manage a web site or an intranet site. The content manager includes a processor and an analyzer for analyzing the findability of the document set from within the document collection . The analyzer includes a means for finding a best set of query terms for the document set and a findability measure for the document set .

In the context of the invention document collection or document set including web pages of a web site are provided by one or more servers and a content manager is employed in direct communication with a server providing the document set or may communicate with it via a network. An analyzer may be provided integrally with the simulator a content manager or may be provided to a content manager as a service over a network as long as the service has a full access to the content manager API not shown .

The described method analyzes a document set including the following steps 1. Identification of the best words word parts such as prefixes word collocates lexical affinities or phrases in the document set 2. Assessing how easily typical users will be able to find content in the document set. This is done by invoking a measure of findability for the document set 3. Suggesting ways in which findability could be improved by optimizing the content against the new findability measure and 4. Locating content which is similar to the analyzed content.

The described method is based on a model of query difficulty. The model describes the information retrieval process as a matching of queries to relevant documents both form an underlying topic. The model shows that query difficulty is derived from five distances induced by the difficulty model 1. The distance between the query queries and the entire collection. 2. The distance between queries of the same topic. 3. The distance between relevant documents and the collection. 4. The distance between relevant documents. 5. The distance between the queries and the relevant documents.

The Jensen Shannon divergence JSD is used in one embodiment as described in herein incorporated commonly owned U.S. patent application Ser. No. 11 461 464 filed Aug. 1 2006 now U.S. Pat. No. 7 792 830 to measure the distances between objects sets of documents and queries . In general other distance measures could be used.

The distance measured above is in fact the separation between the relevant documents and the entire collection. It can be thought of as the signal to noise ratio of the topic. In order to analyze findability the JSD distance of a given document set for example a given set of web pages or a web site is measured from the entire collection.

When a document set is provided the first step is to find a list of words word parts word combinations or phrases that best describe the document set. The Query Coverage QC set is defined as the set of terms that minimizes the JSD distance from the given document set. Finding the QC set given a document set is NP hard non deterministic polynomial time hard therefore a greedy algorithm is used. The algorithm builds the QC set incrementally at each stage it finds a single word that is the closest in JSD distance to the document set. This process repeats and words are added to QC so as to minimize the JSD distance from the document set or increase it by the smallest amount .

Content managers can evaluate this list and verify that the QC set indeed contains words that users are likely to submit to a search engine when trying to locate their document set. If not i.e. when the QC set does not contain expected words this is a good indication of problematic findability.

After the list of best words is formed a sequence of queries is created with the first best word the first two best words and so on up to the first N best words. The sequence of queries is executed by any search engine and the average precision AP for each query is computed. The AP for a query is computed by considering the document set as the target set. The resulting curve of AP against the number of terms is then analyzed. This curve shows the findability behavior of a document set.

Taking the example in which a document set is a web site for one type of site the maximal AP is achieved by the first word and additional words do not greatly improve it. Other sites on the other hand show a dramatic increase with the addition of words. It can be shown that there are three typical findability behaviors 1. Sites which are easily findable using the first two or three best terms for example 2. Sites which are not findable even when using very long queries based on the QC set and 3. Sites which require long 5 10 best word queries in order to be located.

By reporting the type the specific site belongs to site managers can appreciate the findability of their site.

Continuing with the flow diagram of an important terms analysis is performed with functionality as shown in an inner loop beginning at step and ending at step for each of the important terms found in the site the distribution of this term is computed over the site i.e. it is determined at step the total number of occurrences in the site and the number of occurrences of this term in each of the pages . Then at step the frequency of this term in the entire collection is retrieved. Term frequency distribution over the site is provided mostly as an evidence to the significance of the term.

In addition the frequency distribution can be used to identity why another site dominates the analyzed site for a specific term e.g. when the term is more frequent in the other site . Then at step the term is then submitted as a query to the search engine in order to retrieve the top results. The loop then determines at step whether there are any more terms in the current website to process in which case the process returns to step . Otherwise the process returns to the next step of identifying based on the query results the place of the current web page in the rank of the top results. After determining the current page s ranking based on the term results analysis returns to provide the simulator output results which includes the ranking as determined for each Web page of the site. The resulting rank data may be provided for storage to and retrieval from a database table.

The above described principles of the invention can be applied to obtain information about an entity s Dominant Competitors by performing a top k dominant competitor analysis for determining any web page in the domain not belonging to the given site that is ranked higher than all the site pages for at least k important terms.

In this top k dominant competitor analysis for each non given web site page belonging to the sets of results retrieved a count is performed for how many important terms a non given web site page is ranked higher than all the given site pages. If this number is larger than k this page is reported as a top k dominant competitor and the list of terms for which it dominants . In one embodiment the top k competitors may be found where k is a configurable integer greater than 1 e.g. having a default value of 3 . As shown in there is performed the top k competitor analysis steps including as shown at step receiving or inputting documents data structure and document set comprising an entity s competitor non given web sites web pages to the simulator. As shown at step the simulator analyzes the competitor site s data set utilizing the steps described herein with respect to and determines a ranking of web pages. Thus in accordance with this analysis the most important terms are determined for each site comprising at least one competitor web site and any page s in the domain not belonging to the given site and its ranking is determined. Then a determination is made as to whether web page not belonging to the given site ranks higher than all the site pages for at least k important terms. In one embodiment as shown in at step for each non site page belonging to the sets of results retrieved there is performed a count for how many important terms this page is ranked higher than all the site pages. Then at step a determination is made as to whether the count value is larger than k. Then as shown at step this web page is reported as a top k dominant competitor and a the list of terms for which it dominants . The process then continues to the next step of the loop to determine whether there are any more web pages to process for the competitor s web site in which case the process returns to step and the process repeats otherwise if no more web pages of a competitor s web site are analyzed the process ends.

The simulator can additionally perform a competitor analysis and competitor comparison function. In this embodiment all the analysis as described herein with respect to can be performed for any of the competitor web pages non given web site . The full analysis is applied for one of the competitor pages. With ranking and top k dominant information a comparison of the competitor may be performed to compare the competitor page to one of the site given pages. In one embodiment a table is generated that comprises a storage for any or all meta data identified as shown at meta data extraction steps of for both pages. Then the list of important terms dominated by that competitor and their distribution in both pages is provided. Then the system automatically provides recommendations. In one embodiment as shown by the table in there is depicted an example user interface providing a list of the most important terms dominating three example webpages labeled A B and C of a given web site and for example their frequency in the entire collection which may be used to analyze a given or competitor s web site and other information that can by utilized by the simulator e.g. to provide recommendations for improving.

A further processing stage may be implemented for automatically utilizing the site findability analysis information e.g. of B obtained from the processing stages described herein with respect to and automatically analyzes the data and make recommendations for improving the given website. Recommendations are provided automatically based on the findabiltiy analysis. Example recommendations in one embodiment may include modifying the web site meta data to wit 1 if meta data does not contain important terms consider to add them 2 If pages titles repeat themselves or are too similar to external pages titles consider modifying them to be more specific 3 if the number of in links is low try to identify external sites that might be interested to link to the website content 4 if there are important terms who fail to retrieve the website consider to increase their frequency in the website etc. provides for more examples of potential recommendations to emphasize weak points in the given site. In one embodiment as depicted in an example recommendations analysis output display is generated that includes recommendations . Example recommendations may include but are not limited to a Meta data improvement e.g. improve page titles to describe the page content if same title for all site pages add important terms to the page meta data if title and keywords do not include important terms look for extra resources that will be interested to link to your site if meta data extraction reveals a Low number of in inks and identify the reasons for why site pages have not been updated in the search index for a long time or even worse are not indexed at all . In one example a recommendation may direct the user to the interface of to review the dominant competitors list and for a selected competitor website click on the analyze button of to initiate findability of the competitor web site.

Advantageously in accordance with the principles of the invention important terms can be analyzed to determine whether the important terms indeed express the main concepts a given web site is focused on.

Thus in accordance with the principles of the invention dominant competitors can be determined and analyzed such that via the analysis output display of to determine the differences between a given site s page s and the competitors which differences may be suitably emphasized or flagged for a user via a client device . Such determination is valuable as the user may learn the reasons that cause their competitors to dominant a given site s page s . It is understood that the simulator analysis is automatic but decisions are made by the content owner. The simulator identifies top k competitors important terms which fail to retrieve the site problematic meta data etc. however the simulator does not make any change in the site content this is left to the content owner.

Further via an interactive process the simulator enables the user to modify his her web site and simulate how these modifications affect its findability. As mentioned herein as shown in the search engine holds a separate mirror index where the site modifications are handled. After modifications has been applied the findability analysis is invoked over the modified site. After the user is satisfied with his her modifications and is satisfied with the new findability of the site the new modified site will be re indexed by the search engine i.e. the user will be able then to replace his her current site in the repository with the modified one.

The invention can take the form of an entirely hardware embodiment an entirely software embodiment or an embodiment containing both hardware and software elements. In a preferred embodiment the invention is implemented in software which includes but is not limited to firmware resident software microcode etc.

The invention can take the form of a computer program product accessible from a computer usable or computer readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description a computer usable or computer readable medium can be any apparatus that can contain store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus or device.

The medium can be an electronic magnetic optical electromagnetic infrared or semiconductor system or apparatus or device or a propagation medium. Examples of a computer readable medium include a semiconductor or solid state memory magnetic tape a removable computer diskette a random access memory RAM a read only memory ROM a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk read only memory CD ROM compact disk read write CD R W and DVD.

The system and method of the present disclosure may be implemented and run on a general purpose computer or computer system. The computer system may be any type of known or will be known systems and may typically include a processor memory device a storage device input output devices internal buses and or a communications interface for communicating with other computer systems in conjunction with communication hardware and software etc.

The terms computer system and computer network as may be used in the present application may include a variety of combinations of fixed and or portable computer hardware software peripherals and storage devices. The computer system may include a plurality of individual components that are networked or otherwise linked to perform collaboratively or may include one or more stand alone components. The hardware and software components of the computer system of the present application may include and may be included within fixed and portable devices such as desktop laptop and server. A module may be a component of a device software program or system that implements some functionality which can be embodied as software hardware firmware electronic circuitry or etc.

The embodiments described above are illustrative examples and it should not be construed that the present invention is limited to these particular embodiments. Thus various changes and modifications may be effected by one skilled in the art without departing from the spirit or scope of the invention as defined in the appended claims.

