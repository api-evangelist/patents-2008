---

title: Method of assigning instructions in a process to a plurality of scheduler instances based on the instruction, in which each scheduler instance is allocated a set of negoitaited processor resources
abstract: A runtime environment of a computer system is provided that creates first and second scheduler instances in a process. Each scheduler instance includes allocated processing resources and is assigned a set of tasks for execution. Each scheduler instance schedules tasks for execution using the allocated processing resources to perform the work of the process.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08650570&OS=08650570&RS=08650570
owner: Microsoft Corporation
number: 08650570
owner_city: Redmond
owner_country: US
publication_date: 20080602
---
Processes executed in a computer system often have tasks with different priorities. In order to operate as desired a process may expend significant overhead to ensure that suitable processing resources are allocated to tasks based on the priorities of the tasks. This overhead may include the use of a scheduler that schedules tasks of the process for execution in the computer system.

Processes with a single scheduler typically share processing resources among all the tasks generated by the process and apply the same scheduling policy to all tasks. Generally a process does not have the ability to directly prioritize a subset of tasks by applying a different scheduling policy to the subset. While a developer may partition subsets of tasks and assign the partition to execution contexts offered by an operating system this approach may force a developer to engineer a complex infrastructure that may not be optimal in computer systems where resources are allocated dynamically.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

A runtime environment of a computer system is provided that creates multiple scheduler instances in a process. Each scheduler instance includes allocated processing resources and is assigned a set of tasks for execution. A scheduler instance schedules tasks for execution using the allocated processing resources to perform the work of the process. In addition a task in one scheduler instance may create a nested scheduler instance.

In the following Detailed Description reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration specific embodiments in which the invention may be practiced. In this regard directional terminology such as top bottom front back leading trailing etc. is used with reference to the orientation of the Figure s being described. Because components of embodiments can be positioned in a number of different orientations the directional terminology is used for purposes of illustration and is in no way limiting. It is to be understood that other embodiments may be utilized and structural or logical changes may be made without departing from the scope of the present invention. The following detailed description therefore is not to be taken in a limiting sense and the scope of the present invention is defined by the appended claims.

It is to be understood that the features of the various exemplary embodiments described herein may be combined with each other unless specifically noted otherwise.

Runtime environment represents a runtime mode of operation in a computer system such as computer system shown in and described in additional detail below where the computer system is executing instructions. The computer system generates runtime environment from a runtime platform such as a runtime platform shown in and described in additional detail below.

Runtime environment includes an least one invoked process A a resource management layer and a set of hardware threads M where M is an integer that is greater than or equal to one and denotes the Mth hardware thread M . Runtime environment allows tasks from process A to be executed along with tasks from any other processes that co exist with process A not shown using resource management layer and hardware threads M . Runtime environment operates in conjunction with resource management layer to allow process A to obtain processor and other resources of the computer system e.g. hardware threads M . Runtime environment also operates in conjunction with resource management layer to allow multiple scheduler instances N to co exist in process A.

Runtime environment includes a scheduler function that generates each scheduler instance . In one embodiment the scheduler function is implemented as a scheduler application programming interface API . In other embodiments the scheduler function may be implemented using other suitable programming constructs. When invoked the scheduler function creates a scheduler instance in process A or another co existing process where each scheduler instance operates to schedule tasks of process A for execution by one or more hardware threads M . Runtime environment may exploit fine grained concurrency that application or library developers express in their programs e.g. process A using accompanying tools that are aware of the facilities that the scheduler function provides.

Process A includes an allocation of processing and other resources that hosts one or more execution contexts viz. threads . Process A obtains access to the processing and other resources in the computer system e.g. hardware threads M from resource management layer . Process A causes tasks to be executed using the processing and other resources.

Process A generates work in tasks of variable length where each task is associated with an execution context in a scheduler instance . Each task includes a sequence of instructions that perform a unit of work when executed by the computer system. Each execution context forms a thread or analogous OS concept such as child process that executes associated tasks on allocated processing resources. Each execution context includes program state and machine state information. Execution contexts may terminate when there are no more tasks left to execute. For each task runtime environment and or process A either assign the task to a scheduler instance to be scheduled for execution or otherwise cause the task to be executed without using a scheduler instance .

Process A may be configured to operate in a computer system based on any suitable execution model such as a stack model or an interpreter model and may represent any suitable type of code such as an application a library function or an operating system service. Process A has a program state and machine state associated with a set of allocated resources that include a defined memory address space. Process A executes autonomously or substantially autonomously from any co existing processes in runtime environment . Accordingly process A does not adversely alter the program state of co existing processes or the machine state of any resources allocated to co existing processes. Similarly co existing processes do not adversely alter the program state of process A or the machine state of any resources allocated to process A.

Resource management layer allocates processing resources to process A by assigning one or more hardware threads to process A. Resource management layer exists separately from an operating system of the computer system not shown in in the embodiment of . In other embodiments resource management layer or some or all of the functions thereof may be included in the operating system.

Hardware threads reside in execution cores of a set or one or more processor packages e.g. processor packages shown in and described in additional detail below of the computer system. Each hardware thread is configured to execute instructions independently or substantially independently from the other execution cores and includes a machine state. Hardware threads may be included in a single processor package or may be distributed across multiple processor packages. Each execution core in a processor package may include one or more hardware threads .

Process A implicitly or explicitly causes each scheduler instance N to be created via the scheduler function provided by runtime environment . A scheduler instance may be implicitly created when process A uses APIs available in the computer system or programming language features. In response to the API or programming language features runtime environment creates a scheduler instance with a default policy . To explicitly create a scheduler instance process A may invoke the scheduler function provided by runtime environment and specify one or more policies for the scheduler instance . Process A may increase or decrease the number of invoked scheduler instances throughout its execution.

Each scheduler instance interacts with resource management layer to negotiate processing and other resources of the computer system in a manner that is transparent to process . Resource management layer allocates hardware threads to scheduler instances based on supply and demand and any policies of scheduler instances .

In the embodiment shown in scheduler instances manage the processing resources by creating virtual processors that form an abstraction of underlying hardware threads . Each scheduler instance includes a set of virtual processors P where each P is an integer greater than or equal to one and denotes the Pth virtual processor P in a scheduler instance . Each scheduler instance may have the same or different numbers of virtual processors at various points in the execution of process A i.e. each P Pmay be less than greater than or equal to any other of P Pduring the execution of process A . Each scheduler instance multiplexes virtual processors onto hardware threads by mapping each virtual processor to a hardware thread . Each scheduler instance may map more than one virtual processor onto a particular hardware thread but maps only one hardware thread to each virtual processor . In other embodiments each scheduler instance manages processing resources in other suitable ways to cause instructions of process to be executed by hardware threads .

The set of execution contexts in each scheduler instance includes a set of execution contexts P with respective associated tasks P that are being executed by respective virtual processors P and at any point during the execution of process A a set of zero or more execution contexts . Each execution context and includes state information that indicates whether an execution context or is executing runnable e.g. in response to becoming unblocked or added to a scheduler instance or blocked. Execution contexts that are executing have been attached to a virtual processor and are currently executing. Execution contexts that are runnable include an associated task and are ready to be executed by an available virtual processor . Execution contexts that are blocked also include an associated task and are waiting for data a message or an event that is being generated by another execution context or will be generated by another execution context .

Each execution context executing on a virtual processor may generate in the course of its execution additional tasks which are organized in any suitable way e.g. added to work queues not shown in . Work may be created by using either application programming interfaces APIs provided by runtime environment or programming language features and corresponding tools in one embodiment. When processing resources are available to a scheduler instance tasks are assigned to execution contexts or that execute them to completion or a blocking point e.g. waiting for a message or a stolen child task to complete on virtual processors before picking up new tasks. When a task unblocks the task is re scheduled to execute on an available virtual processor possibly with priority given to choosing a virtual processor on the hardware thread where it executed before blocking in the hope that the memory hierarchy viz. cache hierarchy already contains data that can be optimally reused. An execution context executing on a virtual processor may also unblock other execution contexts by generating data a message or an event that will be used by other execution contexts .

Each task in each scheduler instance may be realized e.g. realized tasks and which indicates that an execution context or has been or will be attached to the task and the task is ready to execute. Realized tasks typically include unblocked execution contexts and scheduled agents. A task that is not realized is termed unrealized. Unrealized tasks e.g. tasks may be created as child tasks generated by the execution of parent tasks and may be generated by parallel constructs e.g. parallel parallel for begin and finish . Each scheduler instance may be organized into a synchronized collection e.g. a stack and or a queue for logically independent tasks with execution contexts i.e. realized tasks along with a list of workstealing queues for dependent tasks i.e. unrealized tasks as illustrated in the embodiment of described below.

Upon completion blocking or other interruption e.g. explicit yielding or forced preemption of a task associated with an execution context running on a virtual processor the virtual processor becomes available to execute another realized task or unrealized task . A scheduler instance searches for a runnable execution context or an unrealized task to attach to the available virtual processor for execution in any suitable way. For example a scheduler instance may first search for a runnable execution context to execute before searching for an unrealized task to execute. Each scheduler instance continues attaching execution contexts to available virtual processors for execution until all tasks and execution contexts of the scheduler instance have been executed.

Scheduler instances may have execution contexts of heterogeneous types. In embodiments of the computer system that include the Windows operating system where process A is a Windows process different scheduler instances in a Windows process may include thread execution contexts and fiber execution contexts. Accordingly thread execution contexts and fiber execution contexts may exist in the same Windows process.

Prior to executing tasks each scheduler instance obtains execution contexts and from runtime environment or an operating system e.g. OS of . Available virtual processors locate and execute execution contexts to begin executing tasks. Virtual processors become available again in response to a task associated with an execution context completing blocking or otherwise being interrupted. When virtual processors become available virtual processors switch to a runnable execution context or execute a next task or as a continuation on a current execution context if the previous task executed by the current execution context completed.

In one embodiment scheduler instances operate autonomously from each other and communicate with a common resource management layer underneath. In other embodiments scheduler instances communicate with resource management layer and with each other in order to allow work scheduled on one instance of a scheduler instance to co ordinate with work scheduled on another scheduler instance .

Scheduler instances may each have the same or different policies . Runtime environment and or process A specify policies for a scheduler instance when the scheduler instance is invoked. Policies of each scheduler instance may specify one or more of 

5 behavior types e.g. a rogue chore threshold an idle threshold a fragmentation threshold and or other resource reallocation behaviors 

6 an execution order type e.g. a last in first out LIFO order a first in first out FIFO order or a default order for quality of service or ordering guarantees and

7 a topology type i.e. information that specifies a particular locality characteristic e.g. a set of related processing resources in a computer system and or information that specifies a particular resource characteristic e.g. a set of processing resources with selected chipset capabilities in a computer system .

In addition to process A other co existing processes in runtime environment not shown may include zero or more scheduler instances that may increase or decrease throughout the execution of the processes.

At least first and second scheduler instances and are created in process A as indicated in a block . Scheduler instances and each include instructions executable by the computer system to cause respective sets of one or more tasks assigned by runtime environment and or process A to be executed on respective subsets of processing resources. The set of processing resources includes hardware threads and in one embodiment also includes virtual processors allocated by resource management layer . Where resource management layer allocates sets of virtual processors to scheduler instances and the sets of virtual processors represent respective subsets of processor resources i.e. hardware threads of the computer system. Accordingly resource management layer maps each sets of virtual processors to a respective set of hardware threads .

Scheduler instances and may be implicitly or explicitly initiated by runtime environment and or process A using the scheduler function of runtime environment as described above. Scheduler instances and may also be initiated at the same time e.g. when process A is initiated or at different times during the execution of process A. In addition scheduler instances and may have the same or different policies .

Runtime environment and or process A assigns a set of one or more tasks to scheduler instance for execution and a set of one or more tasks to scheduler instance for execution. Runtime environment and or process A may assign sets of tasks based on respective policies of scheduler instances and as described in additional detail below with reference to or based on other criteria.

Referring to a first set of tasks is scheduled for execution by scheduler instance as indicated in a block . When a virtual processor of scheduler instance becomes available scheduler instance attaches an execution context to the available virtual processor and associates a task from the set of tasks in scheduler instance with the execution context to cause the task to be executed by the virtual processor via the underlying hardware thread . Scheduler instance continues executing tasks from the set of tasks until all of the tasks in scheduler instance have been executed.

Likewise a second set of tasks is scheduled for execution by scheduler instance as indicated in a block . When a virtual processor of scheduler instance becomes available scheduler instance attaches an execution context to the available virtual processor and associates a task from the set of tasks in scheduler instance with the execution context to cause the task to be executed by the virtual processor via the underlying hardware thread . Scheduler instance continues executing tasks from the set of tasks until all of the tasks in scheduler instance have been executed.

An example of the use of the method of will now be described according to one embodiment. In this example process A is an application that performs audio and video processing and the audio processing takes priority over the video processing. Accordingly process A invokes a first scheduler instance with a high number of processing resources to perform the audio processing and a second scheduler instance with a low number of processing resources to perform the video processing. Runtime environment assigns a set of tasks related to the audio processing to scheduler instance as specified by process A and assigns a set of tasks related to the video processing to scheduler instance as specified by process A. If the number of processing resources allocated to process A changes runtime environment may adjust the number of processing resources allocated to scheduler instances and or while ensuring that scheduler instance has sufficient processing resources for the higher priority audio processing.

Runtime environment may provide process A with the ability to request a scheduler instance with one or more policies that most closely match one or more policies specified by process A. Runtime environment searches scheduler instances in process A and selects the scheduler instance based on pre defined heuristics which may be configured.

Referring back to the example above where process A performs audio and video processing runtime environment may determine from respective policies of scheduler instances and that a scheduler instance is configured to have more processing resources than scheduler instance . Accordingly runtime environment may assign higher priority audio processing tasks to scheduler instance as specified by process A and lower priority video processing tasks to scheduler instance as specified by process A.

The use of multiple scheduler instances as described above with reference to may advantageously provide a way of specifying policy restrictions on partitions of work in process A. Process developers may choose to create several scheduler instances in a process each with a different policy and cause units of work to be pushed onto suitable scheduler instances depending on the nature of the work. Developers may tune the parameters of policies of scheduler instances to affect throughput or responsive of processes as desired.

In addition to sets of tasks assigned to scheduler instances process A may obtain access to processing resources that are separate from those allocated to scheduler instances . For example runtime environment may allow process A to be allocated virtual processors from resource management layer in addition to those allocated to scheduler instances . Runtime environment and or process A may cause selected sets of tasks to be executed on these separate processing resources to cause the selected execution contexts to be executed without using scheduler instances .

As shown in the embodiments of and runtime environment also allows an execution context to dynamically nest a new scheduler instance within an existing scheduler instance . A task that is executing on an execution context in an existing scheduler instance may invoke the scheduler function of runtime environment in order to create a new instance of a scheduler instance . are block diagrams illustrating embodiments of scheduler instances and existing side by side in a process B where an execution context of scheduler instance nests scheduler instance within scheduler instance . is a flow chart illustrating an embodiment of a method for creating a nested scheduler instance on an execution context initially belonging to scheduler in process B.

Referring to a first scheduler instance is created in process B as indicated in a block . In the example of scheduler instance includes a set of virtual processors and which are executing execution contexts and respectively. Scheduler instance also includes a pool of execution contexts that are waiting to be executed and policies . Each execution context and includes data that identifies scheduler instance . Data is stored with each execution context and as a result of each execution context and being allocated to scheduler instance . Data may be stored in a stack in local storage of each execution context and and represents the first entry that has been pushed onto the stack in one embodiment.

A task executing on an execution context in scheduler instance in process B may cause a second scheduler instance to be created as indicated in a block . Policies of scheduler instance may differ from policies of scheduler instance to allow scheduler instances and to execute different sets of tasks with different performance characteristics. In the example of task executing on execution context causes scheduler instance to be created with policies and thereby dynamically nests scheduler instance in execution context . A virtual processor within scheduler instance picks up execution context for execution. In scheduler instance virtual processor which was previously assigned to execution context becomes available to execute other tasks in scheduler . Accordingly virtual processor in scheduler instance picks execution context to execute task 

Data that identifies scheduler instance is stored with execution context as a result of execution context being moved to scheduler instance . Data may be stored in a stack in local storage of execution context and is pushed on top of the first entry in the stack which includes data in one embodiment. The top entry of the stack indicates the present scheduler instance for each execution context .

The nested scheduler instance may be created with additional virtual processors such as a virtual processor as shown in the example of .

Scheduler instances and each schedule respective sets of tasks for execution using respective sets of virtual processors as indicated in a block .

Scheduler instance continues to schedule tasks of scheduler instance for execution on virtual processors and of scheduler instance and scheduler instance schedules tasks of scheduler instance which are generated by task on execution context for execution on virtual processors and of scheduler instance .

Runtime environment and or process B may continue to assign additional sets of tasks to scheduler instance which are picked up by execution contexts and for execution. Data that identifies scheduler instance is stored with any additional execution contexts allocated to scheduler instance .

Runtime environment and or process B however allows only tasks which are generated by task on execution context to be assigned to nested scheduler instance . In the example of a task on execution context is being executed by virtual processor and a pool of execution contexts are waiting to be executed by scheduler instance . Data that identifies scheduler instance is stored with execution contexts and in scheduler instance .

Execution context may eventually be returned to scheduler instance as indicated in a block . To do so data is removed from execution context so that data indicates that execution context belongs to scheduler instance . Where data and are stored as a stack data is popped from the top of the stack and data returns to the top of the stack. A virtual processor of scheduler picks up execution context for execution.

Using the method of any number of scheduler instances may be stacked or nested on each execution context where each scheduler instance includes a desired policy that may differ from the policies of other scheduler instances . Each execution context includes data that identifies an assigned scheduler instance . New data that identifies a new scheduler instance is added e.g. onto the stack to an execution context each time that the execution context moves to a new scheduler instance .

In other embodiments a nested scheduler instance may be more closely integrated with a parent scheduler instance to potentially allow resource sharing between the parent and nested scheduler instances .

Using the method of library developers may advantageously create libraries that nest scheduler instances with selected scheduler policies or policy preferences. This may allow a library developer to ensure that library functions in the library execute with the most suitable scheduler policies for the functions regardless of the scheduler policies of the overlying process. For example task on execution context may represent a library function called by process B in the example of . By using scheduler instance execution context may execute more efficiently than if it was executed by scheduler instance .

In one embodiment processes A and B organize tasks into one or more schedule groups and presents schedule groups to scheduler instances . is a block diagram illustrating an embodiment of a schedule group for use in a scheduler instance .

Schedule group includes a runnables collection a realized task collection a work collection and a set of zero or more workstealing queues . Runnables collection contains a list of unblocked execution contexts . A scheduler instance adds an execution context to runnables collections when an execution context becomes unblocked. Realized task collection contains a list of realized tasks e.g. unstarted agents that may or may not have associated execution contexts . A scheduler instance adds a realized task to realized task collection when a new runnable task is presented to a scheduler instance by process . Work collection contains a list of workstealing queues as indicated by an arrow and tracks the execution contexts that are executing tasks from the workstealing queues . Each workstealing queue includes one or more unrealized tasks .

Using the embodiment of a scheduler instance may first search for unblocked execution contexts in the runnables collection of each schedule group in the scheduler instance . The scheduler instance may then search for realized tasks in the realized task collection of all schedule groups in the scheduler instance before searching for unrealized tasks in the workstealing queues of the schedule groups .

In one embodiment a virtual processor that becomes available may attempt to locate a runnable execution context in the runnables collection or a realized task in the realized task collection in the schedule group from which the available virtual processor most recently obtained a runnable execution context i.e. the current schedule group . The available virtual processor may then attempt to locate a runnable execution context in the runnables collections or a realized task in the realized task collection in the remaining schedule groups of the scheduler instance in a round robin or other suitable order. If no runnable execution context is found then the available virtual processor may then attempt to locate an unrealized task in the workstealing queues of the current schedule group before searching the workstealing queues in the remaining schedule groups of the scheduler instance in a round robin or other suitable order.

Computer system represents any suitable processing device configured for a general purpose or a specific purpose. Examples of computer system include a server a personal computer a laptop computer a tablet computer a personal digital assistant PDA a mobile telephone and an audio video device. The components of computer system i.e. processor packages memory system input output devices display devices peripheral devices network devices and interconnections may be contained in a common housing not shown or in any suitable number of separate housings not shown .

Processor packages include hardware threads M . Each hardware thread in processor packages is configured to access and execute instructions stored in memory system . The instructions may include a basic input output system BIOS or firmware not shown an operating system OS a runtime platform applications and resource management layer also shown in . Each hardware thread may execute the instructions in conjunction with or in response to information received from input output devices display devices peripheral devices and or network devices .

Computer system boots and executes OS . OS includes instructions executable by hardware threads to manage the components of computer system and provide a set of functions that allow applications to access and use the components. In one embodiment OS is the Windows operating system. In other embodiments OS is another operating system suitable for use with computer system .

Resource management layer includes instructions that are executable in conjunction with OS to allocate resources of computer system including hardware threads as described above with reference to . Resource management layer may be included in computer system as a library of functions available to one or more applications or as an integrated part of OS .

Runtime platform includes instructions that are executable in conjunction with OS and resource management layer to generate runtime environment and provide runtime functions to applications . These runtime functions include a scheduler function as described in additional detail above with reference to . The runtime functions may be included in computer system as part of an application as a library of functions available to one or more applications or as an integrated part of OS and or resource management layer .

Each application includes instructions that are executable in conjunction with OS resource management layer and or runtime platform to cause desired operations to be performed by computer system . Each application represents one or more processes such as processes A and B described above that may execute with multiple scheduler instances as provided by OS resource management layer and or runtime platform .

Memory system includes any suitable type number and configuration of volatile or non volatile storage devices configured to store instructions and data. The storage devices of memory system represent computer readable storage media that store computer executable instructions including OS resource management layer runtime platform and applications . The instructions are executable by computer system to perform the functions and methods of OS resource management layer runtime platform and applications described herein. Examples of storage devices in memory system include hard disk drives random access memory RAM read only memory ROM flash memory drives and cards and magnetic and optical disks.

Memory system stores instructions and data received from processor packages input output devices display devices peripheral devices and network devices . Memory system provides stored instructions and data to processor packages input output devices display devices peripheral devices and network devices .

Input output devices include any suitable type number and configuration of input output devices configured to input instructions or data from a user to computer system and output instructions or data from computer system to the user. Examples of input output devices include a keyboard a mouse a touchpad a touchscreen buttons dials knobs and switches.

Display devices include any suitable type number and configuration of display devices configured to output textual and or graphical information to a user of computer system . Examples of display devices include a monitor a display screen and a projector.

Peripheral devices include any suitable type number and configuration of peripheral devices configured to operate with one or more other components in computer system to perform general or specific processing functions.

Network devices include any suitable type number and configuration of network devices configured to allow computer system to communicate across one or more networks not shown . Network devices may operate according to any suitable networking protocol and or configuration to allow information to be transmitted by computer system to a network or received by computer system from a network.

Although specific embodiments have been illustrated and described herein it will be appreciated by those of ordinary skill in the art that a variety of alternate and or equivalent implementations may be substituted for the specific embodiments shown and described without departing from the scope of the present invention. This application is intended to cover any adaptations or variations of the specific embodiments discussed herein. Therefore it is intended that this invention be limited only by the claims and the equivalents thereof.

