---

title: Application delivery control module for virtual network switch
abstract: A virtualized platform includes a virtual switch connected to the virtual network interface cards (vNICs) for a group of virtual machines running the same application program that is associated with multiple software ports. A module in the virtualized platform monitors the virtual switch's receipt of a network packet that includes control information relating to the application program and its software ports. The module applies a load balancing algorithm to select a vNIC from the vNICs connected or connectable to the virtual switch, based on the rate of processing of previous network packets by each the vNICs (e.g., as measured by the size of a network packet queue). The module might also apply the load balancing algorithm to select a software port for the application. The module then causes the virtual switch to route the network packet to the selected vNIC and software port.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07962647&OS=07962647&RS=07962647
owner: VMware, Inc.
number: 07962647
owner_city: Palo Alto
owner_country: US
publication_date: 20081124
---
In computing it is often useful to think of virtualization defined broadly in this application to include paravirtualization as falling into two major categories platform or machine virtualization and resource virtualization. Typically platform virtualization involves the creation of a virtual machine through the use of a software abstraction layer which separates an operating system from its hardware resources in terms of processing e.g. CPU memory and I O e.g. storage BIOS etc. . In some implementations the abstraction layer extends to network I O e.g. through the use of software abstractions such as virtual network interface cards vNICs and virtual switches. It will be appreciated that the virtual machine in platform virtualization is a hardware or system virtual machine as opposed to a process or application virtual machine such as the Java Virtual Machine. Examples of platform virtualization include the VMware ESX and Citrix XenServer hypervisors both of which enable virtualization for platforms based on the x86 and x86 64 architectures e.g. platforms in which the guest operating system might be non Itanium Linux or Windows . Informally one might think of platform virtualization as creating a virtualized environment or as making one machine work as many machines 

Resource virtualization involves the virtualization of specific system resources such as storage volumes or network resources. Typically resource virtualization does not involve the creation of virtual machines with guest operating systems. Examples of resource virtualization include Beowolf cluster virtualization and the Linux Virtual Server LVS which creates a load balanced virtual server from a cluster of Linux based physical servers without recourse to virtual machines with guest operating systems. Informally one might think of resource virtualization as making many machines look as one machine .

It will be appreciated that load balancing is a technique to spread work among two or more computers microprocessors or other resources such as hard drives or network connections in order to achieve a more optimal resource utilization throughput response time uptime etc. It is often used to spread work among a cluster of servers running the same application program e.g. an Internet server program database server program or other application that tends to involve a large amount of I O. Usually load balancing functionality is provided by a dedicated program or hardware device. Examples of such hardware devices are the Citrix NetScaler and the F5 BIG IP which operate at layers 4 7 of the of the Open Systems Interconnection Basic Reference OSI Model and are referred to as application switches. These hardware devices were not originally designed for virtualized platforms and are not optimized to perform with vNICs virtual switches etc. That is to say these hardware devices are not virtualization aware . Further they tend to be relatively expensive.

In particular implementations of the ESX hypervisor virtual switches enable load balancing to spread the network traffic from one or more vNICs in an arrangement that is referred to as NIC teaming. See VMware Inc. 2007 which is incorporated by reference herein. When NIC teaming is in place one can use load balancing to choose a physical NIC for routing based on a the originating virtual switch port ID b a hash of the source MAC Media Access Control address or c a hash of the source and destination IP Internet Protocol addresses. Load balancing in conjunction with NIC teaming makes use of and is constrained by a network packet s control information for layer 2 of the OSI Model e.g. the data link layer.

In an example embodiment a virtualized platform includes a virtual switch connected to the vNICs for a group of virtual machines running the same application program that is associated with multiple software e.g. TCP or UDP ports. A module in the virtualized platform monitors the virtual switch s receipt of network packets that include control information relating to the application program and its software ports. The module applies a load balancing algorithm to select a vNIC from the vNICs connected to the virtual switch based on the rate of processing of previous network packets by each the vNICs e.g. as measured by the size of a network packet queue for the vNIC . The module then causes the virtual switch to route the network packet to the selected vNIC. In an example embodiment the module might launch a virtual machine running the application program and connect one or more vNICs associated with the virtual machine to the virtual switch if the virtual machine is not already running when the vNIC is selected by the load balancing algorithm. Also in an example embodiment the module might apply the load balancing algorithm to select a software port for the application in addition to or instead of a vNIC based on the rate of processing of previous network packets by each of the software ports associated with the application program e.g. as measured by the size of a network packet queue for the software port .

In an alternative example embodiment a virtualized platform includes a virtual switch connected to the vNICs for a group of virtual machines running the same application program that is associated with multiple software e.g. TCP or UDP ports. A module in the virtualized platform applies a method including the operations of 1 monitoring the virtual switch s receipt of network packets that include control information relating to the application program and its software ports 2 applying a load balancing algorithm to select a vNIC from the vNICs connected to the virtual switch based on the rate of processing of previous network packets by each the vNICs e.g. as measured by the size of a network packet queue for the vNIC and 3 causing the virtual switch to route the network packet to the selected vNIC. In an example embodiment the method might further include the operation of launching a virtual machine running the application program and connecting a vNIC associated with the virtual machine to the virtual switch if the virtual machine is not already running when the vNIC is selected by the load balancing algorithm. Also in an example embodiment the method might include the operation of applying the load balancing algorithm to select a software port for the application in addition to or instead of a vNIC based on the rate of processing of previous network packets by each of the software ports associated with the application program e.g. as measured by the size of a network packet queue for the software port .

In yet another example software encoded in one or more computer readable media for execution by a processor is disclosed. The software when executed operable to receive a plurality of network packets destined for an application program running on a plurality of virtual machines. Each of the plurality of virtual machines is connected to a distributed virtual switch by a virtual network interface card. Each of the network packets includes control information relating to one or more of layers 4 7 of the Open Systems Interconnection Basic Reference OSI Model and wherein the distributed virtual switch enables inheritance of policies applicable to a cluster of host systems. The software when executed further operable to load balance the network packets among the plurality of virtual machines at least in part on the basis of the control information and the rate of processing of the network packets by the virtual network interface cards.

In an example embodiment each vNIC might be a virtual Ethernet adapter e.g. Layer 2 of the OSI Model with its own MAC address and unicast multicast broadcast filter. The virtual Ethernet adapter might emulate the AMD Lance PCNet 32 Ethernet adapter or the Intel E1000 Ethernet adapter e.g. in the case of a virtual machine comprising a guest operating system that is 64 bit. . Alternatively the virtual Ethernet adapter might be a paravirtualized device. It will be appreciated that the speed and duplex settings found in physical networking are not relevant in a virtual network because all the data transfer takes place in the random access memory RAM of the host system e.g. an x86 or x86 64 server running a hypervisor nearly instantaneously and without the possibility of collisions or other signaling related errors. It will also be appreciated that another type of vNIC e.g. a virtual token ring adapter as opposed to a virtual Ethernet adapter might be used in an alternative example embodiment. Further it will be appreciated that another type of host system e.g. a Power architecture server such as a Cell Broadband Engine Architecture server running a hypervisor or virtual machine monitor might be used in an alternative example embodiment.

Running on top of the network stack are the virtual Ethernet adapters e.g. vNICs and virtual switches collectively identified as . In the example embodiment shown in a module for load balancing network traffic among vNICs and or software ports might be located at position in the software stack where the module would have access to the vNICs and virtual switches in the hypervisor as well as the network packets defined broadly in this application to include data link layer frames stored in the RAM of the host system e.g. an x86 or x86 64 server running the hypervisor . In other example embodiments the load balancing functionality described below might be located in an appliance virtual machine or in server management software both of which are described further below.

In an example embodiment a virtual switch might work in much the same way as a physical e.g. Ethernet switch. That is a virtual switch might perform the following operations 1 maintaining a MAC port forwarding table 2 looking up a frame s destination MAC e.g. in the frame s layer 2 Ethernet header when the frame arrives 3 forwarding a frame to one or more ports for transmission and 4 avoiding unnecessary deliveries e.g. the virtual switch is not a hub . Further the ports on a virtual switch provide logical connection points among virtual devices and between virtual and physical devices. One might think of the ports on a virtual switch as virtual registered jack RJ connectors. Virtual switch ports provide a control channel for communication with the vNICs e.g. virtual Ethernet adapters attached to them since the virtual switch ports a know authoritatively what the configured receive filters are for attached vNICs e.g. no MAC learning is required to populate forwarding tables and 2 know authoritatively the hard configuration of attached vNICs unlike physical switches . This capability makes it possible to set policies such as guest operating system cannot change MAC address because the virtual switch port knows what is burned into ROM e.g. stored in the configuration file outside control of the guest operating system . Also this capability allows the virtual switch to dispense with the physical switch tasks of learning unicast addresses or performing Internet Group Management Protocol IGMP snooping to learn multicast group membership.

In an example embodiment a physical NIC might connect to a virtual switch through a virtual port when the physical NIC is initialized by a device driver or when the teaming policies for a virtual switch are reconfigured. A vNIC e.g. a virtual Ethernet adapter might connect to a virtual switch through a virtual port a during powering on of the virtual machine on which the vNIC is configured b during an explicit action to connect the vNIC or c during migration of a virtual machine using VMotion e.g. live migration of a virtual machine from one physical server to another with minimal down time . A vNIC e.g. a virtual Ethernet adapter updates the virtual port with MAC filtering information when it is initialized and whenever it changes. A virtual port might ignore any requests from the vNIC e.g. a virtual Ethernet adapter that would violate the Layer 2 security policy in effect for the virtual port in an example embodiment. For example if the policy is that MAC spoofing is blocked the virtual port might drop any packets which violate that policy

In an example embodiment each virtual switch might have up to approximately 1 016 virtual ports with a limit of approximately 4 096 virtual ports on all virtual switches on a host system e.g. an x86 or x86 64 server running a hypervisor . Further a single host system might have a maximum of approximately 32 physical NICs e.g. Ethernet adapters which might be on one virtual switch or distributed among a number of virtual switches.

To some extent is an extension of . As shown a virtual machine e.g. VM comprising a guest operating system e.g. running an application program e.g. might be associated with one or more vNICs e.g. . In turn each of these vNICs might be associated with a virtual switch e.g. through the use of a virtual port . Also a virtual switch might be associated with one or more virtual ports e.g. associated with a physical NIC . In an example implementation one or more of the physical NICs e.g. might connect a virtual machine e.g. VM with a vNIC e.g. to a production LAN local area network . It will be appreciated that a production LAN is a live network that is engaged in the processing of network transactions. Also as shown in one or more of the physical NICs e.g. might connect a service console e.g. a management interface which might comprise a graphical user interface or GUI with a vNIC to a management LAN . It will also be appreciated that the functionality provided by vNIC and vNIC might be similar but not identical in an example embodiments as explained in VMware Inc. 2007 incorporated by reference.

Also as depicted in the appliance virtual machine communicates with the virtual machines e.g. VM on the host system through shared memory messaging such as that enabled by a Virtual Machine Communication Interface VMCI . In an example embodiment the appliance virtual machine might monitor and report results on a virtual machine s network traffic and health e.g. metrics related to availability and or performance to the server management software . It will be appreciated that by providing this functionality the appliance virtual machine frees up the hypervisor to perform other tasks such as resource scheduling.

In the process s second operation the load balancing module determines if the vNICS e.g. virtual Ethernet adapters for the primary virtual machine are becoming heavily loaded with incoming network packets or if the primary virtual machine is becoming unavailable. If so in the process s third operation the load balancing module causes the virtual switch to route the stored incoming network packets to a redundant secondary virtual machine running the same application program. In the event that such a redundant secondary virtual machine is not already running the load balancing module might launch the redundant secondary virtual machine and the application. In an example embodiment the load balancing module might perform the launch using functionality such as a advanced host profiling e.g. with a template for a virtual machine stored in a virtual machine library VMCI and DVS or b VMotion . Here it will be recalled that the VMCI described above permits the hypervisor to perform operations on an application program running on a guest operating system using messages in shared memory and that the DVS described above allows a virtual switch to inherit policies configured at the level of a cluster of host systems rather than at the level of a single host system. As indicated in the process shown in the figure would work equally well with outgoing network packets from an application program. In this regard the load balancing module might associate each virtual machine running an application with a particular transmit receive queue in a physical NIC with multiple transmit receive queues in an example embodiment.

In an example embodiment the results reporting in operation might involve a daemon e.g. a background process which runs in the VMkernel see in and which collects data related to network traffic and the health e.g. metrics related to availability and or performance of the host system e.g. its hardware hypervisor guest operating systems virtual machines application programs etc. . Additionally or alternatively the results reporting might involve the console service e.g. described in . For example the console service might display the results using graphics in a graphical user interface GUI . In another alternative example embodiment an appliance virtual machine might retrieve the results from the daemon and transmit them to server management software for display on a GUI as described above or even display them on the console service s GUI.

As indicated in operation the load balancing module might report the results to a health monitoring module in an example embodiment. In turn the health monitoring module might take corrective action based on the results e.g. launching a redundant virtual machine running the same application program or using VMotion to move a virtual machine running an application to another host system without involving the user unless the corrective action fails. If the corrective action succeeds the health monitoring module might report that result along with the results from the load balancing module to the user e.g. through the use of the daemon the console service an appliance and or server management software.

The operations described in involve a single virtual machine. However it will be appreciated that the operations described in that figure are equally applicable to a scenario in which multiple virtual machines with multiple vNICs are running the same software application with multiple software ports. All of the load balancing algorithms described below and elsewhere could also be used in this scenario.

It will also be appreciated that numerous load balancing algorithms might be employed in operation including by way of example 1 round robin scheduling 2 weighted round robin scheduling 3 least connection scheduling 4 weighted least connection scheduling 5 locality based least connection scheduling 6 locality based least connection with replication scheduling 7 destination hashing scheduling 8 source hashing scheduling 9 shortest expected delay scheduling and 10 never queue scheduling.

In an example embodiment the load balancing algorithm employed in operation might make use of a network packet s control information for layers 4 7 of the OSI Model. It will be appreciated that the latter OSI layers deal with a network packet s control information related to software ports e.g. TCP and UDP and applications e.g. HTTP and FTP . Additionally the load balancing algorithm might be based in whole or in part on the content of the payload of the network packets like a content or application switch. In an example embodiment the load balancing module employs a load balancing algorithm that depends upon dynamic feedback which in this instance involves monitoring of the rate of processing by the each of the vNICs and or by each of the software ports of the network packets stored in the RAM of the host system e.g. as measured by the size of a network packet queue for the vNIC or the software port . Additionally or alternatively the load balancing algorithm might be configurable by a user to handle a particular use case. So for example the user might configure the load balancing algorithm to use vNICs and or software ports in a particular sequence in the event of heavy loading or unavailability.

Programming instructions for executing above described methods are provided. The programming instructions are stored in a computer readable media.

With the above embodiments in mind it should be understood that one or more embodiments of the invention may employ various computer implemented operations involving data stored in computer systems. These operations are those requiring physical manipulation of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. Further the manipulations performed are often referred to in terms such as producing identifying determining or comparing.

Any of the operations described herein that form part of one or more embodiments of the invention are useful machine operations. One or more embodiments of the invention also relates to a device or an apparatus for performing these operations. The apparatus may be specially constructed for the required purposes such as the carrier network discussed above or it may be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular various general purpose machines may be used with computer programs written in accordance with the teachings herein or it may be more convenient to construct a more specialized apparatus to perform the required operations.

The programming modules and software subsystems described herein can be implemented using programming languages such as Flash JAVA C C C Visual Basic JavaScript PHP XML HTML etc. or a combination of programming languages. Commonly available protocols such as SOAP HTTP may be used in implementing interfaces between programming modules. As would be known to those skilled in the art the components and functionality described above and elsewhere herein may be implemented on any desktop operating system such as different versions of Microsoft Windows Apple Mac Unix X Windows Linux etc. executing in a virtualized or non virtualized environment using any programming language suitable for desktop software development.

The programming modules and ancillary software components including configuration file or files along with setup files required for providing the method and apparatus for troubleshooting subscribers on a telecommunications network and related functionality as described herein may be stored on a computer readable medium. Any computer medium such as a flash drive a CD ROM disk an optical disk a floppy disk a hard drive a shared drive and storage suitable for providing downloads from connected computers could be used for storing the programming modules and ancillary software components. It would be known to a person skilled in the art that any storage medium could be used for storing these software components so long as the storage medium can be read by a computer system.

One or more embodiments of the invention may be practiced with other computer system configurations including hand held devices microprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like. The invention may also be practiced in distributing computing environments where tasks are performed by remote processing devices that are linked through a network.

One or more embodiments of the invention can also be embodied as computer readable code on a computer readable medium. The computer readable medium is any data storage device that can store data which can thereafter be read by a computer system. Examples of the computer readable medium include hard drives network attached storage NAS read only memory random access memory CD ROMs CD Rs CD RWs DVDs Flash magnetic tapes and other optical and non optical data storage devices. The computer readable medium can also be distributed over a network coupled computer systems so that the computer readable code is stored and executed in a distributed fashion.

While one or more embodiments of the present invention have been described it will be appreciated that those skilled in the art upon reading the specification and studying the drawings will realize various alterations additions permutations and equivalents thereof. It is therefore intended that embodiments of the present invention include all such alterations additions permutations and equivalents as fall within the true spirit and scope of the invention as defined in the following claims. Thus the scope of the invention should be defined by the claims including the full scope of equivalents thereof.

