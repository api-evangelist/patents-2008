---

title: System and method for adding a disk to a cluster as a shared resource
abstract: A system and method are described for adding a disk to a cluster as a shared resource. In one embodiment, a request is received to add a disk to a cluster as a shared disk resource. The disk may share a disk identifier with a second disk currently connected to the cluster as a shared resource. A determination is made as to which partition format is used by the disk. A unique disk identifier is retrieved and written to the disk in accordance with the determined partition format. The disk is then connected to the node as a shared disk resource. The disk may be a snapshot, mirror, or backup of the second disk currently connected to the cluster.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08095753&OS=08095753&RS=08095753
owner: NetApp, Inc.
number: 08095753
owner_city: Sunnyvale
owner_country: US
publication_date: 20080618
---
A cluster is a group of individual servers or nodes configured to appear as a single virtual server to both users and applications. The nodes are physically connected by cables and programmatically connected by clustering software such as Microsoft s Cluster Server and Microsoft s Failover Cluster . The clustering software may run on each node and manage all cluster specific activity. The cluster nodes may be attached to one or more shared disks by a shared bus. The clustering software differentiates between the shared disks by using a disk identifier stored on the disks themselves.

If a cluster node attempts to connect to a disk having the same disk identifier as a shared disk currently connected to another node in the cluster such as a backup or snapshot of an existing disk on the cluster the clustering software will be unable to differentiate between the two disks rendering the new disk inaccessible. Thus there may be a need for enabling a disk to be added to a cluster as a shared resource when the disk has the same disk identifier as an existing shared disk resource on the cluster.

In these embodiments a system is presented for adding a disk to a cluster node as a shared disk resource irrespective of the unique identifier or partition type of the disk which provides an advantage over the prior systems by allowing a disk to be added to a cluster as a shared disk resource regardless of whether the disk shares a disk identifier with an existing shared disk resource on the cluster. Allowing a disk to be added to a cluster as a shared disk resource irrespective of the unique identifier or partition type of the disk enables adding copies of shared disks to the same cluster which hosts the shared disks the copies originate from. Examples of copies of shared disks may include snapshot disks mirror disks and backup disks. Snapshot mirror and backup disks provide access to copies of files directories or entire disks at a particular moment in time. Allowing snapshot mirror and backup disks to be connected to a node on a cluster where the cluster also contains the original disks may greatly reduce the costs associated with data integrity regulatory compliance and testing operations on the cluster. For example these operations can be performed without the need for a separate host to perform them.

The system in these embodiments enables adding any disk to a cluster as a shared disk resource without generating conflicts with existing shared disks on the cluster. When a request to add a disk to a cluster node is received a determination is made as to which partition format is utilized by the disk. A unique identifier is retrieved from the clustering software and written to the disk in accordance with the partition format. The disk can then be connected to the cluster node as a shared disk resource.

The partition format of the disk can be any self identifying or non self identifying format such as the globally unique partition table GPT partition format or the master boot record MBR partition format. The disk added to the cluster can be a snapshot backup or mirror disk. The disk may be a snapshot backup or mirror disk of an existing shared disk resource on the cluster. The disk to be added also may have the same disk identifier as a shared disk resource on the cluster.

Since the system writes a new disk identifier to the disk there will be no conflicts with existing shared disk resources on the cluster. Furthermore since the disk identifier was written in accordance with the partition format of the disk there is no risk of corrupting the disk or otherwise rendering the disk inaccessible.

Other systems methods features and advantages will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems methods features and advantages be included within this description be within the scope of the embodiments and be protected by the following claims and be defined by the following claims. Further aspects and advantages are discussed below in conjunction with the description.

Turning now to the drawings provides a general overview of a system of an embodiment for adding a disk to a cluster as a shared disk resource. Not all of the depicted components may be required however and some implementations may include additional components. Variations in the arrangement and type of the components may be made without departing from the spirit or scope of the claims as set forth herein. Additional different or fewer components may be provided.

In this embodiment system includes a cluster containing cluster nodes A N also referred to as nodes connected to disks A N. Disks A N may be logical storage volumes such as the logical unit numbers LUNs A N in below. Nodes A N may be programmatically connected using clustering software such as Microsoft s Cluster Server and Microsoft s Failover Cluster . The functionality provided by the system may be integrated into the clustering software or may be provided by a third party software application such as NetApp s SnapDrive .

Any of nodes A N may access any of disks A N however the clustering software may only allow one of nodes A N to access a particular disk at a time. Disks A N may utilize a partition format to organize the data stored on the disks A N. In one embodiment the partition format may be a self identifying partition format such as the GPT format or a non self identifying partition format such as an MBR format. Each of the disks A N may store a disk identifier. The disk identifier is used by the clustering software to differentiate between the disks A N connected to the nodes A N on the cluster . The disk identifier may also be used by the underlying operating system or third party applications to identify the disks A N. Each of the partition formats may use separate protocols for writing the disk identifier on the disks A N. For example self identifying partitions may write a backup of the disk identifier to the disk while the non self identifying partitions may not. Thus when writing the disk identifier to a disk utilizing a self identifying partition two separate values may need to be written whereas setting the disk on a disk utilizing a non self identifying partition may only require writing one value.

In one operation disk B B may be a copy of disk A A such as a snapshot mirror or backup of disk A A. Since disk A A and B B are copies disk A A and B B share the same disk identifier. Node A A may be connected to disk A A when the system receives a request from the node B B to connect to disk B B. The system retrieves a unique identifier from the underlying operating system such as Microsoft Windows Server 2003 or Microsoft Windows Server 2008 via an application programming interface API . The system determines the partition format utilized by disk B B such as a self identifying partition or a non self identifying partition. The system sets the disk identifier of disk B B to the retrieved unique identifier in accordance with the disk identifier write protocol associated with the partitioning format utilized by disk B B. The system achieves increased efficiency by writing the disk identifier of disk B B irrespective of whether the unique identifier was previously written. Thus regardless of whether this is first time disk B B is connected to the cluster or whether disk B B has been previously connected to the cluster the system sets the disk identifier of disk B B to the retrieved unique identifier. The system then connects disk B B to the node B B. Since the system has updated the disk identifier of disk B B disk B B no longer contains the same disk identifier as disk A A. Thus the clustering software will recognize disk B B as a new disk not as disk A A.

The cluster may include a cluster database which stores the configuration information for the cluster nodes A N. The configuration information may include which nodes A N are part of the cluster what resources are installed in the cluster and what state those resources are in such as offline offline pending online online pending or failed. The cluster database may be part of a quorum resource which is typically a shared disk resource connected to the cluster . The cluster database may identify the LUNs A N in the cluster database by their disk identifiers. The disk identifier of a GPT disk may be the disk globally unique identifier GUID and the disk identifier of an MBR disk may be the disk signature. The disk identifiers of GPT and MBR disks are discussed in more detail in below.

Each of the devices attached to the network includes an appropriate conventional network interface arrangement not shown for communicating over the network using desired communication protocols such as the well known Transport Control Protocol Internet Protocol TCP IP User Datagram Protocol UDP Hyper Text Transport Protocol HTTP Simple Network Management Protocol SNMP or Virtual Interface Connections VI .

In operation the cluster may utilize snapshot technology to perform data protection and other tasks such as data mining and data cloning on one or more of the LUNs A N. The snapshot technology may be provided on a cluster node A A by NetApp s SnapDrive or on the file server by NetApp s Data ONTAP file operating system. The snapshot technology may be capable of creating a point in time image of data referred to as a snapshot of the data. The data may include files directories and or entire LUNs. A snapshot of an entire LUN will have the same disk identifier as the original LUN.

For example the LUN A A may be connected to the node A A. The node A A may use NetApp s SnapDrive to create a snapshot of the LUN A A. The snapshot of the LUN A A may be used to create a snapshot LUN B B. Since the snapshot LUN B B is a copy of original LUN A A the snapshot LUN B and the original LUN A share the same disk identifier. If the node B B requests to connect to the LUN B B the system will determine the partition format of the LUN B B such as GPT or MBR. The system retrieves a new disk identifier such as a globally unique identifier from the underlying operating system by calling an API. The system sets the disk identifier of the LUN B B to the new disk identifier in accordance with the disk identifier write protocol associated with the partition type used by the LUN B B. Disk identifier storage and write protocols for GPT and MBR disks may be discussed in more detail in below. The system then connects the snapshot LUN B B to the node B B.

The cluster may also utilize mirroring technology for data protection and disaster recovery. The mirroring technology may be provided by NetApp s SnapMirror software running on the file server . The mirroring technology may maintain a mirror or second copy of a data source such as one of the storage volumes A N. A mirror LUN may be one or more of the LUNs A N connected to the cluster as shared disk resources. A mirrored LUN will share the same disk identifier as the original LUN it was mirrored from.

For example the LUN A A may be connected to the node A A. The node A A may use NetApp s SnapDrive to create a mirror LUN B B of the LUN A A. Since the mirror LUN B B is a copy of original LUN A A the mirror LUN B B and the original LUN A A share the same disk identifier. If the node B B requests to connect to the LUN B B the system will determine the partition type of the LUN B B such as GPT or MBR. The system will retrieve a new disk identifier such as a globally unique identifier from the underlying operating system by calling an API. The system sets the disk identifier of the LUN B B to the new disk identifier in accordance with the disk identifier write protocol associated with the partition type used by the LUN B B. Disk identifier storage and write protocols for GPT and MBR disks may be discussed in more detail in below. The system then connects the mirror LUN B B to the node B B.

Lastly the cluster may utilize backup technology for storing data backups such as to comply with regulations that require backup data copies that cannot be deleted or modified. The backup technology may be provided by NetApp s SnapVault . The backup technology may create backups of files directories and or entire LUNs A N. The backup may include one or more of the LUNs A N connected to the cluster as shared disk resources. A backup LUN will share the same disk identifier as the original LUN it was backed up from.

For example the LUN A A may be connected to the node A A. The node A A may use NetApp s SnapDrive to create a backup LUN B B of the LUN A A. Since the backup LUN B B is a copy of original LUN A A the backup LUN B B and the original LUN A A share the same disk identifier. If the node B B requests to connect to the LUN B B the system will determine the partition type of the LUN B B such as GPT or MBR. The system will retrieve a new disk identifier such as a globally unique identifier from the underlying operating system by calling an API. The system sets the disk identifier of the LUN B B to the new disk identifier in accordance with the disk identifier write protocol associated with the partition type used by the LUN B B. Disk identifier storage and write protocols for GPT and MBR disks may be discussed in more detail in below. The system then connects the backup LUN B B to the node B B.

The network adapter comprises the mechanical electrical and signaling circuitry needed to connect the file server to a cluster node A A over network . Cluster node A A maybe a general purpose computer configured to execute applications such as clustering software and third party applications. Moreover cluster node A A may interact with the file server in accordance with the client server model of information delivery. That is cluster node A A may request the services of the file server and the file server may return the results of the services requested by cluster node A A by exchanging packets defined by an appropriate networking protocol.

The storage adapter incorporates with the storage operating system executing on the file server to access information requested by cluster node A A. The cluster node A A may request data appearing on the LUNs A N. The information may be physically stored on the disks of the set of storage volumes that is attached via the storage adapter to the file server . The storage adapter includes input output I O interface circuitry that couples to the disks over an I O interconnect arrangement such as a conventional high performance Fibre Channel serial link topology. The information is retrieved by the storage adapter and if necessary processed by the processor or the adapter itself prior to be forwarded over the system bus to the network adapter where information is formatted into appropriate packets and returned to cluster node A A as if the information resided on the LUNs A N.

In one exemplary file server implementation the file server can include a non volatile random access memory NVRAM that provides fault tolerant backup of data enabling the integrity of file server transactions to survive a service interruption based upon a power failure or other fault. The storage operating system may be NetApp s Data ONTAP residing on the file server processing file service requests from the cluster nodes A N.

In the MBR disk partition format the disk identifier may be stored as the disk signature . Thus when setting the disk identifier of an MBR disk only the disk signature needs to be set. The MBR disk partition format is not fully self identifying i.e. some data critical to platform operation is located in unpartitioned or hidden sectors.

In the GPT disk partition format the disk identifier may be stored as a disk GUID which is part of the primary GPT header . However the GPT disk partition format also stores a backup disk identifier as a backup disk GUID which is part of the backup GPT header . Thus changing the disk GUID in a GPT disk also requires changing a partition GUID of each partition in the GPT disk. The partition GUIDs of the partitions are stored in the partition entry array and like the disk GUID a backup of each partition GUID is stored in the backup partition entry array . In addition the GPT disk partition format stores verification values for the GPT header and the partition entry array in the GPT header and verification values for the backup GPT header and the backup partition entry array in the backup GPT header . The verification values are cyclic redundancy check values. Thus when setting the disk identifier of a GPT disk the disk GUID needs to be set in the GPT header and the backup GPT header . In addition the partition GUIDs need to be set in the primary partition entry array and the backup partition entry array . Lastly the verification values for the GPT header and the partition entry array must be calculated and set in the primary GPT header and verification values for the backup GPT header and the backup partition entry array must be set in the backup GPT header . Setting the disk GUID of a GPT disk is discussed in more detail in below.

The GPT disk partition format is well defined and fully self identifying i.e. data critical to platform operation is located in partitions and not in unpartitioned or hidden sectors.

Since the system updated the disk identifier of the disk there will be no conflicts with existing shared disk resources on the cluster . Furthermore since the disk identifier was set in accordance with the protocols associated with the partition format used by the disk there is no risk of corrupting the disk or otherwise rendering the disk inaccessible.

Once all of the partition GUIDs are set in the partition entry array the system moves to step . At step the system re reads the partition entry array to retrieve the newly set values. At step the system calculates and sets the partition entry array verification value in the GPT header . The partition entry array verification value can be determined by calculating a cyclic redundancy check CRC value of the data stored in the partition entry array . A CRC may be a type of function that takes an input of data stream of any length and produces as output a value of a certain fixed size. The output value can then be used as a checksum to detect alteration of the data during transmission or storage. The CRC value may be a CRC 16 value a CRC 32 value a CRC 64 value or generally any CRC value. At step the system calculates and sets the GPT header verification value in the GPT header . The GPT header verification value can be determined by calculating a CRC value of the data stored in the GPT header .

At step the system reads the GPT backup header . At step the system sets the backup disk GUID in the backup GPT header to the GUID retrieved in step . At step the system reads the backup partition entry array from the disk. At step the system sets the backup first partition GUID in the backup partition entry array to the partition GUID retrieved in step above. At step the system determines if there are additional partitions in the backup partition entry array . If at step there are additional partitions in the backup partition entry array the system moves to step and sets the next backup partition GUID to the value retrieved in step above. The system will set the backup partition GUID for each partition stored in the backup partition entry array .

Once all of the backup partition GUIDs are set in the backup partition entry array the system moves to step . At step the system re reads the backup partition entry array to retrieve the newly set values. At step the system calculates and sets the backup partition entry array verification value in the backup GPT header . The backup partition entry array verification value can be determined by calculating a CRC value of the data stored in the backup partition entry array . At step the system calculates and sets the backup GPT header verification value in the backup GPT header . The backup GPT header verification value can be determined by calculating a CRC value of the data stored in the backup GPT header .

Since the system updated the disk identifier of the LUN B B there will be no conflicts with the LUN A A on the cluster . Furthermore since the disk identifier was set in accordance with the procedures associated with the partition format used by the LUN B B the system avoided corrupting the LUN B B or otherwise rendering the LUN B B inaccessible.

Since the system updated the disk identifier of the LUN B B there will be no conflicts with the LUN A A on the cluster . Furthermore since the disk identifier was set in accordance with the procedures associated with the partition format used by the LUN B B the system avoided corrupting the LUN B B or otherwise rendering the LUN B B inaccessible.

Since the system updated the disk identifier of the LUN B B there will be no conflicts with the LUN A A on the cluster . Furthermore since the disk identifier was set in accordance with the procedures associated with the partition format used by the LUN B B the system avoided corrupting the LUN B B or otherwise rendering the LUN B B inaccessible.

In a networked deployment the computer system operates in the capacity of one of the cluster nodes A N in the cluster . The computer system may also be implemented as or incorporated into various devices such as a personal computer PC a tablet PC a set top box STB a personal digital assistant PDA a mobile device a palmtop computer a laptop computer a desktop computer a communications device a wireless telephone a land line telephone a control system a camera a scanner a facsimile machine a printer a pager a personal trusted device a web appliance a network router switch or bridge or any other machine capable of executing a set of instructions sequential or otherwise to connect to a shared disk resource in a cluster environment. While a single computer system is illustrated the term system includes any collection of systems or sub systems that individually or jointly execute a set or multiple sets of instructions to perform one or more computer functions.

As illustrated in the computer system includes a processor such as a central processing unit CPU a graphics processing unit GPU or both. The processor may be a component in a variety of systems. For example the processor may be part of a standard personal computer or a workstation. The processor may also be one or more general processors digital signal processors application specific integrated circuits field programmable gate arrays servers networks digital circuits analog circuits combinations thereof or other now known or later developed devices for analyzing and processing data.

The computer system includes a memory that can communicate via a bus . The memory can be a main memory a static memory or a dynamic memory. The memory can be any type of computer readable storage media such as various types of volatile and non volatile storage media including but not limited to random access memory read only memory programmable read only memory electrically programmable read only memory electrically erasable read only memory flash memory magnetic tape or disk optical media and the like. In one embodiment the memory includes a cache or random access memory for the processor . Alternatively the memory can be separate from the processor such as a cache memory of a processor the system memory or other memory. The memory could also be an external storage device or database for storing data. Examples may include a hard drive compact disc CD digital video disc DVD memory card memory stick floppy disc universal serial bus USB memory device or any other device operative to store data. The memory stores instructions executable by the processor . The functions acts or tasks illustrated in the figures or described herein may be performed by the programmed processor executing the instructions stored in the memory . The functions acts or tasks can be independent of the particular type of instructions set storage media processor or processing strategy and may be performed by software hardware integrated circuits firm ware micro code and the like operating alone or in combination. Likewise processing strategies may include multiprocessing multitasking parallel processing and the like.

The computer system further includes a display such as a liquid crystal display LCD an organic light emitting diode OLED a flat panel display a solid state display a cathode ray tube CRT a projector a printer or other now known or later developed display device for outputting determined information. The display acts as an interface for the user to see the functioning of the processor or specifically as an interface with the software stored in the memory or in the drive unit .

Additionally the computer system includes an input device configured to allow a user to interact with any of the components of system . The input device can be a number pad a keyboard or a cursor control device such as a mouse or a joystick touch screen display remote control or any other device operative to interact with the system .

The computer system may also include a disk or optical drive unit . The disk drive unit includes a computer readable medium in which one or more sets of instructions e.g. software can be embedded. Further the instructions can perform one or more of the methods or logic as described herein. The instructions may reside completely or at least partially within the memory and or within the processor during execution by the computer system . The memory and the processor can also include computer readable media as discussed above.

The present disclosure contemplates a computer readable medium that includes instructions or receives and executes instructions responsive to a propagated signal so that a device connected to a network may communicate voice video audio images or any other data over the network . Further the instructions may be transmitted or received over the network via a communication interface . The communication interface may be a part of the processor or may be a separate component. The communication interface may be created in software or may be a physical connection in hardware. The communication interface may be configured to connect with a network external media the display or any other components in system or combinations thereof. The connection with the network may be a physical connection such as a wired Ethernet connection or may be established wirelessly as discussed below. Likewise the additional connections with other components of the system may be physical connections or may be established wirelessly.

The network may include wired networks wireless networks or combinations thereof. The wireless network may be a cellular telephone network an 802.11 802.16 802.20 or WiMax network. Further the network may be a public network such as the Internet a private network such as an intranet or combinations thereof and may utilize a variety of networking protocols now available or later developed including but not limited to TCP IP based networking protocols.

The computer readable medium may be a single medium or the computer readable medium may be a single medium or multiple media such as a centralized or distributed database and or associated caches and servers that store one or more sets of instructions. The term computer readable medium may also include any medium that may be capable of storing encoding or carrying a set of instructions for execution by a processor or that may cause a computer system to perform any one or more of the methods or operations disclosed herein.

The computer readable medium may include a solid state memory such as a memory card or other package that houses one or more non volatile read only memories. The computer readable medium also may be a random access memory or other volatile re writable memory. Additionally the computer readable medium may include a magneto optical or optical medium such as a disk or tapes or other storage device to capture carrier wave signals such as a signal communicated over a transmission medium. A digital file attachment to an e mail or other self contained information archive or set of archives may be considered a distribution medium that may be a tangible storage medium. Accordingly the disclosure may be considered to include any one or more of a computer readable medium or a distribution medium and other equivalents and successor media in which data or instructions may be stored.

Alternatively or in addition dedicated hardware implementations such as application specific integrated circuits programmable logic arrays and other hardware devices may be constructed to implement one or more of the methods described herein. Applications that may include the apparatus and systems of various embodiments may broadly include a variety of electronic and computer systems. One or more embodiments described herein may implement functions using two or more specific interconnected hardware modules or devices with related control and data signals that may be communicated between and through the modules or as portions of an application specific integrated circuit. Accordingly the present system may encompass software firmware and hardware implementations.

The methods described herein may be implemented by software programs executable by a computer system. Further implementations may include distributed processing component object distributed processing and parallel processing. Alternatively or in addition virtual computer system processing maybe constructed to implement one or more of the methods or functionality as described herein.

Although components and functions are described that may be implemented in particular embodiments with reference to particular standards and protocols the components and functions are not limited to such standards and protocols. For example standards for Internet and other packet switched network transmission e.g. TCP IP UDP IP HTML HTTP represent examples of the state of the art. Such standards are periodically superseded by faster or more efficient equivalents having essentially the same functions. Accordingly replacement standards and protocols having the same or similar functions as those disclosed herein are considered equivalents thereof.

The illustrations described herein are intended to provide a general understanding of the structure of various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus processors and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. Additionally the illustrations are merely representational and may not be drawn to scale. Certain proportions within the illustrations may be exaggerated while other proportions may be minimized. Accordingly the disclosure and the figures are to be regarded as illustrative rather than restrictive.

Although specific embodiments have been illustrated and described herein it should be appreciated that any subsequent arrangement designed to achieve the same or similar purpose may be substituted for the specific embodiments shown. This disclosure is intended to cover any and all subsequent adaptations or variations of various embodiments. Combinations of the above embodiments and other embodiments not specifically described herein may be apparent to those of skill in the art upon reviewing the description.

The Abstract is provided with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition in the foregoing Detailed Description various features may be grouped together or described in a single embodiment for the purpose of streamlining the disclosure. This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather as the following claims reflect inventive subject matter may be directed to less than all of the features of any of the disclosed embodiments. Thus the following claims are incorporated into the Detailed Description with each claim standing on its own as defining separately claimed subject matter.

The above disclosed subject matter is to be considered illustrative and not restrictive and the appended claims are intended to cover all such modifications enhancements and other embodiments which fall within the true spirit and scope of the description. Thus to the maximum extent allowed by law the scope is to be determined by the broadest permissible interpretation of the following claims and their equivalents and shall not be restricted or limited by the foregoing detailed description.

