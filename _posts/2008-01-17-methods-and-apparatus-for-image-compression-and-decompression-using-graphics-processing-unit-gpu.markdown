---

title: Methods and apparatus for image compression and decompression using graphics processing unit (GPU)
abstract: The invention provides, in some aspects, methods for image compression that utilize the central processing unit (CPU) of a digital data processor and its associated graphics processing unit (GPU), together, in order to compress an image. In related aspects of the invention, the GPU is adapted to render at least a portion of an image to an associated texture buffer (i.e., a texture buffer of the GPU) and to transform the resulting image values in that texture buffer to a frequency-based representation. The GPU can, further, order coefficients comprising that frequency-based representation and transfer at least a portion of those coefficients to the associated CPU. That CPU can, in turn, effect transfer of the downloaded coefficients to another digital data processor (or image processing apparatus). Still other aspects of the invention provide methods of image decompression that utilize the central processing unit (CPU) of a digital data processor and its associated graphics processing unit (GPU), together, in order to decompress an image. These methods parallel the compression methods discussed above, albeit in substantially reversed order. Other aspects of the invention provide digital data processing apparatus for image compression, decompression and/or remote image display operating in accord with the methods described above.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08019151&OS=08019151&RS=08019151
owner: Visualization Sciences Group, Inc.
number: 08019151
owner_city: Burlington
owner_country: US
publication_date: 20080117
---
This application claims the benefit of U.S. Provisional Patent Application Ser. No. 60 943 106 filed Jun. 11 2007 entitled Methods and Apparatus for Image Compression and Decompression Using Graphics Processing Unit GPU the teachings of which are incorporated herein by reference.

The invention relates to digital data processing and more particularly to image compression and decompression. It has application by way of non limiting example in the compression of two and three dimensional images for storage and or remote visualization.

Digital data processors are increasingly used for the acquisition transfer storage analysis and display of images. In many industries their use is the norm having long ago supplanted competing technologies such as photochemical media e.g. recording films for storage and telefax machines for transmission. This is the natural outgrowth of increases in storage capacity and processing power of today s digital data processors as well as of ubiquitous high speed digital networks supporting communications among those devices.

Notwithstanding these advances storage and transmission of digital images remain the bane of image processing system designers and users alike. Whereas faster backplanes and increased use of image co processors such as graphics processing units or GPUs have brought image processing and display speeds to acceptable levels even on desktop and laptop computers image data is often too large for storage in quantity on typical disk drives or other storage devices or for rapid transmission over local area networks wide area networks and internets by way of example.

As a consequence image compression i.e. the systematic reduction of the number of bits or other information bearing units representing an image is typically used to reduce image sizes for both storage and transmission. The converse image decompression is used to reconstitute an image for processing or display. Common compression techniques exploit bit patterns within the original image such as in run length encoding and or mathematical transformations of image regions such as in JPEG encoding .

Regardless of the technique used image compression and decompression are computationally intensive. In most digital data processor implementations these tasks are handled on the central processing unit or CPU. While this affords the flexibility that is often demanded by compression algorithms it can have the effect of bringing down overall digital data processor performance.

Accordingly an object of this invention is to provide improved methods and apparatus for digital data processing. A more particular object is to provide such methods and apparatus for image compression and or decompression.

Related objects of the invention are to provide such methods and apparatus as facilitate data storage and or transmission. Still further related objects are to provide such methods and apparatus as facilitate remote image viewing.

Further objects of the invention are to provide such methods and apparatus as more fully utilize the processing resources found in typical digital data processors.

Still further objects of the invention are to provide such methods and apparatus as can be implemented at reasonable cost on legacy current and future digital data processing systems.

The foregoing are among the objects attained by the invention which provides in some aspects methods for image compression that utilize the central processing unit CPU of a digital data processor and its associated graphics processing unit GPU together in order to compress an image e.g. for transmission and viewing by a remote digital data processor.

In related aspects of the invention the GPU is adapted to render at least a portion of an image to an associated texture buffer i.e. a texture buffer of the GPU and to transform the resulting image values e.g. voxels in that texture buffer to a frequency based representation. The GPU can further order coefficients comprising that frequency based representation and transfer or readback at least a portion of those coefficients to the associated CPU. That CPU can in turn effect transfer of the readback coefficients to another digital data processor or image processing apparatus .

In other aspects of the invention the CPU applies compression to the readback coefficients before effecting their transfer to the other digital data processor or image processing apparatus . This can be for example a run length encoding based compression technique or otherwise.

Still further aspects of the invention provide methods as described above in which the GPU transforms the image values in the texture buffer from a first color space to a second color space prior to applying the frequency transform. The first color space can be for example an RGB color space. The second color space can be for example a YCbCr color space.

Yet still further aspects of the invention provide methods as described above in which the frequency transform is a Fourier related transform. In related aspects of the invention the frequency transform is a discrete cosine transform DCT . In further related aspects of the invention GPU applies the DCT transform in two passes one on lines or rows of image values the other on columns of image values.

Other aspects of the invention provide methods as described above in which the GPU applies a quantization factor to the coefficients that result from the DCT transform and that comprise the frequency based representation . That quantization factor can for example reduce information in high frequency components of the representation since those are not as readily visible to the human eye and likewise reduce the space required for the frequency based representation.

Further aspects of the invention provide methods as described above in which the GPU orders coefficients comprising the frequency based representation so that they will be linearly ordered upon download to the CPU. In related aspects the ordering places DC or zero order coefficients first followed by lower frequency AC coefficients and then higher frequency AC coefficients.

Still further related aspects of the invention provide methods as described above in which the GPU downloads only a portion of the ordered frequency based coefficients to the CPU.

Still other aspects of the invention provide methods of image decompression that utilize the central processing unit CPU of a digital data processor and its associated graphics processing unit GPU together in order to decompress an image. These methods parallel the compression methods discussed above albeit in substantially reversed order.

Yet still further aspects of the invention provide methods for remote image display in which a first digital data processor uses a compression methodology as described above to compress an image for transfer to a second processor and in which the second processor utilizes a decompression methodology as described above to decompress that image for display.

Other aspects of the invention provide digital data processing apparatus for image compression decompression and or remote image display operating in accord with the methods described above.

The digital data processor comprises a mainframe server workstation desktop computer laptop computer embedded computer or other computing device of the type generally known in the art as configured and adapted in accord with the teachings hereof to compress images e.g. for transmission to digital data processor . Thus illustrated digital data processor includes a central processing unit graphics processing unit GPU random access memory and input output subsystem and frame buffer all of the type conventionally known in the art as configured and adapted in accord with the teachings hereof. In the discussion that follows digital data processor is sometimes referred to as a server and the operations performed by it are referred to as server side operations.

GPU serves as a coprocessor operating under the control of the CPU to compress images for transfer to digital data processor . The GPU may comprise any of many contemporary graphics processing units of the type available in the marketplce e.g. NVIDA ATI and others having programmable shaders. It includes a front end shaders output merger section and buffers as shown.

Front end provides for input assembly and or other conventional functions including by way of non limiting example canonicalizing vertex data generating IDs for primitives vertices instances and so forth. Shaders provide for programmable processing of graphics data and include a texture shader of the type conventionally known in the art as configured and adapted in accord with the teachings hereof for processing data e.g. in an associated 2D texture buffer . Although shown as part of the GPU it will be appreciated that in other embodiments texture buffer may reside elsewhere. Output merger section provides for color buffer blending and or other conventional functions including by way of example reading writing and access data in frame buffer . It will be appreciated that the GPU architecture shown in is merely an example and that the GPUs used in other embodiments of the invention may vary.

Although only a single GPU is shown in the drawing other embodiments of the invention may employ multiple such GPUs. Still other embodiments may incorporate in CPU or other processing subsystems e.g. ASICs the functionality ascribed herein to GPU .

Frame buffer comprises a conventional frame buffer of the type known in the art that maintains data representing an image or images to be displayed on monitor or other display device e.g. LCD display CRT or so forth . The frame buffer which can be separate from or integral to the GPU operates in accord with the GPU or other subsystems to drive that data to device . In some embodiments frame buffer includes additional storage supporting one or more of the buffers of the GPU.

I O subsystem operates in the conventional manner as adapted in accord with the teachings hereof to exchange data with digital data processor and other clients over network . The I O subsystem also supports the input of image data from disk drive s or other store s and or image acquisition device s e.g. video cameras still cameras and other imaging equipment of the type known in the art.

Digital data processor of the illustrated embodiment comprises a mainframe server workstation desktop computer laptop computer embedded computer or other computing device of the type generally known in the art albeit as configured and adapted in accord with the teachings hereof to decompress and display images received from digital data processor . As above in the discussion that follows digital data processor is sometimes referred to as a client and the operations performed by it are referred to as client side operations.

Illustrated digital data processor includes a central processing unit graphics processing unit GPU random access memory and input output subsystem and frame buffer all of the type conventionally known in the art as configured and adapted in accord with the teachings hereof.

GPU serves as a coprocessor operating under the control of the CPU to decompress images transferred from digital data processor as well as to render those images on device . As above the GPU may comprise any of many contemporary graphics processing units having programmable shaders of the type available NVIDA ATI and the like and includes a front end shaders output merger section and buffers as shown. As above front end provides for input assembly and or other conventional function including by way of non limiting example canonicalizing vertex data generating IDs for primitives vertices instances and so forth. Shaders provide for programmable processing of graphics data and include texture shader of the type conventionally known in the art as configured and adapted in accord with the teachings hereof for processing data e.g. in texture buffer . Although shown as part of the GPU it will be appreciated that in other embodiments texture buffer may reside elsewhere. Output merger section provides for color buffer blending and or other conventional functions including by way of example reading writing and access data in frame buffer . As above of course it will be appreciated that the architecture here is merely an example and that the GPUs used in other embodiments of the invention may vary.

Moreover as above although only a single GPU is shown in the drawing other embodiments of the invention may employ multiple such GPUs. Still other embodiments may incorporate in CPU or other processing subsystems e.g. ASICs the functionality ascribed herein to GPU .

Frame buffer comprises a conventional frame buffer of the type known in the art that maintains data representing an image or images to be displayed on monitor or other display device e.g. LCD display CRT or so forth . The frame buffer which can be separate from or integral to the GPU operates in accord with the GPU or other subsystems to drive that data to device . In some embodiments frame buffer includes additional storage supporting one or more of the buffers .

I O subsystem operates in the conventional manner as adapted in accord with the teachings hereof to exchange data with digital data processor and other serves over network .

Although digital data processor is configured in a similar manner as digital data processor in other embodiments these devices may vary more widely.

Moreover although only two digital data processors are shown in the drawing it will be appreciated that other embodiments of the invention may include a greater or lesser number of digital data processors. Thus for example server digital data processor may compress images for transmission to and decompression display by multiple client digital data processors e.g. including digital data processor . Conversely client digital data processor may be coupled to multiple server digital data processors including digital data processor for decompression and display of compressed images received from them. It will be further appreciated that in some embodiments a single digital data processor is both server and client e.g. as where a digital data processor compresses image data for storage and later decompression and display via that same device.

Illustrated network comprises LAN WAN Internet or other communications medium or combination of media of the type known in the art suitable for transfer of digital data between computing devices. Although such transfer may be accomplished electronically e.g. via wired wireless and or satellite networks or a combination thereof in the illustrated embodiment in other embodiments the transfer may comprise the physical transfer of data via CD ROM DVD magnetic tape or other media instead of or in addition to electronic transfer.

By way of overview and as noted above illustrated server digital data processor compresses images for transmission to digital data processor . These may be images acquired from drive s or store s image acquisition device s or otherwise transformations of such images synthetically generated images or otherwise. Client digital data processor decompresses images received from digital data processor for further processing and or display.

Use of the GPUs by digital data processors and to execute these methods and particularly to execute compresssion decompression has several advantages in terms of memory access bandwidth and computation performance. With respect to compression performed by server these include by way of non limiting example 

Parallel benefits are attained by client with respect to decompression of images received from server .

In the illustrated embodiment operations 1A 8A executed on the server side i.e. on digital data processor are executed under a global process wherein the CPU GPU GPUCPU and Network tasks so demarcated by regions and respectively of are done in different threads. This is likewise true of the client side operations 1B 8B as so indicated in the drawing by corresponding regions and on digital data processor . Other embodiments may execute such operations in a single thread on each of the server and client sides in multiple processes or otherwise. Moreover it will be appreciated that in other embodiments other operations may be executed on the server and client for the foregoing purposes instead or in addition to the operations depicted in and discussed below.

Bypass direct rendering to video memory to render to a texture attached to frame buffer which will be available for next transformation pass.

In this step the GPU makes the image available for rapid processing via the texture buffer . To this end the GPU renders the 3D image or scene to 2D texture buffer rather than to video memory or frame buffer . The scene which may be in the form of a scene graph or other data structure can represent i an image acquired from drive s or store s image acquisition device s or otherwise ii a transformation of such an image iii a synthetically generated image or iv otherwise. Prior to execution of step 1A the scene may be stored in memory associated with or accessible by GPU e.g. such as buffers and or frame buffer and indeed may represent an image currently being processed e.g. transformed analyzed etc. on server and more specifically on GPU .

Rendering is effected with a 3D graphics engine of the type conventionally known in the art that executes on the GPU . Examples of such engines include OpenGL and DirectX though other graphics engines known in the art may be used instead or in addition. Output of the rendered 3D scene to the 2D texture buffer is accomplished utilizing instructions provided by the graphics engine or otherwise.

The YCbCr color space conversion allows greater compression for the same image quality or greater image quality for the same compression .

In this step the GPU converts the 3D image in the texture buffer following Step 1A from the red green blue RGB color space into the YCbCr color space thereby making it readily amenable to compression. In the illustrated embodiment the conversion is effected by texture shader or another shader of GPU utilizing a conventional methodology for RGB to YCbCr conversion. In the illustrated embodiment the shader stores results of the conversion to texture buffer or another buffer on GPU .

Two passes of 1D Discrete Cosine Transform DCT are applied to the texture one on lines the second on columns. The DCT is applied on sub blocks of the Input on each component or channel in parallel using intrinsic vector computing capabilities of the GPU.

In this step the GPU converts sub blocks of the image generated in Step 2A from YCbCr color space to frequency space. In the illustrated embodiment this is effected by texture shader or another shader of GPU . As noted the shader applies two passes of one dimensional 1D Discrete Cosine Transform DCT to the YCbCr values output by Step 2A and stored in texture buffer the first pass on lines and the second on columns. As also noted the DCT is applied on sub blocks of each channel i.e. the Y channel the Cb channel and the Cr channel of the input in parallel using as noted intrinsic vector computing capabilities of the GPU. The shader stores the result an array of DCT coefficients for each channel of values of each sub block to texture buffer or another buffer on GPU .

Transformation of an exemplary 4 4 sub block of YCbCr values to an array of DCT coefficients is illustrated in . Referring to array it will be appreciated that the designation DC refers to the zero order coefficient the designation 1 refers to the first order coefficient the designation 2 refers to the second order coefficient and so forth up through the designation 15 which refers to the fifteenth order coefficient. Although the illustration shows transformation of sixteen values per channel in sub block to sixteen coefficients per channel in array thus insuring that the frequency representation of the image will occupy the same space as the color representation in other embodiments the number of coefficients may not match the number of intensity values in the sub block.

Quantization results in a first level of quality loss targeted. It reduces the amount of information in the high frequency components as the human eye is not good at distinguishing the exact strength of a high frequency brightness variation.

In this step the GPU quantizes the coefficients stored in texture buffer following Step 3A reducing them from their native size of 16 or 32 bits per coefficient depending on the native floating point processing capacity of the GPU to 8 bits per coefficient. In the illustrated embodiment this is effected by texture shader or another shader of GPU which applies quantization matrix multiplication of the type known in the art. Other embodiments may employ other quantization techniques instead or in addition. The shader stores the resulting quantized coefficients to texture buffer or another buffer on GPU .

CPU memory organization is linear whereas GPU memory organization is two dimensional 2D which means that by way of non limiting example an 8 8 image with 4 4 sub blocks of the type shown in in GPU memory would be represented in the manner shown in if directly download or readback to the CPU. For illustrative purposes the coefficients of the four respective 4 4 sub blocks that make up the 8 8 image of are denoted with subscripts a b c and d respectively.

Once in this format on a CPU a good compression algorithm would be forced to reorganize data to find dictionary patterns inside this image. Such operations are costly on a CPU because of the pseudo random data pattern and the limited memory bandwidth available on the CPU.

Instead of directly downloading to the CPU the illustrated embodiment uses the GPU high memory bandwidth capabilities to sort not only sub block coefficient but all DCT coefficients of the image in a way that it will be linearly ordered for the CPU memory. This is effected by the texture shader or another shader of GPU which reorders the coefficient arrays generated in Step 4A in the manner shown in . As above the subscripts a b c and d are used to denote coefficients from the respective blocks of .

Particularly as evident in the shader orders the coefficients to get first zero order DC coefficients then low frequencies coefficients and then high frequencies coefficients. More particularly the shader reorders the coefficients generated in Step 5A or Step 4A in the event Step 5A is not utilized to place all DC coefficients for the image or a portion thereof first followed by all first order coefficients followed by all second order coefficients and so forth through all highest order coefficients. Put another way the shader reorders the coefficients of the frequency based representation of the image so that rather than coefficients for like sub blocks being stored together as in coefficients of like order are stored together. The shader stores the resulting reordered quantized coefficients to texture buffer or another buffer on GPU .

Of course it will be appreciated that although depict an 8 8 image comprised of 4 4 sub blocks in a preferred embodiment images of still larger size are supported and are partitioned into sub blocks of 8 8.

It will be further appreciated that and the discussion above focus on only the coefficients for a single channel of the image e.g. coefficients generated from the Y channel in practice the shader performs this Step 5A separately but preferably in parallel on coefficients of all three channels of the image e.g. coefficients generated from each of the Y Cb and Cr channels .

This compression step is done at no cost as it consists in downloading from the GPU to the CPU only a specified portion of the reordered filtered image generated in Step 5A. All coefficients that are not readback are considered as zero and are referred to occasionally hereinafter as dropped . As coefficients are ordered by importance from the human eye point of view increasing the percentage of coefficients downloaded will increase precision quality in a pseudo linear way in the frequency domain .

In this step the GPU downloads a portion of the reordered coefficients generated in Step 5A to the CPU . This is effected using the GPU readback operation with the texture buffer as the source and specified memory locations of the RAM or other memory associated with the CPU as the destination. Although all coefficients in each channel may be downloaded the illustrated embodiment permits programmatic specification of a lesser portion of each channel here specified as a percentage of lines or rows though in other embodiments specified otherwise. The readback transfer i.e. download proceeds from DC or zero order coefficients to first order coefficients to second order coefficients and so forth in accord with the ordering effected in Step 5A. Hence where a percentage is specified it results in transfer of the most significant lower order coefficients from each of the channels and dropping of the least significant higher order coefficients.

As most of the work to reorder data in a way where patterns are more easily found the CPU compression algorithm can use a smaller buffer for pattern matching and using simple RLE or ZLib compression library gives very good results at very low CPU cost.

In this step the CPU is used to provide further compression of the image data downloaded from the GPU in Step 6A and stored in RAM or otherwise . To that end the CPU performs conventional data compression on the downloaded coefficients preferably using a lossless compression technique such as RLE or ZLib which allows for the image texture to be perfectly represented upon decompression in step 7B. However in other embodiments a lossy compression technique may be used which will result in less perfect representation of the image texture upon decompression. Regardless such compression is performed on the coefficients for each channel of the image.

Following compression of the image in Steps 1A 7A the compressed image values can be sent through the network to one or more remote clients . This step is effected in the conventional manner by the I O subsystem operating in connection with CPU .

1 in embodiments in which the server side has only one GPU frame pipeline GPU does filtering of a frame when CPU does the compression of the previous frame.

2 in embodiments in which the server side has multiple GPUs SMP or distributed each GPU works on a portion of frame and for each GPU a CPU process does the CPU part in parallel. In this case frame pipeline parallelism is used too.

As further illustrated on the client side of image decompression is effected by reversing the steps described above to get back the original texture image that it will map to a quad defining its complete viewport as described further below. Notwithstanding that the steps performed by the client side are labelled 1B through 8B in the illustrated embodiment and the discussion that follows processing proceeds from 8B to 1B .

Thus Step 8B reverses the operation of Step 8A. More specifically the remote digital data processor receives the compressed image data transmitted for all channels of the image in Step 8A at I O subsystem and stores it in RAM . In other embodiments the compressed texture may be received and or stored by other components of the digital data processor e.g. under control of CPU .

Similarly Step 7B reverses the operations of Step 7A. More particularly the CPU decompresses the image data stored to RAM in Step 8B. To this end the CPU utilizes a decompression algorithm corresponding to the compression mechanism used in Step 7A e.g. RLE Zlib etc. . The result is an array of coefficients of the frequency based representation of the image arranged so that coefficients of like order are stored together e.g. in the manner of albeit without the coefficients dropped in Step 6A . The CPU stores that result back to RAM . In the illustrated embodiment the operations of this Step 7B are performed on all channels of the received data.

In this step the CPU downloads to GPU and particularly to texture buffer the coefficients generated in Step 7B. Missing coefficients namely those dropped during the readback operation in Step 6A and accordingly not transmitted by the server in Step 8A nor received by the client in Step 8B are assumed to be zero. The CPU pads the downloaded coefficients accordingly. The operations of this Step 6B are performed on the coefficients of all of the channels.

In this step the GPU and particularly the texture shader reorders the coefficients downloaded to buffer in Step 6B so as to place coefficients for like sub blocks back into those sub blocks e.g. in the manner of FIG. A in essence reversing the ordering that was effected in Step 5A. The shader stores the results of that operation in texture buffer or another buffer associated with GPU . As above the operations of this Step 5B are performed on the coefficients of each channel.

In this step GPU and particularly the texture shader unquantizes the coefficients stored to texture buffer following Step 5B. This can be effected by converting the coefficients from 8 bit values to 16 or 32 bit values depending on the native floating point processing capacity of GPU or otherwise using unquantization techniques known in the art. Results of the operation are stored to texture buffer or another buffer associated with GPU . As above the operations of this Step 4B are performed on the coefficients of each channel.

In this step GPU reverses Step 3A transforming the coefficients stored to buffer following step 4B from frequency space to each of the respective channels of YCbCr color space and thereby filling lines and columns of the sub blocks of each of the channels with respective YCbCr intensity values. To effect this the shader applies a conventional inverse DCT operation of the type known in the art storing the result to texture buffer or another buffer associated with GPU .

In this step the GPU shader transforms the color values generated in Step 3B from YCbCr space to RGB color space. This is effected by texture shader utilizing a conventional methodology for YCbCr to RGB conversion. In the illustrated embodiment the shader stores results of the conversion to texture buffer or another buffer associated with GPU .

In this step the GPU generates a 3D image from the RGB values generated in step 2B. To this end the GPU uses a 3D graphics engine of the type described above to generate a 3D image in the video memory or frame buffer of the client digital data processor for display on monitor .

Described above are methods and apparatus meeting the aforementioned objects. Those skilled in the art will appreciate that the embodiments illustrated and discussed herein are merely examples of the invention and that other embodiments employing changes therein fall within the scope of the invention. Thus by way of example it will be appreciated that operations attributable to texture shaders in the discussion above may be accomplished by other functionality operating within the GPUs. In view thereof what I claim is 

