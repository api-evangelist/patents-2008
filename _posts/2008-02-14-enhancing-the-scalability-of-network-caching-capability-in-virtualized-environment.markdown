---

title: Enhancing the scalability of network caching capability in virtualized environment
abstract: A mechanism is provided to enhance the scalability of network caching capabilities. All network client applications running on a partition in a virtualized environment are configured to query information from a single virtual input/output server (VIOS) network caching daemon. Thus, the illustrative embodiments provide a 1:n model where a VIOS partition has a network caching daemon, and each of the n partitions uses the network caching daemon of the VIOS partition. The mechanism of the illustrative embodiments only requires the system administrator to control one copy of the local files on the VIOS server. The system administrator does not need to monitor all of these local files on each individual partition. The system administrator consolidates the entries used by the different individual partitions into one single file on the VIOS server side.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08418174&OS=08418174&RS=08418174
owner: International Business Machines Corporation
number: 08418174
owner_city: Armonk
owner_country: US
publication_date: 20080214
---
The present application relates generally to an improved data processing system and method. More specifically the present application is directed to a mechanism to enhance the scalability of network caching capability in a virtualized environment.

Transmission control protocol Internet Protocol TCP IP is a communications protocol developed under contract from the U.S. Department of Defense to inter network dissimilar systems. A TCP IP network application can use operating system OS provided network application program interfaces APIs to request information on a remote machine that runs the server application. This is referred to as a client server architecture.

The operating system provided network APIs can support multiple map types such as group password services protocols hosts networks and netgroup. For example for the hosts map type the operating system will provide APIs gethostbyname and gethostbyaddr to do host name to IP address mapping and IP address to host name mapping respectively. This task is done by the resolver which is the client part of a name service.

The resolver can be configured to get the information from different locations such as a network information services NIS server a domain name system DNS server a lightweight directory access protocol LDAP server or a local etc hosts file for example.

If the resolver uses DNS then for each API call e.g. gethostbyname the resolver sends the request over the network to a remote DNS server. The DNS server returns an answer. The time spent between resolver and DNS server over the network may become significant if the application makes a lot of API calls.

If the resolver uses a local file then for each API call e.g. gethostbyname the resolver must parse the entire local etc hosts file to find the answer. If the etc hosts file is large which happens on a lot of real customer systems the resolver will take a long time to get the answer.

To solve this problem operating system vendors provide a network caching daemon that runs on the client resolver side. The network caching daemon hashes all of the local file e.g. etc group etc passwd etc services etc protocols etc hosts etc networks etc netgroup entries into the network caching daemon so that the resolver does not do the linear search from the local file if it is configured to resolve the local way. The network caching daemon caches all of the positive and negative answers from the network server e.g. NIS NIS DNS LDAP . The resolver may then query the network caching daemon first before going out on the network to query the network server if it is configured to use the non local way.

The network caching daemon works well. However the network caching daemon technique requires a 1 1 model. For each network client there must be a network caching daemon running.

The illustrative embodiments recognize the disadvantages of the prior art and provide a mechanism to enhance the scalability of network caching capabilities. All network client applications running on a partition in a virtualized environment are configured to query information from a single virtual input output server VIOS network caching daemon. Thus the illustrative embodiments provide a 1 n model where a VIOS partition has a network caching daemon and each of the n partitions uses the network caching daemon of the VIOS partition. The mechanism of the illustrative embodiments only requires the system administrator to control one copy of the local files on the VIOS server. The system administrator does not need to monitor all of these local files on each individual partition. The system administrator consolidates the entries used by the different individual partitions into one single file on the VIOS server side.

In one illustrative embodiment a method for network caching in a virtualized environment comprises configuring a first partition within a plurality of partitions in a virtualized environment with a network caching daemon configuring a second partition within the plurality of partitions within the virtualized environment with an address of the network caching daemon and responsive to a request to resolve a host from a network application running in the second partition sending the request to the address of the network caching daemon through a virtualization layer.

In one exemplary embodiment the network caching daemon hashes entries from local file. In a further exemplary embodiment the local file consolidates all the local files of the plurality of partitions. In another exemplary embodiment the method further comprises if the second partition is configured to resolve the host a local way hashing by the network caching daemon the local file.

In another exemplary embodiment the method further comprises if the second partition is configured to resolve the host a non local way searching by the network caching daemon answers in a cache file and if the answer appears in the cache file returning the answer to the second partition. In a further exemplary embodiment the method further comprises if the answer does not appear in the cache file sending a request from the network caching daemon to a server through a network layer and caching an answer from the server in the cache file.

In still another exemplary embodiment the first partition and the second partition run on separate computer systems within a subnet.

In another illustrative embodiment a data processing system comprises a plurality of partitions running in a virtualized environment within the data processing system and a virtualization layer. A first partition within the plurality of partitions is configured with a network caching daemon. A second partition within the plurality of partitions is configured with an address of the network caching daemon. Responsive to a request to resolve a host from a network application running in the second partition the second partition sends the request to the address of the network caching daemon through the virtualization layer.

In one exemplary embodiment the network caching daemon hashes entries from local file. In a further exemplary embodiment the local file consolidates all the local files of the plurality of partitions. In another exemplary embodiment if the second partition is configured to resolve the host a local way the network caching daemon hashes the local file.

In another exemplary embodiment if the second partition is configured to resolve the host a non local way the network caching daemon searches answers in a cache file. If the answer appears in the cache file the network caching daemon returns the answer to the second partition. In a further exemplary embodiment if the answer does not appear in the cache file the network caching daemon sends a request to a server through a network layer and caches an answer from the server in the cache file.

In a further illustrative embodiment a computer program product comprises a computer useable medium having a computer readable program. The computer readable program when executed on a computing device causes the computing device to configure a first partition within a plurality of partitions in a virtualized environment with a network caching daemon configure a second partition within the plurality of partitions within the virtualized environment with an address of the network caching daemon and responsive to a request to resolve a host from a network application running in the second partition send the request to the address of the network caching daemon through a virtualization layer.

In one exemplary embodiment the network caching daemon hashes entries from local file and if the second partition is configured to resolve the host a local way hashing by the network caching daemon the local file.

In another exemplary embodiment the computer readable program when executed on a computing device causes the computing device if the second partition is configured to resolve the host a non local way search by the network caching daemon answers in a cache file and if the answer appears in the cache file return the answer to the second partition.

In still another exemplary embodiment the computer readable program comprises instructions that are stored in a computer readable storage medium in a data processing system and wherein the instructions were downloaded over a network from a remote data processing system.

In yet another exemplary embodiment the computer readable program comprises instructions that are stored in a computer readable storage medium in a server data processing system and wherein the instructions are downloaded over a network to a remote data processing system for use in a computer readable storage medium with the remote data processing system.

These and other features and advantages of the present invention will be described in or will become apparent to those of ordinary skill in the art in view of the following detailed description of the exemplary embodiments of the present invention.

With reference now to the figures and in particular with reference to exemplary diagrams of data processing environments are provided in which illustrative embodiments of the present invention may be implemented. It should be appreciated that are only exemplary and are not intended to assert or imply any limitation with regard to the environments in which aspects or embodiments of the present invention may be implemented. Many modifications to the depicted environments may be made without departing from the spirit and scope of the present invention.

With reference now to the figures depicts a pictorial representation of an exemplary distributed data processing system in which aspects of the illustrative embodiments may be implemented. Distributed data processing system may include a network of computers in which aspects of the illustrative embodiments may be implemented. The distributed data processing system contains at least one network which is the medium used to provide communication links between various devices and computers connected together within distributed data processing system . The network may include connections such as wire wireless communication links or fiber optic cables.

In the depicted example servers and are connected to network along with storage unit . In addition clients and are also connected to network . These clients and may be for example personal computers network computers or the like. In the depicted example server provides data such as boot files operating system images and applications to the clients and . Clients and are clients to server in the depicted example. Distributed data processing system may include additional servers clients and other devices not shown.

In one illustrative embodiment one or more of clients and servers may run a virtualized environment such as AIX logical partitioning LPAR . In one exemplary embodiment a client or server running a virtualized environment has one virtual input output server VIOS partition that controls all of the resources. A single network caching daemon is provided in the VIOS partition. At the VIOS side the network caching daemon consolidates the entries in each local file e.g. etc passwd etc hosts etc. so that this information can be shared by all of the individual partitions. The system administrator configures the network interface at the VIOS side and starts the network caching daemon which listens on the network interface. The network caching daemon may listen on a well known port number and hashes all of the local files into its cache.

On each individual partition side the system administrator may configure the operating system with the network caching daemon Internet protocol IP address and the server port number if not the default well known port number so the resolver knows where to send the request. For example a user may specify the IP address and server port number information in a text configuration file. The resolver side code may be modified to hold the network caching daemon server IP address and port number. All of the existing network applications need not be modified or recompiled. Even though the IP address appears to be a remote IP address the resolver actually communicates with the same system through the virtualization layer. The query is not sent out on the network unless a response is not cached in the network caching daemon.

In the depicted example distributed data processing system is the Internet with network representing a worldwide collection of networks and gateways that use the Transmission Control Protocol Internet Protocol TCP IP suite of protocols to communicate with one another. At the heart of the Internet is a backbone of high speed data communication lines between major nodes or host computers consisting of thousands of commercial governmental educational and other computer systems that route data and messages. Of course the distributed data processing system may also be implemented to include a number of different types of networks such as for example an intranet a local area network LAN a wide area network WAN or the like. As stated above is intended as an example not as an architectural limitation for different embodiments of the present invention and therefore the particular elements shown in should not be considered limiting with regard to the environments in which the illustrative embodiments of the present invention may be implemented.

With reference now to a block diagram of an exemplary data processing system is shown in which aspects of the illustrative embodiments may be implemented. Data processing system is an example of a computer such as host in in which computer usable code or instructions implementing the processes for illustrative embodiments of the present invention may be located.

In the depicted example data processing system employs a hub architecture including north bridge and memory controller hub NB MCH and south bridge and input output I O controller hub SB ICH . Processing unit main memory and graphics processor are connected to NB MCH . Graphics processor may be connected to NB MCH through an accelerated graphics port AGP .

In the depicted example local area network LAN adapter connects to SB ICH . Audio adapter keyboard and mouse adapter modem read only memory ROM hard disk drive HDD CD ROM drive universal serial bus USB ports and other communication ports and PCI PCIe devices connect to SB ICH through bus and bus . PCI PCIe devices may include for example Ethernet adapters add in cards and PC cards for notebook computers. PCI uses a card bus controller while PCIe does not. ROM may be for example a flash binary input output system BIOS .

HDD and CD ROM drive connect to SB ICH through bus . HDD and CD ROM drive may use for example an integrated drive electronics IDE or serial advanced technology attachment SATA interface. Super I O SIO device may be connected to SB ICH .

An operating system runs on processing unit . The operating system coordinates and provides control of various components within the data processing system in . As a client the operating system may be a commercially available operating system such as Microsoft Windows XP Microsoft and Windows are trademarks of Microsoft Corporation in the United States other countries or both . An object oriented programming system such as the Java programming system may run in conjunction with the operating system and provides calls to the operating system from Java programs or applications executing on data processing system Java is a trademark of Sun Microsystems Inc. in the United States other countries or both .

As a server data processing system may be for example an IBM eServer System p computer system running the Advanced Interactive Executive AIX operating system or the LINUX operating system eServer System p and AIX are trademarks of International Business Machines Corporation in the United States other countries or both while LINUX is a trademark of Linus Torvalds in the United States other countries or both . Data processing system may be a symmetric multiprocessor SMP system including a plurality of processors in processing unit . Alternatively a single processor system may be employed.

Instructions for the operating system the object oriented programming system and applications or programs are located on storage devices such as HDD and may be loaded into main memory for execution by processing unit . The processes for illustrative embodiments of the present invention may be performed by processing unit using computer usable program code which may be located in a memory such as for example main memory ROM or in one or more peripheral devices and for example.

A bus system such as bus or bus as shown in may be comprised of one or more buses. Of course the bus system may be implemented using any type of communication fabric or architecture that provides for a transfer of data between different components or devices attached to the fabric or architecture. A communication unit such as modem or network adapter of may include one or more devices used to transmit and receive data. A memory may be for example main memory ROM or a cache such as found in NB MCH in .

Those of ordinary skill in the art will appreciate that the hardware in may vary depending on the implementation. Other internal hardware or peripheral devices such as flash memory equivalent non volatile memory or optical disk drives and the like may be used in addition to or in place of the hardware depicted in . Also the processes of the illustrative embodiments may be applied to a multiprocessor data processing system other than the SMP system mentioned previously without departing from the spirit and scope of the present invention.

Moreover the data processing system may take the form of any of a number of different data processing systems including client computing devices server computing devices a tablet computer laptop computer telephone or other communication device a personal digital assistant PDA or the like. In some illustrative examples data processing system may be a portable computing device which is configured with flash memory to provide non volatile memory for storing operating system files and or user generated data for example. Essentially data processing system may be any known or later developed data processing system without architectural limitation.

LPARs and may communicate with one another through virtualization layer . Virtualization layer is software that performs communications and resource management to allow multiple instances of operating systems to run on data processing system at the same time. Virtualization layer performs tasks such as processor timeslice sharing memory allocation and the like. Virtualization layer may be for example a hypervisor.

Applications and may include network applications that communicate with devices on network . When communicating with network applications and make calls to APIs and operating system communicates through virtualization layer and network layer to network . Network layer is software that performs tasks for network communication. Network layer may perform tasks such as end to end packet delivery quality of service maintenance error control and the like.

A transmission control protocol Internet protocol TCP IP network application such as application for example can make a call to APIs to request information on a server which may run a server application. Operating system for instance may provide multiple map types such as group password services protocols hosts networks and netgroup. For example for the hosts map type operating system may provide within APIs gethostbyname and gethostbyaddr methods to do the host name to IP address mapping and IP address to host name mapping. This task is done by the resolver i.e. the network application.

The resolver may be configured to get the information from different locations such as server which may be a network information services NIS server a domain name system DNS server or a lightweight directory access protocol LDAP server. Alternatively the resolver can get the information from a local etc hosts file such as file for example. LPAR has local file and VIOS partition has local file .

If the resolver uses DNS for example then for each API call e.g. gethostbyname the resolver will send the request over network to server . Server then looks up the answer in storage and returns the answer to the resolver. The time spent between resolver such as one of applications and server over network may be significant particularly if the application makes a lot of API calls.

If the resolver uses the local method then for each API call e.g. gethostbyname the OS must parse the entire etc hosts file within local file to get the answer. If the etc hosts file is significantly large as is the case with many real customer systems it may take a long time for the resolver to get the answer.

To solve this problem in one illustrative embodiment operating system vendors may provide network caching daemons that run on the client resolver side in LPARs . Network caching daemons hash entries from local files so that the resolver will not do the local search from local files if it is configured to resolve the host name or IP address the local way. Having network caching daemons hash local files reduces the time to get an answer because the OS does not have to parse the entire file for each API call.

Each one of network caching daemons caches positive and negative answers from server into its respective cache file . The resolver then queries the network caching daemon first before it goes out to query server over network if the resolver is configured to resolve the host name or IP address the non local way.

The network caching daemon works well. However the network caching daemon technique requires a 1 1 model. For each network client there must be a network caching daemon running.

LPARs and may communicate with one another through virtualization layer . Virtualization layer is software that performs communications and resource management to allow multiple instances of operating systems to run on data processing system at the same time. Virtualization layer performs tasks such as processor timeslice sharing memory allocation and the like. Virtualization layer may be for example a hypervisor.

Applications and may include network applications that communicate with devices on network . When communicating with network applications and make calls to APIs and operating system communicates through virtualization layer and network layer to network . Network layer is software that performs tasks for network communication. Network layer may perform tasks such as end to end packet delivery quality of service maintenance error control and the like.

A transmission control protocol Internet protocol TCP IP network application such as application for example can make a call to APIs to request information on a server which may run a server application. Operating system for instance may provide multiple map types such as group password services protocols hosts networks and netgroup. For example for the hosts map type operating system may provide within APIs gethostbyname and gethostbyaddr methods to do the host name to IP address mapping and IP address to host name mapping. This task is done by the resolver i.e. the network application.

The resolver may be configured to get the information from different locations such as server which may be a network information services NIS server a domain name system DNS server or a lightweight directory access protocol LDAP server. Alternatively the resolver can get the information from a local etc hosts file such as file for example in the VIOS partition .

If the resolver uses DNS for example then for each API call e.g. gethostbyname the resolver will send the request over network to server . Server then looks up the answer in storage and returns the answer to the resolver. The time spent between resolver such as one of applications and server over network may be significant particularly if the application makes a lot of API calls.

If the resolver uses the local method then for each API call e.g. gethostbyname the OS must parse the entire etc hosts file within local file to get the answer. If the etc hosts file is significantly large as is the case with many real customer systems it may take a long time for the resolver to get the answer.

In the illustrative embodiment the system administrator may provide network caching daemon that runs on the client resolver side in VIOS LPAR . Network caching daemon hashes entries from local file so that the resolver will not do the local search from local files if it is configured to resolve the host name or IP address the local way. Having network caching daemon hash local file reduces the time to get an answer because the OS does not have to parse the entire file for each API call.

Network caching daemon caches positive and negative answers from server into cache file . The resolver then queries the network caching daemon first before it goes out to query server over network if the resolver is configured to resolve the host name or IP address the non local way.

On the VIOS side local file consolidates all the local files such as etc passwd etc hosts etc so that local file can be shared by all of the individual LPAR . The system administrator may configure the network interface not shown start network caching daemon and configure network caching daemon to listen on the network interface e.g. a valid IP address . Network caching daemon may listen on a well known port number. Network caching daemon may also hash all of the local files into cache .

On each individual LPAR side the system administrator configures operating systems with the IP address of network caching daemon and the server port number if not the well known port number so that the resolver knows where to send the requests. For example the system administrator may specify the IP address of network caching daemon and the server port number in a local text configuration file. The resolver side code may be modified to hold the network caching daemon server IP address and port number. All of the existing network applications need not be modified or recompiled. Even though the IP address appears to be a remote IP address the resolver actually communicates with the same system through virtualization layer . The query is not sent out on network unless a response is not cached in network caching daemon .

In the depicted example servers and are connected to network along with clients . Distributed data processing system may include additional servers clients and other devices not shown. Servers and client belong to subnet . Servers and client belong to subnet .

The resolver may be configured to get the information from different locations such as server which may be a network information services NIS server a domain name system DNS server or a lightweight directory access protocol LDAP server. Alternatively the resolver can get the information from a local etc hosts file. If the resolver uses DNS for example then for each API call e.g. gethostbyname the resolver will send the request over network to server . Server then looks up the answer in storage and returns the answer to the resolver. The time spent between resolver and server over network may be significant particularly if the application makes a lot of API calls. If the resolver uses the local method then for each API call e.g. gethostbyname the OS must parse the entire etc hosts file to get the answer. If the etc hosts file is significantly large as is the case with many real customer systems it may take a long time for the resolver to get the answer.

In one illustrative embodiment one of the computing systems within servers and client for example may run a network caching daemon such that one instance of the network caching daemon runs in each subnet . Each partition running in each of the computing systems may then be configured with the IP address and port number of the network caching daemon of its subnet.

For instance server in subnet may run a network caching daemon. Each of the computing systems within may then be configured with the IP address and port number of the network caching daemon of the respective subnet. The network caching daemon may then consolidate the local files of each of the computing systems within the subnet. The network caching daemon may also cache positive and negative answers in a local cache file.

Accordingly blocks of the flowchart illustrations support combinations of means for performing the specified functions combinations of steps for performing the specified functions and program instruction means for performing the specified functions. It will also be understood that each block of the flowchart illustrations and combinations of blocks in the flowchart illustrations can be implemented by special purpose hardware based computer systems which perform the specified functions or steps or by combinations of special purpose hardware and computer instructions.

With reference now to operation begins and the system administrator consolidates the entries in each local file within the virtual environment into one local file associated with the network caching daemon block . Then the system administrator configures the network interface block . The system administrator then starts the network caching daemon listening on the network interface block . The network caching daemon may listen on a well known port number. Thereafter operation ends.

The resolver side code determines whether there is a network application programming interface API call block . If a network application makes an API call such as gethostbyname or gethostbyaddr for example then the operating system sends the request to the server IP address and port number of the network caching daemon block . Thereafter or if a network application does not make an resolver related API call in block then application determines whether an exit condition exists block . An exit condition may exist for example if the data processing system is being shut down. If an exit condition exists operation ends. If an exit condition does not exist in block operation returns to block to determine whether a network application makes an API call.

Thus the illustrative embodiments solve the disadvantages of the prior art by providing a mechanism to enhance the scalability of network caching capabilities. All network client applications running on a partition in a virtualized environment are configured to query information from a single virtual input output server VIOS network caching daemon. Thus the illustrative embodiments provide a 1 n model where a VIOS partition has a network caching daemon and each of the n partitions uses the network caching daemon of the VIOS partition. The mechanism of the illustrative embodiments only requires the system administrator to control one copy of the local files on the VIOS server. The system administrator does not need to monitor all of these local files on each individual partition. The system administrator consolidates the entries used by the different individual partitions into one single file on the VIOS server side.

It should be appreciated that the illustrative embodiments may take the form of a specialized hardware embodiment a software embodiment that is executed on a computer system having general processing hardware or an embodiment containing both specialized hardware and software elements that are executed on a computer system having general processing hardware. In one exemplary embodiment the mechanisms of the illustrative embodiments are implemented in a software product which may include but is not limited to firmware resident software microcode etc.

Furthermore the illustrative embodiments may take the form of a computer program product accessible from a computer usable or computer readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description a computer usable or computer readable medium can be any apparatus that can contain store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus or device.

The medium may be an electronic magnetic optical electromagnetic or semiconductor system apparatus or device. Examples of a computer readable medium include a semiconductor or solid state memory magnetic tape a removable computer diskette a random access memory RAM a read only memory ROM a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk read only memory CD ROM compact disk read write CD R W and DVD.

The program code of the computer program product may comprise instructions that are stored in a computer readable storage medium in a client or server data processing system. In a client data processing system embodiment the instructions may have been downloaded over a network from one or more remote data processing systems such as a server data processing system a client data processing system or a plurality of client data processing systems using a peer to peer communication methodology. In a server data processing system embodiment the instructions may be configured for download or actually downloaded over a network to a remote data processing system e.g. a client data processing system for use in a computer readable storage medium with the remote data processing system.

A data processing system suitable for storing and or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code bulk storage and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.

Input output or I O devices including but not limited to keyboards displays pointing devices etc. can be coupled to the system either directly or through intervening I O controllers. Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems cable modems and Ethernet cards are just a few of the currently available types of network adapters.

The description of the present invention has been presented for purposes of illustration and description and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

