---

title: Method and system for bandwidth control on a network interface card
abstract: A method for bandwidth control on a network interface card (NIC), the method that includes initiating a current time period, receiving a plurality of incoming packets for a receive ring, populating, by a NIC, the receive ring with the plurality of incoming packets according to a size of the receive ring during the current time period, wherein the size of the receive ring is based on an allocated bandwidth for the receive ring, and sending, by the NIC, the plurality of incoming packets to a host when a duration of the current time period elapses, wherein the duration is based on the allocated bandwidth for the receive ring.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07801046&OS=07801046&RS=07801046
owner: Oracle America, Inc.
number: 07801046
owner_city: Redwood City
owner_country: US
publication_date: 20080428
---
The present application contains subject matter that may be related to the subject matter in the following U.S. applications filed on Apr. 22 2005 and assigned to the assignee of the present application Method and Apparatus for Managing and Accounting for Bandwidth Utilization Within A Computing System with U.S. application Ser. No. 11 112 367 Method and Apparatus for Consolidating Available Computing Resources on Different Computing Devices with U.S. application Ser. No. 11 112 368 Assigning Higher Priority to Transactions Based on Subscription Level with U.S. application Ser. No. 11 112 947 Method and Apparatus for Dynamically Isolating Affected Services Under Denial of Service Attack with U.S. application Ser. No. 11 112 158 Method and Apparatus for Improving User Experience for Legitimate Traffic of a Service Impacted by Denial of Service Attack with U.S. application Ser. No. 11 112 629 Method and Apparatus for Limiting Denial of Service Attack by Limiting Traffic for Hosts with U.S. application Ser. No. 11 112 328 Hardware Based Network Interface Per Ring Resource Accounting with U.S. application Ser. No. 11 112 122 Dynamic Hardware Classification Engine Updating for a Network Interface with U.S. application Ser. No. 11 112 934 Network Interface Card Resource Mapping to Virtual Network Interface Cards with U.S. application Ser. No. 11 112 063 Network Interface Decryption and Classification Technique with U.S. application Ser. No. 11 112 436 Method and Apparatus for Enforcing Resource Utilization of a Container with U.S. application Ser. No. 11 112 910 Method and Apparatus for Enforcing Packet Destination Specific Priority Using Threads with U.S. application Ser. No. 11 112 584 Method and Apparatus for Processing Network Traffic Associated with Specific Protocols with U.S. application Ser. No. 11 112 228.

The present application contains subject matter that may be related to the subject matter in the following U.S. applications filed on Oct. 21 2005 and assigned to the assignee of the present application Method and Apparatus for Defending Against Denial of Service Attacks with U.S. application Ser. No. 11 255 366 Router Based Defense Against Denial of Service Attacks Using Dynamic Feedback from Attacked Host with U.S. application Ser. No. 11 256 254 and Method and Apparatus for Monitoring Packets at High Data Rates with U.S. application Ser. No. 11 226 790.

The present application contains subject matter that may be related to the subject matter in the following U.S. applications filed on Jun. 30 2006 and assigned to the assignee of the present application Network Interface Card Virtualization Based On Hardware Resources and Software Rings with U.S. application Ser. No. 11 479 046 Method and System for Controlling Virtual Machine Bandwidth with U.S. application Ser. No. 11 480 000 Virtual Switch with U.S. application Ser. No. 11 480 261 System and Method for Virtual Network Interface Cards Based on Internet Protocol Addresses with U.S. application Ser. No. 11 479 997 Virtual Network Interface Card Loopback Fastpath with U.S. application Ser. No. 11 479 946 Bridging Network Components with U.S. application Ser. No. 11 479 948 Reflecting the Bandwidth Assigned to a Virtual Network Interface Card Through Its Link Speed with U.S. application Ser. No. 11 479 161 Method and Apparatus for Containing a Denial of Service Attack Using Hardware Resources on a Virtual Network Interface Card with U.S. application Ser. No. 11 480 100 Virtual Network Interface Cards with VLAN Functionality with U.S. application Ser. No. 11 479 998 Method and Apparatus for Dynamic Assignment of Network Interface Card Resources with U.S. application Ser. No. 11 479 817 Generalized Serialization Queue Framework for Protocol Processing with U.S. application Ser. No. 11 479 947 Serialization Queue Framework for Transmitting Packets with U.S. application Ser. No. 11 479 143.

The present application contains subject matter that may be related to the subject matter in the following U.S. applications filed on Jul. 20 2006 and assigned to the assignee of the present application Low Impact Network Debugging with U.S. application Ser. No. 11 489 926 Reflecting Bandwidth and Priority in Network Attached Storage I O with U.S. application Ser. No. 11 489 936 Priority and Bandwidth Specification at Mount Time of NAS Device Volume with U.S. application Ser. No. 11 489 934 Notifying Network Applications of Receive Overflow Conditions with U.S. application Ser. No. 11 490 821 Host Operating System Bypass for Packets Destined for a Virtual Machine with U.S. application Ser. No. 11 489 943 Multi Level Packet Classification with U.S. application Ser. No. 11 490 745 Method and System for Automatically Reflecting Hardware Resource Allocation Modifications with U.S. application Ser. No. 11 490 582 Method and System for Network Configuration for Containers with U.S. application Ser. No. 11 490 479 Network Memory Pools for Packet Destinations and Virtual Machines with U.S. application Ser. No. 11 490 486 Method and System for Network Configuration for Virtual Machines with U.S. application Ser. No. 11 489 923 Multiple Virtual Network Stack Instances with U.S. application Ser. No. 11 489 929 Shared and Separate Network Stack Instances with U.S. application Ser. No. 11 489 933 and Multiple Virtual Network Stack Instances using Virtual Network Interface Cards with U.S. application Ser. No. 11 489 942.

Network traffic is transmitted over a network such as the Internet from a sending system e.g. a computer system to a receiving system e.g. a computer system via a physical network interface card NIC . The NIC is a piece of hardware found in a typical computer system that includes functionality to send and receive network traffic. Typically network traffic is transmitted in the form of packets where each packet includes a header and a payload. The header contains information regarding the source address destination address size transport protocol used to transmit the packet and various other identification information associated with the packet. The payload contains the actual data to be transmitted from the network to the receiving system.

Each of the packets sent between the sending system and receiving system is typically associated with a connection. The connection ensures that packets from a given process on the sending system reach the appropriate process on the receiving system. Packets received by the receiving system via a NIC associated with the receiving system are analyzed by a classifier to determine a the connection associated with the packet.

Typically the classifier includes a connection data structure that includes information about active connections on the receiving system. The connection data structure may include the following information about each active connection i the queue associated with the connection and ii information necessary to process the packets on the queue associated with the connection.

Depending on the implementation the connection data structure may include additional information about each active connection. Such queues are typically implemented as first in first out FIFO queues and are bound to a specific central processing unit CPU on the receiving computer system. Thus all packets for a given connection are placed in the same queue and are processed by the same CPU. In addition each queue is typically configured to support multiple connections.

Once the classifier determines the connection associated with the packets the packets are sent to a temporary data structure e.g. a receive ring on the NIC and an interrupt is issued to the CPU associated with the queue. In response to the interrupt a thread associated with the CPU to which the serialization queue is bound retrieves the packets from the temporary data structure and places teem in the appropriate queue. Once packets are placed in the queue those packets are processed through various layers of the network stack. When the packet reaches the application layer of the network stack the operating system of the receiving system may determine whether the bandwidth allocated to the application corresponding to the appropriate queue permits an additional packet. If the bandwidth does not permit the additional packet then the packet is dropped.

In general in one aspect the invention relates to a method for bandwidth control on a network interface card NIC the method that includes initiating a current time period receiving a plurality of incoming packets for a receive ring populating by a NIC the receive ring with the plurality of incoming packets according to a size of the receive ring during the current time period wherein the size of the receive ring is based on an allocated bandwidth for the receive ring and sending by the NIC the plurality of incoming packets to a host when a duration of the current time period elapses wherein the duration is based on the allocated bandwidth for the receive ring.

In general in one aspect the invention relates to a method for bandwidth control on a network interface card NIC the method that includes determining whether an expected dispersion duration has elapsed since a last interrupt time wherein the expected dispersion duration is based on an allocated bandwidth for a receive ring identifying a subset of a plurality of packets in the receive ring wherein the number of packets in the subset is based on the allocated bandwidth for the receive ring associating the subset with an available identifier when the expected dispersion duration has elapsed and sending by the NIC the subset to a host based on the available identifier.

In general in one aspect the invention relates to a network interface card that includes a receive ring and a receive regulation engine. The receive regulation is configured to initiate a current time period receive a plurality of incoming packets for the receive ring populate the receive ring with the plurality of incoming packets according to a size of the receive ring during the current time period wherein the size of the receive ring is based on an allocated bandwidth for the receive ring and send the plurality of incoming packets to a host when a duration of the current time period elapses wherein the duration is based on the allocated bandwidth for the receive ring.

Other aspects of the invention will be apparent from the following description and the appended claims.

Specific embodiments of the invention will now be described in detail with reference to the accompanying figures. Like elements in the various figures are denoted by like reference numerals for consistency.

In the following detailed description of embodiments of the invention numerous specific details are set forth in order to provide a more thorough understanding of the invention. However it will be apparent to one of ordinary skill in the art that the invention may be practiced without these specific details. In other instances well known features have not been described in detail to avoid unnecessarily complicating the description.

In general embodiments of the invention relate to a method and system for performing bandwidth control on a network interface card NIC . The NIC is a piece of hardware found in a typical computer system that includes functionality to send and receive network traffic. In one or more embodiments of the invention the NIC is attached to multiple virtual network stack VNS instances on a single host. The host includes at least one virtual network interface card VNIC for each VNS instance. Each VNS instance may have different allocated bandwidths in accordance with one or more embodiments of the invention.

Bandwidth control manages the frequency at which incoming packets and or outbound packets are sent or received for each VNS instance. Bandwidth control limits the number of incoming packets i.e. packets received from the network or outbound packets i.e. packets sent on the network that may be sent or received for a VNS instance over a certain period as measured in units of time e.g. second s millisecond s microsecond s etc. .

In one or more embodiments of the invention the bandwidth control is managed using a receive ring discussed below and or a transmit ring discussed below on the NIC and associated with the VNS instance. In one or more embodiments of the invention the bandwidth control may be performed by adjusting the size of the receive ring or transmit ring for the specific VNS instance or by delaying the packets on the receive ring according to the allocated bandwidth.

The NIC is configured to send and receive packets. The hardware classifier is configured classify incoming packets. In one or more embodiments of the invention the hardware classifier classifies an incoming packet based on information in the header of incoming packet. Accordingly the hardware classifier may classify the incoming packet based on one or a combination of the following the source internet protocol IP address the destination IP address a source Media Access Control MAC address a destination MAC address a source port a destination port a protocol type e.g. Transmission Control Protocol TCP User Datagram Protocol UDP etc. . The hardware classifier is not limited to classifying an incoming packet based on one of the aforementioned parameters.

Continuing with the discussion of once an incoming packet has been classified the incoming packet is sent to the appropriate RR . Typically each RR is configured to receive incoming packets for a specific non global container or a particular packet destination in the global container . In one embodiment of the invention each RR corresponds to a buffer in the NIC which is configured to store a finite number of incoming packets.

In one or more embodiments of the invention receive regulation engines are interposed between the RR and the hardware classifier . The receive regulation engines may correspond to firmware on the NIC that includes functionality to perform bandwidth control for a specific RR e.g. . In one or more embodiments of the invention the receive regulation engines include functionality to receive bandwidth parameters for a receive ring and adjust the bandwidth according to the bandwidth parameters.

In one or more embodiments of the invention the bandwidth parameter may be specified for both incoming packets and outbound packets discussed in . In one or more embodiments of the invention the bandwidth parameters for incoming packets may specify one or more of the following a size of the receive ring an identifier of the receive ring the allocated bandwidth for the receive ring a time period with a specified number of incoming packets allowed during the time period a number of interrupts allocated in the time period a threshold number of incoming packets to receive before issuing an interrupt and an expected dispersion duration. Each of these bandwidth parameters are discussed below.

In one or more embodiments of the invention the size of the receive ring is the number of descriptors allocated to the receive ring. A descriptor is a unique identifier and optionally associated data structure such as a pointer assigned to an incoming packet. In one or more embodiments of the invention the receive ring identifier may be a VNS instance identifier discussed below a VNIC identifier or any other unique identifier that may be used to identify the receive ring from other receive rings on the NIC.

In one or more embodiments of the invention a time period is a duration of time in which only a preset number of interrupts may be sent to the host.

Specifically in the time period an interrupt is sent to the host during a current time period when the threshold number of packets is received and if an interrupt is remaining i.e. the preset number of interrupts is not exceeded . At the end of the current time period an interrupt is sent to the host if at least one packet is in the receive ring and a new time period is started. Thus the size of the receive ring the preset number of interrupts and the duration of time in the time period may be used to perform bandwidth control.

In one or more embodiments of the invention an expected dispersion duration is used to perform bandwidth control. An expected dispersion duration is amount of time before forwarding a specified number of incoming packets to the host . For example the expected dispersion duration may be eight packets every microsecond. In such scenario eight packets in the receive ring are marked every microsecond as available and may be forwarded to the host. The expected dispersion duration may be used in conjunction with an available marker and an unavailable marker. Specifically when an unavailable marker is associated with the packet then the packet is not available to send to the host. In such cases the packet is placed if there is available space in the corresponding receive ring. Conversely the available marker indicates that the packet is ready to transmit to the host. Thus for example unavailable markers are associated with packets when the packets are received. When the expected dispersion duration elapses then a specified number of packets may be associated with an available marker. The packets that are associated with the available marker may then be sent to the host.

Returning to the receive ring each RR is associated with a non global container or a packet destination in a global container . Thus the bandwidth of the receive ring identifies the bandwidth of a non global container or a packet destination in a global container . Further once the RR is associated with a non global container or a packet destination in a global container the container ID discussed below corresponding to the a non global container or the packet destination ID discussed below corresponding to a packet destination in a global container is associated with the RR . For example if RR is associated with non global container then the container ID corresponding to non global container is associated with RR .

Associating the RR with the non global container or the packet destination in a global container may include but is not limited to i storing the container ID or packet destination ID in the RR ii associating each incoming packet stored in the RR with the container ID or packet destination ID or iii maintaining a RR Container mapping in the NIC where the RR Container mapping specifies the container ID or packet destination ID for the non global container or the packet destination in a global container associated with each RR in the NIC .

In one embodiment of the invention in addition to associating the RR with a container ID or packet destination ID each RR is associated with one or both of the following cookies i a VNIC cookie and a ii Network Layer cookie. The VNIC cookie specifies a function entry point into a specific VNIC in the host and the Network Layer cookie specifies a function entry point into the Network Layer .

In addition each RR is associated with an acceptor function. The acceptor function takes as input i one of the aforementioned cookies VNIC cookie or Network Layer cookie ii an incoming packet in the RR and iii the container ID or packet destination ID. If the VNIC cookie is used as input to the acceptor function then the incoming packet and container ID are sent to the VNIC specified in the VNIC cookie. Alternatively if the Network Layer cookie is used as input to the acceptor function then the incoming packet and container ID are sent to the Network Layer .

For example an incoming packet in RR may be sent to VNIC using a VNIC cookie that specifies VNIC or the incoming packet may be sent directly to the Network Layer using the Network Layer cookie. In one embodiment of the invention the Network Layer cookie allows the incoming packet to bypass the MAC layer i.e. the layer in which the VNIC resides thereby reducing the amount of processing required to send the incoming packet from the RR to the non global container or packet destination.

In one embodiment of the invention the container ID or packet destination ID is not stored in the RR rather the container ID or packet destination ID is stored in the VNIC associated with the RR. For example VNIC stores the container ID for non global container instead of RR . In such cases the aforementioned acceptor function does not require the container ID or packet destination ID as input.

In one embodiment of the invention the RR or VNIC may include the VNS Instance ID wherein the VNS Instance ID corresponds to the VNS Instance associated with the non global container or packet destination in the global container. In such cases the RR or the VNIC may not include the container ID or the packet destination ID. Further the acceptor function takes the VNS Instance ID as input instead of or in addition to the container ID or the packet destination ID. In addition storing the VNS Instance ID corresponds to associating the RR with the non global container or packet destination in the global container.

In one embodiment of the invention the VNS Instance ID is not stored in the RR rather the VNS Instance ID is stored in the VNIC associated with the RR. For example VNIC stores the VNS Instance ID corresponding to the VNS Instance associated with non global container instead of RR . In such cases the aforementioned acceptor function does not require the container ID or packet destination ID as input.

Continuing with the discussion of the host includes a device driver not shown a number of virtual network interface cards VNICs a Network Layer Transport Layer one or more packet destinations in the global container and one or more non global containers . Each of the aforementioned components is described below.

Though not shown in the device driver is configured to expose the NIC to the host . Further the device driver is configured to expose the individual RRs to the host . Exposing the aforementioned components to the host includes providing application programming interfaces APIs to allow the host or components executing therein to interact with the NIC and the RRs on the NIC . Interacting with the NIC typically includes obtaining incoming packets from the NIC sending outbound packets to the NIC and sending and receiving messages and or signals for the purposes of bandwidth control.

Each VNIC in the host provides the functionality of a NIC for a specific VNS instance. However unlike the NIC the VNICs are implemented in the host typically in a MAC layer of the host . To components above the VNICs e.g. the network layer the transport layer the packet destination in the global container and the non global containers the VNICs appear as physical NICs.

Each VNIC is associated with a MAC address and an IP address. Further each VNIC may be optionally associated with a TCP port or UDP port. Further each VNIC is associated with a RR such that the VNICs obtain incoming packets from the RR with which it is associated. For example VNIC obtains incoming packets from RR . In addition each VNIC is configured to send incoming packets received from an associated RR to the Network layer .

In one embodiment of the invention the Network layer is configured to perform Network layer processing. Network layer processing corresponds to functionality to manage packet addressing and delivery on a network e.g. functionality to support Internet Protocol including but not limited to IPv4 and IPv6 Address Resolution Protocol ARP Internet Control Message Protocol ICMP etc. .

The Network layer shown in is used by all packet destinations in the global container e.g. as well as all non global containers . However the specific portions of the Network layer implemented for a packet destination or non global container depend on the VNS Instance parameters associated with the packet destination or non global container .

Said another way the Network layer corresponds to a common set of methods used to perform Network layer processing. However one or more of the methods in the Network layer requires one or more VNS Instance parameters as input for example one method may require the IP address associated with a non global container as well as the IP routing algorithm e.g. RIP OSPF etc. . Thus depending on the VNS Instance parameters input into the one or more of the aforementioned methods the manner in which packets for a first non global container are processed may be different than the manner in which packets for a second non global container are processed.

In one embodiment of the invention the Transport layer is configured to perform Transport layer processing. Transport layer processing corresponds to functionality to manage the transfer of packets on the network e.g. functionality to support Transmission Control Protocol User Datagram Protocol Stream Control Transmission Protocol SCTP etc. .

The Transport layer shown in is used by all packet destinations in the global container e.g. as well as all non global containers . However the specific portions of the Transport layer implemented for a packet destination or non global container depends on the VNS Instance parameters associated with the packet destination or non global container .

Said another way the Transport layer corresponds to a common set of methods used to perform Transport layer processing. However one or more of the methods in the Transport layer requires one or more VNS Instance parameters as input for example one method may require a protocol to implement e.g. TCP or UDP . Thus depending on the VNS Instance parameters input into the one or more of the aforementioned methods the manner in which packets for a first non global container are processed may be different than the manner in which packets for a second non global container are processed.

In one embodiment of the invention the Network layer and the Transport layer are configured to support multithreading. Thus multiple non global containers and or packet destinations in the global container may be simultaneously processing packets in the Network layer and the Transport layer .

As shown in the host includes a global container and a number of non global containers . The global container corresponds to an isolated execution environment within the host . Further each non global container corresponds to an isolated execution environment within the global container . All of the containers global and non global share a common kernel and accordingly are executing the same operating system. While all of the aforementioned containers share a common kernel the non global containers are configured such that processes executing in a given non global container are restricted to execute in the non global container and have no access to resources not assigned to the non global container. The isolated execution environments of each non global container as well as the global container are managed by a container management component not shown executing on the host . The container management component typically executes outside of the global container . An example of a container is a Solaris Container. Solaris is a trademark of Sun Microsystems Inc. of California USA .

Each of the non global containers is configured to send and receive packets to and from the NIC using the Network layer and the Transport layer . In one embodiment of the invention the packet destination in the global container corresponds to a process executing in the global container where the process is configured to send and receive packets but does not include its own internal networking stack. Rather the packet destination uses the Network layer and the Transport layer executing in the global container .

In one embodiment of the invention each non global container and the global container are identified by a container ID. The container ID uniquely identifies the container in the host . Further each packet destination in the global container is also associated with an ID i.e. a packet destination ID . The packet destination ID uniquely identifies the packet destination in the global container .

In one or more embodiments of the invention the host may also include a VNS database not shown and a Container VNS Instance Mapping not shown . The VNS database includes VNS Instance parameters for each VNS Instance in the host. Typically there is one VNS Instance for each non global container and at least one VNS Instance for the packet destinations in the global container or there may be multiple VNS Instances in the global container where each packet destination is associated with one of the multiple VNS instances . In one embodiment of the invention a VNS Instance corresponds to grouping of VNS Instance parameters and is identified by a VNS Instance ID. The VNS Instance ID uniquely identifies the VNS Instance in the host .

In one embodiment of the invention a VNS Instance parameter corresponds to any parameter that is associated with networking. Examples of VNS Instance parameters may include but are not limited to Media Access Control MAC address Internet Protocol IP address IP routing algorithm e.g. Routing Information Protocol RIP Open Shortest Path First OSPF etc. Transport layer protocol e.g. Transmission Control Protocol TCP User Datagram Protocol UDP an IP routing table default route i.e. the route set in the IP routing table used when no other entry in the IP routing table matches the destination IP address of the packet TCP parameters i.e. parameters in the TCP that may be changed for example bandwidth delay product buffer size etc. IP parameters i.e. parameters in the IP that may be changed TCP port number and UDP port number.

In one embodiment of the invention each VNS Instance includes a value for all VNS Instance parameters for the particular VNS Instance. The value for a particular VNS instance parameter may be specified or a default value for the VNS Instance parameter may be used. For example assume that each VNS instance must specify an IP address an IP routing algorithm a default route and a Transport Layer protocol. Further assume that only values for the IP address and IP routing algorithm are provided. Accordingly default values are obtained for the default route and Transport Layer Protocol.

The VNS Instance parameters are typically specified by a packet destination in the global container or a non global container. The specific values for VNS Instance parameters is typically dictated by the requirements of the packet destination in the global container or the non global container with which the VNS Instance is associated.

In one embodiment of the invention the Container VNS Instance Mapping maps each container global and non global to a VNS Instance. The container is typically identified by a container ID and the VNS Instance is typically identified by the VNS Instance ID. In one embodiment of the invention if the global container includes multiple packet destinations then each of the packet destinations may be identified by a packet destination ID. Further if the packet destination IDs are included in the Container VNS Instance Mapping then the global container may not be listed in an entry in the Container VNS Instance Mapping. Further the Container VNS Instance Mapping may additionally include mappings between packet destinations in the global container and VNS instances Both the VNS database and a Container VNS Instance Mapping are typically located in the global container .

In one or more embodiments of the invention a virtual network stack VNS database not shown includes dynamic entries and optionally static parameters. Each of the dynamic entries identifies a VNS Instance using a VNS Instance ID and includes the VNS Instance parameters associated with the VNS Instance. In one embodiment of the invention the VNS database is configured to receive a VNS Instance ID locate the corresponding dynamic entry using the VNS Instance ID and return the VNS Instance parameters associated with the VNS Instance ID.

In one embodiment of the invention the VNS database also includes logic to determine which of the VNS Instance parameters to return at any given time. For example if a process in the Network layer sends the VNS Instance ID to the VNS database then the VNS database may only return VNS Instance parameters associated with the Network layer i.e. which may be used by the Network layer . In such cases all other VNS Instance parameters are not sent to the Network layer.

The VNS database may include default values for VNS instance parameters. As discussed above the default values correspond to values used for any VNS instance parameter not specified for the VNS Instance.

In one embodiment of the invention the VNS Instance parameters for a particular VNS Instance may include both the VNS Instance parameters specified for the VNS Instance as well as the default values for VNS Instance parameters not specified for the VNS Instance. Alternatively the VNS Instance parameters for a particular VNS Instance only include the VNS Instance parameters specified for the VNS Instance and the default values for the VNS Instance parameters not specified for the VNS Instance are located in a separate location in the VNS database or in another location in the host.

In one embodiment of the invention the static parameters correspond to parameters used by all VNS instances in the host . The static parameters typically correspond to parameters that must be the same for all VNS instances executing on the host . As discussed above the static parameters are optionally located in the VNS database. As an alternative the static parameters may be located in a separate location in the global container or may be hard coded into the appropriate locations in the Network layer and the Transport layer .

In one or more embodiments of the invention a Container VNS Instance Mapping includes a mapping of container ID to VNS Instance ID. The aforementioned mapping associates the VNS Instance with a container. Thus when an incoming packet for the container is received by the host the. Container VNS Instance Mapping may be used to determine which of the VNS instances to use to process the incoming packet. Further when the container issues an incoming packet the Container VNS Instance Mapping may be used to determine which of the VNS instances to use to process the outbound packet.

As discussed above each packet destination in the global container may be identified with a packet destination ID and associated with a VNS Instance. In such cases the Container VNS Instance Mapping also includes a packet destination VNS Instance mapping.

In addition or as an alternative to the components discussed above the NIC may include transmit rings transmit regulation engines and an outbound rate regulation engine in order to perform bandwidth control for outbound packets.

In one or more embodiments of the invention each transmit ring is configured to receive outbound packets from a specific non global container or a particular packet origin in the global container . In one embodiment of the invention each transmit ring corresponds to a buffer in the NIC which is configured to store a finite number of outbound packets.

In one or more embodiments of the invention a transmit regulation engine is interposed between the transmit ring and the VNIC . The transmit regulation engine may be firmware on the NIC that includes functionality to populate a transmit ring e.g. . In one or more embodiments of the invention each transmit regulation engine may include sending stop and resume signals to the host based on whether the maximum number of packets is in the transmit ring . The maximum number of packets are determined to be in the transmit ring when the transmit ring is full. Rather than sending the stop signal and resume signal when the transmit ring is full the sending of a stop or resume signal may be based on a threshold number of packets are in the receive ring.

In one or more embodiments of the invention an outbound rate regulation engine includes functionality to obtain packets from the transmit rings and send the packets via the network to the packets destinations. The outbound rate regulation engine may obtain the packets from each transmit ring in a round robin manner. For example the outbound rate regulation engine may obtain packets from transmit ring then obtain packets from transmit ring etc. Those skilled in the art will appreciate that if the transmit ring does not have packets or the packets are not available then the outbound rate regulation engine may skip that particular transmit ring e.g. during a pass of the round robin.

In one or more embodiments of the invention the transmit regulation engine the outbound rate regulation engine or the size of the transmit ring may be used for performing bandwidth control for the transmission of packets based on one or more bandwidth parameters. Similar to bandwidth parameters for incoming packets in one or more embodiments of the invention the bandwidth parameters for outbound packets may specify one or more of the following a size of the transmit ring an identifier of the transmit ring and the allocated bandwidth for the transmit ring . In one or more embodiments of the invention the size of the transmit ring is the number of descriptors allocated to the transmit ring 

In one or more embodiments of the invention the identifier for the transmit ring may be a VNS instance identifier discussed below a VNIC identifier or any other unique identifier that may be used to identify the transmit ring from other transmit rings on the NIC .

The follow discussion details how different components in the NIC may be used to perform bandwidth control in accordance with one or more embodiments of the invention. In one embodiment of the invention an available marker and or an unavailable marker may be used by the NIC to perform bandwidth control. Specifically when an unavailable marker is associated with the packet then the packet is not available to transmit on the network. Conversely the available marker indicates that the outbound rate regulation engine may transmit the packet. For example consider the scenario in which the allocated bandwidth for transmit ring is five packets per time period. In the example at each time period transmit regulation engine may associate the oldest five packets in the transmit ring with an available marker. In the example the outbound regulation engine may be configured to only transmit packets that are associated with an available marker. Thus the outbound regulation engine only sends five packets per time period for the non global container .

In one of the invention the outbound rate regulation engine may perform bandwidth control. For example the outbound rate regulation engine may identify the bandwidth of each of the transmit ring in a time period. The outbound rate regulation engine may obtain packets proportionally to the bandwidth from each transmit ring . In the example consider the scenario in which transmit ring has an allocated bandwidth of five packets per time period transmit ring has an allocated bandwidth of two packets per time period transmit ring has an allocated bandwidth of four packets per time period and transmit ring has an allocated bandwidth of three packets per time period. In the example the outbound rate regulation engine may in one pass of a round robin obtain five packets from transmit ring two packets from transmit ring four packets from transmit ring and three packets from transmit ring .

In one or more embodiments of the invention the size of the transmit ring may be used to perform bandwidth control. In such scenarios the transmit regulation engine may populate the corresponding transmit ring with packets until the corresponding transmit ring is full. The outbound rate regulation engine may obtain all packets in each pass of the round robin from each transmit ring . For example consider the scenario in which transmit ring has an allocated bandwidth of five packets per time period and each pass of the round robin takes one time period. In the example the size of transmit ring may be set to allow for only five packets in the transmit ring at once. Thus in each time period a maximum of five packets are stored in the transmit ring. Any additional packets may be dropped.

The receive ring for the container is identified Step . The receive ring may be identified by the administrator or the host. Specifically the receive ring identifier is obtained. As discussed above the receive ring identifier may be the VNS instance identifier a VNIC identifier or any other unique identifier that may be used to identify the receive ring from other receive rings on the NIC.

In Step the allocated bandwidth of the receive ring for the container is defined. Bandwidth may be allocated by specifying a number of packets per time period allowed for the container or by specifying a percentage of the total bandwidth provided by the NIC that is allocated to the container.

Similar to the receive ring the transmit ring for the container is identified Step . If the transmit ring and the receive ring use the same identifier e.g. the VNS identifier then a separate step of identifying the transmit ring may not be required. In Step the allocated bandwidth of the transmit ring for the container is defined. The bandwidth of the transmit ring may be allocated in a as the bandwidth for the receive ring.

In Step the bandwidth parameters are sent to the NIC. In one embodiment of the invention sending the bandwidth parameters to the NIC may include specifying the identifier of the receive ring the bandwidth of the receive ring the identifier of the transmit ring the allocated bandwidth of the transmit ring or any of the bandwidth parameters discussed above with reference to and . In one or more embodiments of the invention transmitting the bandwidth parameters to the receive ring may be performed using the device driver for the NIC.

In step the NIC adjusts the receive regulation engine the size of the transmit ring the transmit regulation engine the size of the transmit ring and or the outbound rate regulation engine using the bandwidth parameters. The NIC adjusts the above components depending on the mechanism s used to perform bandwidth control.

For example if the bandwidth control is performed based on the size of the transmit or receive ring then the NIC accesses the transmit or receive ring and adjusts the number of descriptors that may be stored by the transmit or receive ring. For incoming packets the NIC may also adjust the number of interrupts which are allowed to be issued in a particular time period and the threshold number of packets to arrive before generating an interrupt. Further for outbound packets the NIC may adjust the threshold number of packets received before issuing a stop signal. The NIC may also or alternatively adjust the threshold number of descriptors available before a resume signal is issued. In another example if the bandwidth control is performed by the receive regulation engine marking packets as available then the receive regulation engine adjusts the expected dispersion duration at which packets are marked as available based on the bandwidth parameter. Using the adjusted allocated bandwidth the NIC may perform bandwidth control for the host.

Continuing with once the host is interrupted an interrupt routine on the host may request to receive all available packets for the receive ring. Accordingly the packets are sent to the host Step and subsequently processed by the host Step . The host may process the packet by optionally sending the packet to the VNIC associated with the receive ring. The target ID and or the VNS Instance ID may be sent with the packet depending on whether the target ID and or the VNS Instance ID is associated with the receive ring. In one embodiment of the invention the target of the packet is a non global container or a packet destination in the global container. The VNIC subsequently sends the packet to the Network Layer. The target ID and or the VNS Instance ID may be sent with the packet depending on the implementation. As discussed above the target ID and or the VNS Instance ID may be obtained from the VNIC.

The host or a process executing thereon obtains the VNS Instance parameters using the VNS Instance ID or the target ID. If the VNS Instance ID is provided then the VNS Instance parameters may be obtained directly from the VNS database. If the target ID is available then the target ID is used to obtain the VNS Instance ID corresponding to the VNS Instance associated with the target using the Container VNS mapping. The VNS Instance ID is then used to obtain the VNS Instance parameters from the VNS database.

Regardless of how they are obtained the VNS Instance parameters are then used by the Network layer and the Transport layer to process the packet. The processed packet is then sent to the target. In one embodiment of the invention the packet may be forwarded directly from the receive ring to the network layer.

If the current time period has not elapsed then a determination is made about whether the receive regulation engine has sent the preset number of allocated interrupts to the host in the current time period Step . As discussed above the receive ring is allocated a preset number of interrupts. Determining whether the interrupt exists in the current time period may be performed using a counter on the NIC that is associated with the receive ring. Each time an interrupt is generated the counter is updated e.g. decremented when the counter counts the number of allocated interrupts remaining in the current time period or incremented when the counter counts the number of interrupts sent in the current time period . At the end of the current time period the counter may be reset. One skilled in the art will appreciate that the preset number of interrupts may be set to zero to indicate that the only interrupt to the host is at the end of the current time period.

In one or more embodiments of the invention if the host has not sent the preset number of allocated interrupts in the current time period then a determination is made about whether the number of packets received is greater than or equal to a threshold number Step . As discussed above the threshold number of packets is the number of packets that the receive ring is to receive before the host is interrupted.

If the number of packets is greater than or equal to the threshold number then the host is interrupted Step . Interrupting the host may be performed as discussed above and in Step of .

Alternatively if the number of packets is not greater than or equal to the threshold number then the receive ring may continue to receive packets and or wait until the current time period elapses Step . If the receive ring is full then the receive ring may start to drop packets. Therefore in one or more embodiments of the invention the total number of packets that the receive ring can receive is the size of the receive ring multiplied by the preset number of interrupts with an additional interrupt i.e. total packets time period size of receive ring preset number 1 .

Returning to Step if the host has sent the preset number of allocated interrupts in the current time period then the receive ring may continue to receive packets until the current time period elapses Step . Each time the NIC receives a packet the packet is stored in the receive ring.

At this stage the counter for the preset number of interrupts and the counter for the time period may be reset.

Further in one or more embodiments of the invention a determination is made about whether a packet is available Step . Specifically a determination is made whether the receive ring has a packet. The receive ring may be determined to have a packet if a descriptor of the receive ring is associated with a packet. If a packet is available then the host is interrupted Step . Interrupting the host may be performed as discussed above in Step of FIG. . Alternatively if a packet is not available then the processing may end or continue for the next time period.

Although shows that the host is interrupted only once those skilled in the art will appreciate that the method may repeat starting with Step to continue processing packets received on the NIC. and the discussion below is for exemplary purposes only and not intended to limit the scope of the invention. Thus the receive regulation engine may continue to receive a packet or detect when the current time period elapses. Further although shows a flowchart for a single receive regulation engine multiple receive regulations engines may perform the method shown in for their corresponding receive ring.

In the example at time unit the receive ring is empty and no packets are received. At time unit packet A is received and stored in the receive ring. Because there is only one packet in the receive ring and the threshold number of packets is five no interrupts are sent to the host. Packet B is received at time unit and stored in the receive ring with A. At time unit packet C is received. At time unit packets D and E are received. At this time unit the receive regulation engine determines that the receive ring has five packets therefore the receive ring is storing the threshold number of packets. Further the receive regulation engine determines that the preset number of interrupts have not been issued. Accordingly at time unit an interrupt is sent to the host. Subsequently the host obtains the packets from the receive ring. Thus the receive ring no longer includes packets A B C D or E.

Continuing with packets F and G are received at time unit and stored in the receive ring. At time unit packets H and I are received. At time unit packet J is received and stored with F G H and I in the receive ring. At this time unit the receive regulation engine determines that the receive ring has five packets. Therefore the receive ring is currently storing the threshold number of packets at time unit . Further the receive regulation engine determines that an interrupt is remaining before the preset number of interrupts is exceeded. Accordingly at time unit an interrupt is issued to the host. Subsequently the host obtains the packets from the receive ring. Thus the receive ring no longer includes packets F G H I or J.

At time unit packets K L M N and O are received and stored in the receive ring. Because there are no more interrupts remaining in this time period no interrupt is issued. At time unit packets P Q R and S are received but not stored because the receive ring can store only five packets. Accordingly packets P Q R and S are dropped. At the end of time unit the time period has elapsed. At time unit not shown the number of interrupts available is reset to two and thus the host is interrupted not shown and packets K L M N and O are sent to the host.

Those skilled in the art will appreciate that is for exemplary purposes only. In actuality there may be some delay for sending the interrupt processing the interrupt by the host and receiving packets. Further although in the example the threshold number of packets is the same as the size of the receive ring the threshold number of packets may be less than the number of packets that can be stored in the receive ring. In such scenario rather than sending all packets the NIC may only send the host the threshold number of oldest packets in the receive ring assuming the host is operating in FIFO mode as opposed to for example FILO mode .

When the expected dispersion duration elapses then the packet s with the oldest arrival time s is are identified Step . The number of packets that are identified is dependent on the bandwidth. For example if the bandwidth specifies that n oldest packets are to be sent to the host every t time units and the expected dispersion duration is t 2 then the n 2 oldest packets are identified to be sent to the host.

Accordingly the packet s with the oldest arrival time are associated with an available identifier the time of last interrupt is set or the counter for the expected dispersion duration is reset and the host is interrupted Step . The host may be interrupted as discussed above. When the host is interrupted the host may obtain only the packets associated with an available identifier. Packets that are not associated with an available identifier in the receive ring may be dropped or remain in the receive ring.

In one or more embodiments of the invention the flowchart shown in may continually repeat for additional packets that are in the receive ring or arrive in the receive ring. Further in one or more embodiments of the invention the method for consuming packets may be performed in parallel by each of the receive rings. In alternative embodiments of the invention the packets from different receive rings may be consumed in a round robin fashion. For example while waiting for the expected dispersion duration to elapse from one receive ring packets may be consumed from another receive ring.

In the example at time unit the receive ring is empty and no packets are received. At time unit packets A B C are received and stored in the receive ring with an unavailable identifier. Packets D E and F are received at time unit and stored in the receive ring with an unavailable identifier. Further because the expected dispersion duration has elapsed packets A B C are associated with an available identifier and the host is interrupted. At any time after the packets are marked with an available identifier the host may obtain packets A B and C in accordance with one or more embodiments of the invention.

At time unit packet G is received associated with an unavailable identifier and stored in the receive ring. At time unit packets H and I are received associated with an unavailable identifier and stored in the receive ring. Packets J and K are received at time unit associated with an unavailable identifier and stored in the receive ring. Further because the expected dispersion duration elapsed at time unit the three oldest packets i.e. D E and F are associated with an available identifier and the host is interrupted. Therefore the host may obtain packets D E and F. At time unit packet L is received associated with an unavailable identifier and stored in the receive ring. At time unit packet M is received associated with an unavailable identifier and stored in the receive ring. Packets N and O are received at time unit stored in the receive ring and associated with an unavailable identifier. Further because the expected dispersion duration has elapsed the three oldest packets i.e. G H and I in the receive ring are associated with an available identifier. Accordingly an interrupt is sent to the host. At time unit packet P is received stored in the receive ring and associated with an unavailable identifier.

Those skilled in the art will appreciate that is for exemplary purposes only. In actuality there may be some delay for sending the interrupt processing the interrupt by the host and receiving packets. Further although in the example the size of the receive ring seems unlimited the size of the receive ring may be limited according to the allocated bandwidth for the receive ring. Thus when the number of packets in the receive ring exceeds the limited number allowed by the size of the receive ring packets may be dropped.

Accordingly the NIC receives the packet for transmission Step . Upon receipt of the packet the NIC stores the packet in the transmit ring associated with the VNS instance sending the packet Step . A determination is made whether the maximum number of packets are in the transmit ring Step . If the maximum number of packets are in the transmit ring then a stop signal is sent to the host Step . The maximum number may be when the transmit ring is full or when a threshold number of packets are in the transmit ring. The threshold number may allow for the stop signal to propagate to the non global container or packet origin in the global container.

While packets are received packets may be transmitted via the network Step . For example the outbound rate regulation engine may obtain all packets in each transmit ring in a round robin. Once the packets are transmitted from the transmit ring and or space is available in the transmit ring to store packets then a resume signal may be sent to the host not shown . When the resume signal is received the host may continue sending packets to the NIC for the transmit ring.

The host with the NIC may be virtually any type of computer regardless of the platform being used. For example as shown in a computer system includes one or more processor s associated memory e.g. random access memory RAM cache memory flash memory etc. a storage device e.g. a hard disk an optical drive such as a compact disk drive or digital video disk DVD drive a flash memory stick etc. and numerous other elements and functionalities typical of computers not shown . The computer may also include input means such as a keyboard a mouse or a microphone not shown . Further the computer may include output means such as a monitor e.g. a liquid crystal display LCD a plasma display or cathode ray tube CRT monitor . The computer system may be connected to a network e.g. a local area network LAN a wide area network WAN such as the Internet or any other similar type of network via a network interface connection not shown . Those skilled in the art will appreciate that many different types of computer systems exist and the aforementioned input and output means may take other forms. Generally speaking the host and the NIC includes at least the minimal processing input and or output means necessary to practice embodiments of the invention.

Embodiments of the invention allow for bandwidth control by the NIC for each specific VNS Instance. Thus for example bandwidth may be allocated based on one or more of a variety of factors such as the different types of network traffic used by the container as opposed to other containers a priority for the network traffic in the container level of service required by the container and other such factors. The NIC enforcement of the allocated bandwidth saves CPU resources on the host and may prevent undue processing by the host.

While the invention has been described with respect to a limited number of embodiments those skilled in the art having benefit of this disclosure will appreciate that other embodiments can be devised which do not depart from the scope of the invention as disclosed herein. Accordingly the scope of the invention should be limited only by the attached claims.

