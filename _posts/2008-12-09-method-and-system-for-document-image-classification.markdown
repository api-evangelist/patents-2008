---

title: Method and system for document image classification
abstract: A method of classifying an input image includes the initial steps of labeling an input image in accordance with a class and extracting at least one connected component from the input image. The method also includes the steps of calculating at least one feature of the input image and generating a model based on the at least one calculated feature. The method also includes the steps of repeating at least one of the previous steps for at least one other input image and comparing the at least one other input image with the model. The at least one other input image is classified in accordance with the class of the model if the at least one calculated feature of the at least one other input image is substantially similar to that of the model.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08520941&OS=08520941&RS=08520941
owner: Xerox Corporation
number: 08520941
owner_city: Norwalk
owner_country: US
publication_date: 20081209
---
The present disclosure relates to document classification systems and in particular to a system and method for document image classification based on visual appearance.

The use of digital input scanners which can successively scan a set of sheets and record the images thereon as digital data is common in the office context such as in digital copiers and electronic archiving. Document categorization is a technique utilized to analyze a scanned document and assign one or more pre defined category labels to the analyzed document. In this manner automatic analysis tasks e.g. indexing retrieval sorting organization may be tailored to specific document types.

In high volume document scanning scenarios considerable time and resources are dedicated to visual and or functional categorization of documents. Typically a recently obtained input image is compared to a predetermined and preprocessed reference image or training model. In a practical situation such as in a digital copier or a network printing and copying system the reference image must be somehow obtained in advance. In a basic case such as when a user of a digital copier is scanning in what is known to be a set of slides with a uniform template the user can indicate to the scanning system through a user interface that the first scanned page image in the set should serve as the reference image in regard to subsequent page images in the set. A variation of this idea would be to have the user cause the scanning system to enter a training phase of operation in which a plurality of sheets believed to have a common template are scanned in and analyzed using an algorithm to find objects common to all of the sheets. From this training phase of operation a basic template of common objects can be derived. This basic template of common objects can be used to determine the reference image data.

To make scanned documents searchable some document classifier engines index electronic documents utilize Optical Character Recognition OCR technology. This technique is typically slow e.g. 1 2 pages per second for high volume document scanning operation where speed e.g. 20 30 pages per second is needed. Further OCR technology is not capable of recognizing graphical features e.g. logos shapes etc. within an image document or recognizing image documents of the same category that are represented with different language locales. This shortcoming is exposed in various document classification scenarios such as for example wherein images belonging to the same category of document are visually different but are nonetheless labeled the same. During the training phase most classifier engines combine the computed features of scanned images belonging to the same category to generate training data and or a training model. This method of generating training data and or training models contributes to poor accuracy and slow processing during subsequent classification of scanned documents.

In an embodiment of the present disclosure a method of classifying an input image includes the initial steps of labeling an input image in accordance with a class and extracting one or more connected components from the input image. The method also includes the steps of calculating one or more features of the input image based on the one or more extracted connected components and generating a model based on the one or more calculated features. The model corresponds to the class of the input image. The method also includes the steps of repeating one or more of the previous steps for one or more other input images and comparing the one or more other input images with the model. The one or more other input images are classified in accordance with the class of the model if the one or more calculated features of the one or more other input images is substantially similar to that of the model.

In another embodiment of the present disclosure a method of classifying an input image includes the initial steps of labeling an input image in accordance with a class and extracting one or more connected components from the input image. The method also includes the steps of calculating one or more features of the input image based on the one or more extracted connected components and repeating one or more of the previous steps for one or more other input images. The method also includes the steps of clustering input images of the same class into a sub class and aggregating the one or more calculated features of the clustered input images of the sub class. The method also includes the steps of generating a model of the sub class based on the one or more aggregated features of the clustered input images. An input image having one or more calculated features substantially similar to the aggregated features of the model is classified in accordance with the class of the clustered input images of the sub class.

In another embodiment of the present disclosure a method of classifying an input image includes the initial steps of bounding one or more targets of an input image and labeling the bounded target s in accordance with a class of the input image. The method also includes the steps of extracting one or more connected components from the bounded target s and calculating one or more features of the bounded target s based on the extracted connected component s . The method also includes the step of generating a model of the bounded target s based on the calculated feature s . The model is labeled in accordance with the class of the input image to which the label of the bounded target s corresponds. The method also includes the steps of extracting one or more connected components from one or more other input images and calculating one or more features of the other input image s based on the extracted connected component s . The method also includes the step of comparing the other input image s with the model. The other input image s is labeled in accordance with the class of the model if the calculated feature s of the other input image s is substantially similar to that of the model.

Embodiments of the presently disclosed image categorization system and method will now be described in detail with reference to the drawings in which like reference numerals designate identical or corresponding elements in each of the several views.

The present disclosure relates to the image based analysis of scanned images to classify document types. In embodiments of the present disclosure attributes or features of input images are automatically learned by an image classification engine ICE through use of an efficient connected component analysis to generate training data or training models models . Other scanned input images are compared with the models and classified based on the comparison. The ICE is a fast multi facet machine learning classifier that is configured to classify documents based on visual appearance. The ability to classify documents based on visual appearance negates the need for optical character recognition OCR . Once a model is generated through use of methods embodied by the present disclosure see the ICE may utilize any suitable probabilistic classification model e.g. Naive Bayes or support vector machine to classify documents based on comparisons between input documents and the model.

Connected component analysis is an image analysis algorithm utilized to group pixels of a scanned image into components based on pixel connectivity. More specifically all pixels included within a connected component share substantially similar pixel intensity values e.g. gray level color etc. . In one embodiment particular features of scanned images are calculated by the ICE utilizing a fast and efficient connected component analysis such as the analysis described in commonly owned U.S. Pat. No. 7 379 587 the disclosure of which is incorporated herein by reference in its entirety. Scanned images sharing substantially similar calculated features e.g. images of the same class are clustered into subsets based on these similarities. Clustering is the classification of objects into different groups or more precisely the partitioning of a data set into subsets clusters so that the data in each subset share some common trait e.g. proximity according to some defined distance measure . Based on the aggregate calculated features of the clustered data e.g. the re labeled subsets a model is generated as will be discussed in further detail below. This automatic clustering of image data facilitates the unique implementation of the ICE as a fast and efficient technique for calculating connected components.

In another embodiment particular features of one or more specific targets of a scanned image are calculated by the ICE utilizing connected component analysis. A target may be any graphical feature of the scanned image such as for example a barcode a shape or a logo. Based on the calculated features of the specific target a model is generated as will be discussed in further detail below. This target spotting technique for detecting unique features e.g. barcodes within documents is implemented by the ICE as a fast and efficient technique for calculating connected components.

Each of the above described techniques for calculating connected components quickly and efficiently allow the ICE to be implemented with a small memory footprint relative to conventional categorization techniques.

In one scenario illustrated by documents that are vastly different in appearance may nonetheless belong to the same class of images e.g. prescriptions . Absent user intervention existing classification models would fail to automatically recognize such visually different images as belonging to the same class. As such images in this scenario must be manually labeled as belonging to the same class to generate the corresponding models. Further the documents illustrated in are represented by different language locales namely English and German respectively. Although OCR would recognize the characters in each of the images of the differences in textual content would prevent OCR from recognizing these images as belonging to the same class of document.

In another scenario illustrated by documents may have substantially similar visual features that available classification engines and or methods may not have the capacity to differentiate. That is images may have only slight variations that existing classification engines fail to recognize and as a result undesirably classify these images as belonging to the same class.

As discussed above the ICE utilizes connected component analysis to generate a model for purposes of classifying documents in various scenarios such as the scenarios discussed above. More specifically the ICE may operate in various modes or phases including a so called training phase wherein the ICE automatically learns the attributes or features of input images to generate a corresponding model discussed in further detail below. The ICE may also operate in a so called classification phase wherein the ICE matches attributes or features of input images with a model to classify the input images in accordance with the classification of the matching model. In use the ICE may operate in the training phase and classification phase concurrently or operate in either one of the training phase and classification phase independently.

With reference to the scenario illustrated by by way of example the ICE calculates features of an input image e.g. via connected component analysis received through for example a digital input scanner as part of a digital copier not explicitly shown and suitably processed e.g. segmented analyzed converted to a known format etc. . The digital copier may include several components including a processor memory e.g. RAM a hard disk drive a USB interface a network interface a display monitor and or other components. In embodiments the ICE may be a software application stored in the memory of the copier and executable by the processor of the copier. The ICE may be implemented through an application programming interface API . The API implementation provides the ability to invoke methods and or software applications e.g. the ICE that reside on another computer system.

In an initial step of method an input image is labeled in accordance with a class as will be discussed in detail below with reference to . In step the input image is divided into a plurality of regions e.g. 128 pixels 128 pixels . In step the ICE extracts one or more connected components from each of the plurality of regions of the input image. In step one or more features for each of the plurality of regions of the input image is calculated based on the one or more connected components extracted in step . The one or more features calculated may include for example without limitation the quantity of connected components within a region e.g. the number of individual components within each region the pixels of each of which share substantially similar intensity values the pixel population e.g. number of ON pixels within each connected component e.g. the number of pixels that share substantially similar intensity values within a connected component the relative location of each connected component within a region e.g. the x and y coordinates of each connected component within the region and the dimensions of a so called bounding box discussed in further detail below bounding each component e.g. x y width height .

Returning to the above mentioned scenario illustrated by input images that are substantially visually different may nonetheless be of the same category or class of document. In this scenario the ICE clusters each of such input images into a sub class of the common root class in step . Each clustered image of a particular class is re classified or re labeled in accordance with one of any number of sub classes of the root class as will be discussed in further detail below with reference to . In step for each sub class of a root class the calculated features of each and every image within a sub class are aggregated. In embodiments the mean and standard deviation of the calculated features of each region of each image in a particular sub class are calculated and the resulting calculation is utilized to generate the model for that particular sub class. In step a model is generated for each sub class based on the aggregate features of the clustered image s of that sub class. In embodiments the model of a sub class is stored within a model file corresponding to the root class of the sub class within the memory of a digital copier. That is each sub class clustered from the same root class of input images includes a unique model that corresponds to or points to that class of input images as a common root class. Input images sharing one or more respective calculated features with the model of a particular sub class are classified in accordance with the label of the root class to which that particular sub class points. The ICE is a self learning application that accumulates a knowledge base of training data with each model generated.

With reference to the scenario illustrated by and described above illustrates by way of example a method by which the ICE clusters one or more input images . The ICE includes a clustering module a feature module and a model generator . The clustering module clusters input images belonging to the same class e.g. Label into one or more sub classes e.g. Label   Label  k . As shown in by way of example Label  k represents a sub class k of root class 1. Each sub class includes one or more clustered images that share one or more calculated features. Each sub class may include at minimum one clustered image and at maximum n clustered images wherein n represents the number of input images clustered by the clustering module . The feature module aggregates the calculated features from each and every clustered image within a sub class. Based on the aggregated features for a particular sub class the model generator generates a unique model corresponding to that sub class. More specifically the generated model corresponding to a particular sub class is based upon the aggregate features of the clustered image s of that sub class. In embodiments the aggregate features for a particular sub class may correspond to the mean and standard deviation of the calculated features from each and every clustered image of a particular sub class. The generated model is compared with subsequent input images for purposes of document classification of the input image.

To classify an input image e.g. and or in the scenario illustrated by a suitable method such as for example a maximum likelihood estimation is utilized to match or fit the calculated features of the input image to a model corresponding to a class or sub class. Upon a successful match or fit with a model corresponding to a particular sub class the label or classification returned or generated corresponds to the root class to which that particular sub class points. In a practical scenario a digital copier may operate in a so called classification phase that corresponds to the classification phase of the ICE wherein input images are scanned and analyzed to calculate one or more features as described above with reference to method for purposes of comparison to models stored within the memory of a digital copier. Upon classification of an input image or failure to classify an input image the ICE may provide a suitable indication e.g. via a user interface of the digital copier of the resulting classification of the input image or resulting failure to classify the input image.

With reference to the scenario illustrated by by way of example the ICE calculates features of an input image e.g. via connected component analysis received through for example a digital input scanner as part of a digital copier and suitably processed e.g. segmented analyzed converted to a known format etc. . In an initial step of method one or more zones e.g. zones of an input image are selected e.g. zones may be selected by a user of a printing device during the training phase of the ICE . More specifically zones may be selected to target features or properties of an input image which differentiate that image from images belonging to a different class or stated differently features or properties that define an input image as belonging to a particular class e.g. a distinguishing feature . With reference to each zone and may be embodied as a bounding box of a general type known in image processing to isolate smaller images of a single identifiable type called objects within a large image. In this scenario zones may be the smallest possible rectangle having dimensions along the x and y directions of the large image that encompasses or bounds an object. The number of objects found in an image may vary depending on a particular segmenting technique or filtering technique.

In step each zone selected from a particular input image is labeled in accordance with a class of images to which that particular input image belongs. That is zones selected from the same input image share the same label. In this manner each input image includes a single label representative of the class of images to which the input image belongs. In a practical scenario the label selected for the one or more zones of an input image may be selected by a user through use of a digital copier e.g. via a user interface during a training phase of the ICE.

In step one or more connected components are extracted from the selected zone s of the input image selected in step . In step one or more features of the selected zone s are calculated based on the connected component s extracted from that zone. The one or more features calculated may include for example without limitation the size of each extracted connected component e.g. the surface area of a zone occupied by the pixels included within a connected component the pixel population e.g. number of ON pixels within each extracted connected component the relative location of each extracted connected component within a zone e.g. the x and y coordinates of each connected component within the region and the normalized shape histogram or distribution of tones for each side of each extracted connected component e.g. left right top bottom .

In step for each zone selected for an input image the ICE generates a model based on the one or more features calculated in step . Each model generated is labeled in accordance with the label selected for the zone on which the model is based. In this way for each zone selected from a particular input image a model is generated to represent the class of images to which that input image belongs. The model of a particular zone is based on the one or more features calculated for that selected zone. Based on the features calculated the ICE may learn a specific sequence of the target bounded by the zone. A barcode for example may include a specific sequence of shapes or figures spaced in a specific relation relative to each other. This specific sequence may be compared to calculated features of subsequently input images for purposes of classification as will be discussed in further detail below.

To classify an input image e.g. and or in the scenario illustrated by one or more features of the entire input image are calculated and compared to the one or more models generated in step of method . More specifically one or more connected components are extracted from the entire input image to be classified. Based on the one or more connected components extracted one or more features of the input image to be classified are calculated. In this scenario the calculated features of the entire input image are analyzed by the ICE to detect certain sequences of features and or shapes e.g. a barcode for comparison to the calculated features of the selected zone corresponding to one or more models generated in step of method . That is if an input image shares a particular sequence of features with the selected zone corresponding to a model e.g. the zone selected during the training phase of the ICE the input image is classified in accordance with the model. Because a particular sequence of features e.g. barcode logo etc. may be located anywhere on the input image to be classified and is not restricted to the relative location of a selected zone corresponding to a particular generated model connected components are calculated across the entire input image to detect any possible sequences that may match the features or sequence of the zone corresponding to a generated model. The above described matching technique ensures accurate matching of input images with a model e.g. during a classification phase of the ICE during the scenario presented by the comparison of two or more images e.g. page images and that include only slight variations relative to each other. For example the barcode on page image of is slightly different than the barcode on page image of . More specifically the spacing of the shapes comprising barcode relative to each other is not the same as that of barcode . Applying the above described matching technique in this scenario would result in page images and being classified differently based on a comparison to each other or to a comparison to one or more models.

Upon a successful match between the one or more calculated features or detected sequence of the input image to be classified and the one or more calculated features corresponding to a particular model the label or classification returned corresponds to the class of input images that the matching model represents. In a practical scenario a digital copier may operate in a so called classification phase that corresponds to the classification phase of the ICE wherein input images are scanned and analyzed to calculate one or more features as described above for purposes of comparison to models stored within the memory of a digital copier. Upon classification of the input image a digital copier may provide a suitable indication e.g. via a user interface of the digital copier of the resulting classification of the input image or resulting failure to classify the input image.

It will be appreciated that variations of the above disclosed and other features and functions or alternatives thereof may be desirably combined into many other different systems or applications. Also that various presently unforeseen or unanticipated alternatives modifications variations or improvements therein may be subsequently made by those skilled in the art which are also intended to be encompassed by the following claims.

