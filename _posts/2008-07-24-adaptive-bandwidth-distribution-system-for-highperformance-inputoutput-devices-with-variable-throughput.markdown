---

title: Adaptive bandwidth distribution system for high-performance input/output devices with variable throughput
abstract: A method for issuing shadow requests to manage bandwidth allocation between an application that issues input/output (I/O) operation requests and an I/O device. A bandwidth manager detects the completion of an I/O operation, which includes either a read operation or a write operation. The bandwidth manager calculates a statistical duration for future I/O operations between the application and the I/O device based on throughput statistics related to past I/O operations. The bandwidth manager generates a shadow request for reserving a position in a queue that stores pending I/O requests for the I/O device for a first future I/O operation request from the application and having a duration related to the statistical duration, and inserts the shadow request into the queue. Advantageously, applications that do not make frequent I/O operation requests in advance may still execute I/O operations because bandwidth is reserved for future I/O operation requests via the shadow requests.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08060660&OS=08060660&RS=08060660
owner: AUTODESK, Inc
number: 08060660
owner_city: San Rafael
owner_country: US
publication_date: 20080724
---
This application claims the priority benefit of provisional U.S. Patent Application Ser. No. 61 047 395 filed Apr. 23 2008 the subject matter of which is hereby incorporated by reference.

The present invention generally relates to the field of data access. More specifically the invention relates to an adaptive bandwidth management system for high performance input output devices with variable throughput.

In a computer system an input output I O device is generally a hardware device with which the computer system may perform I O operations. Common I O devices include memory systems hard drives CD ROM drives and printers among others. Such an I O device is typically managed via a device driver which is a software program written specifically to allow one or more applications running on the computer system to communicate with the I O device. An application may make a request to use the I O device via a call to the driver associated with the I O device.

The number of I O operations an I O device can execute in a given time period is limited by the bandwidth of that I O device. Since applications normally request bandwidth faster than the bandwidth can be made available the driver maintains a queue of pending I O requests received from the various applications running on the system. Typically I O requests are handled by a driver in the order in which they are received. When a queued I O request is executed the driver allows the application that made the I O request to use the I O device for a period of time. After the requested I O operation is executed the driver advances to the next queue position.

Some computer systems may manage I O device bandwidth at the device driver level according to a set of rules followed by the operating system or implemented via a proprietary application programming interface API embedded within each application. Request scheduling for a particular I O device is based on the bandwidth required by each application and the I O requests currently in the queue of the driver associated with the I O device. The maximum bandwidth required by an application may define a priority ranking of the application relative to the other applications that access the I O device. When the queue is not empty high priority applications are allowed to use the I O device regardless of queue position.

One drawback of this approach is that the bandwidth management system is prevented from making optimal scheduling decisions. For example in a scenario where a low priority application queues I O requests far in advance and then a high priority application queues an I O request only when the I O operation is required the I O request of the high priority application may be delayed because the queue is clogged with low priority I O requests. Another drawback is that when a high bandwidth application requests more bandwidth than what is actually required to execute the relevant I O operation I O device bandwidth is wasted. For example if a high bandwidth application uses less time to complete an I O operation with respect to a particular I O device than the time requested then that I O device remains reserved for the high bandwidth application throughout the requested time period even though the I O device is not in use. Yet another drawback is that the actual bandwidth that an I O device can handle may vary over time according to fragmentation hardware degradation or partial failure among other things thus further complicating efficient scheduling using prior art techniques.

As the foregoing illustrates there is a need in the art for a more effective bandwidth management system.

Embodiments of the invention provide a method for issuing shadow requests to manage bandwidth allocation between an application that issues input output I O operation requests and an I O device. A bandwidth manager detects the completion of an I O operation which includes either a read operation or a write operation. The bandwidth manager calculates a statistical duration for future I O operations between the application and the I O device based on throughput statistics related to past I O operations. The bandwidth manager generates a shadow request for reserving a position in a queue that stores pending I O requests for the I O device for a first future I O operation request from the application and having a duration related to the statistical duration and inserts the shadow request into the queue.

Advantageously applications that do not make frequent I O operation requests in advance may still execute I O operations because bandwidth is reserved for future I O operation requests via the shadow requests.

The memory includes one or more applications one or more APIs corresponding to each of the applications a bandwidth manager and a driver corresponding to each of the I O devices . The applications may perform I O operations with one of the I O devices by making an I O operation request to the bandwidth manager via the API . In one embodiment the I O operation request may include the requested I O device the size of the operation and the type of operation. The bandwidth manager includes a scheduling logic that schedules I O requests for each of the applications with the requested device for the proper amount of time.

The bandwidth manager includes scheduling logic one or more sets of application statistics execution logic one or more queues corresponding to each of the I O devices and one or more configuration files corresponding to each I O device . The scheduling logic schedules I O requests for the applications with the different I O devices by inserting either actual requests or shadow requests into the queue associated with the requested I O device . Actual requests are generated by the scheduling logic in response to I O operation requests made by the application . Shadow requests are generated in response to completed execution of I O operations by the application . As described in greater detail herein shadow requests are scheduled to anticipate future I O operation requests made by the application .

The scheduling logic generates the actual requests and the shadow requests for each of the applications on each of the I O devices based on statistical data stored in the one or more application statistics and the one or more configuration files . In one embodiment the statistical data includes an average duration of I O operations a size of those I O operations and a frequency of those I O operations being executed by each application with each of the I O devices as further described in . The execution logic executes both actual requests and shadow requests as further described in .

The application transmits the I O operation request along leg to the corresponding API which acts as an interface between the bandwidth manager and the application . The API transmits the I O operation request to the scheduling logic along leg . The scheduling logic then retrieves statistical data from the application statistics along leg and determines the actual throughput of the requested I O device during previous I O operations executed for the requesting application . The scheduling logic then determines the duration of time needed for the requested I O device to execute the requested I O operation based on the size of the requested I O operation and the actual throughput of the I O device . If the I O device has not executed an I O operation for the application yet then a nominal value for the throughput of the I O device is used for the throughput determination. This nominal throughput data is stored in the configuration file for each I O device and retrieved by the scheduling logic along leg when scheduling the initial I O request. In alternative embodiments the I O device transmits the nominal throughput data directly to the application statistics without the use of the configuration file .

Once the scheduling logic determines the duration of time for the I O operation the scheduling logic generates an actual request associated with the duration and schedules the actual request for the application by inserting the actual request into the queue associated with the requested I O device . If any unexecuted shadow requests for the application are located in the queue then the scheduling logic replaces the shadow request closest to the front of the queue with the actual request along leg . If no unexecuted shadow requests for the application are located in the queue then the actual request is inserted at the end of the queue along leg

The execution logic is configured to detect actual requests at the front of the queues along leg . When an actual request is detected the execution logic instructs the API associated with the application for which the actual request was made along leg to unblock the application . The application initiates the I O operation with the requested I O device via the driver along leg . The application declares the start of the I O operation to the API along leg . Once execution of the I O operation is complete the application declares the end of the I O operation to the API along leg . The API records in the application statistics the actual time the I O device took to complete the I O operation based on the start and end times received from the API . The API also records the size of the I O operation in the application statistics . The recordations to the application statistics are performed along leg . In one embodiment the scheduling logic may use the statistical data stored in the application statistics to schedule I O requests for the application as discussed in .

The scheduling logic is configured to schedule shadow requests for one of the applications in response to completed execution of I O operations by the application with an I O device . When the application completes execution of an I O operation the scheduling logic retrieves the previously recorded I O operation statistics associated with that application along leg including the size and duration of previous I O operations. The scheduling logic then calculates the throughput of the I O device when the I O device executes I O operations for the application . In one embodiment the calculation is based on average values of the application statistics . The scheduling logic also retrieves I O operation frequency data associated with the application and the I O device . In one embodiment the frequency data is determined based on the average difference between timestamps recorded by the API when the application makes I O operation requests. In another embodiment timestamps are recorded when the application completes execution I O operations and the frequency data is determined relative to completed executions of I O operations. The scheduling logic inserts one or more shadow requests into the queue associated with the I O device along leg so that the measured frequency of the I O operations performed by the application with the I O device is preserved.

In one embodiment the shadow requests are inserted between I O requests in the queue so that the inserted shadow requests will be separated from both each other and from the front of the queue by approximately the average interval. For example if an application performs I O operations with one of the I O devices every 100 ms then a shadow request may be inserted approximately 100 ms from the front of the queue associated with that I O device . Additional shadow requests would be separated from each other by 100 ms intervals. In alternate intervals when shadow requests are inserted into the queue I O requests already in the queue are pushed back.

The execution logic is configured to detect shadow requests at the front of the queue along leg . When a shadow request is detected in the queue associated with one of the I O devices the execution logic polls the API associated with the application for which the shadow request was made for I O operation requests. If the application does not issue an I O operation request with the I O device during the time that the execution logic polls the API then the execution logic advances to the next queued I O request. If the application issues an I O operation request with the I O device during the time that the execution logic polls the API then the API unblocks the application along leg . The application initiates the requested I O operation via the driver along leg . The application declares the start of execution of the I O operation to the API along leg . Once the I O operation is complete the application declares the end of execution of the I O operation to the API along leg

The API records in the application statistics the actual time the I O device took to execute the I O operation based on the start and end times received from the API . The API also records the size of the I O operation in the application statistics . The recordations to the application statistics are performed along leg . In one embodiment the scheduling logic may use the statistical data stored in the application statistics to schedule I O requests for the application as previously discussed in .

The method begins at step where the scheduling logic receives an I O operation request from the application via the API . At step the scheduling logic determines whether application statistics have been gathered for I O operations executed between the requested I O device and the requesting application . If the scheduling logic determines that the application statistics have been gathered then the method advances to step where the scheduling logic retrieves the size and duration of previous I O operations executed with the requested I O device by the requesting application to calculate the throughput of the requested I O device when executing I O operations with the requesting application . If at step the scheduling logic determines that the application statistics have not been gathered then the method advances to step where the scheduling logic retrieves the nominal I O device throughput data from the configuration file . The method then advances to step .

At step the scheduling logic generates an actual request . In one embodiment the scheduling logic may determine the throughput of the requested I O device based on either the application statistics or the configuration file as previously described at steps . The scheduling logic may also calculate the amount of time required by the I O device to execute the requested I O operation. Based on the throughput of the requested I O device and the amount of time required by the I O device to execute the I O operation the scheduling logic generates an actual request .

At step the scheduling logic checks the queue for unexecuted shadow requests scheduled for the application . If the scheduling logic does not find any unexecuted shadow requests in the queue then the method advances to step where the scheduling logic replaces the unexecuted shadow request closest to the front of the queue with the actual request and the method terminates. If at step the scheduling logic does not find any unexecuted shadow requests for the application in the queue then the method advances to step where the scheduling logic inserts the actual request at the end of the queue and the method terminates.

The method begins at step where the execution logic determines whether an I O request either an actual request or a shadow request is at the front of the queue . Step repeats until an I O request is found at the front of the queue . When an I O request is found at the front of the queue then the method advances to step . At step the execution logic then determines whether the I O request is an actual request or a shadow request .

If the execution logic determines that the I O request is an actual request then the method advances to step . At step the API unblocks the application . At step the application starts execution of the I O operation and declares the start of execution of the I O operation to the API . At step the application completes execution of the I O operation and declares the end of execution of the I O operation to the API . At step the API updates the application statistics with the size and duration of execution of the I O operation. At step the execution logic advances to the next position in the queue and the method terminates.

If at step the execution logic determines that the I O request is a shadow request then the method advances to step where the execution logic begins to poll the application for an I O operation request. At step if an I O operation request is not received from the application during the polling time then the method advances to step where the execution logic advances to the next position in the queue and the method terminates. If at step an I O operation request is received by the API from the application during the polling time then the method advances to step and executes steps as previously described herein.

The method begins at step where the scheduling logic detects the completion of execution of an I O operation by the application with one of the I O devices . At step the scheduling logic calculates the duration of a shadow request to be generated based on the calculated throughput of that I O device as previously described. At step the scheduling logic generates a shadow request based on the calculated throughput. At step the scheduling logic inserts the shadow request into the queue preserving the I O operation request frequency of the application as previously described.

In sum the bandwidth of an I O device is efficiently managed by recording statistical usage patterns of applications that utilize the bandwidth of the I O device. The bandwidth manager is capable of predicting future I O bandwidth requirements of those applications such that I O request placeholders e.g. shadow requests are scheduled for each application in advance of real I O operation requests. A scheduling logic component of the bandwidth manager schedules actual requests and shadow requests for each application. When an application makes a request to read or write a certain amount of data the scheduling logic calculates the length of time required to complete the requested operation with the requested I O device based on throughput data for the I O device. An actual request is generated based on this information and inserted into the queue. If an unexecuted shadow request for the application is found in the queue then that shadow request may be replaced with the actual request. Otherwise the actual request is inserted at the end of the queue. When the I O operation has completed executing at some time in the future one or more shadow requests are generated and inserted into the queue so that the duration and frequency of those shadow requests are consistent with previous I O operations performed by the application with the I O device.

An advantage of the disclosed technique is that applications that do not make I O operation requests in advance may still execute I O operations based on the predicted requirements specific to each application. In this way applications that make I O operation requests in advance are prevented from displacing other applications in the queue. Yet another advantage is that the actual bandwidth an I O device can provide is continuously monitored so that hardware deficiencies in the I O device which may reduce the available bandwidth of that I O device can be accounted for because the actual amount of time required for a particular application to execute an I O operation with an I O device can be predicted.

While the forgoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present invention are embodiments of the present invention. Therefore the scope of the present invention is determined by the claims that follow.

