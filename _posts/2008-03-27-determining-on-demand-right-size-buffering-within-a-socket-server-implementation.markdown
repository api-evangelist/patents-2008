---

title: Determining on demand right size buffering within a socket server implementation
abstract: Method, apparatus and article of manufacture for acquiring a buffer after data from a remote sender (e.g., client) has been received by a local machine (e.g., server). Because the client data has already been received when the buffer is acquired, the buffer may be sized exactly to the size of the client data. In general, the buffer may be caller supplied or system supplied.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07822814&OS=07822814&RS=07822814
owner: International Business Machines Corporation
number: 07822814
owner_city: Armonk
owner_country: US
publication_date: 20080327
---
This application is a continuation of U.S. patent application Ser. No. 10 038 008 filed Jan. 4 2002 now U.S. Pat. No. 7 373 378 which is a continuation in part of U.S. patent application Ser. No. 09 990 850 filed Nov. 21 2001 issued as U.S. Pat. No. 7 054 925 on May 30 2006. Each of the aforementioned related patent applications is herein incorporated by reference in its entirety.

The present invention generally relates to distributed systems. More particularly embodiments provide client server systems for efficient handling of client requests.

Generally a distributed computer system comprises a collection of loosely coupled machines mainframe workstations or personal computers interconnected by a communication network. Through a distributed computer system a client may access various servers to store information print documents access databases acquire client server computing or gain access to the Internet. These services often require software applications running on the client s desktop to interact with other applications that might reside on one or more remote server machines. Thus in a client server computing environment one or more clients and one or more servers along with the operating system and various interprocess communication IPC methods or mechanisms form a composite that permits distributed computation analysis and presentation.

In client server applications a server is typically a software application routine or thread that is started on a computer that in turn operates continuously waiting to connect and service the requests from various clients. Thus servers are broadly defined as computers and or application programs executing thereon that provide various functional operations and data upon request. Clients are broadly defined to include computers and or processes that issue requests for services from the server. Thus while clients and servers may be distributed in various computers across a network they may also reside in a single computer with individual software applications providing client and or server functions. Once a client has established a connection with the server the client and server communicate using commonly known e.g. TCP IP or proprietary protocol defined and documented by the server.

In some client server implementations sockets are used to advantage. A socket as created via the socket application programming interface API is at each end of a communications connection. The socket allows a first process to communicate with a second process at the other end of the communications connection usually on a remote machine. Each process communicates with the other process by interacting directly with the socket at its end of the communication connection. Processes open sockets in a manner analogous to opening files receiving back a file descriptor specifically a socket descriptor by which they identify a socket.

Sockets and other client server mechanisms are shown in the server environments and of and respectively. illustrates synchronous processing and illustrates asynchronous processing. In general shows server environment comprising a main thread and a plurality of worker threads . An initial series of operations includes creating a socket socket binding to a known address bind and listening for incoming connections on the socket listen . An accept operation is then issued to accept a new client connection which is then given to one of the worker threads . The operations for accepting a new client connection and giving the client connection to a worker thread define a loop which is repeated until the server is shut down.

Upon taking the client connection from the main thread the worker thread issues a receive operation . This operation is repeated as indicated by loop until the full request is received. The request is then processed and a response is sent using a send operation . A loop causes processing to repeat the receive operations thereby handling additional requests from the current client. The worker thread may then take another client connection from the main thread as represented by loop .

Alternatively some server platforms provide a set of asynchronous I O functions to allow the server design to scale better to a large number of clients. While these implementations vary across platforms most support asynchronous read and write operations and a common wait or post completion mechanism. The server applications provide buffers to be filled or emptied of data asynchronously. The status of these asynchronous I O operations can be checked at a common wait or can be posted back to the application via some mechanism such as a signal. This I O model can allow a pool of threads to scale to process a much larger set of clients with a limited number of threads in the server application s thread pool.

As an illustration consider the server environment which uses asynchronous I O consisting of one main thread accepting client connections and multiple worker threads processing client requests received by the main thread . An initial series of operations are the same as those described above with reference to synchronous processing . Processing of a client request begins when the main thread requests a connection from a client by issuing an asynchronous accept operation for a new client connection to a pending queue . Each asynchronous accept operation results in a separate pending accept data structure being placed on the pending queue . Once a client connection is established the appropriate pending accept data structure is removed from the pending queue and a completed accept data structure is placed on a completion queue . The completed accept data structures are dequeued by the main thread which issues an asynchronous wait for which a wakeup operation is returned from the completion queue . An asynchronous receive operation is then started on a client connection socket for some number of bytes by configuring the pending queue to queue the pending client requests. The number of bytes may either be determined according to a length field which describes the length of the client request or in the case of terminating characters for some arbitrary number. Each asynchronous receive operation results in a separate pending receive data structure being placed on the pending queue . When a receive completes the complete client record has been received the appropriate pending receive data structure is removed from the pending queue and a completed receive data structure is placed on the completion queue . An asynchronous wait is issued by a worker thread A for which a wakeup operation is returned from the queue with the data.

In the case where a length field is used the specified number of bytes from the length field is used by the worker thread A to issue another asynchronous receive operation to obtain the rest of the client request which is typically received incrementally in portions each of which is placed in an application buffer. The second asynchronous receive operation is posted as complete to the queue upon receiving the full request and the same or another thread from the thread pool processes the client request. This process is then repeated for subsequent client requests. Where a terminating character s is used each incoming request is dequeued from the queue and checked for the terminating character s . If the character s is not found another asynchronous receive operation is issued. Asynchronous receive operations are repeatedly issued until the terminating character s is received. This repetition for both length field and terminating character implementations is represented by loop in .

Sockets receive data from clients using well known receive semantics such as readv and recvmsg . The receive semantics illustrated in are receive and asyncReceive respectively. Sockets receive semantics are either synchronous or asynchronous . Synchronous APIs such as readv and recvmsg receive data in the execution context issuing the API. Asynchronous APIs such as asyncRecv return indications that the receive will be handled asynchronously if the data is not immediately available.

Synchronous receive I O will wait until the requested data arrives. This wait is typically performed within the sockets level of the operating system. During this wait a buffer supplied by the application server is reserved until the receive completes successfully or an error condition is encountered. Unfortunately many client connections have a bursty data nature where there can be significant lag times between each client request. As a result the buffers reserved for the incoming client requests and can typically sit idle while waiting for client requests to be received. This can cause additional storage to be allocated but not used until the data arrives resulting in inefficient use of limited memory resources. Further where multiple allocated buffers are underutilized system paging rates can be adversely affected.

Asynchronous I O registers a buffer to be filled asynchronously when the data arrives. This buffer cannot be used until the I O completes or an error condition causes the operation to fail. When data arrives the buffer is filled asynchronously relative to the server process a completed request transitions to a common wait point for processing. While advantageous this asynchronous behavior suffers from the same shortcomings as the synchronous receive I O into the buffer supplied is reserved until the operation completes and an indication is returned to the application server. As a result the storage and paging concerns described above with respect to synchronous receive I O also applied to asynchronous I O processing.

In summary synchronous and asynchronous I O suffer from at least two problems. First the multiple buffers reserved at any given time are more than what are needed to service the number of incoming requests. As a result the memory footprint for processing is much larger than needed. Second memory allocated for each incoming requests will consume this valuable resource and cause memory management page thrashing.

To avoid the foregoing problems it is desirable to acquire a buffer large enough to hold all of the data when it arrives. Such an approach would keep the buffer highly utilized from a memory management paging perspective. However one problem with this approach is determining what size buffer an application server should provide when the I O operation is initiated. This problem arises because the record length is contained within the input data stream and will only be known when the data arrives. One solution would be to code the application server for the worst possible case and always supply a buffer large enough to accommodate the largest record possible. However this would be a waste of resources and could adversely affect the paging rates not only for the server but the system itself.

The present invention generally provides embodiments for acquiring a buffer only once client data has been received. Because the client data has already been received when the buffer is acquired the buffer may be sized exactly to the size of the client data thereby making efficient use of storage.

One embodiment provides a method of processing client server messages comprising receiving at a sockets layer of a computer data from a remote source via a network connection prior to allocating a buffer to contain the data and subsequently allocating the buffer to contain the data.

Another embodiment provides computer readable medium containing a program which when executed by a computer performs operations for processing client server messages the operations comprising processing an input operation issued from a sockets server application to a sockets layer of the computer wherein the input operation is configured with a buffer mode parameter indicating to the sockets layer a buffer acquisition method for acquiring a buffer for containing data received from a remote source via a network connection.

Still another embodiment provides a system in a distributed environment comprising a network interface configured to support a network connection with at least one other computer in the distributed environment a memory comprising a sockets server application a socket in communication with the sockets server application and a protocol stack in communication with the socket wherein the protocol stack is configured to transport messages between the network interface and the socket and a processor which when executing at least a portion of the contents of the memory is configured to perform operations for processing client server messages. The operations comprise processing an input operation issued from the sockets server application to the socket wherein the input operation is configured with a buffer mode parameter indicating to the socket a buffer acquisition method for acquiring a buffer for containing data received from the at least one other computer.

Embodiments of apparatus methods and articles of manufacture are provided for handling messages in a client server environment. In particular the computers of the client server environment are sockets based to facilitate a variety of I O processing.

One embodiment of the invention is implemented as a program product for use with a computer system such as for example the network environment shown in and described below. The program s of the program product defines functions of the embodiments including the methods described below and can be contained on a variety of signal bearing media. Illustrative signal bearing media include but are not limited to i information permanently stored on non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive ii alterable information stored on writable storage media e.g. floppy disks within a diskette drive or hard disk drive or iii information conveyed to a computer by a communications medium such as through a computer or telephone network including wireless communications. The latter embodiment specifically includes information downloaded from the Internet and other networks. Such signal bearing media when carrying computer readable instructions that direct the functions of the present invention represent embodiments of the present invention.

In general the routines executed to implement the embodiments of the invention whether implemented as part of an operating system sockets layer or a specific application or as a component program module object or sequence of instructions may be referred to herein as a program . The computer program typically is comprised of a multitude of instructions that will be translated by the native computer into a machine readable format and hence executable instructions. Also programs are comprised of variables and data structures that either reside locally to the program or are found in memory or on storage devices. In addition various programs described hereinafter may be identified based upon the application for which they are implemented in a specific embodiment of the invention. However it should be appreciated that any particular program nomenclature that follows is used merely for convenience and thus the invention should not be limited to use solely in any specific application identified and or implied by such nomenclature.

In general the distributed computer system consists of a plurality of users or clients a network one or more servers and a plurality of input output devices e.g. peripheral devices. Each of the users or clients can be one or more hardware devices e.g. a mainframe a workstation a personal computer or a terminal. Alternatively each of the clients can be a software application process or thread residing in the memory of a hardware device.

The clients access other resources within the distributed computer system via the network . In general the network may be any local area network LAN or wide area network WAN . In a particular embodiment the network is the Internet.

In turn one or more servers are coupled to the network and thereby communicate with the clients . In a particular embodiment the servers are eServer iSeries computers available from International Business Machines Inc. For simplicity the details of a single server are shown where the server is representative of each of the servers . Connection of the server to the network is accomplished by the provision of a network interface . The network interface may support for example a Token Ring or Ethernet configuration. As such the network interface may comprise a communication adapter e.g. a local area network LAN adapter employing one or more of the various well known communication architectures and protocols e.g. the transmission control protocol internet protocol TCP IP . Such protocols are represented as a protocol stack in a memory of the server .

The server controls access to a plurality of peripheral devices resources . Namely the server is coupled to a plurality of peripheral devices that are accessible to all the clients . The peripheral devices may include but are not limited to a plurality of physical drives e.g. hard drives floppy drives tape drives memory cards compact disk CD drive a printer a monitor and the like. These peripheral devices should be broadly interpreted to include any resources or services that are available to a client through a particular server.

The server may comprise a general purpose computer having a central processing unit CPU and the memory e.g. random access memory read only memory and the like for managing communication and servicing user requests. The memory contains the necessary programming and data structures to implement the methods described herein. Illustratively an operating system and a plurality of applications also referred to herein as sockets server applications are loaded and executed in the memory . In a particular embodiment the operating system is the OS 400 available from International Business Machines Inc. Communication between the operating system and applications is facilitated by application programming interfaces APIs . Common wait points are implemented as queues which may be read to and from by I O operations. Illustrative queues that may be used to advantage include a pending queue and a completion queue. In general a pending queue is a memory area at which a socket or other component may queue a pending client request in response to an input operation from a server application . A completion queue is a memory area where a completed request i.e. a request that has been completely received by a server may be queued.

The memory is also shown configured with buffers . The buffers provide a memory area into which data e.g. client request data can be read. Once a complete client request has been received in a buffer one or more applications may access the buffer to service the request. The location and size of the buffer into which data should be read is specified by a receive parameters data structure . Illustratively the receive parameters data structure may be configured with a buffer address entry A and a buffer length entry B. The buffer address entry A may contain a pointer to a buffer into which data should be read. On input the buffer length entry B indicates the size of the buffer supplied and denotes nothing about the length of client data. In one embodiment the specified size of the buffers supplied is large enough to accommodate the largest client request that could be received. On output the buffer length entry B contains the size of the client request returned to an application .

In general the buffers may be allocated from available memory. In one embodiment available memory includes application owned memory and system owned memory . Application owned memory is memory controlled by an application . System owned memory is memory controlled by the operating system .

In one embodiment a portion of the buffers is configured as cache . The cache provides a supply of buffers that may be re used for subsequent I O. In one embodiment the cache contains buffers of particular sizes. For example the cache buffers may be sized according to the most common data request sizes.

In one embodiment record definitions are incorporated on the receive interfaces implemented by the servers . Illustratively the memory is shown configured with a length field record definition and a terminating character record definition . Embodiments of the record definitions and are described below with reference to and .

Once the applications are executed in the memory server can then begin accepting and servicing client connections. It should be noted that additional software applications or modules can be executed as required in the memory . In addition all or part of the programming and or data structures shown in memory can be implemented as a combination of software and hardware e.g. using application specific integrated circuits ASIC .

In one embodiment a socket of at least one of the computers of the client server environment is configured to recognize a format of a message to be received from another computer whereby the socket is configured to handle receiving the message without invoking the application s responsible for servicing the message until the message is completely received. In general the message may be formatted with a length field or with terminating characters. In one embodiment the socket utilizes a record definition to recognize the message format.

Referring now to one embodiment of a length field record definition is shown. In general the length field record definition may be any data structure which is provided to a socket and indicates to the socket how to interpret a record header i.e. the portion of the client request indicating the size of the request provided by a client. Illustratively the length field record definition comprises a length field indicator a record header size an offset a length field size a network byte order and a maximum size entry . The length field indicator indicates whether the length field of the client request includes the record header itself or only the remaining data following the header. The record header size specifies the size of the record header. The offset indicates the offset within the header at which the length field begins while the length field size indicates the size of the length field. The network byte order indicates a client specified format in which the length field is stored e.g. big little Endian . The maximum size entry specifies the maximum size client record allowed.

Referring now to one embodiment of a terminating character record definition is shown. In general the terminating character record definition may be any data structure which is provided to a sockets layer and configures the sockets layer to identify a terminating character s of a client request. Illustratively the terminating character record definition comprises a pointer a number of bytes field and a maximum size field . The pointer points to a string which denotes the end of the client record. The number of bytes field specifies the number of bytes within the terminating string. The maximum size field specifies the maximum allowable size of the client record.

Although not shown in some preliminary operations e.g. creating the sockets layer binding to a known address listening for client connections accepting a client connection are assumed to have occurred in order to establish a network communication between the server and the client . Once a connection with the client has been accepted by the server the application issues an asynchronous receive operation to the sockets layer whereby a pending record request is queued on a pending queue . The receive operation includes a receive parameters data structure and a length field record definition . Illustratively the length field record definition is part of the receive parameters data structure . However and other embodiment the data structures may be separate.

The receive parameters data structure specifies both a buffer into which data should be read buffer address entry A and a size of the buffer buffer length entry B . In one embodiment the size of the supply buffer is sufficiently large to accommodate the largest client request that may be received.

The length field record definition describes a format of an incoming client request to the sockets layer . Illustratively the client request is 100 000 bytes in length and is received as a series of messages . An initial message includes a header and a portion of the request data itself illustratively 10 000 bytes of the total 100 KB . The header includes a length field . Illustratively the length field specifies a data length of 100 000 bytes to the sockets layer . In such an implementation the length field indicator indicates to the sockets layer that the length specified by the length field does not include the header .

Interpretation of the header by the sockets layer in accordance with the record definition occurs upon receiving the initial message . In addition the 10 000 bytes of data are copied into the user buffer specified by the receive parameters data structure . The remainder of the client request is then received messages and copied into the user buffer at 10 000 bytes increments.

After receiving the last message the user buffer is queued on a completion queue as represented by the queuing operation . The application then retrieves the request from the queue as represented by the dequeuing operation .

Although not shown in some preliminary operations e.g. creating the sockets layer binding to a known address listening for client connections accepting a client connection are assumed to have occurred in order to establish a network communication between the server and the client . Once a connection with the client has been accepted by the server the application issues an asynchronous receive operation to the sockets layer whereby a pending record request is queued on a pending queue . The receive operation includes a receive parameters data structure and a terminating character record definition . Illustratively the terminating character record definition is part of the receive parameters data structure . However and other embodiment the data structures may be separate.

The receive parameters data structure specifies both a buffer into which data should be read buffer address entry A and a size of the buffer buffer length entry B . In one embodiment the size of the supply buffer is sufficiently large to accommodate the largest client request that may be received.

The terminating character record definition describes a format of an incoming client request to the sockets layer . Illustratively the client request is 100 000 bytes in length and is received as a series of messages . An initial message includes a portion of the request data itself illustratively 10 000 bytes of the total 100 KB . Upon receipt of each message the sockets layer copies 10 000 bytes to the user buffer specified by the receive parameters data structure and checks the message for a terminating character s . Upon locating the terminating character in the last message the user buffer is placed on a completion queue as represented by the queuing operation . A dequeuing operation then provides the completed client request to the application for processing.

In this manner the sockets layer can accumulate all the data for the client request before completing the input operation. If the data is not immediately available the record definition information will be used to asynchronously receive the data. The server application need only perform one input operation per client request thereby reducing the path length at both the server and the sockets layer.

While the foregoing embodiments describe asynchronous processing synchronous processing is also contemplated. The manner in which synchronous processing may utilize the inventive record definition to advantage will be readily understood by those skilled in the art based on the foregoing description of asynchronous processing. Accordingly a detailed discussion is not necessary.

As described above in one embodiment the size of the buffer allocated for the client request is large enough for the largest request that can be received. However in some cases this approach may not be desired because storage is not efficiently utilized. Accordingly in another embodiment a buffer is acquired i.e. allocated only once the client data has been received. Because the client data has already been received when the buffer is acquired the buffer may be sized exactly to the size of the client data thereby making efficient use of storage. This approach is referred to herein as on demand right size buffering . In general the on demand right size buffer may be caller supplied i.e. the buffer comes from application owned storage or system supplied i.e. the buffer comes from operating system owned storage .

Accordingly the operating system of the server is configured for at least three modes of buffer allocation. A particular mode may be selected by adding a buffer mode parameter to the receive API. Three illustrative buffer mode parameters are referred to herein as caller supplied caller supplied dynamic and system supplied. Each of the buffering modes is described below. While the following discussion is directed toward asynchronous processing persons skilled in the art will recognize application to synchronous processing by extension of the principles described.

Utilizing the caller supplied parameter configures the server to operate in a conventional manner. That is the application supplies a buffer address and a buffer length on the API call. The buffer is not used until the receive operation completes and an indication of completion has been received by the application . The operating system loads the buffer asynchronously to the application .

The caller supplied dynamic buffering mode allows the application to supply a callback function to be called by the operating system in order to obtain a right sized buffer allocated from application owned memory . No buffer pointer needs to be supplied on the asynchronous receive operation thereby avoiding unnecessarily tying up memory. In some cases a buffer length specifying the amount of data requested may be provided. In other cases one of the previously described record definitions may be provided.

In one embodiment data copy when using the caller supplied dynamic buffer mode parameter does not occur asynchronously to the server thread. However when running on a multiprocessor system it may be advantageous to provide for asynchronous copies. Accordingly to provide for asynchronous copies when using the caller supplied dynamic buffer mode parameter the application may optionally supply a buffer to be used. If the supplied buffer is not large enough then another buffer will be acquired using the callback function .

Referring first to a network environment is shown illustrating I O operations of the network environment using when using the caller supplied dynamic buffer mode parameter and allocating a typical size buffer. Initially the application issues an asynchronous receive operation with a caller supplied dynamic buffer mode parameter and specifying a typical sized buffer from the application owned memory . The sockets layer reports with a response indicating that the sockets layer is ready to begin accepting client connections. The application then issues an asynchronous wait operation which may be queued by the sockets layer . Incoming client data is then received by the sockets layer on a client connection. Once a full client record has arrived and if the allocated typical sized buffer is large enough a communications router task operates to asynchronously copy the record into the buffer. As used herein the communications router task is any operation which delivers data. The particular implementation of the task may vary according to the operating system being used. In any case a wakeup operation is then issued and the application receives the client request for processing. After processing the request block the application manages the typical sized buffer according to its own memory management scheme block . Accordingly such embodiment facilitates integration into existing buffering allocation models of applications.

Initially the application issues an asynchronous receive operation with a system supplied buffer mode parameter. The sockets layer reports with a response indicating that the sockets layer is ready to begin accepting client connections. The application then issues an asynchronous wait operation which may be queued by the sockets layer . Incoming client data is then received on a client connection and is handled by communications router task . As the data arrives a system owned buffer is acquired. Specifically the buffer may be allocated from unallocated system owned memory or may be taken from a cache of previously allocated system owned memory . The length of the buffer is based on a length in the original asynchronous receive operation or is determined according to the specification of a record definition . In the case of a record definition the sockets layer preferably waits until the entire client record has arrived and then operates to right size the buffer. However in the case of a length field record definition the buffer may be acquired once the record header has been interpreted by the sockets layer . An asynchronous wakeup operation then issues to dequeue the application thread responsible for processing the client request. At this point the application has received the client request in system supplied memory. Once the application has finished processing the request the application may release the system supplied memory with a free buffer command one of the inventive APIs configured to free system supplied memory or may implicitly free the buffer by using it on the next asynchronous receive operation .

The latter embodiment i.e. system supplied buffer mode provides a number of advantages. First the data buffer for incoming data is obtained at the time it is needed resulting in a minimal paging rate. Second the data buffer is correctly sized based on the data request thereby efficiently and fully utilizing storage. Third the record definitions described above can be used to advantage. Fourth data is copied asynchronously. Fifth automatic buffer allocation and caching is enabled and managed by the system providing for improved performance.

In other embodiments methods systems and articles of manufacture are provided for improving performance and throughput while reducing memory requirements of sockets server applications. In some cases these embodiments may be used in tandem with the embodiments described above. While synergistic in some cases such combination and cooperation between embodiments is not necessary in every implementation.

The embodiments described in this section i.e. Controlling Socket Server Send Buffer Usage make system supplied storage available to socket server applications to be used when sending data. In one embodiment standard synchronous sockets interfaces for controlling socket attributes are configured with an inventive attribute which specifies that all storage to be used on send operations will be system supplied. Such standard synchronous sockets interfaces include ioctl and setsockopt . Once such system supplied storage is used on a send operation it is considered to be given back to the system. Therefore the system is allowed to hold onto the storage as long as needed without affecting individual applications. Further data copies from application buffers to system buffers is avoided thereby improving performance and throughput. In some embodiments the data may be DMA d direct memory accessed by a communications protocol stack. The system supplied storage can be managed and cached on behalf of any or all server applications to reduce paging rates and storage demand. When used in combination with the embodiments described in the section entitled RIGHT SIZE BUFFERING the present embodiments reduce multiple function calls. Specifically calls to alloc malloc storage are unnecessary if a buffer is received on incoming data and calls to free storage are unnecessary if the buffer is then used on a send operation. This benefit is particularly advantageous in a request response architecture where a server application waits for requests performs some work and sends a response. In such an architecture the request arrives in system supplied storage the work is done and the same system supplied storage can then be used for the response. These and other advantages may be achieved according to the description that follows. It is understood that the foregoing advantages are merely illustrative results achieved in some embodiments. Implementations which do not achieve these advantages may nevertheless be considered within the scope of the invention as defined by the claims appended hereto.

Referring now to a network environment is shown illustrating I O operations of the network environment when using the system supplied buffers acquired by a function call from an application. Accordingly like numerals are used to denote components described above with reference to network . In general the network environment includes a server communicating with a client via a network . The server comprises an application a sockets layer implemented by the APIs and the protocol stack .

The operations performed in the network environment are illustratively described in three phases. The phases are not limiting of the invention and are merely provided to facilitate a description of the operations performed in the network environment . The operations may be synchronous or asynchronous. In a first phase the application issues a buffer acquisition operation by invoking a get buffer function call . In response a system supplied buffer A is acquired by the sockets layer and returned to the application . The system supplied buffer may be retrieved from a cache containing a plurality of buffers or may be allocated from available system owned memory . In a second phase the application uses the system supplied buffer A in any manner needed. Illustratively the application reads data directly into the buffer A. In a third phase the application initiates a send operation whereby the buffer A is provided to the sockets layer . The buffer A is then detached from the user request i.e. no longer available to the application and the send operation returns.

It is contemplated that the send operation may be synchronous send with MSG SYSTEM SUPPLIED or asynchronous asyncSend . In the case of a synchronous send standard synchronous sockets interfaces for sending data may be configured with an inventive flag value. By way of illustration the flag value is shown in as MSG SYSTEM SUPPLIED. In another embodiment the flag value is provided with the inventive attribute on the standard synchronous sockets interfaces for controlling socket attributes e.g. ioctl and setsockopt which were described above. In any case the flag value indicates that the memory used on send interfaces is defined as system supplied.

In the third phase the detached buffer A is under the control of a communications router thread and may be used by the sockets layer and the protocol stack . In some cases DMA processing is used. In any case no data copy is necessary. Once the data is sent the buffer is freed using a free buffer function call or is cached for use on the next system supplied operation. During this time phase the application continues processing e.g. reading data and preparing to send more data . Although not shown in the application eventually uses asyncWait to determine whether the send processing has succeeded.

Referring now to a network environment is shown illustrating I O operations of the network environment . Accordingly like numerals are used to denote components described above with reference to network . In particular network environment illustrates I O operations when using system supplied buffers from the system owned memory acquired by an asynchronous receive operation with a buffer mode parameter set to system supplied . Such a buffer mode parameter has been described above with reference to for example .

In general the network environment includes a server communicating with a client via a network . The server comprises an application a sockets layer implemented by the APIs and the protocol stack .

In a first phase the application issues an asynchronous receive operation with a system supplied buffer mode parameter. The sockets layer reports with a response i.e. the receive operation is returned indicating that the sockets layer is ready to begin accepting client connections. The application then issues an asynchronous wait operation which may be queued by the sockets layer .

In the second phase incoming client data is received on a client connection and is handled by communications router task . As the data arrives a system supplied buffer A is acquired and the data is placed in the buffer A. The buffer A may be allocated from unallocated system owned memory or may be taken from a cache containing a plurality of buffers from previously allocated system owned memory . In one embodiment the cache buffers are of selective sizes. Such an approach is particularly efficient if the application uses only a few different sizes of buffers. For example if most application records are 1K 4K or 16K then the cache will only contain buffers of this size. Illustratively the length of the buffer is based on a length in the original asynchronous receive operation or is determined according to the specification of a record definition . In the case of a record definition the sockets layer preferably waits until the entire client record has arrived and then operates to right size the buffer. However in the case of a length field record definition the buffer may be acquired once the record header has been interpreted by the sockets layer . An asynchronous wakeup operation then issues to dequeue the application thread responsible for processing the client request. At this point the application has received the client data in the system supplied buffer A.

In a third phase the application uses the system supplied buffer A in any manner needed. Illustratively the application reads data directly into the buffer A. In a fourth phase the application initiates a send operation whereby the buffer A is provided to the sockets layer . The buffer A is then detached from the user request i.e. no longer available to the application and the send operation returns.

In the fourth phase the detached buffer A is under the control of a communications router thread and may be used by the sockets layer and the protocol stack . In some cases DMA processing is used. In any case no data copy is necessary. Once the data is sent the buffer A is freed using a free buffer function call or is cached for use on the next system supplied operation. During this time phase the application continues processing e.g. reading data and preparing to send more data . Although not shown in the application eventually uses asyncWait to determine whether the send processing has succeeded.

Another embodiment provides for continuous modes for both asynchronous accepts and asynchronous receives. Accordingly only a single asynchronous accept needs to be performed on a listening socket and only a single asynchronous receive needs to be performed on each connected socket. This approach dramatically reduces redundant accept and receive processing at both the application and operating system levels. In addition processing of both the server and the client is substantially improved.

Accordingly as is evident by comparison of with various redundant processing has been eliminated. Comparing to for example the asynchronous accept operation has been taken out of the loop and replaced with the asynchronous continuous accept operation . Further the loop has been eliminated by virtue of utilizing the record definitions and the need for redundant asynchronous receives issued by a worker thread has been eliminated.

The foregoing continuous processing modes may be further described with reference to . shows a network environment representative of the network environment in . Initially a main thread issues a single continuous accept operation on a listening socket . As a result of the accept operation a single pending accept data structure is queued on a pending queue A which is part of the listening socket . The pending accept data structure is configured with a plurality of parameters which facilitate servicing of incoming client connections requests . Illustratively the parameters specify the accept completion queue for placing completed accepts A B and further specify that the pending accept data structure is configured for continuous mode processing. Other parameters known in the art may also be included.

In operation incoming client connections are received on the listening socket . The pending accept data structure is then configured for a particular client connection and subsequently copied into a completed accept data structure A on the accept completion queue . In this manner the pending accept data structure remains on the pending queue . The completed accept data structure may then be populated with completion information such as a socket number address etc. The completed accept data structures are dequeued from the accept completion queue by an asynchronous wait operation issued by the main thread .

The main thread then issues a continuous receive operation on a client socket which is configured with a pending queue B. Only a single continuous receive operation is needed for each connected client socket and each operation specifies a continuous mode a manner of acquiring a buffer a manner of recognizing a format of incoming client data etc. As a result of the continuous receive operation a pending receive data structure is placed on the pending queue B. Parameters of the pending receive data structure specify the receive completion queue for placing completed receive data structures A B that the pending receive data structure is configured for continuous mode processing and that a system supplied buffer will be used. The parameters of the pending receive data structure also specify a length field record definition or a terminating character record definition as described above. Other parameters known in the art may also be included.

Once a completed client record has been received the pending receive data structure is copied to the receive completion queue . Accordingly a plurality two shown of completed receive data structures A B are shown on the receive completion queue . Each completed receive data structure A B has an associated buffer A B containing client data. In particular the buffers A B are allocated from system owned memory as has been described above. The provision of a separate buffer A B for each completed receive data structure A B overcomes conventional implementations in which a single buffer is provided for each pending receive data structure. Because the present embodiment utilizes only a single pending receive data structure a single buffer is insufficient for handling a multiplicity of client requests.

The completed receive data structures A B are then removed from the completion queue by an asynchronous wait operation issued by the worker thread . The worker thread may then take steps to process the client request.

The embodiments described in the present application may be implemented in a variety of fashions. For example in some cases changes may be made to existing operating systems. In other cases changes may be made to socket interfaces. In still other cases changes may be made to both the operating system and the socket interfaces. These changes may include modifications to existing code or the provision of new code. It is understood that the particular implementation undertaken may to some extent depend on the particular operating system and socket interfaces and possibly other code or hardware being used changed. Accordingly the manner in which the invention is implemented is not considered limiting of the invention. Rather the principles described herein will enable any person skilled in the art to make the invention.

Further is understood that use of relative terms is made throughout the present application. For example a particular relationship between servers and clients in a distributed system has been assumed. However the status of a machine as a server or client is merely illustrative and in other embodiments the functionality attributed to a server is available on the client and vice versa.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof and the scope thereof is determined by the claims that follow.

