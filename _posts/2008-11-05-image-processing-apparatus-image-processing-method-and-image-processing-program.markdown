---

title: Image processing apparatus, image processing method, and image processing program
abstract: An image processing apparatus that displays, on a display region having a first number of pixels, an image represented by gigantic image data that is recorded in a recording medium and has a second number of pixels that is significantly greater than the first number of pixels, including: a reproducing unit configured to read image data from the recording medium; an output unit configured to output the image data, which is read by the reproducing unit from the recording medium, in synchronization with a vertical synchronization signal; and a control unit configured to control the reproducing unit and the output unit. The control unit performs control to extract and read a region corresponding to the display region from the gigantic image data recorded in the recording medium.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08237741&OS=08237741&RS=08237741
owner: Sony Corporation
number: 08237741
owner_city: Tokyo
owner_country: JP
publication_date: 20081105
---
The present invention contains subject matter related to Japanese Patent Application JP 2007 289218 filed in the Japanese Patent Office on Nov. 7 2007 the entire contents of which are incorporated herein by reference.

The present invention relates to an image processing apparatus an image processing method and an image processing program which are suitable for use in displaying an image represented by image data having a significantly large number of pixels on a display device having a standard number of pixels.

In recent years as digital transmission technology and video data compression and encoding technology have advanced the resolution of television images has increased. For example a resolution of 1920 pixels 1080 lines in interlace scanning 1080I has been realized for so called high definition video in current terrestrial digital broadcasting. In progressive scanning a resolution of 1920 pixels 1080 lines 1080P has been realized as a standard. Further many monitor devices that are used for displaying such television images and have effective display pixels whose number corresponds to the resolution of high definition video have been developed. An interface standard for transmitting television signals based on high definition video has been defined as the High Definition Multimedia Interface HDMI .

In contrast the technique of obtaining an image covering a wide range that is significantly wider than the angle of view of an image capturing apparatus hereinafter called a panoramic image by sequentially capturing images while continuously moving an image capturing range so that the captured images become continuous and connecting the captured images in a predetermined manner has been developed. Japanese Unexamined Patent Application Publication No. 2007 43505 describes a method of controlling a camera at the time of capturing a panoramic image and a method of generating a panoramic image from image data captured under such control.

A panoramic image having a significantly greater number of pixels than that of image data obtained in one shot using a general image capturing method. In other words when a panoramic image is regarded as image data representing one image the panoramic image has a significantly higher resolution than that of image data obtained in one shot taken by using a general image capturing method.

For example in recent years image pickup devices such as charge coupled device CCD and complementary metal oxide semiconductor CMOS imagers have become more sophisticated. Even with the use of generally used digital still cameras that are designed to be compact and light weight so called compact cameras an image with a resolution of for example 4000 pixels 3000 pixels or 3264 pixels 2448 pixels which is higher than that of high definition video can be easily captured. Digital single lens reflex cameras can capture image data with a yet higher resolution. A panoramic image is generated by connecting items of such image data each having a number of pixels of for example 4000 pixels 3000 pixels or 3264 pixels 2448 pixels. Therefore the total number of pixels of the panoramic image is significantly greater than the number of pixels of the above described high definition video for example and is a vast number of pixels.

There has been a demand for the technique of displaying an image as in a panoramic image represented by image data having a number of pixels exceeding the number of effective display pixels of a monitor device while making the most use of such a high resolution.

Here the case in which an image as in a panoramic image represented by image data having a number of pixels exceeding the number of effective display pixels of a monitor device is to be displayed on the monitor device will be considered. In this case for example the number of pixels of the image data may be reduced in accordance with the number of effective pixels of the monitor device. However reduction of the number of pixels of the image data involves pixel decimation and filtering of the image data and accordingly degradation of the resolution is unavoidable.

In particular in the case of image data as in the above described panoramic image which is generated by connecting items of image data and has a vast number of pixels the reduction ratio of the image becomes significantly great. Therefore most of the detailed information of the image is lost and it is thus difficult to make the most use of the resolution of the image data.

Alternatively a region with a number of pixels corresponding to the number of effective display pixels of the monitor device may be extracted from the image data having a vast number of pixels and an image may be represented by that region of the image data. In this case however a memory with a vast capacity corresponding to the number of pixels of the whole image data becomes necessary in order to develop the image data resulting in an increase in the cost of the device. Even if a memory with a sufficient capacity can be mounted the size of image data that can be handled is limited to the mounted memory.

It is desirable to provide an image processing apparatus an image processing method and an image processing program for displaying an image represented by image data having a number of pixels that is significantly greater than the number of effective pixels of a display device while making the most use of the resolution of the image data.

According to an embodiment of the present invention there is provided an image processing apparatus that displays on a display region having a first number of pixels an image represented by gigantic image data that is recorded in a recording medium and has a second number of pixels that is significantly greater than the first number of pixels including the following elements a reproducing unit configured to read image data from the recording medium an output unit configured to output the image data which is read by the reproducing unit from the recording medium in synchronization with a vertical synchronization signal and a control unit configured to control the reproducing unit and the output unit. The control unit performs control to extract and read a region corresponding to the display region from the gigantic image data recorded in the recording medium.

According to another embodiment of the present invention there is provided an image processing method including extracting and reading a region corresponding to a display region having a first number of pixels from gigantic image data having a second number of pixels that is significantly greater than the first number of pixels and outputting image data included in the read region in synchronization with a vertical synchronization signal.

According to another embodiment of the present invention there is provided an image processing program for causing an apparatus to execute an image processing method including extracting and reading a region corresponding to a display region having a first number of pixels from gigantic image data having a second number of pixels that is significantly greater than the first number of pixels and outputting image data included in the read region in synchronization with a vertical synchronization signal.

As described above according to the embodiments of the present invention a region corresponding to a display region having a first number of pixels is extracted and read from gigantic image data that is recorded in a recording medium and has a second number of pixels that is significantly greater than the first number of pixels. Image data included in the read region is output in synchronization with a vertical synchronization signal. Accordingly an image represented by the gigantic image data can be displayed on the display region without involving a reduction of the resolution and the number of pixels of gigantic image data that can be processed is not limited to the capacity of a memory.

Hereinafter a first embodiment of the present invention will be described. In embodiments of the present invention when displaying an image represented by image data that is recorded in a recording medium and has a number of pixels significantly greater than the number of pixels of a display region of a monitor device hereinafter called gigantic image data on the display region a block corresponding to the display region is extracted from the gigantic image data and is used for display. On this occasion a predetermined amount of the gigantic image data which is less than or equal to the capacity of a memory that can be used for developing the image data for display is read from the recording medium. When a portion of the gigantic image data to be displayed on the display region is arranged to move the next portion of the gigantic image data is read in advance from the recording medium and stored in the memory before the next item of data becomes necessary.

Accordingly the number of pixels of gigantic image data that can be processed is not limited to the capacity of the memory. In addition the case in which a display region moves within the gigantic image data can be handled.

Further according to the first embodiment an image is moved in increments of a pixel in synchronization with a vertical synchronization signal of an output video signal. Accordingly blur or flicker of the image due to the movement of the image can be eliminated or reduced.

Referring to the first embodiment will be more specifically described. schematically shows image display according to the first embodiment of the present invention. schematically shows a system applicable to the first embodiment. In this system compressed and encoded gigantic image data recorded in a recording medium is read in a predetermined manner and the read gigantic image data is decoded by a decoder and output to a monitor device so that an image represented by the gigantic image data is displayed. The decoder performs decoding of the compressed image data using a memory .

For example the case in which as shown in part A of an image represented by gigantic image data having 7680 pixels in the horizontal direction and 1080 pixels in the vertical direction is to be displayed on a monitor device having an effective pixel region having 1920 pixels in the horizontal direction and 1080 pixels in the vertical direction will be considered. In this case image data is extracted from the gigantic image data in increments of a block having a size corresponding to the effective display region of the monitor device and an image represented by the extracted image data is to be displayed on the monitor device.

The gigantic image data which has been subjected to compression and encoding in a predetermined format is provided by being recorded in the recording medium . At the time of displaying an image represented by the gigantic image data the gigantic image data is read from the recording medium and the compressed and encoded gigantic image data is decoded by the decoder and supplied to the monitor device . Note that there is a maximum size of image data that can be decoded by the decoder . It is assumed that the decoder can decode image data up to a size of 2560 pixels 1080 pixels for example. Further it is assumed that the memory used when the decoder performs decoding of compressed image data at least has a capacity twice as large as the size of image data that can be decoded by the decoder .

The case in which a portion of the image represented by the gigantic image data displayed on a display region of the monitor device hereinafter called a display data block is sequentially moved from the left end to the right end of the gigantic image data will be considered. First access is gained to of the gigantic image data recorded in the recording medium data that includes the display data block and has a decodable size and data in that data region is read. The read data is supplied to the decoder and the compressed and encoded data is decoded by the decoder and developed in the memory part B of . In the example shown in part B of image data with a size of 2560 pixels 1080 pixels is decoded by the decoder and developed in the memory which is indicated as decoded data A in .

Firstly from the decoded data A developed in the memory data equivalent to 1920 pixels in the horizontal direction and 1080 pixels in the vertical direction which corresponds to the display region of the monitor device is read as data included in the display data block starting with a position corresponding to the left end of the image for example. The read data is supplied to the monitor device via a video memory which is not shown in the drawings for example. When the display data block is moved from the left end to the right end of the gigantic image data the image displayed on the display region of the monitor device is moved in accordance with the movement of the display data block .

When the display data block approaches the end of the decoded data A developed in the memory access is gained to the next data region of the gigantic image data recorded in the recording medium and data in that data region is read part C of . The read data is supplied to the decoder and the compressed and encoded data is decoded by the decoder and developed in the memory which is indicated as decoded data B in . On this occasion the newly developed decoded data B is mapped onto the memory so that access can be gained to the decoded data B following the decoded data A which has been developed previously.

The display data block is further moved toward the right end of the gigantic image data and when the display data block reaches a position including the boundary between the decoded data A and the decoded data B developed in the memory the display data block is moved in each of the decoded data A and the decoded data B as illustrated in part D of .

In step S data equivalent to a decodable size is read in a predetermined manner from the gigantic image data recorded in the recording medium and a time Rt involved in the reading is measured. For example it is conceivable to read data equivalent to the decodable size from a typical position for example a central portion of the image of the gigantic image data . The time Rt includes the time involved in reading data equivalent to the decodable size and decoding the read data.

When the time Rt is measured in step S data equivalent to a first decodable portion is read for display from the gigantic image data recorded in the recording medium . For example data that is designated to be displayed first includes the display data block and is equivalent to the decodable size is read. This data equivalent to the first decodable portion which has been read from the recording medium is decoded by the decoder and developed as for example the decoded data A in the memory .

In step S a rendering position X of the image data to be displayed on the monitor device in the decoded data A is determined. That is the address of the display data block in the decoded data A is determined in step S. When the rendering position X is determined in step S an image is rendered on the basis of the rendering position X. The rendering of the image is performed in synchronization with a vertical synchronization signal of a video signal output to the monitor device . By performing the rendering in synchronization with the vertical synchronization signal blur or flicker of the image due to the movement of the display region can be eliminated or reduced.

For example the range of the display data block is determined on the basis of the rendering position X and image data within the range of the display data block is read from the memory and written into a video memory which is not shown in the drawings. The data written into the video memory is supplied to the monitor device in synchronization with the vertical synchronization signal and an image represented by the data is displayed on the screen.

When the rendering based on the display data block in step S is completed in step S the rendering position X is displaced n pixels in a predetermined designated moving direction. In step S it is determined whether the position of the current rendering position X in the decoded data A which is the first encoded data has exceeded a predetermined position. That is in step S the timing for preparing the next decoded data B in the case where the display data block is moved within the decoded data A is determined.

Using the processing in step S will be described more specifically. Referring to it is assumed that the number of pixels in the horizontal direction of the decoded data A or decoded data B developed in the memory serves as an image width and the number of pixels in the horizontal direction of the display data block serves as a screen width. In this case in step S the following equation is calculated and a calculation result Xis compared with the rendering position X image width screen width reading time width rendered in unit time margin width 1 

In equation 1 reading time Rt width rendered in unit time indicates the distance moved by the display data block during a period in which data equivalent to the decodable size is read from the recording medium in the case where the display data block is moved at a certain speed. The margin width can be arbitrarily set in accordance with the convenience of the system or the like. That is when the current rendering position X is positioned ahead of the position indicated by the calculation result Xin the moving direction it can be determined that the next decoded data B may not be able to be prepared in the memory by the time at which the display data block moves to the end of the decoded data A developed in the memory .

When it is determined as a result of the comparison in step S between the above described calculation result Xand the rendering position X that the rendering position X is less than the calculation result X the process returns to step S in which the rendering position X is displaced n pixels and rendering is performed. In contrast when it is determined on the basis of the comparison result that the rendering position X is greater than or equal to the calculation result X the process proceeds to step S.

In step S it is determined whether data equivalent to a second decodable portion which is to be used for display after the data equivalent to the first decodable portion read in step S has been read from the recording medium . The data equivalent to the second decodable portion is in the gigantic image data for example data whose image region is adjacent in the moving direction of the display data block to the data equivalent to the first decodable portion. When it is determined that the data equivalent to the second decodable portion has been read from the recording medium the process proceeds to step S.

In contrast when it is determined that no data equivalent to the second decodable portion has been read the process proceeds to step S and the data equivalent to the second decodable portion is read from the recording medium . The process proceeds to step S. The reading of the data equivalent to the second decodable portion is performed in parallel to other processing using for example a different thread.

In step S it is determined whether the current rendering position X exceeds the maximum at which the rendering can be performed on the display region within the decoded data A which is the first decoded data. That is referring to it is determined in step S whether the current rendering position X is greater than the value of image width screen width . When it is determined that the current rendering position X is less than or equal to the maximum the process returns to step S in which the rendering position X is displaced n pixels and rendering is performed.

In contrast when it is determined in step S that the current rendering position X is greater than the maximum the process proceeds to step S. In step S rendering positions for rendering on the display region images represented by the decoded data A and the decoded data B are determined. In step S rendering is performed using the first decoded data A and the second decoded data B. That is when the display data block is covering the decoded data A and the decoded data B portions of the decoded data A and the decoded data B covered by the display data block are read as items of rendering data from the memory . As in step S described above the rendering of an image is performed in synchronization with the vertical synchronization signal of the video signal output to the monitor device .

When the rendering based on the display data block is completed in step S the rendering position X is displaced n pixels in the predetermined designated moving direction.

In step S it is determined whether an image represented by image data which is part of the decoded data A is displayed. That is if the whole display data block is moved to the decoded data B side no image represented by image data which is part of the decoded data A will be displayed. Note that when it is determined that an image represented by image data which is part of the decoded data A is still being displayed the process returns to step S in which the rendering position X is displaced n pixels and rendering is performed.

In contrast when it is determined in step S that no image represented by image data which is part of the decoded data A is displayed the process proceeds to step S and the decoded data A is discarded. Then the process returns to step S. That is when the display data block is continuously moved after the decoded data A has been discarded new data equivalent to the decodable size is read from the recording medium and decoded by the decoder . The new decoded data obtained by the decoding is written into the address in the memory where the discarded decoded data A was written.

When the memory is configured as a ring memory and regions where the decoded data A and the decoded data B are written are recursively used continuous movement of the display data block can be more smoothly performed.

Various methods of accessing data in a desired region of one file storing gigantic image data are conceivable. For example when gigantic image data has been compressed and encoded by block coding such as the Joint Photographic Experts Group JPEG scheme access in increments of a discrete cosine transform DCT block enables extraction of a desired region of the gigantic image data such as data equivalent to the above described decodable size. For example markers described in a JPEG file are retrieved and on the basis of the marker information DCT blocks included in the file are extracted thereby mapping the positions of the DCT blocks in an image rendered with the JPEG file.

A compression and encoding scheme applicable to the first embodiment is not limited to the JPEG scheme. That is other schemes are applicable as long as they can specify from compressed and encoded image data the positions of decoded pixels and decoded blocks. For example it is conceivable to apply the Graphics Interchange Format GIF scheme and the PNG scheme to the first embodiment. An exemplary application of the PNG format will be described later.

Next a second embodiment of the present invention will be described. The second embodiment is an example in which the above described first embodiment is applied to an application based on the BD ROM standard. The BD ROM standard will be briefly described.

The Blu ray Disc standard employs a disc with a diameter of 12 cm and a cover layer thickness of 0.1 mm as a recording medium a blue violet laser with a wavelength of 405 nm as an optical system and an object lens with a numerical aperture of 0.85 to realize a recording capacity of 27 GB at maximum. Therefore a Blu ray disc can record at least two hours of a Japanese broadcasting satellite BS digital high definition television broadcast without degradation of the image quality. The BD ROM standard is a standard for the read only type Blu ray disc and defined in Blu ray Disc Read Only Format Ver. 1.0 part 3 Audio Visual Specifications .

The BD ROM standard handles a BD J object including a movie object including video and audio and an object including a Java program.

That is as schematically shown in a video stream and playback control information for reproducing high definition video a Java program for executing a BD J object navigation for playing the high definition video and image materials used by the BD J object are stored in a disc which is a BD ROM. By playing the disc on a BD player supporting the BD ROM standard the high definition video and image materials recorded in the disc can be output to a monitor device connected to the BD player and images represented by the high definition video and image materials can be displayed on the monitor device in accordance with the playback control information and Java program recorded in the disc .

By giving instructions to the BD player using a predetermined operation unit such as a remote control commander which can communicate from a remote place with the BD player an operation in accordance with the playback control information and the Java program can be performed on the BD player . Therefore playback control operations such as title selection chapter jump search and pause of the high definition video and other interactive operations can be realized.

The index table is a top level table that defines titles in the BD ROM. On the basis of title information stored in the index table playing of the BD ROM is controlled by a module manager in system software residing in the BD ROM. That is as schematically shown in an arbitrary entry in the index table is called a title. A first playback top menu and titles . . . entered in the index table are all titles. Each title provides a link to a movie object or a BD J object. Each title indicates a high definition movie HDMV title or a BD J title.

For example when content stored in the BD ROM is a movie the first playback is a trailer which is an advertisement for a movie company and which is displayed prior to the main part of the movie. The top menu is when the content is a movie for example a menu screen for selecting playback of the main part chapter search subtitles and language settings playback of special features and the like. Individual titles are video images selectable from the top menu. Further a title can be configured as another menu screen.

Further the host layer controls a network protocol a storage system and a text presentation engine and controls communication with the network reading and writing of data into each storage and reading of data from the disc. By accessing a recording medium such as the disc from the host layer via the storage system access to the recording medium such as the disc can be performed in increments of a file or in increments of the smallest recording unit.

An HDMV compliant AV playing and navigation layer is configured above the host layer. The HDMV compliant AV playing and navigation layer includes a graphics decoder that decodes image data and a text subtitle decoder that decodes text data such as subtitles.

An application runtime environment layer is configured above the HDMV compliant AV playing and navigation layer. The application runtime environment layer configures an environment for executing the applications using Java programs in the upper layer. That is the application runtime environment layer includes an access control unit that controls access to storage a Java virtual machine VM that provides an execution environment for the host OS of Java and an application manager that manages the Java applications in the upper layer. The application runtime environment layer further includes various application programming interfaces APIs and modules such as the home audio video interoperability user interface HAVi UI Java media framework JMF JavaTV digital video broadcasting extension DVB Ext. and BD extension.

A program according to the second embodiment of the present invention operates as a BD J application in a layer above the application runtime environment layer.

The background layer handles a background image such as a wallpaper image. The primary video layer and the secondary video layer handle images mainly image data designated by respective playlists. One of the primary video layer and the secondary video layer may be displayed or a frame of one layer may be embedded in a frame of the other layer in a predetermined manner so as to be displayed as a picture in picture. The subtitles graphics layer handles subtitle data representing subtitles displayed during playback of a moving image. The interactivity graphics layer handles character data for displaying the menu screen and graphics data such as bitmap data for displaying button images. Rendering based on the BD J application can be performed using the interactivity graphics layer .

The background layer the primary video layer the secondary video layer the subtitles graphics layer and the interactivity graphics layer can be individually displayed independent of one another. The primary video layer and the secondary video layer have a resolution of 1920 pixels 1080 lines a data length per pixel of 16 bits and a 4 2 2 system of a luminance signal Y and chrominance signals Cb and Cr hereinafter called YCbCr 4 2 2 . The YCbCr 4 2 2 is a color system in which each pixel has an 8 bit luminance signal Y and 8 bit chrominance signals Cb and Cr and chrominance signals Cb and Cr of two horizontal pixels constitute one item of color data. The interactivity graphics layer and the subtitles graphics layer have a resolution of 1920 pixels 1080 lines and the sampling depth of each pixel is 8 bits. The color system of the interactivity graphics layer and the subtitles graphics layer is an 8 bit color map address system using a palette of 256 colors.

The interactivity graphics layer and the subtitles graphics layer can perform alpha blending in 256 steps. At the time of combination with other planes the opacity can be set in 256 steps. The opacity can be set in increments of a pixel. Hereinafter the opacity is indicated within the range 0 1 where the opacity 0 indicates complete transparency and the opacity 1 indicates complete opaqueness.

The interactivity graphics layer and the subtitles graphics layer handle image data in the PNG format for example. The sampling depth of one pixel defined by the PNG format ranges from 1 bit to 16 bits. When the sampling depth is 8 bits or 16 bits an alpha channel that is opacity information of individual pixel components called alpha data can be attached. When the sampling depth is 8 bits the opacity can be designated in 256 steps. Alpha blending is performed using the opacity information based on the alpha channel. Further palette images of up to 256 colors can be used and an index number indicates the ordinal number of an element index in a prepared pallet.

Referring to a PNG signature is an identifier of the PNG image and stores an 8 byte sequence for identifying a PNG image. An IHDR chunk is an image header and stores important data of the overall image such as the image size and bit depth of the PNG image. An ancillary chunk placed after the IHDR chunk contains one or a plurality of chunks relating to displaying colors such as a gamma value and a chroma of the PNG image. A PLTE chunk stores a palette in which an element is designated using an index number as described above. The PLTE chunk is critical in an index color mode. The next ancillary chunk containing one or a plurality of chunks relating to displaying transparent colors or the like. The next additional chunk is optional and is not critical. An IDAT chunk is image data and stores a compressed and encoded image data sequence. A plurality of IDAT chunks may exist in one PNG image file. An IEND chunk marks the end of the PNG image file and has a data length of 0.

In this manner a PNG image file represents data storage positions not using offsets but using a chunk structure and hence is highly expandable. For example an image is split on a two dimensional plane of the image into blocks having a predetermined size and IDAT chunks are formed in the individual blocks whereby access can be gained to data in a desired portion of the image without decoding the PNG image. That is when the above described gigantic image data is recorded as a PNG image file in a recording medium access can be gained to the display data block in the gigantic image data without reading and decoding the whole PNG image file from the recording medium.

Note that image data handled by the interactivity graphics layer and the subtitles graphics layer is not limited to that in the PNG format. Alternatively image data compressed and encoded in other compression and encoding schemes such as the JPEG scheme runlength compressed image data and bitmap data which has not been subjected to compression and encoding can be handled.

The playing apparatus contains two buses a memory bus and a central processing unit CPU bus . The playing apparatus is connected via the CPU bus and an external bus interface I F to an external bus . A CPU is connected to the CPU bus .

The CPU uses a random access memory RAM which is not shown in the drawings as a work memory executes a program stored beforehand in a ROM which is not shown in the drawings sends commands to individual units included in the playing apparatus via the CPU bus receives status signals and the like from the individual units and controls the operation of the playing apparatus . The host OS network protocol storage system and text presentation engine described using are configured by using programs running on the CPU . Similarly the access control unit Java virtual machine application manager and APIs included in the application runtime environment layer are also configured by using programs running on the CPU .

The memory bus is connected to memories and . Data is exchanged via the memory bus between these memories and and the individual units included in the playing apparatus .

A decoder receives input data reproduced from a BD ROM loaded in a drive unit which is not shown in the drawings and decodes the input data in a predetermined manner. The data decoded by the decoder is distributed according to the type of data for example. The decoded data is written into the memory or via the memory bus or supplied to the CPU via the CPU bus .

For example when the decoded data is still image data or video data the decoded data is written into the memory or via the memory bus . Alternatively when the decoded data is a Java program for executing a BD J application or an index table movie object command or playlist for performing playback control of a title the decoded data is supplied to the CPU via the CPU bus . The data supplied to the CPU is written into for example the RAM which is not shown in the drawings.

The image data written into the memory or is subjected to noise elimination using a noise reduction NR block and to image quality correction using an enhancer and the processed data is written into the memory or via the memory bus .

The video data written into the memory or is supplied from the memory bus via a scaling unit to a picture control unit processed in a predetermined manner and supplied to an blending unit . Still image data such as an image material is written as for example a PNG image file in the memory or . This PNG image file is supplied via a graphics unit to a color lookup table CLUT . Reference is made to the index number and the PNG image file is converted into RGB data and supplied via a scaling unit to the blending unit . The scaling unit converts the data into interlaced data the example in which the whole signal processing is based on interlacing is described here . The CLUT extracts data of an alpha channel indicating the opacity.

The blending unit blends the image data supplied from the picture control unit and the image data supplied from the scaling unit and outputs the blended image data. At this time on the basis of the data of the alpha channel extracted by referring to the CLUT the opacity of the image data supplied from the scaling unit is set and blending is performed.

The image data output from the blending unit is output in synchronization with a vertical synchronization signal from a digital output unit and supplied to an interlace progressive I P converter . The I P converter converts interlaced data to progressive data called I P conversion . For example the I P converter converts 1080I based input data into 1080P based data and outputs the 1080P based data. The image data output from the I P converter is supplied to an HDMI transmitter . The HDMI transmitter converts the supplied image data into a signal in a transmission format based on the HDMI standard and outputs the signal.

The monitor device includes a ROM storing information unique to the monitor device such as the name of a vender serial number and resolution. The playing apparatus which is the HDMI signal transmitter communicates with the monitor device using a display data channel DDC and obtains the information unique to the monitor device which is stored in the ROM . DDC is transmitted using cables common to the above described TMDS channels to and TMDS clock channel.

The data format of the information unique to the monitor device is defined as extended display identification data EDID . show a data format defined in EDID. 00h which is the first address h indicates that the immediately preceding 2 digit number is a hexadecimal number is a header. Items of vender and product information are stored at addresses 08h to 11h. Version information and the like of the EDID structure are stored at addresses 12h and 13h. Items of basic information of the monitor device such as the horizontal size and the vertical size of an effective display region are stored at addresses 14h to 18h. Items of information relating to colors are stored at addresses 19h to 22h. Items of timing information unique to the monitor device such as the range of vertical synchronization frequencies and horizontal synchronization frequencies and the number of displayable pixels are stored at addresses 23h to 25h. Items of support information of a standard number of pixels are stored at addresses 26h to 34h. Items of detailed information are stored at addresses 36h to 0Ch. An extension flag is stored at address 11h. A checksum is stored at address 12h.

Note that the obtaining of information unique to the monitor device using the EDID is not limited to connection based on HDMI and is widely adopted by general monitor devices using for example liquid crystal displays LCDs . As with an example shown in a video signal is transmitted through TMDS channels to a monitor device. In addition Plug and Play PnP information is exchanged between a video card and the monitor device via a display data channel standard level 2B DDC2B channel. At the time of this data exchange EDID information stored in a ROM 91 included in the monitor device is read and transmitted to the video card side.

According to the embodiments of the present invention as has been described in the first embodiment at the time of movement of a display data block in gigantic image data movement in increments of a pixel is performed in synchronization with a vertical synchronization signal for display. In the second embodiment the principle of a process of performing movement in increments of a pixel in synchronization with the vertical synchronization signal will be schematically described using .

In response to a command from an application in an upper layer an animator outputs in synchronization with the frame signal supplied from the video source the buffer images . . . N which are copied to the region duplication unit in the sequence in which they are to be displayed in the animated cartoon. The animated image output from the region duplication unit is supplied via a graphics plane to a mixer combined with video data supplied from the video source and output.

Since the animated cartoon is displayed in synchronization with the frame signal of the video data as an example is shown in the updating of animation frames is performed in synchronization with the updating of video frames thereby displaying a visually smooth animated cartoon. Alternatively for example when the application designates display intervals between the animation frames an animated cartoon synchronized with video frames can be displayed on the basis of the designated display intervals.

In the structure shown in it is assumed that the frame signal supplied from the video source to the region duplication unit is a signal synchronized with the vertical synchronization signal of the video signal output to the monitor device. It is also assumed that the images . . . N for displaying an animated cartoon serve as the display data block at respective positions in the case where the display data block is moved in increments of a pixel within the gigantic image data. Accordingly when the display data block is moved in increments of a pixel within the gigantic image data movement of the display data block can be synchronized with the vertical synchronization signal of the video signal output to the monitor device.

That is an image file storing gigantic image data and a BD J application including a Java program for causing the playing apparatus to execute the process described using the flowchart shown in in the first embodiment are recorded in the disc based on the BD ROM standard. The BD J application enables for example a predetermined region of the gigantic image data recorded as a file in the disc to be displayed on the monitor and the displayed region to be moved in accordance with a user operation.

When the disc is loaded into a drive unit which is not shown in the drawings of the playing apparatus for example the disc is played by the playing apparatus and the BD J application is read and written into the RAM which is not shown in the drawings and which is the work memory for the CPU . At the same time the playing apparatus obtains information unique to the monitor device which is stored in the EDID format in the ROM by performing DDC based communication using a communication unit which is not shown in the drawings. The playing apparatus obtains from the unique information information indicating for example the vertical synchronization frequency of the monitor device and the scanning type that can be handled interlace or progressive . When the monitor device supports the progressive scanning it is regarded that the movement of the display data block in the gigantic image data in increments of a pixel in synchronization with the vertical synchronization signal according to the embodiments of the present invention is effective.

When it is determined that the monitor device supports the progressive scanning on the basis of the information unique to the monitor device the process described using the flowchart shown in is performed by using the structure described using . The structure described using can be realized for example using the CPU the memory or and the graphics unit . The process described using the flowchart shown in is executed by the CPU .

That is the CPU accesses the gigantic image data file recorded in the disc in accordance with the BD J application read from the disc reads data at a predetermined position in the gigantic image data file and measures the reading time Rt step S in . Subsequently the CPU reads data that is designated to be displayed on the monitor device includes the display data block and is equivalent to the first decodable portion from the gigantic image data file step S in .

The read data is decoded by the decoder and written via the memory bus into for example the memory . Thereafter the rendering position X is determined for the data written into the memory step S in and rendering of the data equivalent to the display data block is performed in synchronization with the vertical synchronization signal of the video signal output to the monitor device step S in . In response to a movement instruction the rendering position X is displaced n pixels step S in . When it is determined that the new rendering position X is the position at which it is not necessary to read data equivalent to the second decodable portion step S in the next rendering is performed in synchronization with the vertical synchronization signal of the video signal output to the monitor device .

Hereinafter the process from step S in onward that is determination as to whether to read data equivalent to the second decodable portion step S in determination of when data equivalent to the second decodable portion is read from the gigantic image data file recorded in the disc step S in the rendering position X of the display data block on the basis of the data equivalent to the second decodable portion step S in and rendering in synchronization with the vertical synchronization signal at the determined rendering position X step S in is similarly performed.

Note that it has been described above that a region of gigantic image data to be displayed display data block is moved in the horizontal direction. However this is not limited to the foregoing example. That is the display data block can be moved in the vertical direction or diagonal direction with respect to the gigantic image data. Further it has been described above that movement of the display data block is performed in increments of a pixel. In this case however movement can be performed not only in increments of one pixel but also in increments of multiple pixels such as two pixels or three pixels or in increments of a variable number of pixels. Accordingly the movement speed of a displayed image can be changed.

Further it has been described above that gigantic image data which has been compressed and encoded is recorded in a recording medium. However this is not limited to the foregoing example. That is the embodiments of the present invention are applicable to the case where gigantic image data which has not been compressed or encoded such as data in the bitmap format is recorded in a recording medium.

It should be understood by those skilled in the art that various modifications combinations sub combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.

