---

title: Programmable effects for a user interface
abstract: A programmable effects system for graphical user interfaces is disclosed. One embodiment comprises receiving one or more effect elements to apply to an element in a graphical user interface for a device, ordering the effect elements in a pipeline of operations, and storing the pipeline of operations in an effect template. Then, after the graphics hardware capability for a device is determined, the effect template may be used to create a shader that includes supported effects to render an element in the graphical user interface.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08614709&OS=08614709&RS=08614709
owner: Microsoft Corporation
number: 08614709
owner_city: Redmond
owner_country: US
publication_date: 20081111
---
Graphical user interface GUI platforms are deployed on multiple devices with different graphics hardware capabilities. Modern graphics processors are capable of high fidelity visual effects for some classes of applications e.g. video games but GUI platforms have not utilized these hardware capabilities.

Some GUI platforms such as Microsoft s Windows Presentation Format WPF use hardware acceleration to provide a rich GUI experience. However these platforms use hardware acceleration in a least common denominator approach and do not utilize the range of hardware capabilities. Additionally these platforms do not allow GUI developers to build custom graphical effects nor do these GUI platforms provide a fallback mechanism for techniques targeted at high end classes of hardware that are implemented on a device that does not support high fidelity visual effects.

Accordingly various embodiments to provide programmable effects for a user interface are described below in the Detailed Description. For example one embodiment comprises receiving one or more effects to apply to an element in a graphical user interface for a device ordering the effects in a pipeline of operations and storing the pipeline of operations in an effect template. In this way after the graphics hardware capability for a device is determined the effect template may be used to create a shader that includes graphics hardware supported effects to adjust an element in a graphical user interface.

Another example embodiment comprises receiving an effect template including a plurality of effects that are ordered in a pipeline of operations determining graphics hardware capability for a device creating a shader including effects in the pipeline of operations that are supported by the graphics hardware to adjust the element in the graphical user interface and adjusting the element in the graphical user interface.

This Summary is provided to introduce concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

In the illustrated example the pipeline of operations includes a first effect element second effect element up through an Nth effect element . These effect elements may include operations inputs etc. Next one or more shaders may be created that incorporate the effect elements in the pipeline of operations according to the graphics hardware capabilities of a target device. Further these elements may be combined in an arbitrary manner by a GUI author to provide a rich user interface experience according to supported operations for graphics hardware or other graphics sub system of a target device.

In an example including multiple devices comprising different graphics hardware capabilities a GUI author may create a pipeline of operations that is supported on one device with graphics hardware in a different manner than it is supported on another device having graphics hardware . For example a GUI may be designed with 2.0 minimum bar graphics capabilities in mind but this may be supported by graphics hardware and not graphics hardware therefore shader may be created with the 2.0 minimum bar support for device while shader may be created for device without 2.0 minimum bar support.

Effect elements in the pipeline of operations may be implemented in a shader on an effect by effect basis. For example a GUI developer may create a scalable GUI comprising graphics effects that are not supported by current hardware while still allowing a range of fallback graphic effects that provide more than a minimum bar experience where supported as a non limiting example. Additionally scalable elements for graphical user interfaces may be created for target devices based on hardware or software capabilities other than graphics hardware capabilities.

Referring to the embodiment in in detail computing device includes an effect template module configured to receive a plurality of effect elements to apply to an element in a GUI for a device . The effect template module may be further configured to order the plurality of effects into a pipeline of operations. In this way the effect template module may define an effect template that includes the ordered effect elements .

Effects may include inputs operations etc. that adjust a property of a visual element or create a visual element in a graphical user interface. Example effects include inputs such as colors images light sources and blending elements and operations such as desaturate blur tint inverse alpha elements filters etc. Some embodiments may receive previously combined effects user developed graphics effects etc.

In some embodiments the effect template includes a fallback effect to be set as a minimum bar implementation for effects supported by the graphics hardware. In this way each effect template may have a different minimum bar implementation to incorporate fallback effects that scale to different graphics hardware capabilities.

Computing device includes an effect resource module in communication with the effect template module . The effect resource module creates a shader that may be used to adjust an element in GUI in device . In this way the shader uses the effect elements in the pipeline of operations that are supported by graphics hardware in the device .

Computing device is configured to create an instance of the effect template that links to the shader to adjust an element in a graphical user interface such as GUI . As an example an effects template may use a markup language to define user specified graphics elements and therefore create a pipeline of operations including inputs i.e. color and operations filters etc.

In another example an application programming interface may link to an effect resource to define user specified graphics elements and therefore create a pipeline of operations. In either approach the specified graphics elements may be processed based on graphics hardware capabilities and then converted into a graphics hardware shader to execute the pipeline of operations on a graphics processing unit GPU . If an effect is not supported a fallback effect may be used that is supported by the graphics hardware.

In some embodiments element structures in an effects template may define a set of properties that may be animated or changed when an effect is in use. For example these properties may map to shader variables stored on a GPU and an embodiment system then manages the mapping of markup properties to shader variables. After a shader is compiled it may be cached and shared across multiple GUI elements that refer to it.

In one example multiple graphical user interface authors may be working on a large application and may not know of an existing compiled shader effects templates etc. For example the multiple authors may have multiple templates that result in the same compiled shader. Therefore some embodiments so may use a specific element structure to develop a cache key. In this way the cache key may then be implemented in a low level renderer or other graphics engine and when a new effects template is generated the embodiment can do a look up for the cache key and load an already generated shader as opposed to compiling a new shader. Conventional applications either pre compile all requested shaders at startup or they recompile a shader every time an effect is requested.

In some embodiments a template instance approach may be used to expose graphics effects in computationally inexpensive instances while corresponding templates bear the majority of the computational cost. Additionally markup element structures provide an abstraction layer to allow an effects template to run on multiple hardware platforms with varied underlying graphics systems.

In some embodiments the template instance approach provides a many to one mapping allowing multiple effects templates to map to one effect resource as described in the caching example above. Additionally instances may have a many to one for effects templates.

Furthermore the embodiments described herein allow combination of effects in a user specified order control of effects in a non binary fashion where each effect may have an adjustable property and not be implemented in an on or off manner. In this way if the order of effects is important the effects template allows a GUI author to nest effects control when effects get combined control what happens in a specified order etc. For example at a markup level the effects template may provide a blur element may include a number of properties that may be adjusted such as the result of the blur may be desaturated or a complex blend modes may be combined with the blur element instead of a binary blur element that is either on or off.

In some embodiments an effect operation may be an input or an operation for an element in a graphical user interface. Additionally the input or operation may include a property that can be adjusted to change a shader at runtime. Example effect operations include inputs such as colors images light sources and blending elements and operations such as desaturate blur tint inverse alpha elements filters etc. Some embodiments may receive previously combined effects user developed graphics effects etc.

Method also comprises receiving a second effect operation to apply to the element in the graphical user interface as indicated in block . Next method comprises ordering the first effect operation and the second effect operation into a pipeline of operations as indicated at . In some embodiments a single effect operation may be used with fallback positions while in other embodiments a plurality of effects may be used and ordered in the pipeline according to developer preference ordered arbitrarily etc.

In block method comprises defining an effect template that includes the pipeline of operations the effect template being configured to create a shader to adjust an element in a graphical user interface for a device wherein the shader includes effect operations in the pipeline of operations that are supported by graphics hardware in the device.

For example graphics hardware capability may be associated with a device driver firmware number accessed from a database or online user specified queried etc. In one example the effect template may comprise markup language that links to an effect resource and the effect resource may be configured to create the shader including effects supported by graphics hardware in the device.

In some embodiments the shader may be created with a fallback effect for an effect not supported by the graphics hardware. Additionally the shader may be dynamically created at runtime to provide a rich user interface experience by using the shader to provide an element in a graphical user interface. In some embodiments method may include caching the shader for a first effect template and providing the shader for a second effect template.

In some embodiments an effect may be an input or an operation for an element in a graphical user interface. Additionally the input or operation may include an adjustable property for adjusting the shader at runtime. Example effects include inputs such as colors images light sources and blending elements and operations such as desaturate blur tint inverse alpha elements filters etc. Some embodiments may receive previously combined effects user developed graphics effects etc.

Method also comprises determining graphics hardware capability for a device as indicated in block . For example graphics hardware capability may be associated with a device driver firmware number accessed from a database or online user specified queried etc.

Next method comprises creating a shader to adjust the element in the graphical user interface wherein the shader includes effects in the pipeline of operations that are supported by the graphics hardware as indicated at . In some embodiments the shader may be created with a fallback effect for an effect not supported by the graphics hardware. Additionally the shader may be dynamically created at runtime.

In block method comprises rendering the element for display in the graphical user interface according to the graphics hardware capabilities and the effects implemented in the shader. In some embodiments method may include caching a shader for a first effect template and providing the shader for a second effect template.

It will be appreciated that the embodiments described herein may be implemented for example via computer executable instructions or code such as programs stored on a computer readable storage medium and executed by a computing device. Generally programs include routines objects components data structures and the like that perform particular tasks or implement particular abstract data types. As used herein the term program may connote a single program or multiple programs acting in concert and may be used to denote applications services or any other type or class of program. Likewise the terms computer and computing device as used herein include any device that electronically executes one or more programs including but not limited to personal computers servers laptop computers hand held devices cellular phones microprocessor based programmable consumer electronics and or appliances and other suitable computer devices.

It will further be understood that the configurations and or approaches described herein are exemplary in nature and that these specific embodiments or examples are not to be considered in a limiting sense because numerous variations are possible. The specific routines or methods described herein may represent one or more of any number of processing strategies. As such various acts illustrated may be performed in the sequence illustrated in other sequences in parallel or in some cases omitted. Likewise the order of any of the above described processes is not necessarily required to achieve the features and or results of the embodiments described herein but is provided for ease of illustration and description.

The subject matter of the present disclosure includes all novel and nonobvious combinations and subcombinations of the various processes systems and configurations and other features functions acts and or properties disclosed herein as well as any and all equivalents thereof.

