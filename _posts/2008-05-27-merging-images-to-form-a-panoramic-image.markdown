---

title: Merging images to form a panoramic image
abstract: Methods, systems, and apparatus, including computer program products, for merging images of segments of a view. Methods include: receiving, from a network, a first image representing a first segment of the view and a second image representing a second segment of the view; determining the position of the second segment of the view relative to the first segment of the view; blending the first image with the second image based on the determined position of the second segment relative to the first segment to form a panoramic image of the view; and transmitting the panoramic image over the network.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07646932&OS=07646932&RS=07646932
owner: Adobe Systems Incorporated
number: 07646932
owner_city: San Jose
owner_country: US
publication_date: 20080527
---
This application is a continuation application of and claims priority to U.S. application Ser. No. 11 498 948 filed on Aug. 2 2006 which is a continuation of U.S. application Ser. No. 09 657 949 filed on Sep. 8 2000 now U.S. Pat. No. 7 095 905.

This invention relates to a server for merging images to form a panoramic image and methods practiced by the server.

Image capture devices such as cameras can be used to capture an image of a section of a view such as a section of the front of a house. The section of the view whose image is captured by a camera is known as the field of view of the camera. Adjusting a lens associated with a camera may increase the field of view. However there is a limit beyond which the field of view of the camera cannot be increased without compromising the quality or resolution of the captured image. It is sometimes necessary to capture an image of a view that is larger than can be captured within the field of view of a camera. To do so multiple overlapping images of segments of the view can be taken and then the images can be joined together or merged to form a composite image known as a panoramic image.

An image captured by a camera distorts the sizes of objects depicted in the image so that distant objects appear smaller than closer objects. The size distortion which is known as perspective distortion depends on the camera position the pointing angle of the camera and so forth. Consequently an object depicted in two different images might not have the same size in the two images because of perspective distortion.

In one general aspect of the invention a method of merging images of segments of a view includes receiving a first image representing a first segment of the view and a second image representing a second segment of the view from a network determining the position of the second segment of the view relative to the first segment of the view blending the first image with the second image based on the determined position of the second segment relative to the first segment to form a panoramic image of the view and transmitting the panoramic image over the network.

In a second general aspect of the invention an article includes a computer readable medium which stores computer executable instructions for causing a computer to implement the method of the first general aspect of the invention.

Embodiments of the first and second general aspects of the invention may include one or more of the following features. Determining the relative position of the second image and merging the first and second image are performed without the intervention of a human operator. The method further includes determining whether the second image overlaps the first image based on the position of the second segment relative to the first segment and the first image and the second image are only blended when the second image overlaps the first image. Perspective distortion in the second image relative to the first image is corrected prior to blending the first image with the second image. Blending the first image with the second image includes dividing the second image into a first portion and a second portion based on the position of the second segment relative to the first segment and compositing the first portion of the second image on the first image at the relative position of the second segment relative to the first segment to produce the panoramic image. The compositing of the first portion of the second image causes the first portion to mask out a part of the first image.

In a third general aspect of the invention a method of merging images of segments of a view includes retrieving a set of images representing a view including a first image representing a first segment of the view a second image representing a second segment of the view and a third image representing a third segment of the view determining a first position of the second segment of the view relative to the first segment of the view determining a second position of the third segment relative to the first segment of the view and a third position of the third segment relative to the second segment of the view checking whether the first image overlaps the third image more than the second image overlaps the third image based on the second position and the third position and if the first image overlaps the third image more than the second image overlaps the third image blending the set of images based on the first position and the second position.

In a fourth general aspect of the invention an article includes a computer readable medium which stores computer executable instructions for implementing the method of the third general aspect of the invention.

Embodiments of the third and fourth general aspects of the invention may include one or more of the following features. Prior to blending the set of images perspective distortion in at least one of the set of images is corrected. A central one and peripheral ones of the set of images are determined based on the first and second positions. Overlap areas between the central one and each of the peripheral ones of the set of images are determined based on the first and second positions. A first peripheral one of the images is selected to maximize the overlap area between the central image and the first peripheral one of the images. Perspective distortion in the first peripheral image is corrected relative to the central image.

A first overlap area is determined between a second one of the peripheral images and the central image and a second overlap area is determined between the second peripheral image and the first peripheral image. If the first overlap area is greater than the second overlap area perspective distortion in the second peripheral image is corrected relative to the central one of the images. Alternatively if the first overlap area is less than the second overlap area perspective distortion is corrected in the second peripheral image relative to the first peripheral image.

The images in the set are then blended as follows. The second image is divided into a first portion and a second portion based on the first position. The first portion of the second image is composited on the first image masking out a part of the first image to produce a composite image. The third image is divided into a third portion and a second portion based on the second position. The third portion is further divided into a fifth portion and a sixth portion based on the third position. The fifth portion is composited on the composite image based on the second position masking out a part of the composite image to form the panoramic image.

In a fifth general aspect of the invention a method of merging images of segments of a view includes transmitting a first image representing a first segment of the view to a server transmitting a second image representing a second segment of the view to the server and receiving a panoramic image of the view from the server. The panoramic image is a composite of the first image and the second image.

In certain instances the first image is transmitted from a first computer and the second image is transmitted from a second different computer.

The invention can be implemented to realize one or more of the following advantages. The images are merged quickly and seamlessly. Images from collaborating users who are geographically distant from each other may be merged on a central server. Images from a client device that lacks the computing power to merge the images such as personal digital assistant PDA may be merged on the server and transmitted to the PDA.

The details of one or more embodiments of the invention are set forth in the accompanying drawings and the description below. Other features and advantages of the invention will become apparent from the description the drawings and the claims.

As shown in a system for merging images includes a server and a network such as the Internet which connects the server to client computers and a personal digital assistant PDA . Users may for example use a scanner to capture digital images and load them onto a client computer before the images are transmitted from the client computer to the server over the network . The images depict overlapping segments of a view that is common to all the images and the server merges the images to create a panoramic image of the view. For example each of the images may represent a segment of the skyline of a city and the server may merge the images to form a panoramic image of the entire skyline. Some of the images merged by the server to form the panoramic image may be transmitted from client computer while others of the images may be transmitted from a different client computer allowing users at different locations to collaborate in creating the panoramic image. The images used in creating the panoramic image may be transmitted from a device such as a PDA which may not have sufficient computing power to merge the images. Server transmits the panoramic image to the client computer where a user may either display the panoramic image or print the panoramic image on a printer .

Server includes a network interface for transmitting and receiving information such as images over the network . Server also includes a processor for executing programs and a storage subsystem for storing information such as data or computer programs. The storage subsystem may include a hard disk a hard disk array a CD ROM drive a floppy drive or memory. The software stored in storage subsystem and executed by the processor includes software implementing a network server such as a web server with an input interface for receiving information from network interface and an output interface for transmitting information using the network interface . The software also includes image stitching software for merging images and an image input interface for receiving images from the input interface of the network server and conveying the images to the image stitching software . The input interface may be an Internet Server Application Programming Interface ISAPI dynamically linked library DLL or some other software for communicating with network server .

Image stitching software includes a positioning module for determining the relative positions of the segments of the view represented by the images a perspective corrector for correcting perspective distortion in the images a dividing line determiner a blending mask determiner and an image blender . The image stitching software will be described in greater detail below.

As shown in the network server transmits the web page to a user on client computer to allow the user to send images to the server . The user may add images to the web page by clicking on an add button . The web page includes images that have been added to the web page using the add button . The images depict overlapping segments of a view of a lake. The user may transmit each of the images by clicking on an upload button that corresponds to the image. The user directs the server to create a panoramic image from the uploaded images by clicking on a create button causing client computer to transmit the images to the server through the network . The input interface of the network server receives the images through the network interface and conveys them to the image input interface which in turn conveys the images to the image stitching software . The images stitching software merges the images to form a panoramic image of the entire view of the scene which it conveys to the output interface of the network server .

As shown in the output interface of the network server creates a web page containing the panoramic image created by image stitching software from the images . The output interface transmits the web page to the client computer through the network interface and the network . The client computer displays the panoramic image to the user for example on a web browser associated with the computer. The web page also includes a download button that the user can click on to download the panoramic image from the server . Additionally the web page contains a hyperlink that the user may click to order a full resolution glossy print of the image.

As shown in the process for merging images implemented by image stitching software will be described. Upon receiving the images to be merged from image input interface the positioning module determines the position of the segment of the view depicted in each of the image relative to the position of the segment of the view depicted in the other images.

For example as shown in the positioning module uses the two image positioner to determine how much a first image needs to be moved relative to a second image so that a certain object depicted in both of the images has its depiction in the second image on top of its depiction in the first image . In the image must be moved 68 pixels to the right and 2 pixels upwards so that a branch which is depicted in both image has its depiction in the second image on top of its depiction in the first image . This ensures that the two images are positioned so that the images continue into each other as seamlessly as possible without altering the pixels of the images.

The two image positioner determines the relative position offset of the two images for example based on the cross spectrum method described in Direct Estimation of Displacement Histograms proceedings of the OSA meeting on image understanding and machine vision June 1989 Bernd Girod and David Kuo Girod the disclosure of which is incorporated by reference in this specification. The Girod method returns a probability density function see FIG. 3 of Girod that has a peak at the value of the relative displacement. Two image positioner determines the relative position by first finding the location of the peak which gives the magnitude of the relative position. Two image positioner also finds the highest value of the probability density function that is outside a five pixel radius of the peak and computes a confidence value in the relative position by subtracting the ratio of the highest value outside the five pixel radius and the value of the peak from 1.

Although Girod discloses how to compute the relative distances the two images have to be moved Girod s method does not determine the direction that the images have to be moved relative to each other. Consequently after performing the Girod method there are four possible relative positions depending on whether the image is moved to the left and up left and down right and up or right and down. To determine the direction that the images have to be moved relative to each other the two image positioner determines a pair of overlapping segments of the two images for each of the possible relative positions. For each pair of determined overlapping segments the two image positioner computes the correlation between the overlapping segments according to the formula 

The actual relative position of the first image relative relative to the second image yields the greatest value for the correlation q. Relative positions that yield very small overlapping segments are discarded because the correlation for the small segments is likely to yield false positive results.

The two image positioner repeats the process described above for each pair of the images to yield adjacent lists which contain the relative positions of the images. For example from the adjacent list the image must he moved 68 pixels to the left and two pixels upwards relative to image . Similarly from the adjacent list image must be moved 68 pixels to the right from the negative sign and two pixels downwards from the negative sign relative to image while image must be moved 69 pixels to the left and 4 pixels upwards relative to image . Based on the relative positions of the pairs of images the multiple image positioner determines how the images should be translated relative to each other to form the panoramic image as will be described below.

Referring again to after determining the positions of each of the segments relative to the other segments the perspective corrector corrects perspective distortion in the images. Multiple image corrector of the perspective corrector selects pairs of images to be corrected as will be described below and two image corrector corrects for perspective in one of the images relative to the other. Two image corrector uses for example the virtual bellows method of perspective correction described in Virtual Bellows High Quality Stills from Video proceedings of the first IEEE international conference on image processing November 1994 Steve Mann and Rosalind Picard Mann the disclosure of which is incorporated by reference in this specification. Thus perspective corrector corrects perspective distortion in the images to yield substantially trapezoidal corrected images . The multiple image corrector also arranges the images in the order in which they should be blended as will be described later.

Referring again to stitching software then sets a visible property of the pixels of all the images to indicate that all the pixels of all the images start as being visible. The stitching software then sets the current image to the first image and proceeds to determine the visible area of each of the images as described below.

The stitching software sets the current image to be the next image after the current image and sets the reference image to be the first image . Thereby leaving all the pixels of the first image visible. Although all the pixels of the first image are set visible some of the pixels of the first image may be obstructed or masked out by visible portions of subsequent images as described later.

The dividing line determiner determines an outline of a composite image formed by aligning the current image and the reference image as previously described with reference to . The dividing line determiner also determines a pair of points where the outlines of the aligned images intersect thereby defining a line that joins the points and divides the panoramic outline into two sections . If the outlines of the aligned images intersect at more than two points the dividing line determiner selects the two intersection points that are furthest apart from each other to define the dividing line . The dividing line determiner then determines which one of the two sections has less of the current image that is not overlapped by the reference image and sets that section of the current image to be invisible. In the example of the section has none of the current image that is not overlapped by the first image . Consequently the portions of the image profile contained within the section are set invisible leaving the hashed section of the image visible.

The stitching software checks whether there are any more images between the reference image and the current image . If there are more images the stitching software sets the reference image to be the next image after the current reference image and repeats the process of setting a section of the current image invisible as described above. Otherwise if there are no more images the blending mask determiner determines the pixels within the current image that will mask out pixels of earlier images. Only visible pixels of the current image mask out pixels of earlier images . Consequently the mask value of pixels contained within the region is set to 1 while the mask property of pixels contained within the region is set to 0 .

After determining the mask values of the image the stitching software checks whether there are any images after the current images. If there are more images the stitching software sets a new current image to be the next image after the current image and proceeds to determine the mask values of the new current image . The processing of subsequent images is preformed using the techniques that have been described above.

If there are no more images after the current image the image blender overlaps the images based on the masking value to create the panoramic image . The section of the second image with a mask value of 1 is first composited on the first image thereby obstructing the part of the first image that is to the right of the dividing line . The portions of the third image with a mask value of 90 are then composited on the composite image from the first and second image to create another image and so on until the composite image is created. Thus image stitching software merges images depicting sections of a scene to create a panoramic image of the whole scene.

As shown in the process performed by the multiple image positioning module to position the images relative to each other begins when the multiple image positioning module creates an empty positioned list for storing images whose translation in pixels relative to the other images has been determined. The multiple image positioning module checks the input interface to determine whether any images have been received that are not on the positioned list. If no images have been received then the multiple image positioning module stops the process. Otherwise if an unpositioned image has been received the multiple image positioning module checks if the positioned list is empty. If the positioned list is empty the multiple image positioning module adds the unpositioned image to the positioned list since there are no images to position the image relative to and checks if there are any other unpositioned images.

Otherwise if the positioned list is not empty multiple image positioning module creates an empty overlap list for storing images from the positioned list which overlap the unpositioned image. The multiple image positioning module then begins the process of determining the overlapping images by setting a best confidence value to zero a best confidence image to NO MATCH and a current image to the first image in the positioned list. The best confidence image represents the image that the process considers most likely to overlap the unpositioned image while the best confidence value is a statistical measure of confidence that the best confidence image overlaps the unpositioned image. Since multiple image positioning module has not found an image that overlaps the unpositioned image when the overlap list is empty the best confidence image and the best confidence are initially set as described.

The two image positioner then determines the relative position offset of the unpositioned image relative to the current image and a confidence value for the offset as previously described with reference to . The multiple image positioner then checks if the confidence value is greater than a threshold confidence value which must be met by overlapping images. If it is not then the multiple image positioner checks whether the current image is the last image in the positioned list. Otherwise if the confidence value is greater than the threshold confidence value the multiple image positioner adds the current image its position offset and the confidence value of the position offset to the overlap list. The multiple image positioner checks if the confidence value is greater than the best confidence value. If it is not the multiple image positioner checks if the current image is the last image in the positioned list. Otherwise if it is the multiple image positioner makes the current image the best confidence image by setting the best confidence image to be the current image and the best confidence value to be the confidence value of the current image.

The multiple image positioner then checks whether the current image is the last image in the positioned list. If it is not the multiple image positioner sets the current image to be the next image in the positioned list and repeats the processes for the new current image. Thus the multiple image positioner and the two image positioner determine the relative positions of the unpositioned image relative to the positioned images while keeping track of a confidence value for the relative positions.

Otherwise if the current image is the last image in the list the multiple image positioner sets a reference image to be the first image in the overlap list and checks whether the reference image is the last image in the overlap list. If the reference image is the last image the multiple image positioner appends the unpositioned image to an adjacent list of images that are adjacent to reference image along with the position of the unpositioned image relative to the reference image which is given by the negative of the positioned offset. Otherwise if the reference image is not the last image in the overlap list the multiple image positioner determines whether the unpositioned image connects two previously disjoint sets of images as will described below. For example as shown in the multiple image positioner may have determined that images and are positioned adjacent to each other and that images and are connected to each other by image resulting in two disjoint sets and of images. The following steps would determine that a new image is positioned adjacent to images from the two sets and therefore joins the previously disjoint set of images to create one set of connected images.

The multiple image positioner begins by checking if the reference image is the last image in the overlap list. If it is the last image the multiple image positioner appends the unpositioned image to the adjacent list of images that are adjacent to the reference image. Otherwise if it is not the last image in the overlap list the multiple image positioner sets the current image to be the next image in the overlap list after the reference image. The multiple image positioner then checks if the adjacent lists of the reference image and the current image indicate that the reference and current images are adjacent to each other. If the adjacent lists do indicate that they are adjacent the multiple image positioner checks whether the current image is the last image in the overlap list. Otherwise if the adjacent lists do not indicate that the two images are adjacent the multiple image positioner translates the current image and all the images that are connected to it relative to the reference image based on the offsets of the current image and the reference image relative to the unpositioned image. Thus the multiple image positioner uses the positions of the current image and the reference image relative to the unpositioned image to position the current image and the reference image relative to each other. The multiple image positioner then appends the unpositioned image to the adjacent list of images that are adjacent to the current image.

The multiple image positioner then checks if the current image is the last image in the overlap list. If it is not the multiple image positioner sets the current image to be the next image in the overlap list and checks if the adjacent lists indicate that the new current image is connected to the reference image. Thus the multiple image positioner goes through the overlap list connecting sets of images that were previously disjoint from the reference image but are now connected to the reference image by the unpositioned image.

The multiple image positioner then appends the unpositioned image to the adjacent list of images that are adjacent to the reference image and checks whether the reference image is the last image in the overlap list. If the reference image is not the last image in the overlap list the multiple image positioner sets the reference image to be the next image after the reference image. The process of steps is repeated for the new reference image to determine which disjointed sets of images are connected by the unpositioned image and to add the unpositioned image to the adjacent lists of images that are adjacent to the positioned image.

The multiple image positioner checks whether the best confidence value is greater than zero to determine whether an overlapping image was found in the process that was described above. If the best confidence value is not greater than zero the multiple image positioner adds the images in the overlap list and their offsets to the adjacent list of the unpositioned image to keep a permanent record of the images that are adjacent to the unpositioned image. Otherwise the multiple image positioner translates the unpositioned image relative the best confidence image based on the position offset of the best confidence image. By translating the unpositioned image based on the positional offset that is most certain the multiple image positioner moves the unpositioned image to its most likely position. The multiple image positioner adds the images in the overlap list and their offsets to the adjacent list of the unpositioned image to keep a permanent record of the images that are adjacent to the unpositioned image and adds the unpositioned image to the positioned list.

The multiple image positioner then checks whether there are other images that have not been relatively positioned and processes subsequent unpositioned images as described above. The process of determines the relative positions of the images without the intervention of a human operator.

As shown in multiple image corrector corrects perspective distortion in the images in a process that begins by determining the most centrally positioned of the images centermost image based on the relative positions stored within the adjacent lists created by the multiple image positioner . For example in the centermost image may be . The multiple image corrector does not correct perspective distortion in the centermost image but instead corrects perspective distortion of the other images relative to the centermost image.

The multiple image corrector creates a list of images whose perspective distortion has been corrected list of corrected images that includes only the centermost image. The multiple image corrector also creates a list of images whose perspective distortion has not been corrected list of uncorrected images that includes all of the images . The multiple image corrector then initializes the correction process by setting the value of the maximum overlap area max overlap area to zero the image from the corrected list that will be used in perspective correction selected warped to be undefined and the image whose perspective is to corrected selected unwarped to also be undefined.

The multiple image corrector then sets the current warped image to be the first image in the corrected list and the current unwarped image to be the first image in the uncorrected list. The multiple image corrector computes an overlap area between the current warped image and the current unwarped image based on the relative positions from the adjacent lists and the sizes of the two images. The multiple image corrector checks if the overlap area is greater than max overlap area. If it is not the multiple image corrector checks if there are any more images in the corrected list. Otherwise if the overlap area is greater than max overlap area the multiple image corrector changes the images that will be used in perspective correction by setting max overlap area to be the overlap area setting the selected warped image to be the current warped image and setting the selected unwarped image to be the current unwarped image.

The multiple image corrector then checks if there are any more images in the corrected list. If there are more images the image corrector sets the current warped image to be the next image in the corrected list and repeats the process of conditionally changing the selected images. Thus the image corrector identifies the corrected image that most overlaps the current unwarped image.

The multiple image corrector then checks if there are any more images in the uncorrected list. If there are more images in the uncorrected list the multiple image corrector sets the current unwarped image to be the next image in the uncorrected image and sets the current warped image to be the first image in the list of corrected images. The multiple image corrector repeats the process of changing the selected images to identify a corrected and an uncorrected image that overlap each other more than any other corrected and uncorrected images.

If there are no more images in the uncorrected list the multiple image corrector checks if max overlap area is greater than zero. If max overlap area is not greater than zero no overlapping images were identified and the multiple image corrector terminates the process. Otherwise if max overlap area is greater than zero multiple image corrector corrects the perspective of the selected unwarped image based on its position relative to the selected warped image. The multiple image corrector then moves the selected unwarped image from the list of uncorrected images to the list of corrected images and repeats the process of correcting perspective distortion in the uncorrected image that most overlaps a corrected image. Thus the multiple image corrector corrects the perspective distortions of the images by selecting the uncorrected image that most overlaps a corrected image and correcting its distortion based on its position relative to the corrected image. The process of results in realistic corrections and can be performed without the intervention of a human operator.

A number of embodiments of the invention have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the invention. For example the image to be blended may be obtained form a digital camera storage or a network . The positioning module may determine the relative positions of segments depicted in two images by prompting the user to use the pointing device to click on an object such as the top left corner of the doorway that is depicted in both of the images and determining the relative positions based on the positions that the user clicks on.

The invention can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. Apparatus of the invention can be implemented in a computer program product tangibly embodied in a machine readable storage device for execution by a programmable processor and method steps of the invention can be performed by a programmable processor executing a program of instructions to perform functions of the invention by operating on input data and generating output. The invention can be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. Each computer program can be implemented in a high level procedural or object oriented programming language or in assembly or machine language if desired and in any case the language can be a compiled or interpreted language. Suitable processors include by way of example both general and special purpose microprocessors. Generally a processor will receive instructions and data from a read only memory and or a random access memory. Generally a computer will include one or more mass storage devices for storing data files such devices include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM disks. Any of the foregoing can be supplemented by or incorporated in ASICs application specific integrated circuits .

The invention has been described in terms of particular embodiments. Other embodiments are within the scope of the following claims. For example the steps of the invention can be performed in a different order and still achieve desirable results. Certain steps described in the example above may be omitted in certain instances. For example certain images may be merged without correcting perspective distortion in the images.

