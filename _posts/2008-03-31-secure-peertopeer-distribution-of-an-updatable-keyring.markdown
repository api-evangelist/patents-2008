---

title: Secure peer-to-peer distribution of an updatable keyring
abstract: A distributed peer-to-peer document archive system provides version-control, security, access control, linking among stored documents and remote access to documents usually associated with centralized storage systems while still providing the simplicity, personalization and robustness to network outages associated with personal and peer-to-peer storage systems. A “keyring” is an encrypted repository that allows a user to recover and access a user's entire digital archive with a single master key. After the key is created, it does not need to be updated, and can be stored in a safe, safety-deposit box or other secure location. In the event the user's computer is stolen or destroyed, the user need only install the system on a new machine and import the master key. The system will then use that key to browse nearby servers to find and decrypt all files necessary to recreate the full digital archive in its most recent state.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08885832&OS=08885832&RS=08885832
owner: Ricoh Company, Ltd.
number: 08885832
owner_city: Tokyo
owner_country: JP
publication_date: 20080331
---
This application is a continuation in part application of commonly owned U.S. application Ser. No. 11 731 623 filed Mar. 30 2007 and is fully incorporated herein by reference for all purposes.

The present invention relates generally to document archiving and document distribution and in particular to a distributed secure peer to peer document archival system.

In a typical business workgroup IT infrastructure two basic functions must be provided. The first is to insure that team members are able to access their documents and share them with other members. The second is to insure that no one else can access those documents. The first function typically requires a dedicated file server centralized backups dedicated network static IP address and domain name service the second requires firewalls account and password management and physical security for one s servers. Even when membership of a team is clearly defined and relatively static such an infrastructure is difficult and expensive for a small business to maintain. It is even more difficult when a team is made up of members from several different organizations and who might collaborate in some areas and compete in others.

From a user s perspective the main difference between the centralized and decentralized solution is whether control naturally lies with the publisher or the reader of a document. On the Web the publisher of a site or his designated site administrator has ultimate control and responsibility over who has access to a document who can modify it and whether past versions are made available. The publisher may also decide to take a site down entirely thus denying access to everyone. With email and paper based solutions it is the reader who has control. Anyone who receives a paper document has the ability to share it with someone else simply by making a photocopy and once someone receives a paper document it is very difficult for the original author to take it back. Similarly email is often forwarded to others sometimes with modifications or annotations made by the person doing the forwarding. The decision to grant or deny access to a document is distributed among those who already have access with limitations imposed through social and sometimes legal rules.

Whether publisher or reader control is better depends on the organization the environment in which the information is being produced and used and sometimes on who is doing the judging. Centralized solutions such as password and firewall protected Web servers work well in environments where there are clearly defined groups of people who need access to clearly defined sets of documents and where there is a clear distinction between authors and consumers of information. In more collaborative environments where group boundaries are fuzzier a distributed solution is often better. Most workers today fall somewhere between these two environments engaging in both ongoing and ad hoc collaborations and thus need the advantages of both centralized and decentralized systems.

A personal document archive system according to the present invention provides for secure publication of compound documents to a limited audience. The present invention has been reduced to practice by the inventors and is referred to herein generally as Makyoh. Features include version control secure storage permanent handles for publications and versions URI s and the ability to build compound documents and organize documents into directory trees. It also provides features including robust redundant storage an intuitive paper like publication and access control model and the ability to operate in environments with slow partitioned or no network access.

The present invention introduces the idea of a feed a term borrowed from but otherwise not to be confused with news feeds used on the Web. A feed in accordance with the present invention can represent a mutable document wherein each new feed entry represents a new version of the document. A feed can also represent a publication channel where each feed entry is its own content e.g. blog entries or messages on a message board. Each individual entry in a feed can be accessed through its own unique URI. The present invention provides special URI s for accessing the latest entry in a feed useful for representing version controlled documents and for accessing a merged view of all known entries useful for representing blogs and other aggregations of multiple documents over time .

Entries can be posted to a feed from multiple machines Makyoh servers and if desired by multiple authors. Authoring distribution and reading of documents are all completely decentralized. The ability to publish is garnered by obtaining the publication key for a feed.

To access a particular document or feed a user must possess that document s or feed s key. Each document as represented by a file or set of files is associated with a unique key called a document key. A document key grants the ability to both identify and decrypt the file or set of files that make up a single fixed version of the associated document. Each feed and its entries is associated with two unique keys called a subscription key and a publication key. A subscription key grants the ability to both identify and decrypt the file or set of files that make up entries in the associated feed but does not grant the ability to add new entries to the feed. A publication key grants the ability to both identify and decrypt the file or set of files that make up entries in the associated feed and also grants the ability to add new entries to the feed through a process called publication. A user can grant access to a document or feed to someone else by giving the appropriate key. The receiver will then import the key into his or her personal Makyoh server. In an embodiment of the present invention the key is encrypted using the user s passphrase and stored in a private directory on his or her personal Makyoh server s local disk.

In accordance with an aspect of the present invention the keys are managed as a feed. A keyring feed stores only document keys subscription keys and publication keys. A temporary local cache contains a database that manages all the keys imported during the current session since the Makyoh server was started . The database is deleted when the user s Makyoh server is shut down. The database is re created empty on server start up.

A personal document archive system according to the present invention provides robust secure document storage and sharing without requiring any of the infrastructure required in conventional archiving systems. It is robust without requiring dedicated servers scheduled backup or even a reliable network and it is secure without the need for account password firewalls or secure server rooms. To an end user and his applications the archive appears to be a local disk. Once the user has entered his passphrase to unlock the system his entire archive is available in this manner. In a particular embodiment of the present invention each file and directory is actually stored on disk in its own encrypted file called a blob Binary Large OBject . Each blob has its own unique 128 bit symmetric decryption key. No one can access the contents of an archive without the appropriate key even if they steal the hard drive. Blob decryption keys can be listed in encrypted directory blobs but not in all cases. For example the key for a blob representing a single file document might only exist as a printed 2D barcode representing the document key.

As stated above conventional centralized and decentralized systems typically differ in how control over a document is divided between the publisher and the reader with centralized systems leaving more control in the hands of the publisher and decentralized systems giving the reader more control. In accordance with the present invention control over how resources e.g. files directories and feed entries can be accessed and modified is more evenly balanced between publishers and consumers than is the case in either typical central server systems like the Web or decentralized systems like email. In particular the present invention ensures the following needs are met for readers publishers and re publishers e.g. readers who are also publishers e.g. readers who modify material they have read and then publish the modified material .

While striving to satisfy the needs of publishers compared to Web based publishing systems a system according to the present invention tends to grant more power to readers and re publishers. This is for two reasons First as was stated above there are many environments where giving end readers the ability to re distribute and republish information is far more efficient than central control. Words like sharing and republishing give nightmares to executives in the music and movie industries but this kind of communication is the norm when it comes to internal office communication especially when dealing with paper documents. Second most technology trends are pointing towards more reader control rather than less. Local storage capacity continues to increase and local CPUs continue to get faster while mobile network speeds and the batteries necessary to power them are improving far more slowly. Web pages that might disappear are cached not just by Google but by non profit organizations like The Internet Archive the Memory Hole and even independent bloggers. Content sites that were once published exclusively on the Web are increasingly offering podcasting and RSS feeds that make it easy for readers to download content and read or listen to it from their own local cache. Meanwhile Digital Rights Management DRM systems that are designed to restore power to publishers in the music movie and book industries are finding their schemes cracked soon after release and security experts say the very idea of DRM is fundamentally flawed.

The present invention has been reduced to practice by the inventors and is referred to hereinafter generally as Makyoh. A prototype version of the Makyoh personal server has been implemented on a Java based server. Encryption storage versioning digital signature functions peer to peer distribution and server discovery have all been implemented.

Makyoh provides robust and secure document storage and document sharing without needing any of the conventional infrastructure as described above for example. It is robust without requiring dedicated servers scheduled backup or even a reliable network and it is secure without the need for account passwords firewalls or secure server rooms. In accordance with an embodiment of the present invention to an end user and his applications a Makyoh archive appears to be a local disk actually a locally running WebDAV server what is sometimes called a Web Folder . Once the user has entered his passphrase to unlock the Makyoh system his entire archive is available in this manner i.e. as a local disk . As with all WebDAV servers his archive can also be viewed as a web page using a standard web browser. In a particular embodiment each file and directory is stored in its own encrypted file called a blob for Binary Large OBject on persistent storage media such as a hard drive or removable media e.g. devices popularly referred to as thumbnail drives . Each blob has its own unique 128 bit symmetric decryption key. Consequently no one can access the contents of an archive without the appropriate key even if they steal the storage media. Blob decryption keys can be listed in encrypted directory blobs but not in all cases. For example the key for a blob representing a single file document might only exist as a printed 2D barcode representing the document key.

A personal document archive system also referred to herein as Makyoh in accordance with the present invention is shown in . The system comprises a plurality of personal servers referred to herein variously as personal servers Makyoh personal servers Makyoh servers servers and the like for receiving and storing documents and for serving documents. The figure illustrates as an example four portable personal servers such as laptop computers hand held data devices cell phones etc. It will be apparent that the personal servers can also be traditionally non portable computing devices such as desktop PCs and the like. Communication among the personal servers can be by any suitable wireless technology e.g. Bluetooth IEEE 802.11 and so on or over any suitable wired technology e.g. ethernet serial port connections and so on .

The personal servers collectively provide both secure storage of resources and a secure peer to peer model for publishing resources to a limited audience. Each personal server stores a Makyoh archive comprising of one or more resources where a resource is a file directory feed or feed entry. Each Makyoh archive can be thought of as an encrypted locally cached mirror of both resources that have been created locally and resources that have been created on other Makyoh servers and subsequently published. A Makyoh archive is implemented using a combination of encrypted blobs representing files directories and feed keys a set of decryption keys and feed entry files each of which is associated with a particular feed. Typically every user will have stored on her personal server her own locally stored Makyoh archives Additional details of a Makyoh archive will be given below.

A Makyoh personal server performs three main functions. First the server maintains an encrypted version controlled personal archives Second the server acts as a local mirror of resources that have been published by other Makyoh personal servers . Finally the server distributes these mirrored resources to other Makyoh personal servers with which it comes into contact. In this way every Makyoh personal server functions as a personal archive as a node and router in a peer to peer network and as a mirror for nearby archives. All personal servers are able to participate in routing and mirroring activities but since all resources are encrypted only those who know the decryption key for a given resource are able to read its contents.

Because blobs are always encrypted they can be distributed freely without worrying about revealing sensitive information. In particular whenever a user accesses a resource his local Makyoh server will automatically find all nearby Makyoh servers using an open protocol called Bonjour and distribute all the blobs associated with that document to all other Makyoh servers in the area. This process referred to herein as local superdistribution accomplishes two things First it automatically creates an encrypted backup of the user s documents on all the other machines Makyoh servers in the area. Second it pre caches documents that the user might want to share with other people in the area.

A communication interface represents hardware and software elements for communication with users and other Makyoh servers . For example the communication interface can include one or more connectors to which a display device and an input device e.g. keyboard are connected and related drivers for interacting with the display device and the input device. The communication interface can include connectors e.g. ethernet for wired communication with other Makyoh servers . The communication interface can include a wireless transceiver e.g. Bluetooth or 802.11 compliant hardware for wireless communication with other Makyoh servers .

The data processing component is shown executing an operating system OS . For example in an embodiment of present invention the OS can be the Microsoft Windows operating system the Apple OS X operating system or the Linux operating system. The data processing component is also shown executing two application programming interfaces API one called a trusted user API and the other called a remote user API . These APIs working in conjunction with functionality of the OS provide application level programs with functionality in accordance with the present invention. The APIs are discussed in further detail below.

The APIs provide services for higher level applications . In a particular embodiment of the present invention one such application is a Java based server. The server application includes all the WebDAV WEB based Distributed Authoring and Versioning functionality necessary for mounting a resource or full archive as a disk under the OS e.g. Microsoft Windows operating system Apple OS X operating system Linux operating system etc. . The archive can then be browsed and modified using the operating system s standard file browsing user interface or any other suitable file browsing application.

Every resource in a Makyoh archive explained below can be associated with a unique URI Universal Resource Identifier referred to herein as a hash URI. This special type of URI follows the general URI format commonly used with Web browsers having the following specific form 

hash URI s function as both identifiers and keys and thus can be used to both retrieve encrypted blobs from nearby servers and to decrypt those blobs once they are retrieved. Once retrieved the remaining fields let the server know how the blob contents should be decrypted and presented to the user.

Access control in Makyoh is primarily done using hash URI s. Once someone imports a hash URI often simply called a key into his Makyoh archive he has access to the contents of the file it identifies. Makyoh also uses special kinds of files namely directory blobs and feedkey blobs to grant access to a large and possibly extensible set of files given a single hash URI. In general users will interact with three kinds of hash URI s document keys which give access to a single immutable file or directory tree subscription keys which give the ability to read feed entries for a particular feed and publication keys which give the ability to both read feed entries for a particular feed and publish new entries for that feed.

A hash URI can be used directly as a hyperlink similar to how URLs are embedded in email and web pages. All that would be necessary is to write a browser plug in to access the new URI format and retrieve the necessary blobs from some data store. However this kind of usage is discouraged in Makyoh because it is not very flexible in terms of access if a user has access to a document that contains a hash URI for another document he automatically has access to both. If at a later time the author wanted to allow access to only the first document he would need to edit its contents and remove all mentions of the second hash URI before handing out the hash URI to the first document.

Instead of using a hash URI directly it is preferable to use the archive directory structure that is presented in the trusted user API which is based on the ID of a document or feed. As with hash URI s the path to a particular document or feed entry is the same for all Makyoh users but unlike hash URI s an archive path does not reveal the document s decryption key. Users who already have the key and thus have been given access to the document or feed will be able to access the file or files at the given path while other users will not.

Makyoh provides a personal archive and typically every user will run his own individual personal server . The personal server maintains an encrypted local copy of all the user s entire archive and will also replicate encrypted documents on nearby servers . This distinguishes Makyoh from conventional distributed document stores like FreeNet or OceanStore which assign each file to specific nodes in a distributed network of storage servers. Makyoh presents two separate APIs 

The first API is the trusted user API shown in . As the figure illustrates the Makyoh archive appears via the trusted user API as a virtual file system also referred to as the archive view . It is virtual in that the file system structure that is presented to the trusted user is not necessarily that of the underlying organization of the constituent files of the Makyoh archive as they are stored on the storage device. The virtual view presents abstractions of the underlying physical files that constitute the Makyoh archive. The virtual view can be any suitable file structure view a common paradigm of course is the hierarchical file structure. For purposes of discussion a virtual hierarchical file system will be assumed.

As illustrates the trusted user API presents the Makyoh archive as a file system of folders and documents organized in a directory hierarchy virtual file system archive view . Additional details of this archive view are discussed below. The Makyoh archive can be accessed either using a standard Web browser communicating with the local Makyoh server also referred to as localhost using HTTP or as a part of the local file system sometimes called Web Folders using the WebDAV protocol. The trusted user API is only available from locally generated connections that is connections to localhost and only after the user has authenticated with the Makyoh server using his passphrase.

The second API is the remote user API also shown in . The remote user API presents to other Makyoh servers so called un trusted users the raw files comprising the Makyoh archive e.g. feed entry files encrypted blobs and so on as they are actually stored in the storage component . These raw files are also accessible via HTTP and WebDAV protocols and are used by other Makyoh servers to find and retrieve needed blobs and feed entries and to push blobs and feed entry files onto yet other servers.

From an authenticated user s perspective the virtual file system view of the Makyoh archive comprises two kinds of resources documents and feeds. A document is an immutable file or directory tree while a feed specifies a distribution channel through which one may subscribe to new documents called entries that are published to the feed. Each document and feed is associated with a unique URI Universal Resource Identifier which serves both as an identifier and a decryption key allowing access to the resource. Documents are immutable a URI pointing to a document is guaranteed to always point to the same exact contents. Feeds are mutable in that new entries can be published to a given feed. Each feed entry is identifiable by its own URI and will itself point to an immutable document that represents the contents of the entry. A feed can be used as a publication channel where each feed entry is its own content e.g. blog entries or messages on a message board or it can represent a mutable version controlled document where each new feed entry represents a new version of the document.

A docs directory contains documents which are immutable i.e. do not change. A feeds directory contains feed entries which are mutable by virtue of receiving entries published by the local server or by any of the remote servers . The user can decrypt and view those documents in the docs directory and feed entries in the feeds directory for which he has imported the appropriate document subscription or publication key. A keyring directory contains all keys that the user has ever imported. In an embodiment of the present invention these keys are been encrypted using the user s passphrase as a symmetric key and stored in a private directory on the local server .

Documents are stored under the docs directory in respective subdirectories . Each subdirectory is named by an identifier referred to as the blob Id which is defined as the SHA 1 hash of the encrypted contents of the blob representing the file or root directory for the document written as a lowercase 40 character hexadecimal string. For example where the document is a single file e.g. my document.pdf the name of the subdirectory within which that file is presented is based on the SHA 1 hash of the encrypted contents of the file s corresponding blob. For example suppose the SHA 1 hash of the encrypted contents of the encrypted blob representing my document.pdf is the text string 

If a document consists of a directory of files then the name of the subdirectory is based on the SHA 1 hash of the directory blob corresponding to the directory of files. The directory blob is an invisible file which stores information about the contents of the directory itself e.g. a list of files and or sub directories. For example shows that subdirectory contains a directory of files called my web page. The directory file schematically indicated in by the dash lined box contains information about the directory my web page. The name of the subdirectory is based on the SHA 1 hash of the encrypted contents of its directory file and in an embodiment of the present invention the pathnames might appear as 

Referring to feeds are stored under the feeds directory . Each feed is stored in a feed subdirectory named by the feed s ID which is defined as the fingerprint of the public key used to verify the feed s signature described later . Each feed directory contains a subdirectory for each entry named by the creation time of the entry followed by a period . followed by the SHA 1 hash of the contents of the feed entry file. The creation time should be encoded in Coordinated Universal Time UTC in the form yyyyMMdd T HHmmss Z where hh is the hour in 24 hour format and T and Z are the literal characters T and Z.

Within a feed subdirectory is a file or a directory tree representing the entry. For example a feed with two entries might appear as 

Feeds also contain up to three other directories a scratch directory . . . a latest directory . . . latest and a merged directory . . . merged . If a user has the ability to publish to a given feed the scratch directory will be available in the corresponding subdirectory . This is an editable local only directory that can later be published as a feed entry. The contents of the scratch directory are not available to other Makyoh servers until they are published. If a feed contains at least one published entry then corresponding latest and merged directories will be available. The latest directory always contains a copy of the latest known entry determined by the entry s timestamp. The merged directory contains a merge of all paths contained within all known entries.

For example if a feed contains two entries one containing the path . . . images thing1.jpg and the other containing the path . . . images thing2.jpg a listing of . . . merged images would show both thing1.jpg and thing2.jpg. The directory structure might appear as 

The keyring directory is a directory containing all keys that a user has ever imported. Keys are represented as key files with the extension .makyoh. Key files for document keys contain the hash URI of the file or directory that represents the document associated with the key. As will be explained below there are two kinds of keys for a feed a subscription key and a publication key. Key files for a feed s subscription key contain the hash URI of the subscription feedkey blob. Similarly key files for a feed s publication key contain the hash URI of the publication feedkey blob.

Local users can perform the usual HTTP and WebDAV requests GET PUT HEAD MKCOL PROPFIND LOCK UNLOCK DELETE MOVE COPY and OPTIONS POST is not currently supported . In addition local users i.e. users on the localhost may perform various operations by performing an HTTP GET request to the localhost on the appropriate port with the query parameter op e.g. GET http localhost 8088 op create . The following operations are provided 

Referring to connections to Makyoh server from remote Makyoh servers are presented with a view physical view of the files as they are stored on the storage device of the storage component of the Makyoh server . This is compared to the archive logical or virtual view that is presented a trusted user described in .

In a particular embodiment the remote user is presented with a blobs directory and an entries directory . The blobs directory simply contains encrypted blob files each with the SHA 1 hash of its encrypted file contents as its filename. For example 

The entries directory contains feed entry files each within a subdirectory named with the feed s ID. The entry file itself is named by the creation time of the entry followed by a period . followed by the SHA 1 hash of the contents of the feed entry file. As described above the creation time should be encoded in Coordinated Universal Time UTC in the form yyyyMMdd T HHmmss Z where hh is the hour in 24 hour format and T and Z are the literal characters T and Z. For example 

In accordance with an embodiment of the present invention the files and directories presented in the remote view are the actual files and directory structure as stored on disk. Remote servers can perform a subset of the HTTP and WebDAV type requests e.g. GET PUT HEAD MKCOL PROPFIND LOCK UNLOCK and OPTIONS. Other requests e.g. POST DELETE MOVE or COPY will return with a Bad Request error.

Referring now to blob files are immutable and represent just a single version of a file as it existed at a particular time. In each blob file is illustrated by a document icon and a lock icon. The document icon associated with a blob file represents the contents of the file which the associated lock icon indicates that the contents are encrypted. The encrypted contents of the blob files are decrypted using their respective symmetric decryption keys . Each decryption key is illustrated in with an arrow leading to the encrypted blob file for which it is serves as the decryption key.

As stated above a blob file is immutable i.e. a given instance of a blob file cannot be modified. A user can nonetheless make modifications for example by reading in the file making desired edits to the file and then writing out the modified contents of the file into an entirely new blob file along with its own unique ID and decryption key . A blob file along with its ID and key are automatically computed based on the contents of the file being encrypted. The file is first prepended with a null terminated header consisting of the blob s type currently blob directory or feedkey the document s length in bytes and an optional salt string all separated by spaces. This plaintext is then compressed using a known algorithm called the DEFLATE algorithm and encrypted with the known Advanced Encryption System algorithm using the MD5 hash of the plaintext as the encryption key. The ID for the resulting blob is the SHA 1 hash of the encrypted blob s contents encoded as a 40 hex digit lowercase string. More formally 

The header serves two purposes. First it guarantees that even zero length documents can generate an MD5 hash. Second it includes an optional salt which can be used to generate a blob file with a different ID than would be obtained if no salt was used. This can be less efficient in terms of storage but provides additional privacy against some kinds of attacks.

One advantage of using hashes for a blob s key and ID is that the process is entirely determined by document contents multiple copies of the same exact document will produce the same blob file and blob Id even if the documents were independently published by different people. This reduces the amount of storage an archive uses especially in cases where the same file appears in several different documents directory trees. The only exception is when a publisher adds the optional salt to their headers which by design creates a different blob and blob Id based on the salt.

A directory blob is simply a list of hash URI s pointing to the files and subdirectories the directory contains encoded and encrypted in blob format as described above. Directory blobs have the type directory. For example the decrypted contents of a directory blob containing two files and a subdirectory might consist of the following 

When a directory is retrieved in the trusted user API the corresponding directory blob is decrypted and the ID key MIME type and name of its contents are cached in a temporary database. This database is then used to present the directory structure and files of the user s archive. The use of a caching database improves performance but is not necessary and other embodiments of the present invention can easily be implemented without a database.

A feed key blob is a file containing keys necessary for decrypting verifying and optionally for creating publishing feed entries. Feed keys come in two forms subscription keys which give read only access to a feed and publication keys which grant both the ability to read entries and to publish new entries. The feed key file consists of the following fields each separated by a linefeed n . The entire contents are then encrypted and encoded as a blob as described above.

A feed s ID is defined as the 160 bit key fingerprint of the feed s verify key in accordance with the OpenPGP Format standard encoded as a 40 character lowercase hexadecimal string.

A feed entry file is a file that contains information about an entry to a feed. The feed entry file comprises the following fields each separated by a linefeed n . These contents are not encoded as an encrypted blob though the Entry field shown in is encoded in encrypted form as described below .

The keyring is a collection of keys i.e. hash URI s the user has imported. In one instantiation of the invention the keyring is implemented as a private directory stored on the local Makyoh server . Referring to when a user logs into a Makyoh server for the very first time a personal keyring directory is automatically created. When a key is imported it is encrypted using the user s passphrase as the symmetric key and the resulting encrypted file is then stored in the keyring directory . When the user logs in using his passphrase Makyoh bootstraps by decrypting all key files in the user s keyring directory. The process of importing keys hash URI s is explained further below.

A typical usage scenario of the present invention will now be described. As an example imagine a user Alan is attending business negotiations with a competitor and the user s documents are stored in his personal Makyoh archive running on his laptop. When Alan accesses an outline of the negotiation strategy on his laptop the encrypted blob s for that outline will be replicated by his laptop on all other laptops running Makyoh in the area. If the key for that document is never revealed then Alan has effectively securely backed up a copy of his document on the laptops of everyone else in the meeting. Conversely Alan s Makyoh server is likewise backing up documents of other laptops when documents on those laptops are accessed. If Alan s laptop is later stolen he can recover his document s by purchasing a new laptop and installing Makyoh and re importing his key s . Makyoh would then automatically retrieve all the necessary blobs from the other laptops in the area. In a particular embodiment of the present invention the key is the hash URI described above. Users carry hash URI s one for each document or directory of documents or feed entries and pass them around to other users to give them access to the information. The hash URI is a small amount of data on the order of a hundred or so bytes that can be conveniently stored in a key file on a storage device e.g. thumbdrive on a printable medium e.g. linear barcode two dimensional barcode etc and so on.

Now imagine that later in the meeting a colleague Bob asks for a copy of Alan s strategy outline. The file may be very large especially if it contains multimedia content and would likely take several minutes to transfer over wireless or even USB thumbdrive. However because Alan s Makyoh had previously distributed the encrypted blobs that make up the document to the other laptops including Bob s the data is already on Bob s laptop. Alan need only give Bob the associated key file hash URI stored in a file used to decrypt the file which will typically be less than a couple hundred bytes. Because keys are so small they can be transmitted quickly and securely in a variety of ways that are not possible with larger files. For example they can be printed on business cards as 2 dimensional barcodes beamed to a PDA via infrared transmitted by human touch using a technology such as NTT s RedTacton or through more traditional means such as Bluetooth or even instant messaging. Within a few seconds the colleague can access the document even if the original transmission of the blobs already completed at this point had taken several minutes.

The foregoing usage description illustrates various operations of the present invention which will now be discussed in more detail in connection with the process descriptions in the figures to follow. The processing can be performed by a suitable data processing component of the Makyoh server such as shown in . The processing described in figures to follow can be embodied in suitable computer program code that is executed by the data processing component .

When a document is accessed from an archive the blobs IDs associated with it are automatically added to a list of files to be pushed to other servers the Put Blob Queue and any blobs required by the document that are not found are added to a list of files to get from other servers the Get Blob Queue . Similarly when a feed entry is accessed the corresponding feed entry file is added to a list of feed entries to push to other servers the Put Feed Entry Queue and its feed Id is added to a list of feeds to check for new entries on other servers the Get Feed Queue . Requests added to the Get Blob Queue Put Blob Queue the Get Feed Queue and the Put Feed Entry Queue expire after a certain amount of time by default one hour after which they are removed from the respective queue. Typically these queues are implemented as data structures in the memory of the Makyoh server. However it will become apparent from the discussion below that other mechanisms are possible.

Refer to for a description of the general flow for accessing a document in accordance with an embodiment of the present invention. The requester i.e. a trusted user will specify to a Makyoh server the local server the pathname of the document to be accessed. In the trusted API a user specifies a full pathname for the file or directory to retrieve for example 

Recall in an embodiment of the invention that the trusted user s view of the Makyoh archive is that of a virtual file system . The pathname provided by the user is in the context of that virtual file system. In the embodiment of the virtual file system described herein the file system is hierarchical such as in the Unix operating system and hence a the pathname appears as a Unix pathname.

In a particular embodiment of the present invention the pathname leads to the encrypted blob file from which a cleartext representation of the requested document will be obtained. When the encrypted blob is obtained a key the hash URI is used to decrypt the content of the obtained blob. The discussion that follows will describe the processing that takes place in the local Makyoh server.

In a step the blob Id of the requested document is determined based on the pathname specified by the requestor. In a particular embodiment of the present invention the blob Id is the name of the subdirectory in the pathname. Using the example above suppose the pathname given by the requestor is 

In a step a determination is made whether the blob Id is already in the keyring. In the particular embodiment described above the keyring directory contains key files each of which contains the hash URI of the file or document that represents the document associated with the key. Recall that the hash URI includes the blob Id. A search is performed of the hash URI s in the key files for the blob Id determined from step thus identifying the key file associated with the requested document. If it is determined in step that the blob Id is not found then the requested document is deemed not found and a suitable response is sent in a step to the requester indicating that the requested document was not found.

If it is determined in step that the blob Id is found in one of the key files then a determination is made in a step whether a local copy of the requested blob file is stored in the docs directory of the requestor s local Makyoh server. If not then in a step a pull request is queued on a Get Blob Queue by placing the blob Id in the queue in order to attempt to obtain the requested document from another remote Makyoh server. In a step the Get Blob Queue is serviced as will be discussed in more detail below. The blob Ids in the Get Blob Queue can be serviced with each document access or after some predetermined number of document accesses have occurred or after a predetermined period of time has elapsed or based other suitable criteria or based on some combination of the foregoing. In an embodiment of the present invention requests added to the Get Blob Queue expire after a certain amount of time e.g. one hour after which they are removed from the queue.

If in a step it is determined that the blob was successfully retrieved from a remote Makyoh server and stored in the storage component of the local server then processing proceeds to step discussed below. If it is determined in step that the blob was not successfully retrieved e.g. no other Makyoh servers contain the blob then a suitable response is sent in step to the requester indicating that the requested document was not found.

If a local copy of the requested blob was found step or a copy of the requested blob file was retrieved from a remote Makyoh server step then a push blob service is performed step . The push blob service described in distributes or pushes the received blob to other Makyoh servers e.g. . Then in a step the blob key contained in the hash URI stored in the key file associated with the requested document is obtained and used to decrypt the encrypted blob file. The resulting clear text constitutes the requested document.

Processing of contents is then handed over to the application performing the access. A determination is made in a step whether the requested document is in fact a directory or an actual document e.g. a PDF file . If the application is a browser or the OS s windowing system then it can present the file step or directory step to the user. In the case of a directory the user might select one of the documents in the directory and initiate an access thus repeating the foregoing to obtain the selected document. Another application might take an action that does not display anything to the user e.g. it might read its configuration information from the accessed file.

Referring back to for a moment recall that in an alternative embodiment of the present the Makyoh server can be embodied in a document processing device such as a printer or a fax machine and so on. In one context of a user can make a request on his personal server such as a laptop or PDA to access a document. In another context the user can make a similar request on a printer device or fax machine to access the document to be printed or faxed . The device can be configured as a Makyoh server and access the documents in accordance with including obtaining the document s from another Makyoh server if necessary and distributing the document s to other Makyoh servers in addition to printing or faxing the obtained document s .

Referring to the general flow for accessing a feed entry is similar to the flow for accessing a document. As described above the user would specify a pathname in terms of the archive view presented to a trusted user. In the case of a feed however the path for a particular feed entry might look like 

In a step the feed Id of the requested feed is determined based on the pathname specified by the requester at the local Makyoh server. In a particular embodiment of the present invention the feed Id is the name of the subdirectory in the pathname.

In a step a determination is made whether a feedkey associated with the feed Id is known. In an embodiment this can be accomplished by maintaining an associative list called the Feedkey List and searching it. The Feedkey List allows the lookup of feedkey files for a particular feed Id. When the user first logs in with his or her passphrase the Feedkey List is initialized to contain all feedkeys for which a subscription key or a publication key exists in the user s keyring and for which the associated blob is stored in the user s local repository. The process by which this initialization is discussed in more detail below. A search is performed in the Feedkey List for the feedkey associated with the feed Id determined from step thus identifying the feedkey file associated with the requested feed. If the feed Id and associated feedkey is not found then a suitable response is sent in a step to the requester indicating that the requested feed was not found.

If the feed Id is found in the Feedkey List then a determination is made in a step whether a local copy of an entry file for requested feed is stored in the entries directory of the requestor s Makyoh server . If the feed Id is not found in the Feedkey List then in a step a pull request is queued on a Get Feed Queue by placing the feed Id in the queue in an attempt to obtain the entry file for the requested feed from another remote Makyoh server. In a step the Get Feed Queue is serviced as will be discussed in more detail below. The feed Ids in the Get Feed Queue can be serviced with each feed access or after some predetermined number of feed accesses have occurred or after a predetermined period of time has elapsed or based other suitable criteria or based on some combination of the foregoing. In an embodiment of the present invention requests added to the Get Feed Queue expire after a certain amount of time e.g. one hour after which they are removed from the queue.

If in a step it is determined that the entry file was successfully retrieved from a remote server and stored in the local storage component then processing proceeds to step discussed below. If it is determined in step that the entry file was not successfully retrieved e.g. no other Makyoh servers contain the entry file then a suitable response is sent in step to the requester indicating that the requested document was not found.

If a local copy of the entry file for the requested feed was found step or a copy of the entry file was retrieved from another Makyoh server step then in a step the Entry field is decrypted using the feedkey file retrieved from Feedkey List associated with the requested feed to obtain the hash URI for the file or root directory associated with the requested feed entry. In a step this hash URI is imported into the keyring to be detailed below. In a step the document path associated with the hash URI is calculated by concatenating the string docs the Blob ID specified in the hash URI the string and the filename specified in the hash URI. For example suppose the hash URI is 

In a step the feed entry is retrieved in the same manner as a document is retrieved in accordance with described above including communicating the feed entry to the requester via suitable software for example to permit viewing and or editing the document.

Every Makyoh server maintains set of servers with which it should share blobs and feed entries called that server s neighborhood. Generally speaking a neighborhood is limited to those servers running Makyoh that can be considered nearby. For example in one embodiment of the invention the neighborhood of a given Makyoh server also referred to as the local server is defined as those other Makyoh servers also referred to as remote servers that are communicating on the same local subnet as the local server. Note that nearby may or may not imply physical proximity. For example while most servers on a local subnet will likely to be physically near each other some may be physically remote for example if they are connected through a VPN Virtual Private Network . What is important is that distribution is limited to machines that have a higher than average probability of either eventually being able to decrypt the blobs being transmitted or of themselves redistributing the blobs to a machine that can decrypt them. In this example users on the same subnet are probably part of the same organization and are therefore likely to share documents with one another.

Other embodiments might use other criteria for what constitutes a neighborhood. For example a neighborhood might include both a user s work machine and home machine. As another example the Makyoh servers of people who regularly communicate via email instant messaging or phone might be considered neighbors even though they are physically thousands of miles apart and communicate on different subnets. These servers might be in each other s neighborhood only while communication is in progress e.g. when the users are communicating over the phone to each other or might continue to be in each other s neighborhood for some time after communication has ceased.

In an embodiment a local Makyoh server is notified whenever a machine running Makyoh joins or leaves the local subnet using an open protocol called Bonjour generically known as Multicast DNS DNS Service Discovery . Whenever the local Makyoh server is notified of a new server it automatically determines whether the newly joining server has the blobs and entry files on the Get and Put Blob Queues using HTTP Head and HTTP PROPFIND requests and then performs the appropriate push or pull of the files as necessary using HTTP GET and HTTP PUT requests. A similar set of actions is taken for all known servers in the local server s neighborhood whenever a new request is added. The files held on each remote server are cached so requests need not be made more than once per session.

In another embodiment of the invention a local Makyoh server s neighborhood is defined as the set of servers running Makyoh within a particular organization as determined by using DNS resource discovery to query that organization s Domain Name Service server for all Makyoh servers running in the organization. In this embodiment new servers join the neighborhood by using the open DNS UPDATE protocol. In another embodiment the neighborhood of a local Makyoh server is explicitly set e.g. through the use of configuration files.

In another embodiment the neighborhood of a local Makyoh server is defined as the set of other servers running Makyoh with which direct wireless communication can be established that is those within wireless range . In this embodiment new servers join the neighborhood by broadcasting their existence over the wireless channels to any other Makyoh servers within range.

In another embodiment the neighborhood of a local Makyoh server is defined as the set of machines running Makyoh with which other recent network traffic has recently been communicated. For example if a user initiated an instant message IM chat with another user each of their personal Makyoh servers would join the other s neighborhood. Their personal Makyoh servers would also join each other s neighborhoods when one user sent email to the other when one user called the other on the telephone etc.

In another embodiment a remote Makyoh server is automatically added to a local server s neighborhood if the remote Makyoh server attempts to initiate a GET or PUT on the local Makyoh server. This embodiment insures that servers using different criteria for a neighborhood will still reciprocate joining each other s neighborhood. Of course one might also combine different definitions of neighborhood for example by including both servers on the local subnet and servers within wireless range or use multiple definitions for neighborhood and one can imagine still other definitions of neighborhood.

A session refers to the time from when the local server detects a remote server e.g. is announced by Bonjour to the time when the remote server quits its application or otherwise leaves the neighborhood. When a remote server leaves the neighborhood it has effectively quit or logged out . All record of the files it held is discarded. This is done in part because typically there is no direct way to tell whether a new server that is being announced is one that had been previously known to the local server. Servers typically do not have unique IDs and server IP addresses may change for example in the case of DHCP dynamic host configuration protocol .

Returning to the usage scenario above recall that Alan s laptop had replicated his encrypted strategy outline onto Bob s laptop. If a new user Carl had joined the group subsequent to replication of the encrypted strategy outline by Alan s Makyoh server then Carl will not have a copy. However when Alan later gives Bob his key hash URI for example by scanning a barcode then Bob will import Alan s key and by so doing Carl will receive a copy of the encrypted strategy outline by operation of the processing described in . Carl would then need only obtain the key from Alan or even Bob.

Now suppose that Dan enters the group. He does not have a copy of Alan s encrypted strategy outline. Suppose further that no one has imported Alan s key within the last hour assuming blob Ids are removed from the queue after one hour stale ids are discussed below since Dan s joining the group. As will be explained below stale ids are removed from the queues. What this means for Dan is that when he joins Alan s server will not send a copy of the outline because the id in Alan s Put Blob Queue will have been deleted. Nonetheless Dan can still obtain a copy of Alan s outline simply by importing Alan s key after logging in and per the processing of a copy of the outline will be replicated on Dan s Makyoh server.

If it is determined in step that the candidate server does contain the blob Id then in a step a GET request is performed on that server to obtain the corresponding blob the new blob . The new blob is serviced in a step additional details of which will be discussed below. A determination is made in a step whether the new blob was rejected or not. If the new blob was rejected then in a step that candidate server is marked as not having the blob so that in step the NO branch will be taken for this server. If the new blob is not rejected then processing continues with the next blob Id in the Get Blob Queue steps .

If there is a match then in a step the blob is stored in subdirectory with the blob Id as the blob s filename in the storage of the local server. In a step any requests for blob Id are removed from the Get Blob Queue. In a step a push blob service is performed as described in below. As will become apparent in this context the push blob service will serve to distribute push the received blob to other Makyoh servers e.g. . Thus in the embodiment where a device such as a printer or fax is configured as a Makyoh server if the documents had to be obtained from another server the documents will be distributed to other Makyoh servers by operation of servicing the Get Blob Queue.

If it is determined in step that the target server does not contain the blob Id then in a step a PUT request is performed on that server to send the corresponding blob to that server. Processing then continues with the next target server in the REMOTE list steps . When every server is processed then processing continues with the next blob Id in the Put Blob Queue steps .

If in step it is determined that the target server contains the feed Id or that the determination cannot be made then in a step a PROPFIND request is performed on the candidate server to obtain a directory listing of that candidate server s feed Id directory . Steps and are iterated for each feed entry file see also in that is listed in the candidate server s directory . Thus in a step a determination is made whether a candidate feed entry file in the list is already stored locally. If so then the next feed entry file in the list is processed steps .

If the local Makyoh server does not already have a copy of the candidate feed entry file then in a step a GET request is performed on the candidate server to obtain a new feed entry file for the local server. The new feed file is processed in a step which will be discussed shortly. Processing then continues with the next feed Id in the Get Feed Queue steps .

A validated feed entry is stored in step in the storage of the local server. If the feed key is for a feed Id in the Feedkey list step then the entry key is obtained from the feed key file in a step . In a step the entry field of the Feed Entry is decrypted using the entry key to obtain its hash URI which is then imported in a step in the manner shown in .

Referring to in a step request to push the blob to other servers is queued by adding blob Id to the Put Blob Queue. A determination is made in a step whether a hash URI corresponding to the blob Id is in the local server s keyring. In one embodiment of the invention this determination is accomplished by searching each key file and comparing the blob Id part of the enclosed hash URI to the blob Id being pushed. In another embodiment the keyring is stored in a temporary database which allows fast lookup of hash URI s based on their blob Id component. If an appropriate hash URI is not found in step then in a step the Put Blob Queue is serviced in accordance with processing shown in and the processing is complete.

Returning to step if an appropriate hash URI is found then in a step the blob contents are decrypted using the key specified in the hash URI. A determination is made in a step whether the blob is a feedkey. This determination is made by examining the blob type as specified in the blob s header.

If the blob is of type feedkey then in a step the feed Id of the feed corresponding to that feedkey is obtained by calculating the fingerprint of the feedkey s verify key e.g. by using the known method specified in the OpenPGP standard. The feedkey is then associated with the calculated feed Id in the Feedkey List in a step . Then in a step a request to retrieve any new feed entries from other servers is queued by adding the feed Id to the Get Feed Queue. The Get Feed Queue is then serviced in a step in accordance with processing shown in . Then in a loop represented by steps and a number of locally stored feed entries associated with feed Id are determined by listing the directory associated with feed Id. The number of locally stored feed entries so listed is determined by a configuration parameter and may include all none or some number of such entries. If the number so listed is less than the number of entries locally stored for the feed Id then the most recent entries are listed as based on the timestamp in the feed entry s filename . The feed entries determined in steps and are then queued to be pushed to other servers in a step by adding each feed entry s path to the Put Feed Entry Queue. Once all listed entries are added the Put Feed Entry Queue is serviced in a step in accordance with . The Put Blob Queue is then serviced in a step in accordance with and the processing is complete.

Returning to step if the blob is not of type feedkey then another determination is made in step whether the blob is a directory by examining the blob type as specified in the blob s header. If the received blob is not a directory e.g. if it is a normal content file of type blob then the Put Blob Queue is serviced in a step per and the processing is complete. Returning to step if the blob is of type directory then a loop is performed over each hash URI listed in the directory blob steps and in which each hash URI is imported in a step in accordance with . Once the loop over the directory s listed hash URI s is complete the Put Blob Queue is then serviced in a step per and the processing is complete.

Login processing includes steps which define a loop that is performed on a local directory of encrypted key files stored on the physical local disk of the server. This directory is in a private local configuration directory it is not distributed over either the trusted API or the remote API. Each file contains one key in the keyring encrypted using the user s passphrase. Recall that the directories in are virtual and thus only shown to the trusted local user. The virtual key files are presented as plaintext and are intended as an easy way for him to access his keys so he can give them to someone else. The keyring directory is also only available after the user logs in and thus can t be looped during login.

For each of the user s key files the key file is decrypted in a step using the user s passphrase in order to access its contents namely the hash URI. In a step the blob Id is obtained from the hash URI. If in a step it is determined that the blob associated with the obtained blob Id is not locally stored i.e. stored in the user s server then the next key file in the user s keyring is processed steps . The determination uses the type field in the header part of the decrypted blob discussed above in the Blob file format section.

If in step it is determined that the blob associated with the obtained blob Id is locally stored then the blob is decrypted in a step using the decryption key obtained from the hash URI to obtain cleartext content. If in a step it is determined from the cleartext content that the blob is a file then the next key file in the user s keyring is processed steps .

If in step it is determined from the cleartext content that the blob is a feedkey then the feed Id is obtained in a step from the signature of the verify key. The feed Id and the blob are then added to the Feedkey List in a step . Processing then continues with the next key file in the user s keyring steps .

New files and directories are created in Makyoh in a scratch directory using standard WebDAV methods in particular PUT COPY DELETE MOVE and RENAME . These files and directories are only accessible locally and are not distributed to other Makyoh servers. To make the contents of scratch directories available to other servers they must first be published by executing an HTTP GET request for the path to be published with the query parameter op createdoc. The Makyoh server will then ensure that blob files associated with each file and directory being published are made available to remote servers in subdirectory import the associated hash URI s into the local keyring and push associated blobs out to known remote servers.

Referring to when a file is published in a step blob header consisting of the file s length the file s type blob or feedkey and an optional salt is prepended to the file and a blob key is determined in a step by computing the MD5 hash of the resulting prepended file. The prepended file is then encrypted in a step using the blob key as a symmetric key for example using the known Advanced Encryption Standard AES 128 to produce the blob blob file . The blob Id is then calculated in a step by computing the SHA 1 hash of the resulting encrypted blob file. Then in a step the blob is stored in subdirectory using the calculated blob Id as its filename. The hash URI is then generated for the blob in a step by concatenating the following components hash id the blob Id aes128 key the blob key content type the MIME type of the file being published name and the filename of the file. This hash URI is then imported into the keyring in a step per processing described in . As discussed above this service will cause the newly added file to be distributed.

In the context of a user s laptop or PDA or similar device the user creates the document or otherwise receives a new document. If the user desires to add it to his Makyoh archive then he can invoke the process described in . In the context of a document handling device such as a printer or a fax or a scanner a user or another machine can send a document to the device to be printed or faxed or the user may place thd document on the scanner to be scanned. If the device is also configured as a Makyoh server the received document can be viewed as a new document and trigger the process of to incorporate the received document in the device s Makyoh archive and also distribute the received document to other Makyoh servers.

The device would receive unencrypted image or file data. The device would then publish the document store the encrypted blobs locally and give the user a key to decrypt the document e.g. in the form of a 2D barcode . In an embodiment of the present invention the device would not store the key locally or indeed have a keyring at all that way the data remains completely secure.

Referring to when a directory is published a blank directory file is created in step . Then each child that is each file or subdirectory is processed in a loop steps and in which first a determination is made in step whether the child is a directory. If the child is not a directory i.e. if it is a file then in step child is published by the method described above and in . The resulting hash URI is then added in step to the directory file created earlier. If in step the child is determined to be a directory then the child is published in step by recursively applying the method described here after which the resulting hash URI is added in step to the directory file created earlier. Once all files and subdirectories in the published directory are processed the loop completes step and the directory file created earlier is published in a step by the method described above and in .

A feed must be created before any entries can be published to it. Feed creation is accomplished in one embodiment of the invention by executing an HTTP GET request with the query parameter op create which will generate feedkeys for the new feed and then publish those feedkeys. Referring to a new publication feedkey is generated in step by generating an asymmetric key pair for example using the known OpenPGP standard for the write key and verify key fields of the key and a random symmetric key is generated for the feedkey s Entry Key field. The file is then published in step using the method described above and in . The subscription feedkey that corresponds to the created publication feedkey is then computed in step by removing the verify key field from the publication feedkey. This subscription key is then published in step and the creation process is complete.

New feed entries are created and published for a feed by executing an HTTP GET request for the path corresponding to the scratch directory containing the entry to be published with the query parameter op publish. The Makyoh server will then ensure that the entry feed entry file is made available to remote servers in subdirectory ensure that blob files representing all files and directories that make up the contents of the entry are made available to remote servers in subdirectory import the associated hash URI s into the local keyring and push the entry file and associated blobs out to known remote servers.

Referring to first a determination is made in step whether a publication feedkey associated with the feed Id to be published can be found in the Feedkey List. If not then an error is reported in step and processing is complete. If a publication feedkey is found then another determination is made in step for whether the root of the entry that is the entry s main contents is a directory. If not i.e. if the entry consists of just a single file then the entry s root file is published in a step . The feed entry file is then created in a step using the entry key specified in the publication feedkey to encrypt the hash URI of the newly published entry root using the write key specified by the publication feedkey to sign the contents of the feed entry. The feed entry file is then stored in a step in the feed s subdirectory . A request to push the feed entry is added to the Put Feed Entry Queue in step that queue is serviced in step per this serves to distribute the received feed entry to other Makyoh servers and processing is complete.

Returning to step if the entry root is a directory then the directory is published in step using the method described above and in . The process then continues through steps as described above.

The foregoing disclosure of the present invention embodied in a system referred to generally as Makyoh provides a distributed digital archive system and method for document storage and retrieval. As discussed above one of Makyoh s unique and novel features is the ability to securely share documents with others on a document by document basis. It also supports feeds which are secure distribution channels to which one can publish multiple documents to a limited audience thus enabling the creation of secure documents such as blogs wikis version controlled documents and so on. This is accomplished by encrypting each document or directory of documents or feed using its own unique key to create a blob. Because these unique keys are very small relative to the size of a full document they are much easier to maintain store and distribute.

As discussed above these encrypted document files directories and feed files hereinafter referred to generally as a blob are distributed among reachable Makyoh devices by a process referred to as local superdistribution. As explained above reachable refers to other devices executing a Makyoh server that are in data communication with respect to a given Makyoh server. Superdistribution facilitates two goals 1 backing up the files and 2 decrease download time by mirroring copies to other nearby machines who might want to access those files. Because blobs are encrypted only those who have the unique key referred to above as the hash URI for a given blob can access its contents i.e. document directory or feed . Typically every user s personal Makyoh server will store all the blobs necessary to recreate his own archive. The user will also use part of his storage capacity to locally mirror blobs he cannot currently decrypt. In return other servers on the network will similarly be mirroring blobs that they cannot decrypt thus ensuring redundant storage. One could also specifically distribute encrypted blobs to an online storage service such as Amazon s S3 online storage service or to a dedicated Makyoh server installed for that purpose.

A key in accordance with the present invention serves to both locate and decrypt the blob s associated with that key for example if the key is associated with a document then it identifies only one blob to produce document content. Sharing a document is as simple as giving the document s key to another Makyoh user. When the recipient imports the received key into his personal Makyoh server Makyoh will automatically identify the appropriate blob s either on other user s server or on other servers in the area. For blobs located on other servers they will be downloaded and decrypted so the content can be accessed. The recipient may also copy his key and redistribute it to his own colleagues just as he might photocopy and redistribute a paper document.

Much of Makyoh s flexibility in secured document sharing comes from the fact that each document directory or feed has a unique key hash URI hereinafter key and hash URI will be used interchangeably . These keys are stored on a keyring. In the particular embodiment of the present invention described above the keyring comprises a locally stored list of all imported key s as illustrated in . In the foregoing disclosed embodiment the keyring is implemented as a subdirectory that serves two purposes 1 it is a place for a user to store keys that he would receive from other users and 2 it serves as a local cache for fast retrieval of known hash URI s. In other words when Makyoh receives a key it will compare the received key against those already stored in subdirectory to see if the key and its corresponding blob are already stored on the device.

While the directory approach for implementing the keyring such as illustrated in can be a suitable implementation in a small community of documents shared among a small number of Makyoh users performance limitations and practical issues can arise in a larger setting. In a larger user environment a user is likely to collect keys to a large number of documents feeds in the course of his work. These keys can be self generated as would be the case for newly created documents or they can be generated by other users and given to the user so he can access their documents. The user can also use multiple personal Makyoh servers for example one on his desktop computer and one on his laptop. The collection of keys can become quite large including keys for documents collected and shared among colleagues over the years and keys for personal documents which likely have not been shared and for which may very well be the only copies in existence.

An alternate keyring management structure in accordance with another embodiment of the present invention will now be described. A keyring management structure shown in can be used to facilitate users who handle large numbers of documents. In accordance with an instantiation of this embodiment of the present invention the keyring management system provides a user with access to all keys seen by that user regardless of the machine he is currently using and with a way to recover all keys seen by the user in case of computer theft or catastrophic failure. Because keys give access to confidential data they would also need to be stored so as not to be readable by others including those who might have physical access to backups or to other servers on the network.

In accordance with this particular embodiment of the present invention the underlying Makyoh mechanisms disclosed above for secured sharing of documents directories and feeds are utilized to provide secured management and distribution of a user s keys among other Makyoh users. In a particular instantiation of this embodiment of the present invention the keyring is implemented as a Makyoh feed rather than as the local directory shown in the embodiment of . In the directory embodiment of the keyring depicted in the key files are plaintext files each containing a single hash URI that represents a key in the keyring.

An embodiment of this keyring feed is logically represented in . The keyring feed is a feed for receiving and storing hash URI s the keys . The hash URI s are the keys that one user would give to one or more other users to grant access to a blob. A hash URI includes information as to the identity of the document or feed and a cryptographic key for decrypting the blob. As with any feed described above the keyring feed includes a feed blob e.g. referred to as the keyring feed key blob . Referring to it can be seen that the keyring feed key blob is an instantiation of a publication feed key blob see explanation in the section entitled Feed Key Blob . The plaintext file referred to simply as the keyring feed key is shown in in its encrypted form indicated by the lock icon and hence is identified as the keyring feed key blob . It will be understood from the context of the discussion whether refers to the encrypted blob form or the plaintext form.

Each hash URI managed by the keyring feed is contained in a feed entry referred to as the keyring feed entry . The physical storage for the data file s that comprise a keyring feed are stored on a suitable storage medium of the Makyoh device such as a hard disk or flash memory where the data persists even if the device is powered off.

The keyring feed is accessed by a master key . More specifically the master key is the hash URI of the keyring feed key blob . As with any hash URI in accordance with the present invention the master key comprises a component that identifies the keyring feed key blob and includes a component that is used to decrypt the keyring feed key blob. Each key hash URI in the keyring feed is contained in a keyring feed entry . More specifically the hash URI is contained in the entry field in encrypted form. The keyring feed key includes an entry key field which contains a cryptographic key that is used to decrypt the entry field and hence obtain a plaintext copy of the hash URI. The decrypted hash URI is then used to identify its corresponding blob and to decrypt that blob to obtain the desired content be it a document a directory or a feed including another keyring feed .

Referring now to a discussion of how the keyring is initially created will be given. Keyring initialization is performed for example when the user logs into a particular Makyoh server for the very first time and has never produced or otherwise collected any keys. The flow chart shown in illustrates the steps for creating a keyring feed in accordance with this particular embodiment of the present invention.

When the user accesses the particular Makyoh server for the first time the user will be prompted step for a passphrase in addition to other information that may be needed when logging in for the first time. The Makyoh server will generate a keyring feed that will be used to manage the keyring. Step creates the keyring feed key blob component of the keyring feed. The keyring feed key blob is a file containing a write key a verify key and an entry key . The write key verify key and entry key are cryptographic keys as described above in the Feed Key Blob section. In the particular context of the keyring feed the entry key is used to encrypt and decrypt received hash URIs and hence is a symmetric cryptographic key and in this particular embodiment is a randomly generated key. A received hash URI can be a user created hash URI or a hash URI received from another Makyoh user.

In step the master key for the keyring feed is created. The master key is a hash URI computed from the keyring feed key blob . Recall from the discussion above in the section entitled Keys and Hash URI s a hash URI comprises among other elements a SHA 1 hash called the id or the blob Id . The id component of the hash URI that constitutes the master key is obtained by computing the SHA 1 hash of the encrypted contents of the keyring feed key blob . The decryption key component of the master key is based on the MD5 hash of the plaintext file contents of the keyring feed key blob .

In accordance with this embodiment of the present invention the master key in turn is encrypted step using the passphrase obtained from the user in step to produce an encrypted master key . The encrypted master key is then stored to a special configuration file on the local disk step the idea being to protect the master key since it will unlock the entire keyring feed. Completing the discussion of the master key is then added as the first key in the newly created keyring feed. The discussion will continue with for a description of a process in accordance with this embodiment of the present invention by which a hash URI such as the master key is added to the keyring feed.

During the course of using Makyoh the user will create documents directories and or feeds and the user will import other users documents directories and or feeds. Whenever a new document directory or feed is created the Makyoh server will generate a blob create a corresponding hash URI as its key to access the blob and add the newly created key to the keyring as a keyring feed entry in the keyring feed. Likewise other users keys can be added to the user s keyring via a suitable web API to invoke the procedure illustrated in .

In a step a procedure shown in is invoked for the given hash URI. For the case where the given hash URI accesses a document blob the invocation simply results in superdistribution of the document blob. If the given hash URI identifies a feed blob then the procedure of will obtain the hash URI s of all the blobs subordinate to that feed in addition to superdistribution of the feed blob. For example if the user imports a hash URI for another user s feed then all the keys hash URI s for the blobs in that other user s feed will be imported in addition to superdistribution of that other user s feed blob. More on later.

In step a keyring feed entry is created. This includes encrypting the given hash URI using the entry key stored in the keyring feed key blob . In particular the given URI is encrypted using the entry key and stored in the entry field of the created keyring feed entry . In step the resulting file that represents the created keyring feed entry is stored on the user s Makyoh server. In step the created keyring feed entry is then queued on the Put Feed Entry Queue. The Put Feed Entry Queue is then serviced by an invocation made in step to the procedure shown in to effect local superdistribution of the newly created keyring feed entry .

Thus in a step the hash URI is imported by invoking the procedure outlined in . More specifically the process of will either obtain the blob identified by the hash URI in the case where the blob was not already stored in the user s server or the blob will be superdistributed in the case where the blob was already stored in the user s server .

In a step a determination is made whether the blob was successfully retrieved or not. If not then processing in completes. It is noted that some suitable form of error processing e.g. notifying the user logging the error etc can be performed. If the blob was successfully retrieved then a determination is made in step whether the blob is a feed key blob for example the publication feed key blob or the keyring feed key blob . If not then the assumption is made that the retrieved blob is a document and processing in completes.

If on the other hand the retrieved blob is a feed key blob retrieved feedkey then each feed entry accessible via the retrieved feedkey will be examined. A determination is made in step whether the retrieved feedkey is already stored in the user s FeedKey List. If so then the processing in completes.

If the retrieved feedkey is not stored in the user s FeedKey List then processing proceeds to step where a feed Id is computed from the signature contained in the verify key field of the retrieved feedkey. Recall that in an embodiment of the present invention the feed Id is the 160 bit key fingerprint of the verify key per the OpenPGP standard. In a step the feed Id of the retrieved feedkey is added to the user s Feedkey List. In a step the feed Id is added to the Get Feed Queue which is the list of feeds to be checked for new entries on other servers. In a step the Get Feed Queue is serviced by invoking the process of in order to import the feed entries in the feed identified by feed Id.

A loop is executed to consider each of the imported feed entries. Thus in step the entry field of the first feed entry is decrypted using the decryption key contained in the entry key field of the retrieved feedkey to obtain the hash URI of the first feed entry. Then in step the process of is invoked recursion to instantiate a second invocation of this time using the hash URI of this first feed entry as the given hash URI. Processing begins with step and proceeds as discussed above. If the hash URI is associated with a document then processing will stop at the determination step . This would terminate the second invocation of and processing would resume with the first invocation of at step to process the next feed entry. If in the second invocation of the hash URI is associated with another feed i.e. the blob associated with the hash URI is a feed key blob then processing continues with the steps following step to retrieve its feed entries which can include still feeds as well. The procedure terminates when all the imported feed entries have been considered.

Having described and a usage scenario for the initial creation of a user s keyring will now be described. In accordance with a keyring feed is created by generating a keyring feed key file containing a sign key a verify key and an entry key. The keyring feed key blob is then created by encrypting the keyring feed key file. The hash URI the master key for accessing the keyring feed key blob is created and includes an identifier to identify the blob and a cryptographic key to decrypt the blob to obtain the plaintext keyring feed key file. The master key is then passed on in step as the hash URI to be processed according to .

In the master key is passed on to the process of step . In the master key is passed on to via step . Turning to then the procedure reaches step and . Here the extracted Blob Id identifies the keyring feed key blob which was just created above in accordance with . Thus step will evaluate to YES and processing will proceed to step where the keyring feed key blob is superdistributed. Processing continues with step in .

Step will evaluate to YES because the blob referred to in step is the keyring feed key blob . Since this is the first time for the keyring feed key blob step will evaluate to NO because the keyring feed key blob is not yet on the FEEDKEY LIST until step is performed. In step the feed entries for the feed accessed by the keyring feed key are obtained. However in this case the list of feed entries is empty since the keyring feed has just been created. The process in thus completes and processing continues with step .

A feed entry for the master key is created and stored on the user s Makyoh server steps . The feed entry is then superdistributed steps to other reachable Makyoh servers. At this point both the keyring feed key blob and the master key in the form of a keyring feed entry are out there being redundantly backed up among Makyoh servers that were reachable at the time of step beginning of superdistribution of keyring feed key blob and step beginning of superdistribution of keyring feed entry .

The discussion will now turn to processing when a hash URI for a document blob is added to the keyring feed of . The hash URI may originate from the user or may be given to the user by another user directly or indirectly via superdistribution of the hash URI from the other user s Makyoh server. In the first embodiment of the present invention the entry point for a received hash URI was see the section entitled Import Key. In accordance with the second embodiment of the present invention the entry point for processing a received hash URI is .

When the user s Makyoh server receives a hash URI the server will invoke processing according to with the received hash URI in order to add the received hash URI key to the user s keyring feed. Step invokes which in turn invokes in step . If the received hash URI identifies a blob that is already stored on the user s Makyoh device then step is performed to superdistribute the blob otherwise step is invoked in an attempt to obtain the blob from a reachable Makyoh server.

Since we are assuming the received hash URI accesses a document blob content blob processing in will proceed down the NO branch from step assuming success in . Processing continues at step in where a keyring feed entry is created for the received hash URI thus adding the received hash URI into the user s keyring feed. As discussed above this involves encrypting the received hash URI using the entry key in the user s keyring feed key to produce an encrypted hash URI which is then stored in the entry field of the created keyring feed entry . The keyring feed entry is then superdistributed to reachable Makyoh devices steps . Processing for adding a received document hash URI thus concludes.

The discussion will now turn to processing a hash URI that accesses a feed. A feed is accessed by its feed key. Referring to for example the publication feed includes a publication feed key blob which provides access to its constituent feed entries . More specifically the decrypted publication feed key blob is a file that contains among other keys an entry key that is used to access the entry fields of the constituent feed entries . The publication feed key blob is decrypted by the publication key which is a hash URI that identifies the publication feed key blob and includes a key for decrypting the blob. The master key discussed above is another example of a hash URI for a feed in this case the feed is the keyring feed. The master key is the hash URI for the keyring feed key blob . The discussion that follows is a more generalized discussion of the processing that was described for keyring creation.

The process begins when a hash URI is received and in this case the hash URI key for a feed. is invoked to add the received hash URI as another key to the user s keyring feed. is invoked in step and in step is invoked. If the blob identified by the received hash URI in this case a feed key blob e.g. is already stored in the user s Makyoh device then the feed key blob is superdistributed per step . If the feed key blob is not already stored on the user s Makyoh device then an attempt to retrieve it from a reachable Makyoh device is made in step . Processing then continues in step of . Processing continues to step assuming success in .

If the feed key blob had been previously stored in the FeedKey List then processing in concludes and processing continues with step in where a keyring feed entry is created for the received hash URI and superdistributed.

Returning to if in step it is determined that that feed key blob identified by the received hash URI is not already stored in the FeedKey List then processing proceeds to step where the constituent feed entries associated with the feed key blob are obtained. The loop examines each obtained feed entry. For each feed entry the entry key field in the feed key blob is used to decrypt the entry field of the feed entry to obtain a hash URI. If the retrieved hash URI is for a feed i.e. the type field in its header indicates feedkey then is recursively invoked to process the retrieved hash URI. If the retrieved hash URI is not for a feed then the next feed entry is examined. Eventually processing in concludes and resumes with step in . A keyring feed entry is created for the received hash URI and superdistributed. Processing for adding a received feed hash URI thus concludes.

As can be imagined from the above discussions processing of the keyring feed can consume a good deal of computational effort. For this reason it may be desirable though not necessary to store certain intermediate results and computed data on the device running the Makyoh server. This can be loosely analogized to using a disk cache to store frequently accessed data instead of going to the disk drive. Another analogy is an internet search engine. On the one hand a search can performed by brute force where each site on the web is visited including all the links encountered. Of course this is inefficient. Typically web crawlers crawl the web and collect data for each visited site and index that data. A search then amounts to a search of the indexed data. In a similar vein processing of the keyring feed includes tasks such as decrypting blobs and searching hash URIs. The decrypted blobs can be stored to reduce processing overhead.

Referring back to the logical description of the keyring feed in various data structures in the Makyoh server program code and temporary files can be utilized to store information obtained from decrypted blobs and so on in order to reduce the computational load on the Makyoh device. In order to ensure security this temporary information can be retained only during the current user session. The temporary information is collectively referred to herein as a keyring session cache which in for example is logically represented by reference numeral to indicate various implementation specific data structures and files that represent the dynamic state of the keyring during the user session. The Feedkey List described above is an example of a cache for storing feed keys e.g. see step step step .

For example in one instantiation of this aspect of the present invention the keyring session cache is a list of all the hash URIs found in the keyring feed as well as all hash URIs contained within the documents and feed entries that have been accessed so far even the ones that just represent say a single file in a subdirectory of one of the documents which would not be listed in the keyring feed shown in . The keyring session cache is stored in a format that is faster to retrieve than directly accessing file structure s comprising the keyring feed. In a particular instantiation the keyring session cache is implemented as a temporary database which is deleted at the end of a user session typically marked by the user logging out or shutting down the server and re created empty at the start of another user session such as when the user logs backs on or when the server is started up. However it is understood that other data formats can be used e.g. a set of hash tables stored in RAM. For speed purposes the data in the keyring session cache is not typically encrypted at least not using the normal Makyoh style encryption.

For the purpose of discussion the phrase current user session or simply user session refers to the time since the Makyoh server on the user s device was started and continues until the user logs out or the Makyoh server is stopped. For example a typical usage scenario involves the user starting up the Makyoh application program i.e. the Makyoh server and logging on. The session ends when the user logs out of the Makyoh server or exits from the application Microsoft OS or quits the application Apple OS . It is noted that the end of a user session is not necessarily marked by termination of the Makyoh application program. The user can simply log out without terminating the Makyoh server yet still be considered to have ended the user session.

When a user terminates a user session e.g. logs out of Makyoh the keyring session cache is deleted. Deletion of the keyring session cache greatly reduces the risk of unauthorized access to a user s keyring in case the user s Makyoh device is stolen or otherwise accessed without permission.

An aspect of this particular embodiment of the present invention therefore is to perform a bootstrap operation of the user s keyring feed upon logging onto the Makyoh server. will now be discussed to describe steps which result in initialization of the data structures and temporary files comprising keyring session cache when the user logs back into the Makyoh server.

Recall from that the master key is encrypted using a user provided passphrase and stored in a configuration file or some other suitable storage location on the user s Makyoh drive. This serves to protect the master key from unauthorized users. In order to initialize the keyring feed the master key first must be obtained. Typically this involves the user providing his passphrase to the Makyoh server.

Referring to for example as part of the login process the user can provide his passphrase step which is then used to initialize the user s keyring. The passphrase can be used as a password for logging into the Makyoh server as well. An alternative is to employ a login sequence that does not involve the passphrase. In this alternative approach the user would provide his passphrase to the Makyoh server after logging in in order to initialize his keyring. A less secure approach is to simply store the user s passphrase in a file on his Makyoh device that can then be retrieved by Makyoh upon login to produce the master key . The idea is to provide some form of secure storage of the master key . The use of a passphrase represents one of any number of approaches to safeguard the master key

Continuing with the login procedure in step the passphrase is used to decrypt the encrypted master key keyring hash URI . In a step the blob Id can be computed from the master key to identify the keyring feed key blob . The master key is then used in step to access all the other keys to the documents and feeds in the user s archive by invoking the procedure shown in . Recall that the master key is a feed hash URI. The keyring session cache is initialized by invoking with the master key as discussed above in the third usage scenario regarding storing the hash URI of a feed.

Synchronizing files between a laptop and desktop computer is as easy as importing the master key for the Makyoh archive running on each machine into the other machine s keyring. From that time forward whenever the two machines are on the same local network together they will automatically transfer newly added keys to each other s respective keyrings along with the blobs necessary to read the documents and feeds associated with them. One can also do one way synchronization for example to allow a project manager access keys imported or generated by individual team members.

Two things are necessary to recover a user s entire personal Makyoh archive a copy of his master key and access to machines that have cached the encrypted blobs making up his archive. If the machine running a user s personal Makyoh server experiences some kind of catastrophic failure or is stolen the user can recover his archive by installing the Makyoh server software on a new laptop and performing an import his master key via the process of . Makyoh will then poll machines on the local network to find the blobs that make up the entire lost archive.

Note that in the case of a stolen machine it is presumed that the Makyoh user session will have terminated at the time the machine was stolen. The person in possession of such a stolen machine would not have access to the encrypted blobs stored on it because he would not have the necessary passphrase that Makyoh requires to obtain the master key recall that the master key is stored in encrypted form and to recreate the keys in the keyring session cache .

The master key is easy to store outside of a Makyoh device because the key is so small the master key can simply be printed on a scrap of paper either in text or as a two dimensional bar code and placed in a safe safe deposit box or other secure long term storage. Note that this key need not be modified after its initial creation. In particular it need not be updated to incorporate documents that have been newly added to an archive as long as the blobs are available the master key will always recover even the most recently added documents and feed entries in an archive.

Recovery of the blobs making up the archive depends on the extent to which blobs were stored and superdistributed before the failure occurred. Typical scenarios listed from best to worst case include 

Makyoh will recreate as much of an archive as possible even if not all the blobs that make up the archive can be found on nearby servers. Often missing blobs will represent a single file but some blobs can cause more of an archive to be unrecoverable should they go missing. Most important is the feed key blob which is the blob pointed to by the master key itself. In the unlikely case that this blob is not found on any other server then none of the archive can be recovered. Next are individual feed keys which give access to every feed entry within a feed. The final and least significant bottleneck are feed entry files which give access to a single feed entry and directory blobs which must be found to access any files or subdirectories below them.

Makyoh is designed to protect against many kinds of attacks many of which have already been mentioned. To summarize Makyoh protects against the following threats 

