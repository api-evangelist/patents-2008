---

title: Method and system of building a grammar rule with baseforms generated dynamically from user utterances
abstract: A method () of building a grammar with baseforms generated dynamically from user utterances can include the steps of recording () a user utterance, generating () a baseform using the user utterance, creating or adding to () a grammar rule using the baseform, and binding () the grammar rule in a grammar document of a voice extensible markup language program. Generating a baseform can optionally include introducing a new element to VoiceXML with attributes that enable generating the baseform from a referenced recording such as the user utterance. In one embodiment, the method can be used to create () a phonebook and a grammar to access the phonebook by repeatedly visiting a form containing the grammar rule with attributes that enable generating the baseform from the referenced recording.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07962343&OS=07962343&RS=07962343
owner: Nuance Communications, Inc.
number: 07962343
owner_city: Burlington
owner_country: US
publication_date: 20081121
---
This application is a continuation of and accordingly claims the benefit of U.S. patent application Ser. No. 10 924 520 filed with the U.S. Patent and Trademark Office on Aug. 24 2004 now U.S. Pat. No. 7 487 085.

This invention relates to the field of voice extensible markup language and more particularly to a method and system for generating a grammar rule using a referenced recording.

Visual browsers are complex application programs that can render graphic markup languages such as Hypertext Markup Language HTML or Extensible HTML XHTML or XML . As such visual browsers lack the ability to process audible input and or output. Still visual browsers enjoy a significant user base.

Voice browsers are the audio counterparts of visual browsers. More particularly voice browsers can render voice markup languages such as Voice Extensible Markup Language VXML or VoiceXML thereby allowing users to interact with the voice browser using speech.

Recent developments in Web based applications have led to the development of multimodal interfaces. Multimodal interfaces allow users to access multimodal content or content having both graphical and audible queues. Through a multimodal interface the user can choose to interact or access content using graphic input such as a keyboard or pointer entry using an audible queue such as a speech input or using a combination of both. For example one variety of multimodal interface is a multimodal browser that can render content written in XHTML Voice markup language also referred to as X V markup language.

Voice enabling content refers to permitting spoken utterances to be utilized as recognizable application input as well as generating spoken output for an application such as presenting an audible rendition of content contained within an electronic document like a markup language document. Command and control pertains to graphical user interface GUI features such as commands that are accessible through menus and dialog boxes of an application. Content navigation pertains to the ability of a user to select hyperlinks presented within a rendered electronic document using voice thereby causing a browser for example to load the document represented by the hyperlink. Thus to speech enable an application program efforts not only must be directed to voice enabling the content but also to voice enabling command and control and content navigation functions of the application program.

VoiceXML uses grammars that can be generated from text data available to an application through a database webservices or user input. However there is a class of Automatic Speech Recognition ASR applications that record lists of user utterances and creates grammars based on dynamically generated acoustic baseforms. An example is a phone dialer application with a phone book where the user can save the names and numbers for people and dial them later with a command like Dial Brian. The VoiceXML language currently fails to support this application model where a grammar can be built with baseforms generated dynamically from user utterances.

Embodiments in accordance with the invention can enable a method and system for creating or adjusting preexisting grammars based on dynamically generated acoustic baseforms by adding an element to the VoiceXML language and state variables to the VoiceXML platform in accordance with the present invention.

In a first aspect of the invention a method of building a grammar with baseforms generated dynamically from user utterances can include the steps of recording a user utterance generating a baseform using the user utterance creating a grammar rule using the baseform and binding the grammar rule in a grammar document of a voice extensible markup language program. Generating a baseform can include introducing a new element to VoiceXML with attributes that enable generating the baseform from a referenced recording such as the user utterance. The method can further include the step of creating a grammar token when the new element is visited by a form interpretation algorithm FIA . The composition of the grammar rule can be controlled as the grammar token is added to the grammar rule being constructed using values of the attributes. In one embodiment the method can be used to create a phonebook and a grammar to access the phonebook by repeatedly visiting a form containing the grammar rule with attributes that enable generating the baseform from the referenced recording.

In a second aspect of the invention a system having an automatic speech recognition application can include a memory for storing a list of user utterances and associated grammars and a processor coupled to the memory. The processor can be programmed to record a user utterance generate a baseform using the user utterance create a grammar rule using the baseform and bind the grammar rule in a grammar document of a voice extensible markup language program.

In a third aspect of the invention a computer program has a plurality of code sections executable by a machine for causing the machine to perform certain steps as described in the method and systems outlined in the first and second aspects above.

The computer system can be a server for hosting one or more applications such as voice browsers interactive voice response systems voice servers or the like. For example in one embodiment the application can be a phonebook a visual browser or other application that is to be voice or speech enabled. Accordingly the application can function as a multimodal browser once an interpreter is instantiated. In another embodiment the application can be a voice server. In that case the interpreter can function as a voice browser. It should be appreciated however that the application and the voice library need not be located within the same information processing system. For example each can be located within one or more different information processing systems communicatively linked via a suitable communications network. In one embodiment the application can be disposed within a user computing machine while the voice library can be disposed in a network computing machine that is remote from the user machine.

The voice library can include modules configured to perform the various functions described herein. In one embodiment the voice library can include a function for instantiating an interpreter upon request of the application . The voice library can include a library application programming interface API through which the application and the voice library can communicate. As such the library API provides the application with access to the functions of the voice library .

The application can call a function in the voice library via the library API to instantiate the interpreter . In one embodiment the interpreter can function as a voice markup language interpreter. The interpreter can be configured to parse and render any of a variety of voice markup languages such as Voice Extensible Markup Language VoiceXML or any subset superset or derivative thereof.

The application further can invoke another function referred to as addLink . The addLink function of the voice library can pass a VoiceXML fragment or VoiceXML grammar generated in conjunction with the application to the interpreter . The grammar can specify one or more grammars with which speech inputs to the application can be matched. That is the interpreter can match speech inputs received from the application with command and control and content navigation C3N grammar s or other existing grammar rules. Upon detecting a match the interpreter can generate one or more events that are sent back to the application in accordance with a new or modified grammar.

As noted the system can include speech resources such as the ASR engine configured to convert speech to text and the TTS engine for generating synthetic voice from text. Notably an audio playback system not shown can be included for playing recorded portions of audio if so desired. The interpreter can manipulate the speech resources through the speech services API . This allows the interpreter to be implemented independently of the speech resources thereby facilitating the use of speech resources from different vendors.

While the application and the interpreter can function in a cooperative manner the ASR engine and the TTS engine need not be part of the same system. That is in one embodiment the processing resources can execute in one or more other computer systems. Such computer systems can be proximate to or remotely located from the computer system . For example the speech resources can be provided as individual services that are accessible to the interpreter and application via a communications network which can include but is not limited to a local area network a wide area network the public switched telephone network a wireless or mobile communications network the Internet and or the like. Still in another embodiment the resources can be located within a same computer system as the application and or the interpreter .

In operation one or more instances of the interpreter are created through function calls from the application to the voice library . Once created the application can access the speech resources via the interpreter . That is the interpreter can render voice markup languages and access the ASR engine and the TTS engine . Accordingly voice services can be provided to a user accessing the computer system via a telephone or a computer system over another communications network . C3N grammars can be provided or specified by the application to the interpreter through the passing of the VoiceXML fragment . Information indicating matches to user speech such as application commands or content navigation commands i.e. selections of hyperlinks can be passed back to the application from the interpreter as one or more events.

In a specific embodiment a system utilizing a VoiceXML program can record a grammar and also reference or bind the grammar. In order to record a grammar rule in accordance with an embodiment of the present invention a new element to VoiceXML is introduced namely the for acoustic baseform elements. The acoustic baseform element has attributes that enable generating a baseform from a referenced recording to create or add to an existing grammar rule. Each time the element is visited by the FIA the interpreter for example a grammar token is created. The value of the attributes controls the composition of the rule as the token is added to the rule being constructed. The attributes can include 

In a phonebook example the form below could be visited multiple times to create a phone book and a grammar to access phone book entries 

In the binding or referencing of the grammar rule the computer system or a VoiceXML processor maintains a grammar document implied by the set of rules in a dialog context using a variable dialog.grammar. The dialog.grammar variable is also an array where each member of the array is a structure that contains a rule name and a rule e.g. dialog.grammar 1 .rulename and dialog .grammar 1 .rule. An application author can further manipulate that variable modify rules or add entirely new rules. The rules in dialog.grammar are not activated or even validated until referenced by a grammar in the document.

In the example VoiceXML form below the user can say Dial 555 1212 or Call John Smith . The latter matches the rule name in book rule that was created in dialog.grammar using the previous form. The VoiceXML form 

Referring to a method of building a grammar with baseforms generated dynamically from user utterances can include the step of recording a user utterance generating a baseform using the user utterance at step creating or adding to a grammar rule using the baseform at step and binding the grammar rule in a grammar document of a voice extensible markup language program at step . Generating a baseform can optionally include introducing a new element to VoiceXML with attributes that enable generating the baseform from a referenced recording such as the user utterance. The method can further include the step of creating a grammar token when the new element is visited by a form interpretation algorithm FIA . The composition of the grammar rule can be controlled at step as the grammar token is added to the grammar rule being constructed using values of the attributes. In one embodiment as shown in block the method can be used to create a phonebook and a grammar to access the phonebook by repeatedly visiting a form containing the grammar rule with attributes that enable generating the baseform from the referenced recording.

It should be understood that the present invention can be realized in hardware software or a combination of hardware and software. The present invention can also be realized in a centralized fashion in one computer system or in a distributed fashion where different elements are spread across several interconnected computer systems. Any kind of computer system or other apparatus adapted for carrying out the methods described herein is suited. A typical combination of hardware and software can be a general purpose computer system with a computer program that when being loaded and executed controls the computer system such that it carries out the methods described herein.

The present invention also can be embedded in a computer program product which comprises all the features enabling the implementation of the methods described herein and which when loaded in a computer system is able to carry out these methods. Computer program or application in the present context means any expression in any language code or notation of a set of instructions intended to cause a system having an information processing capability to perform a particular function either directly or after either or both of the following a conversion to another language code or notation b reproduction in a different material form.

This invention can be embodied in other forms without departing from the spirit or essential attributes thereof. Accordingly reference should be made to the following claims rather than to the foregoing specification as indicating the scope of the invention.

