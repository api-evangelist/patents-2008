---

title: Scaled management system
abstract: An exemplary system for managing an applications and data space includes a strategy layer configured to receive a query statement and to formulate one or more custom queries based on the query statement and a query scheduler layer configured to schedule issuance of the one or more custom queries to one or more query response modules associated with the applications and data space. Other methods, devices and systems are also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08055649&OS=08055649&RS=08055649
owner: Microsoft Corporation
number: 08055649
owner_city: Redmond
owner_country: US
publication_date: 20080306
---
Software as a service SaaS includes Web based e mail services e.g. the MICROSOFT HOTMAIL e mail service where a vendor typically hosts all of the program logic and data and provides end users with access to this data over the public Internet through a Web based user interface. Such a service relies on distributed applications and a large amount of data which may be stored in more than one data center. Other examples of SaaS include line of business services which are often large customizable business solutions aimed at facilitating business processes such as finances supply chain management and customer relations and consumer oriented services. Regarding consumer oriented services these services are sometimes supported by advertising and offered to the general public at no cost.

Distributed applications can be data intensive and complex. For example consider a financial services organization that actively monitors i financial markets ii individual trader activity and iii customer accounts. An application running on a trader s desktop may track a moving average of the value of an investment portfolio. This moving average needs to be updated continuously as stock updates arrive and trades are confirmed but does not require perfect accuracy. A second application running on the trading floor extracts events from live news feeds and correlates these events with market indicators to infer market sentiment impacting automated stock trading programs. This query looks for patterns of events correlated across time and data values where each event has a short shelf life . In order to be actionable the query must identify a trading opportunity as soon as possible with the information available at that time late events may result in a retraction. Yet another application a third application running in a compliance office monitors trader activity and customer accounts to watch for churn and ensure conformity with Security and Exchange Commission rules and institution guidelines. These queries may run until the end of a trading session perhaps longer and must process all events in proper order to make an accurate assessment. These three applications carry out similar computations but differ significantly in their workload and requirements for consistency guarantees and response time.

Various issues exist in the realm of distributed applications such as multi tenant customization and extensibility data scaling and isolation issues.

An exemplary system for managing an applications and data space includes a strategy layer configured to receive a query statement and to formulate one or more custom queries based on the query statement and a query scheduler layer configured to schedule issuance of the one or more custom queries to one or more query response modules associated with the applications and data space. Other methods devices and systems are also disclosed.

Various exemplary methods devices and system described herein pertain to management of resources for distributed applications. An exemplary management system is configured to receive basic operator queries to formulate strategic queries to schedule queries and to distribute queries in an applications and data space. The system can optionally formulate strategic queries and schedule queries based in part on information responsive to one or more prior queries. Such a system can be used to manage resources in one or more server farms that provide software as a service SaaS . Management of resources can include management for purposes of efficiency maintenance cost debugging etc.

An exemplary system includes one or more event tracing modules and one or more event detection and response modules in an applications and data space. Information from the latter may be routed by an exemplary router to a query and strategy space. In turn components of the query and strategy space can decide whether to provide information to one or more operators or to formulate one or more additional queries.

An exemplary query module receives query statements written in a language parsable by a language engine and formulates custom or strategic queries. An exemplary query scheduler component of the query module schedules and distributes queries to one or more modules in an applications and data space. For example an applications and data space can include servers organized into server blocks where each server in a particular server block includes an operating system level event tracing module and where data transmitted by one or more of the servers optionally passes through an event detection and response module. In such an applications and data space the query scheduler component can schedule and direct queries to one or more event tracing modules and or to one or more event detection and response modules.

An exemplary strategy module includes one or more strategy algorithms and information about an applications and data space. The information can include one or more of an event tracing module map a event detection and response map application information a knowledge base hardware information bandwidth information information about standard queries e.g. types schedules etc. current condition information and trend information e.g. operating trends usage trends query trends etc. .

A system optionally includes one or more intelligent data routers. An exemplary intelligent data router includes maps for routing data and in particular data responsive to one or more queries. Such maps can include one or more of an operator map a query map a strategy map and an event detection and response module map. An intelligent data router can also include bandwidth information and hardware information for resources in a server block or in a server facility e.g. a server farm .

An exemplary method includes receiving a query about increased workload receiving information about workload formulating one or more custom queries based in part on the query and the information about workload receiving information responsive to one or more queries e.g. custom and or standard and deciding whether the information is sufficient to respond to the query about increased workload. In such a method information responsive to a query is optionally issued by one or more event tracing modules and or one or more event detection and response modules. In such a method information responsive to a query is optionally routed by an intelligent data router.

An exemplary method includes receiving a query about latency receiving information about latency formulating one or more custom queries based in part on the query and the information about latency receiving information responsive to one or more queries e.g. custom and or standard and deciding whether the information is sufficient to respond to the query about increased latency. In such a method information responsive to a query is optionally issued by one or more event tracing modules and or one or more event detection and response modules. In such a method information responsive to a query is optionally routed by an intelligent data router.

With respect to what an operator in the operator layer may want to know consider that as databases serve more users concurrently and grow in size the amount of time it takes to perform operations for distributed applications such as Web querying and searching increases significantly. SaaS applications which often use the same databases to serve thousands of customers are particularly susceptible to these types of performance degradation. Consequently an operator may want to know where performance degradation is occurring or where resources are available to perform additional work.

An administrator of resources in an applications and data space may need to know how to scale resources or otherwise manage resources to alleviate performance bottlenecks. One fairly simple way to scale a database is through partitioning which divides data into smaller chunks to improve efficiency. Consider a partitioning strategy that aims to determine the best way to partition data. For example if an application has customers from around the world a geographic partitioning strategy might be appropriate with data belonging to European customers in one partition data belonging to Asian customers in another and so on. Dynamic repartitioning strategies can help ensure that already partitioned data can be repartitioned in order to keep up with performance and scale metrics.

With respect to operational structure of an application an operator may be concerned with what it takes to deliver the application to customers and to keep the application available and running well at a cost effective level. For many operators which have never had to run a data center for their customers this may be the most unfamiliar aspect of SaaS.

Accordingly a variety of people often need to know information about how resources perform. As described herein an exemplary management system can help SaaS providers and others in operating and managing SaaS applications. Such a management system can also help administrators scale and allocate resources. To help such people meet their goals an exemplary query system provides a mechanism to accept a question and to provide an intelligent response to the question.

If the block decides that the query statement is for a standard scheduled query then a standard scheduled query block is notified. As described herein some set of standard scheduled queries exist that are directed to various components in an applications and data space. Responses to such queries are returned as standard results per result block and can be provided to the operator . However at times an operator may need to know information that is not provided in response to a standard query hence the need for providing a mechanism for non standard queries.

If the query statement pertains to a non standard query then a language engine parses the query statement to form one or more custom queries. The one or more custom queries are then scheduled by a query scheduler which may also schedule unscheduled standard queries.

With respect to the language engine the query statement is written in a language that allows the operator to express desired information. For example a natural language can allow the operator to ask For my application X why is the latency so high . The engine can parse the statement to identify application X latency and high . Given these three pieces of query information the language engine can formulate one or more custom queries using appropriate control logic. For example consider the following 

For each group formulate custom queries to query event tracing modules followed by their CEDR modules and

Schedule queries according to group where in each group first query event tracing modules and then corresponding CEDR module s .

In response to issuance of these queries information is provided to the operator via a direct return path as a result or via a strategy module as a result . In this example the strategy module may analyze information responsive to the custom queries and decide if one or more additional queries are required to provide information sufficient to answer the query of the operator . For example an analysis may indicate that a certain block of servers executing application X are responsible for the latency. However the reason cannot be stated without additional information from these servers. So the strategy module formulates a query statement to retrieve additional information to identify as specifically as possible the source of the high latency.

An exemplary system includes event tracing at the operating system level. shows an event tracing architecture for an operating system . As shown in the architecture includes an event tracing module that functions in conjunction with the operating system . The architecture includes four main types of components controllers event providers consumers and event trace sessions . Buffering and logging take place in event tracing sessions which accept events and create a trace file . A number of logging modes typically exist for ET sessions. For instance a session can be configured to deliver events directly to consumer applications or to overwrite old events in a file by wrapping around when a certain size is reached. A separate writer thread created for each session can flush them to a file or to real time consumer applications . To enable high performance per processor buffers can be used to eliminate the need for a lock in the logging path.

An event provider is a logical entity that writes events to ET sessions . Any recordable activity of significance can be an event and each is represented by an event logged to ET. An event provider can be a user mode application a managed application a driver or any other software entity. In general an event provider must register a provider ID with ET through a registration API. A provider first registers with ET and writes events from various points in the code by invoking an ET logging API. When a provider is enabled dynamically by the ET controller application calls to the logging API can send events to a specific trace session designated by the controller . Each event sent by the event provider to a trace session can include a fixed header that includes for example event metadata and additional variable user context data. Due to growing use of event instrumentation in many OS components even a simple application may already contain several components that are event providers .

When an event is logged to a session ET can add a few extra data items along with for example user provided data. Such items can include timestamp process and thread ID processor number and CPU usage data of the logging thread. These data items can be recorded in an ET event header and passed on to event consumers optionally along with the variable event content given by a provider . Many trace consumers find these data fields to be helpful in performance analyses.

A controller can start and stop ET sessions and enable provider access to ET sessions . In some scenarios such as debugging and diagnosis a controller tool may be invoked as needed to collect in depth traces. In contrast for events such as admin targeted events that need to flow to an event viewer at all times providers may be enabled automatically by an event log service when the providers register. In general a controller must have ET permission on the operating system to control sessions which is typically given only to a small group of privileged users by default.

In the example of a consumer is an application that can read log files or listen to a session for real time events. Event consumption is typically callback based a consumer registers an event callback which the ET module calls with one event at a time. Events are typically delivered to the ET consumer in chronological order. General purpose event consumer tools can optionally dump events into any of a variety of formats. For example an XML dump of a Process event logged by a kernel provider may be generated by an appropriate tool on the underlying OS. Such an event indicates the start of a Notepad process. Since events often contain custom user content logged by a provider some type of metadata may be needed for decoding. A provider using certain APIs may be expected to supply an event manifest an XML file that defines all events that providers write along with their layout information. A general purpose consumer application may use Trace Data Helper TDH APIs to retrieve the event metadata decode the events and display them.

For many tracing means collecting events from certain providers of interest. In this way of thinking an event trace session is tied to one or more providers in a conceptual collection as a whole and a session itself the logging engine is often overlooked. The ET architecture allows for more dynamic and flexible trace and event management. Here sessions and providers exist in different spaces. A controller is the one that starts and stops ET sessions and enables providers to sessions dynamically. Thus a controller can choose to enable a group of providers to a session disable some of them after a while and enable another provider to that same session later. Sessions operate in a kernel and are not statically tied to providers . Likewise providers typically are not aware of which sessions their events are being logged to. There are large scale applications and services that are providers controllers and consumers all at the same time.

In the architecture APIs may be provided for all operations for controllers providers and consumers and applications may assume any combination of roles. In conventional event tracing however developers implement only event providers and use in the box tools to collect traces and view them.

Separation of providers and trace sessions allows tracing to become immune to application problems such as crashes or hangs. Events logged by providers before a crash normally reside in kernel memory if not in a trace file already which makes this particularly useful in debugging application anomalies.

The event tracing architecture can be used by developers IT administrators and management tool developers for debugging monitoring diagnosis and capacity planning. The usual analysis methodologies based on events can be categorized into the following techniques Scanning e.g. through an event dump Delta Analysis e.g. via timestamp and CPU usage numbers for each event Property Event B Property Event A e.g. to allow for response time and CPU usage statistics of application activities Statistical Analysis e.g. counting certain events for insight into software behavior State Machine and Resource Tracking construction of a state machine and in turn a simulation based on traces and End to End Tracing e.g. an application that includes a number of distributed components integrated via complicated interconnections .

With respect to the latter in general conventional event tracing requires instrumentation points to be added throughout application components to record activities along with a unique ID for a request currently being served. After traces are collected events that correspond to the same request are correlated during event consumption such that its activity and progress can be tracked. Later specific requests of interest can be looked at individually for problems in different service stages or a group of requests can be summarized through a statistical analysis.

As described herein various exemplary techniques include instructing one or more controllers associated with event tracing to acquire information germane to operation of a computing device and or an application executing on a computing device. For example in the query system the query module can issue one or more queries that instruct a controller to acquire event tracing information.

In the CEDR operator a data stream is modeled as a time varying relation. Each tuple in a relation is an event and has an ID. Each tuple has a validity interval which indicates the range of time when the tuple is valid from an event provider perspective. Given an interval representation of each event it is possible to issue the following continuous query at each time instance t return all tuples that are still valid at t. Thus the CEDR operator can naturally express such a query.

Referring to the query system of the query statement may be written in an intuitive manner that can directly form a query for a CEDR module or can be parsed by the query module to form an appropriate custom query for a CEDR module.

After an event initially appears in a stream its validity interval e.g. the time during which a coupon could be used can be changed by the event provider. Such changes can be represented by tuples with the same ID but different content. A second temporal dimension occurrence time models when such changes occur from the event provider perspective. An insert event of a certain ID is the tuple with minimum occurrence start time value Os among all events with that ID. Other events of the same ID are referred to as modification events. Both valid time and occurrence time are assigned by the same logical clock of the event provider and are thus comparable. The symbol t can be used to denote valid time and the symbol t to denote occurrence time.

The following schema can provide a conceptual representation of a stream produced by an event provider ID Vs Ve Os Oe Payload where Vs and Ve respectively denote valid start and end time Os and Oe respectively denote occurrence start and end time Payload is the subschema consisting of normal value attributes and is application dependent.

1 event pattern expression composed by a set of high level operators that specify how individual events are filtered and how multiple events are correlated joined via time based and value based constraints to form composite event instances or instances for short 

2 instance selection and consumption expressed by a policy referred to as a selection and consumption SC mode and

3 finally instance transformation which takes the events participating in a detected pattern as input and transforms them to produce complex output events via mechanisms such as aggregation attribute projection and computation of a new function.

The SEQUENCE construct specifies a sequence of events that must occur in a particular order. The parameters of the SEQUENCE operator or any operator that produces composite events in general are the occurrences of events of interest referred to as contributors. There is a scope associated with the sequence operator which puts an upper bound on the temporal distance between the occurrence of the last contributor in the sequence and that of the first contributor. In this query the SEQUENCE construct specifies a sequence that consists of the occurrence of an INSTALL event followed by a SHUTDOWN event within 12 hours of the occurrence of the former. The output of the SEQUENCE construct should then be followed by the nonoccurrence of a RESTART event within 5 minutes. Nonoccurrences of events also referred to as negation in this work can be expressed either directly using the NOT operator or indirectly using the UNLESS operator which is used in this query formulation. Intuitively UNLESS A B w produces an output when the occurrence of an A event is followed by non occurrence of any B event in the following w time units w is therefore the negation scope. In this query UNLESS is used to express that the sequence of INSTALL SHUTDOWN events should not be followed by no RESTART event in the next 5 minutes. One can also bind a sub expression to a variable via AS construct such that one can refer to the corresponding contributor in WHERE clause when we specify value constraints.

For the WHERE clause for this query variables defined previously are used to form predicates that compare attributes of different events. To distinguish from simple predicates that compare to a constant like those in the first example such predicates are referred to as parameterized predicates as the attribute of the later event addressed in the predicate is compared to a value that an earlier event provides. The parameterized predicates in this query compare the ID attributes of all three events in the WHEN clause for equality. Equality comparisons on a common attribute across multiple contributors are typical in monitoring applications. For ease of exposition the common attribute used for this purpose is referred to as a correlation key and the set of equality comparisons on this attribute as an equivalence test. The CEDR language offers a shorthand notation an equivalence test on an attribute e.g. Machine Id can be expressed by enclosing the attribute name as an argument to the function CorrelationKey with a keywords such as EQUAL UNIQUE e.g. CorrelationKey Machine ID Equal as shown in the comment on the WHERE clause in this example . Moreover if an equivalence test requires all events to have a specific value for the attribute id Machine X it can be expressed as Machine Id Equal Machine X .

Referring again to the CEDR operator provides a set of composable operators that can be combined to form a pipelined query execution plan. Each CEDR operator in an applications and data space can include the consistency monitor and the operational module . The consistency monitor decides whether to block the input stream in an alignment buffer until output may be produced which upholds the desired level of consistency. The operational module can compute the output stream based on incoming tuples and current operator state .

The CEDR operator can accept occurrence time guarantees on subsequent inputs e.g. provider declared sync points on input streams . These guarantees can be used to uphold the highest level of consistency and allow for reducing operator state in all levels of consistency. The CEDR operator can also annotate the output with a corresponding set of future output guarantees. These guarantees can be fed to a subsequent operator and streamed to a user with a corresponding query result.

A property of an exemplary CEDR operator is that formal descriptions of operator semantics are used to prove that at common sync points operators output the same bitemporal state regardless of consistency level. As a result one can seamlessly switch from one consistency level to another at these points producing the same subsequent stream as if a CEDR operator had been running at that consistency level all along.

The standard scheduled query represents a baseline level of query information from which the query module injects additional queries to provide an answer to a request from for example an operator. In general a query module can act to issue queries for research driven data collection e.g. with optimization adaption incident management and to provide information above a baseline where appropriate e.g. in response to perceived issues trends operator questions etc. .

In the system the queries are directed to the applications and data space components and information returned to the query strategy space as a result or for an operator and or to a strategy module .

The exemplary data router may use the query map to direct information responsive to queries based on a query originator which may be a particular operator. The exemplary data router may use the CEDR map to aggregate or direct information generated in response to a common query statement from an operator e.g. the statement from the operator of .

In the instance that information is not sufficient to answer the query received at block a formation block forms one or more custom queries based on the received query and optionally on the received information about workload. For example a custom query may i Query ET for Server Block X e.g. types of application events and ii Query CEDR for Blocks X and Its Nearest Neighbors e.g. bandwidth . Once issued a receipt block receives information responsive to the custom queries.

Next a decision block decides whether the information responsive to the custom queries is sufficient to answer the query received at receipt block . If the decision block decides that the information is sufficient then an analysis and transmit block transmits a sufficient result to the query originator. For example the result may state Workload Increase OK if T WL

If the decision block decides that the information is insufficient to provide an answer then a formulation block forms one or more additional queries based in part on the received information. For example an additional query may be Query ETs for Server Block X s Nearest Neighbors .

In general the method aims to understand resource utilization with respect to workload. Often an operator will want to know something about the relationship between workload and performance through a server and want to know if workload is increased will performance suffer knowing that at some point performance will be unacceptable. Such a query may acquire information as to workload e.g. disk i o memory processors threads in process what concurrent activities going on etc. . An exemplary query module may issue one or more custom queries to acquire sufficient information to answer a workload related question.

In the instance that information is not sufficient to answer the query received at block a formation block forms one or more custom queries based on the received query and optionally on the received information about latency. For example a custom query may i Query ET for Server Block X e.g. types of application events and ii Query ET for Server Block Y e.g. types of application events . Once issued a receipt block receives information responsive to the custom queries.

Next a decision block decides whether the information responsive to the custom queries is sufficient to answer the query received at receipt block . If the decision block decides that the information is sufficient then an analysis and transmit block transmits a sufficient result to the query originator. For example the result may state 70 of Servers in Block X Performing CPU Intensive Tasks Latency Issue to Resolve in 23 minutes . In this example an operator may simply wait. A recordation block can record the result and corresponding conditions for example to form a knowledge base for use in formulating custom queries.

If the decision block decides that the information is insufficient to provide an answer then a formulation block forms one or more additional queries based in part on the received information. For example an additional query may be Query CPU usage for All Servers in Block Y .

In general latency issues arise with many types of applications e.g. SaaS . A query may ask how long it takes to service queries a search request or a hotmail inbox or how long for round trip. Conventional monitoring usually considers average time at the front end of a system only and does not address applications and data space back end. Sampling of front end machines alone may not provide an answer as to why some requests take longer than others. An exemplary system can help an operator determine why response is slow determine who a front end machine talks to in a back end and or determine machine performance and in response drill down to those machines reporting slowness. In an adaptive feedback driven manner an exemplary system can flow queries across a system e.g. to determine if certain machine tiers are problematic . An exemplary system can uncover issues related to a machine at one tier calling a machine at another tier an unreasonable number of times. An exemplary system can adapt a query more e.g. these 50 machines have an issue to ask what some machines have in common e.g. version of software applications services commonalities differentials . An exemplary system can determine how much data is required to sufficiently answer a question i.e. how much data is needed at a level to satisfy a query . For example an exemplary system may decide that at local cluster a certain version of software is running and then aggregate corresponding information at a lower level.

Information may be collected for use in answering subsequent queries. For example a reservoir of historical information may be maintained for levels of a stack. An application developer can be aware of such a reservoir and chose to collect information that is consistent across reservoirs. In instances where an application developer does not chose to do this then an exemplary system can create a layer of software that intercepts the flow and populates the reservoir. In either instance over time a reservoir becomes populated with information that can be germane to anticipated queries or even unanticipated queries. An exemplary system includes one or more CEDR operators that function as reservoirs for information. An exemplary system can direct a CEDR operator to create or optimize a reservoir on the fly. For example an instruction may ask that SQL queries from hotmail be sampled and every 1 10 000th query maintained in a CEDR operator reservoir.

In a very basic configuration computing device typically includes at least one processing unit and system memory . Depending on the exact configuration and type of computing device system memory may be volatile such as RAM non volatile such as ROM flash memory etc. or some combination of the two. System memory typically includes an operating system one or more program modules and may include program data . The operating system include a component based framework that supports components including properties and events objects inheritance polymorphism reflection and provides an object oriented component based application programming interface API such as that of the .NET Framework manufactured by Microsoft Corporation Redmond Wash. The device is of a very basic configuration demarcated by a dashed line . Again a terminal may have fewer components but will interact with a computing device that may have such a basic configuration.

Computing device may have additional features or functionality. For example computing device may also include additional data storage devices removable and or non removable such as for example magnetic disks optical disks or tape. Such additional storage is illustrated in by removable storage and non removable storage . Computer storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. System memory removable storage and non removable storage are all examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media may be part of device . Computing device may also have input device s such as keyboard mouse pen voice input device touch input device etc. Output device s such as a display speakers printer etc. may also be included. These devices are well know in the art and need not be discussed at length here.

Computing device may also contain communication connections that allow the device to communicate with other computing devices such as over a network. Communication connections are one example of communication media. Communication media may typically be embodied by computer readable instructions data structures program modules or other data forms. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

