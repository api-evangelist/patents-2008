---

title: Method and system for asymmetric independent audio rendering
abstract: Methods and mobile devices are provided for asymmetric independent processing of audio streams in a system on a chip (SOC). More specifically, independent audio paths are provided for processors performing audio processing on the SOC and mixing of decoded audio samples from the processors is performed digitally on the SOC by a hardware digital mixer.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08200479&OS=08200479&RS=08200479
owner: Texas Instruments Incorporated
number: 08200479
owner_city: Dallas
owner_country: US
publication_date: 20081223
---
This application claims priority from European Patent Application No. 08290123.2 filed on Feb. 8 2008.

Mobile phones are no longer just telephones. In addition to providing telephone functionality they are also providing more complex applications e.g. games multimedia music download and playback video with audio content download and playback web browsing etc. that require ever increasing audio processing capabilities. Thus improvements in hardware and software for audio processing in mobile phones and other mobile devices equipped for audio streaming are desired.

Embodiments of the invention provide methods and systems for asymmetric independent rendering of audio streams in mobile devices. More specifically embodiments of the invention provide a method for processing audio streams in a mobile device comprising a system on a chip SOC where the method includes decoding a first audio stream by a first processor comprised in the SOC decoding a second audio stream by a second processor comprised in the SOC wherein the decoding of the first audio stream and the second audio stream is performed concurrently digitally mixing decoded audio samples from the first audio stream and the second audio stream using a hardware digital mixer comprised in the SOC wherein a composite audio stream is generated and providing the composite audio stream to a digital to analog converter.

Embodiments of the invention further provide for a mobile device that includes a digital to analog convertor DAC and a system on a chip SOC operatively connected to the DAC. The SOC includes a first processor configured to decode a first audio stream a second processor configured to decode a second audio stream and a hardware digital mixer configured to mix decoded audio samples from the first audio stream and the second audio stream to generate a composite audio stream wherein the first audio stream and the second audio stream are decoded concurrently and the composite audio stream is provided to the DAC.

Embodiments of the invention further provide for a mobile device that includes a digital to analog converter DAC and a system on a chip SOC operatively connected to the DAC. The SOC includes a first processor configured to decode a first audio stream a second processor operatively connected to the first processor and configured to decode a second audio stream and an audio backend operatively connected to the first processor by a first port and the second processor by a second port. The audio backend includes a memory configured to store a first audio buffer to receive decoded audio samples from the first processor and a second audio buffer to receive decoded audio samples from the second processor and a hardware digital mixer configured to mix decoded audio samples from the first audio buffer and the second audio buffer to generate a composite audio stream wherein the first audio stream and the second audio stream are decoded concurrently and the composite audio stream is provided to the DAC.

Specific embodiments of the invention will now be described in detail with reference to the accompanying figures. Like elements in the various figures are denoted by like reference numerals for consistency.

Certain terms are used throughout the following description and the claims to refer to particular system components. As one skilled in the art will appreciate components of digital systems embodied in mobile and wireless devices may be referred to by different names and or may be combined in ways not shown herein without departing from the described functionality. This document does not intend to distinguish between components that differ in name but not function. In the following discussion and in the claims the terms including and comprising are used in an open ended fashion and thus should be interpreted to mean including but not limited to . . . . Also the term couple and derivatives thereof are intended to mean an indirect direct optical and or wireless electrical connection. Thus if a first device couples to a second device that connection may be through a direct electrical connection through an indirect electrical connection via other devices and connections through an optical electrical connection and or through a wireless electrical connection.

Inasmuch as the systems and methods described herein were developed in the context of a mobile phone the description herein is based on a mobile phone environment. However the discussion of the various systems and methods in relation to a mobile phone environment should not be construed as a limitation as to the applicability of the systems and methods described herein to only mobile phone environments. One of ordinary skill in the art will appreciate that embodiments of these systems and methods may also be implemented in other mobile devices and wireless devices with audio streaming capability such as for example handheld gaming devices iPods MP3 players and the like.

In the following detailed description of embodiments of the invention numerous specific details are set forth in order to provide a more thorough understanding of the invention. However it will be apparent to one of ordinary skill in the art that the invention may be practiced without these specific details. In other instances well known features have not been described in detail to avoid unnecessarily complicating the description. In addition although method steps may be presented and described herein in a sequential fashion one or more of the steps shown and described may be omitted repeated performed concurrently and or performed in a different order than the order shown in the figures and or described herein. Accordingly embodiments of the invention should not be considered limited to the specific ordering of steps shown in the figures and or described herein.

Many mobile phones include two processors a general purpose processor and a digital signal processor DSP both of which may be used to process audio streams. Typically the audio mixing paths are not completely independent between the two processors. Thus while both processors may be used to render audio streams one processor typically the general purpose processor is the master processor for audio rendering and controls mixing of audio streams. In some implementations the mixing is performed in software on the general purpose processor. In other implementations the mixing is performed in analog. In addition some synchronization generally performed by software on the general purpose processor is required as audio streams are processed on the two processors. This synchronization is necessary to ensure that the time it takes to render audio samples on the DSP and send them to the general purpose processor is taken into account so that the different audio streams are mixed with the right latencies.

Embodiments of the invention provide methods and systems for asymmetric independent processing of audio streams in mobile devices such as mobile phones in which synchronizations between two or more processors processing audio streams with differing characteristics e.g. sample rate is not needed. More specifically in one or more embodiments of the invention in a system on a chip SOC embodied in a mobile device independent audio paths are provided for each processor performing audio processing e.g. a DSP and a general purpose processor and mixing of the audio samples from the processors is performed digitally by a hardware digital mixer. Further the independent audio paths may include pre processing of decoded audio samples e.g. sample rate conversion received from the processors prior to the mixing. In addition post processing e.g. equalization may be performed on the composite audio stream generated by the hardware digital mixer.

The modem chipsets provide functionality to send and receive voice and or data and may include a 3G 4G chipset providing connectivity for voice and data transfer according the third generation 3G and fourth generation 4G of mobile phone standards form the International Telecommunication Union ITU family of standards a Bluetooth FM chipset providing Bluetooth and FM connectivity for voice and data transfer and a wireless modem chipset providing connectivity for data transfer in wireless networks. The audio analog subsystem provides functionality convert digital audio samples from the SOC to analog audio for delivery to various peripheral devices e.g. earphones headphones stereo AUX inputs speakers and vibrators . The audio analog subsystem also provides connectivity to convert analog audio from a microphone to a digital audio stream to be processed by the SOC .

The SOC includes a main processing unit MPU and a digital signal processor coupled to an audio backend subsystem via ports on an Open Core Protocol OCP compliant local interconnect. The SOC also includes interfaces for various peripheral devices via standard busses such as the Serial Low power Inter chip Media Bus SLIMbus and Inter IC Sound I2S . SLIMbus is a standard multi channel digital audio interface between baseband or application processors and peripheral components in mobile devices. I2S is a standard digital audio interface for multiplexed stereo audio. The MPU and the DSP are also coupled to various other system components not specifically shown by way of data and instruction busses and or various levels of OCP compliant interconnects. The MPU may be any processor suitable for integration into an SOC and the DSP may be any digital signal processor suitable for integration into an SOC.

The MPU and the DSP are configured to execute software digital audio functions for audio voice data streaming in the SOC . In one or more embodiments of the invention these software functions may include among others speech encoding and decoding for the 3G 4G modem handling voice over internet protocol VoIP transmissions to and from the wireless modem decoding digital audio files encoded in various formats including Advanced Audio Coding AAC MP3 and Musical Instrument Digital Interface MIDI formats tone generation handling Advance Audio Distribution Profile A2DP transmissions to and from the Bluetooth modem and generating 3D audio effects.

The audio backend subsystem is configured to handle all hardware digital audio functions for audio voice data streaming in the SOC . As is explained in more detail below the audio backend subsystem includes hardware and firmware to assist in the management of various audio and voice uplink and downlink streams between a host i.e. the MPU the DSP or a direct memory access DMA channel not specifically shown and various audio interfaces used for exchanging audio samples with digital to analog converters DACs and analog to digital converters ADCs . In one or more embodiments of the invention the audio backend subsystem includes functionality to perform buffering of audio samples from the DSP and the MPU in the audio buffers to mix digital audio with a digital voice down stream and or a microphone up stream real time mixer described in more detail below and or to perform post processing such as equalization EQ bass boost and sample rate conversion SRC .

The various audio interfaces include a digital microphone interface a multi channel pulse density modulation McPDM interface three multi channel buffered serial ports McBSPs a multi channel audio serial port McASP and a SLIMbus interface . The digital microphone interface supports up to three digital stereo microphones and includes functionality to extract audio samples from pulse density modulated streams of bits received from the microphones. The McPDM interface includes five downlink channels and three uplink channels for transferring audio samples between the audio analog subsystem and the audio engine subsystem and or a host e.g. the DSP the MPU or the L3 interconnect. Two additional uplink channels in the McPDM interface are reserved for status communication. The three McBSPs provide a full duplex direct serial interface between the audio backend and external devices in the mobile phone such as modems Bluetooth chips codecs etc. In some embodiments of the invention the McBSP1 interface is used for Bluetooth voice and audio data the McBSP2 interface is used for voice data from a modem and the McBSP3 interface is used for MIDI FM data.

The McASP functions as a general purpose audio serial port which may be used for both inter chip I2S modes and inter component DIT transmission. The SLIMbus interface provides a bidirectional multi drop multi channel two line serial interface between the audio backend and up to seven off chip components such as audio codecs Bluetooth chipsets FM radio receiver transmitters etc. The Slimbus interface can accommodate a wide range of peripherals and clocked frame oriented protocols I2S PCM TDM .

The audio engine subsystem includes an audio engine a memory an audio traffic controller and three special purpose memories . The memory is a consecutive random access memory RAM that is accessible by the audio engine and the audio traffic controller . Further the DSP the MPU and the DMA may access the memory through the OCP local interconnect . In one or more embodiments of the invention the size of the memory is 64 KB.

The memory is configured to store circular buffers of audio samples managed by the audio traffic controller the stack of the audio engine and an interrupt request IRQ configuration table. As is explained in more detail below the memory is also configured to receive and store data from a host e.g. the MPU that indicates to the audio engine which of the audio processing use cases stored in the program RAM is to be executed. The memory is also configured to store various buffers e.g. ping pong buffers used to receive audio samples from the DSP and or the MPU for processing by the audio engine and a post buffer used to hold audio samples after mixing for further processing such as echo cancellation. The size of each of these buffers is programmable.

The three special purpose memories are the coefficient RAM the sample RAM and the program RAM . Each of these memories is accessible by the audio engine and by other components in the audio backend and the hosts i.e. the DSP the MPU and the L3 interconnect via the OCP local interconnect . The coefficient RAM is used to store coefficients needed for digital filtering processes stored in the program RAM . In one or more embodiments of the invention the coefficients are tuned for the acoustic properties of components of the mobile phone .

The sample RAM is configured to store PCM audio samples received from the various components in the audio backend e.g. the McBSPs . The sample RAM is used as working memory by the components of the audio backend .

The program RAM is configured to store signal processing processes e.g. filters sample rate converters equalizers side tone to be executed by the audio engine to process audio signals. The program RAM also stored audio processing use case definitions that may be invoked by a host in the SOC . An audio processing use case specifies the signal processing processes that are to be performed and the order in which they are to be performed for a specific audio processing event occurring on the mobile phone . Audio processing use cases may be defined for example for events such as a voice call occurring during MP3 playback MP3 playback through the McPDM interface MP3 playback when a ring tone occurs a voice call managed by the DSP etc. In operation a host e.g. the MPU determines what use case is to be performed by the audio engine based on current audio processing and incoming audio signals and loads data into the memory that describes to the audio engine which of the use cases to perform.

The audio traffic controller is configured to manage the transfer of audio sample data between all components of the audio backend . More specifically the audio traffic controller is configured to perform data reads and data writes from to memories and peripherals of the audio backend . The data reads and writes may include DMA requests from all components in the audio backend .

The audio engine is configured to perform the real time applications of the audio backend such as mixing muxing filtering volume control smooth muting anti pop acoustic protection sample rate conversion side tone and equalization. Processing in the audio engine is based on a loop which is started when a predefined event occurs. The predefined start event may come from an event generator not shown from a mapped command from a host or from an external DMA request. For example an audio interface typically includes a FIFO queue to hold audio samples received from the audio backend . Samples are removed from the queue and sent to a device connected to the interface. When the queue content goes below a threshold a DMA request is sent to the audio traffic controller to refill the queue. In response to this request the audio backend initiates a processing loop to provide the samples.

More specifically in one or more embodiments of the invention when the DSP begins to receive and decode audio samples the voice audio buffer is created in the memory of the audio engine subsystem and the DSP decoded audio samples are sent to the voice audio buffer . Similarly when the MPU begins to receive and decode audio samples the audio buffer is created in the memory and the MPU decoded audio samples are sent to the audio buffer . Further the audio paths for the DSP and the MPU in the audio backend may be configured according to the characteristics of the respective audio samples. The decoded audio samples in the audio buffers are subsequently mixed by the digital real time mixer under control of the audio engine to produce a composite audio signal. In one or more embodiments of the invention pre processing such as for example source rate conversion may be performed on the decoded audio samples prior to mixing. The digital real time mixer is configured to sum mono or stereo downlink voice flow with stereo audio data flow. The digital real time mixer is also configured to mix ring tones from a separate path with voice and or stereo flows. The composite audio signal from the digital real time mixer may undergo further processing again under control of the audio engine before being sent to the audio analog subsystem where the composite audio signal is converted to analog and sent to a peripheral device.

The MPU operating system may be any operating system suitable for a mobile device. Examples of such operating systems include WinCE and Linux Kernel V2.6. The DSP operating system may be any suitable operating system such as for example DSP BIOS from Texas Instruments. The audio decoders on the MPU and the DSP may include decoders for audio formats such as Advance Audio Coding AAC Adaptive Multi Rate AMR G.7xx MPEG 1 Audio Layer 3 MP3 and Windows Media Audio WMA . The encoders may be G.7xx encoders. The MPU audio manager includes functionality to manage the audio processing on the MPU . Similarly the DSP audio manager includes functionality to manage the audio processing on the DSP . Functionality in the audio managers may include loading and configuring any software needed e.g. a decoder or encoder to perform audio processing tasks for the applications .

The audio interface manager includes functionality to manage the distribution of audio processing between the MPU and the DSP in accordance with the audio processing needs of the applications . More specifically the audio interface manager provides an interface for the applications to request audio processing. The requests from the applications may specify audio processing functionality that is available only on one processor or may allow the audio interface manager to select a processor for performing the audio processing. Because the audio paths for the two processors are independent and programmable the audio interface manager may use either processor for many audio processing needs. In one or more embodiments of the invention the audio interface manager may monitor the processing load on both processors and select a processor for a new audio processing task based on both the current processing load and the audio processing capability available for each processor. Further in some embodiments of the invention the audio interface manager may move audio processing tasks from one processor to the other based on changing requirements of the applications . Once a processor is selected for performing an audio processing task the audio interface manager communicates with the audio manager on the selected processor to cause the required audio processing to be performed.

The audio backend interface abstracts the audio routing and low level audio processing features of the audio backend . In one or more embodiments of the invention the audio backend handles digital mixing of decoded audio streams from the MPU and the DSP and post processing i.e. gain control filtering equalization and acoustic shock protection of the mixed audio stream and or audio streams from external peripherals. In one or more embodiments of the invention the MPU audio manager and the DSP audio manager may communicate directly with the audio backend interface to access audio processing features of the audio backend . In some embodiments of the invention the audio managers may communicate with the audio backend interface through an interface provided by the audio interface manager . Whether the communication is direct or through the audio backend interface the audio managers interact with the audio backend interface to configure the audio paths for the respective processors and to provide decoded audio samples to the audio backend .

The audio backend interface provides an application programming interface API for controlling aspects of the audio backend such as clocking of the serial ports control of the digital microphone clocks watchdog and general purpose timer control the audio traffic controller control of the audio buffers and the audio engine control of code parameters and use case loading and data mapping in the memory . The audio backend interface also manages the virtual to physical addressing of OCP peripherals. The audio backend interface also provides for configuration of the signal processing features in the audio backend such as acoustics shock protection mono stereo conversion equalization side tone filtering test loops dynamic range optimization AGC and sample rate conversion. The API includes both a high level public interface and a low level interface for direct access to hardware registers in the audio backend .

The API may include interfaces for five operations open parameter set read write and close. For example a software PCM interface may follow the following pseudo code 

In one or more embodiments of the invention the audio backend interface defines internal and external ports as source and sink of samples. Internal ports are originated from the DMA and direct host CPU accesses. External ports correspond to the serial port hardware peripherals. A channel connects an audio port to an external peripheral. Programming of the audio backend through the audio backend interface establishing and configuring the channels. The audio backend interface defines through the API the connection to the input and output ports. It defines the parameters of each port to allow the audio engine to make the necessary translation to the internal computation format e.g. 24 bit sample width stereo and 48 kHz for an audio stream. The audio backend interface also provides an interface for configuring digital mixing operations between audio streams and to tune the post processing gain equalizer etc . . . to apply on the composite samples from the real time digital mixer .

For this use case two circular buffers in the memory are used to send and receive samples to from the McPDM interface the circular buffer IN for receiving outgoing voice audio samples from the McPDM interface and the circular buffer OUT for sending the mixed MP3 and incoming voice audio samples i.e. the composite audio samples to the McPDM interface . In addition three PING PONG buffers in the memory are used one for the MP3 playback audio samples from the MPU one for the incoming downlinked voice audio samples from the DSP and one for the outgoing uplinked voice audio samples. As would be known by one of ordinary skill in the art ping pong buffering is a buffering technique in which a pair of buffers is used to receive transmissions. In this buffering technique one of the buffers receives transmissions while the other buffer is being processed. The two buffers alternate functions which helps keep transmissions close to continuous.

In the example of MP3 playback is in progress i.e. an MP3 use case is executing on the mobile phone when a voice call is received. The voice call sample frequency is assumed to a multiple of the McPDM frame frequency. With the incoming call a new use case is to be initiated in the audio backend to handle the combination of the voice call and the MP3 playback. The required buffers in the memory are configured by the host which is assumed to be the MPU . Because MP3 playback is in progress the PING PONG buffers for MP3 playback are already in the memory . However the two circular buffers IN and OUT for the McPDM interface and the downlink DL and uplink UL PING PONG buffers are created in the memory . The DL PING buffer is filled with the first decoded voice frame from the DSP . Various processing activities of this example are explained in reference to the circled reference numbers in .

At circle around the McPDM interface sends a DMA request to the audio traffic controller to request more audio samples from the OUT circular buffer when a threshold is reached in a buffer in the McPDM interface . In other words a buffer for sending audio samples out in the McPDM interface is empty or almost empty and more samples are requested. The audio traffic controller executes the transfer between the OUT circular buffer and the buffer in the McPDM interface . The audio samples in the OUT circular buffer may composite audio samples from mixing MP3 samples from the MP3 PING PONG buffers with voice downlink samples from the DL PING PONG buffers.

At circle around in parallel with circle around the McPDM interface sends a DMA request to the audio traffic controller to request transfer of received voice samples from a buffer in the McPDM interface to the IN circular buffer. The audio traffic controller executes the transfer between the buffer in the McPDM interface and the IN circular buffer.

At circle around in parallel with circle around the audio engine receives a start event from either from an event generator or a McPDM request to indicate audio samples are present to be processed. The audio engine processes samples from the MP3 PING buffer and the DL PING buffer the processing including digitally mixing the samples and writes the resulting composite audio samples to the OUT circular buffer. The audio engine may also process incoming voice samples in the IN circular buffer and write the processed audio samples in the UL PING buffer.

At circle around in parallel with circle around the audio engine requests more decoded audio samples from the DSP to fill the DL PONG buffer when a processing threshold in the DL PING buffer is reached. Also if a threshold in the UL PING buffer is reached the audio engine requests that the DSP take the audio samples in the UL PING buffer. Also when this threshold is reached the audio engine begins filling the UL PONG buffer with uplink voice samples.

At circle around in parallel with circle around the audio engine requests more decoded audio samples from the MPU to fill the MP3 PONG buffer when a processing threshold in the MP3 PING buffer is reached.

The audio samples decoded by the processors are subsequently processed in independent audio paths. More specifically the decoded audio samples are received in separate audio buffers . That is the decoded audio samples from one processor are received in one audio buffer and the decoded audio samples from the second processor are received in another separate audio buffer. In one or more embodiments of the invention the audio buffers are created in a memory of an audio backend coupled to the processors that is accessible by the processors through separate ports provided in the audio backend for the two processors.

The decoded audio samples in the separate audio buffers are then mixed using a hardware digital mixer to generate a composite audio stream . In some embodiments of the invention pre processing such as sample rate conversion may be performed on decoded audio samples from one or both of the audio buffers before the mixing is performed. Optionally post processing may be performed on the composite audio stream . The post processing may include equalization sample rate conversion etc. The composite audio stream is then provided to a digital to analog converter DAC for presentation to the user of the mobile device through a peripheral. The audio streams processed by the method may include audio streams in any encoded format including for example an AAC encoded audio stream and an MP3 encoded audio stream a voice call audio stream and an AAC or MP3 encoded stream an external stereo audio stream e.g. FM radio and a voice call audio stream etc.

While the invention has been described with respect to a limited number of embodiments those skilled in the art having benefit of this disclosure will appreciate that other embodiments can be devised which do not depart from the scope of the invention as disclosed herein. For example one of ordinary skill in the art will appreciate other embodiments having more than two processors on an SOC configured to process audio streams each of the audio streams possibly having different characteristics e.g. encoding formats sample rates etc. . In such embodiments independent audio pathways in an audio backend are provided for each of the multiple processors and the real time hardware mixer mixes the decoded and possibly pre processed audio samples from each of the multiple processors. Accordingly the scope of the invention should be limited only by the attached claims. It is therefore contemplated that the appended claims will cover any such modifications of the embodiments as fall within the true scope and spirit of the invention.

