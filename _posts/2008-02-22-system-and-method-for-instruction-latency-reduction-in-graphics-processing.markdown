---

title: System and method for instruction latency reduction in graphics processing
abstract: A system, method and apparatus are disclosed, in which an instruction scheduler of a compiler, e.g., a shader compiler, reduces instruction latency based on a determined instruction distance between a dependent predecessor and successor instructions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08098251&OS=08098251&RS=08098251
owner: QUALCOMM Incorporated
number: 08098251
owner_city: San Diego
owner_country: US
publication_date: 20080222
---
This disclosure relates to reducing instruction latency in program code used in graphics processing and more particularly to reducing instruction latency in shaders used in graphics processing.

A graphics processing unit GPU is a dedicated graphics rendering device used to generate computerized graphics for display on a display device. A GPU is typically used with a general purpose central processing unit CPU to process graphic image data e.g. three dimensional computerized graphic image data. In such a case a GPU can implement a number of primitive graphics operations to create three dimensional images for display on a display device more quickly than using a CPU to draw the image for display on the display device. Typically a GPU includes hardware that implements some number of the complex algorithms in hardware.

A typical GPU receives an image geometry and uses a pipeline approach to generate graphics which can be output for example for display on a display device. A typical graphics pipeline includes a number of stages which operate in parallel with the output from one stage possibly being used at another stage in the pipeline. For example a typical graphics pipeline comprises vertex shader primitive assembly viewport transformation primitive setup rasterization hidden primitive and pixel rejection attribute setup attribute interpolation and fragment shader stages.

A vertex shader is applied to the image geometry for an image and generates vertex coordinates and attributes of vertices within the image geometry. Vertex attributes include for example color normal and texture coordinates associated with a vertex. Primitive assembly forms primitives e.g. point line and triangle primitives from the vertices based on the image geometry. Formed primitives can be transformed from one space to another using a transformation e.g. a viewport transformation which transforms primitives from a normalized device space to a screen space. Primitive setup can be used to determine a primitive s area edge coefficients and perform occlusion culling e.g. backface culling and 3 D clipping operations.

Rasterization converts primitives into pixels based on the XY coordinates of vertices within the primitives and the number of pixels included in the primitives. Hidden primitive and pixel rejection use the z coordinate of the primitives and or pixels to determine and reject those primitives and pixels determined to be hidden e.g. a primitive or pixel located behind another primitive or pixel in the image frame a transparent primitive or pixel . Attribute setup determines attribute gradients e.g. a difference between the attribute value at a first pixel and the attribute value at a second pixel within a primitive moving in either a horizontal X direction or a vertical Y direction for attributes associated with pixels within a primitive. Attribute interpolation interpolates the attributes over the pixels within a primitive based on the determined attribute gradient values. Interpolated attribute values are sent to the fragment shader for pixel rendering. Results of the fragment shader can be output to a post processing block and a frame buffer for presentation of the processed image on the display device.

Shaders e.g. vertex and fragment shaders are typically computer programs that compute and control the attributes of primitives e.g. vertices or pixels used in graphics or other multi media systems. Shaders are typically written in a programming language such as a high level or low level programming language for example. A high level programming language can be the C programming language and the like. An assembly language is an example of a low level language.

A shader compiler acts as a translator that translates shader program code written in a high level or low level language into a machine level language. In a case that the shader is written in a high level language the translator translates the shader program code from the high level language in which it is written into a low level language and then translates the low level shader program code into machine level instructions. An instruction scheduler of the shader compiler reorders the machine instructions of the shader in an effort to speed up shader execution. In addition the shader compiler addresses time constraints of the hardware by inserting dummy instructions e.g. no operations or NOPs to make the shader conform to the timing constraints of the hardware that executes the shader.

It would be beneficial to be able to optimize a shader s instructions while taking into account hardware constraints.

The present disclosure seeks to address failings in the art and to provide one or more methods apparatuses and computer readable media for use in optimizing scheduling of instructions to implement at least a portion of a graphics processing pipeline e.g. a shader such as a vertex shader and or a fragment shader.

In accordance with one or more embodiments a dependence between two instructions in graphics processing instructions is identified one of the two instructions comprising a predecessor instruction and another of the two instructions comprising a successor instruction. An initial edge latency associated with the dependence between the predecessor and successor instructions is determined. An instruction distance corresponding to the predecessor and successor instructions is determined and is used to reduce the initial edge latency by the determined instruction distance to determine a reduced edge latency associated with the dependence between the predecessor and successor instructions. The graphics processing instructions can implement a shader such as a vertex shader or a fragment shader for example.

In accordance with one or more embodiments a reduced edge latency determined by reducing an initial edge latency by a determined instruction distance is used to schedule execution of a successor instruction. In accordance with one or more embodiments a number of synchronizing instructions e.g. an independent shader instruction or NOP to be executed prior to commencing execution of the successor instruction is determined so as to synchronize execution of the successor instruction with a predecessor instruction.

In accordance with one or more embodiments an initial edge latency is a hardware latency associated with a predecessor instruction and or a dependence between the predecessor and successor instructions comprises a flow dependence such that a destination of the predecessor instruction is a source of the successor instruction.

In accordance with one or more embodiments a dependence between two instructions in graphics processing instructions is identified one of the two instructions comprising a predecessor instruction and another of the two instructions comprising a successor instruction. An initial edge latency associated with the dependence between the predecessor and successor instructions is determined. An instruction distance corresponding to the predecessor and successor instructions is determined and is used to reduce the initial edge latency by the determined instruction distance to determine a reduced edge latency associated with the dependence between the predecessor and successor instructions. The instruction distance is determined by determining a mask distance for each source operand of the successor instruction that corresponds to a destination operand of the predecessor instruction and selecting a smallest mask distance from the determined mask distances as the instruction distance.

In accordance with one or more embodiments a mask distance associated with a source operand and used in determining an instruction distance is determined by determining a component mask for the destination operand of the predecessor instruction and a component mask for the source operand of the successor instruction generating a component string by concatenating the destination operand s component mask and the source operand s component mask determining a component distance associated with each component in a component set using the component string and identifying a smallest component distance of the determined component distances as the mask distance for the source operand.

In accordance with one or more embodiments a component distance associated with each component in a component set is determined by examining the component string to locate a first occurrence of the component in the component string in a case that a first occurrence of the component is located examining the component string to locate a second occurrence of the component in the component string the second occurrence being after the first occurrence in the component string and in a case that a second occurrence of the component is located determining a number of components between the first and second occurrences of the component in the component string and setting the component distance for the component to the determined number of components.

In accordance with one or more embodiments the graphics processing instructions implement a vertex shader the component set comprises X Y Z and W components and the component distance is determined for each one of the components X Y Z and W component in the component set. In accordance with one or more embodiments the graphics processing instructions implement a fragment shader the component set comprises R G B and A components and the component distance is determined for each one of the components R G B and A component in the component set.

This brief summary has been provided so that the nature of the invention may be understood quickly. A more complete understanding of the invention can be obtained by reference to the following detailed description of the preferred embodiment s thereof in connection with the attached drawings.

Certain embodiments of the present disclosure will now be discussed with reference to the aforementioned figures wherein like reference numerals refer to like components.

In accordance with one or more embodiments a system method and apparatus are disclosed in which an instruction scheduler of a compiler e.g. a shader compiler reduces instruction latency based on a determined instruction distance between dependent predecessor and successor instructions. In accordance with one or more embodiments of the present disclosure a shader compiler comprises an instruction optimizer and instruction scheduler that addresses hardware timing constraints and minimizes schedule length e.g. the number of instructions in an instruction execution schedule. While instruction scheduling optimization is disclosed herein with reference to instructions that implement a shader it should be apparent that embodiments of the present disclosure need not be limited to optimization of instructions that implement a shader. Embodiments of the present disclosure can be used to optimize scheduling of any instructions computer program program code or program or program code segment. By way of a non limiting example one or more of the embodiments disclosed herein can be used with any programming language that supports native vectors that consist of multiple components e.g. two three or four components and any program or program segment that is defined using such a programming language.

In the example of computing device includes a central processing unit CPU GPU and a memory module e.g. a random access memory RAM memory module or modules. CPU GPU and memory module communicate using a bus which can comprise any type of bus or device interconnect now known or later discovered. CPU can comprise a general purpose or a special purpose microprocessor. For example CPU may comprise a Core 2 Processor provided by Intel Corporation of Santa Clara Calif. or another type of microprocessor. GPU is a dedicated graphics rendering device. GPU can be integrated into the motherboard of computing device can be present on a graphics card that is installed in a port in the motherboard of computing device or can be otherwise configured to interoperate with computing device for example.

Display unit which is coupled to computing device can comprise a monitor a television a projection device a liquid crystal display a plasma display panel a light emitting diode LED array a cathode ray tube display electronic paper a surface conduction electron emitted display SED a laser television display a nanocrystal display or another type of display unit for example. In the example of display unit can be a part of computing device . For instance display unit can be a screen of a mobile telephone. Alternatively display unit can be external to computer device and can be in communication with computing device via a wired or wireless communications connection or other connection for example. By way of a non limiting example display unit can be a computer monitor or flat panel display connected to a personal computer via a wired or wireless connection.

A software application can be executed via CPU . Software application can comprise any software application capable of executing via CPU such as a video game a graphical user interface engine a computer aided design program for engineering or artistic applications or another type of software application that uses two dimensional 2D or three dimensional 3D graphics by way of non limiting examples.

When CPU is executing software application software application can invoke subroutines of a graphics processing application programming interface API such as any one or more of an OpenVG API an OpenGL API a Direct3D API a Graphics Device Interface GDI Quartz QuickDraw or another type of 2D or 3D graphics processing API by way of non limiting examples.

In accordance with at least one embodiment when software application invokes a subroutine of graphics processing API graphics processing API invokes one or more subroutines of a GPU driver which execute via CPU on computing device . GPU driver can comprise a set of software and or firmware instructions that provide an interface between graphics processing API and GPU for example. When graphics processing API invokes a subroutine of GPU driver GPU driver formulates and issues a command that causes GPU to generate displayable graphics information. A shader compiler in accordance with one or more embodiments disclosed herein can be a component e.g. a software module of GPU driver . GPU driver uses the shader compiler to translate a shader program into machine level instructions and communicate the instructions to GPU . For example when graphics processing API invokes a subroutine of GPU driver to render a batch of graphics primitives GPU driver provides GPU with a processing configuration which GPU uses to render the batch of graphics primitives. GPU renders the batch of graphics primitives and outputs a raster image of the graphics primitives for example.

A command formulated by GPU driver can identify graphics processing configuration s that GPU is to use to perform the command which configuration s can identify a set of instructions to be executed by GPU a set of state register values and other types of information that GPU might need to perform the command.

In a case that GPU driver stores the graphics processing configuration s in memory GPU driver can reference the storage locations in memory module corresponding to the graphics processing configuration s in the command formulated by GPU driver . When GPU receives the command GPU can retrieve from memory the graphics processing configuration s referenced in the command received from GPU driver .

In accordance with at least one embodiment command decoder of GPU decodes the command from GPU driver and configures one or more of processing elements to perform the command. By way of a non limiting example command decoder retrieves the graphics processing configuration s from memory and loads a set of instructions identified by the graphics processing configuration s into processing element s . Command decoder can also be configured to provide input data to one or more processing elements .

In accordance with one or more embodiments processing elements implement a graphics pipeline . In accordance with such embodiments processing elements can implement graphics pipeline in a parallel mode. In a parallel mode processing elements can operate on data in parallel with output from processing element being used as input to another processing element . By way of a non limiting example processing element A performs a first graphics operation on a first set of initial input data received from command decoder and outputs a first set of intermediate results to processing element B. The initial input data can comprise data corresponding to one or more vertices which data can comprise coordinate and attribute data for example. Vertex coordinates identify a location within an image based on for example a four dimensional coordinate system with X Y and Z width height and depth coordinates and a W coordinate that comprises a perspective parameter. Vertex attributes can include color normal and texture coordinates associated with a vertex for example. Processing element B can perform another graphics operation on the first set of intermediate results output by processing element A and output a second set of intermediate results to another of the processing element and so on. While processing element B is performing the second graphics operation processing element A can be performing the first graphics operation on a second set of initial input data received from command decoder .

Processing elements can continue in this manner until processing element N outputs a pixel object to one or more buffers in memory module or output this new pixel object to some other destination. A pixel object is data that describes a pixel. Each pixel object may specify multiple color values and can specify a transparency level of the pixel. In some circumstances a pixel object may specify a first color in a first color format and a second color in a second color format.

In accordance with one or more embodiments of the disclosure one of processing elements comprises a programmable processing element that can be configured as a vertex shader unit that performs one or more vertex shading operations each of which operate on vertex data e.g. X Y Z and W component data. Similarly the same or another one of the processing elements comprises a programmable processing element that can be configured as a fragment shader that performs one or more fragment shading operations each of which operate on pixel data e.g. R G and B component data.

In accordance with one or more embodiments of the present disclosure a compiler generates program code that includes instructions that are to be executed by the programmable processing element to perform shader operations e.g. vertex shader or fragment shader operations. provides an example of a compiler that compiles program code e.g. shader program code. The compiler comprises at least one translator . Translator translates the shader program code which includes a set of instructions written in either a high level programming language or an assembly language into machine level instructions recognizable by the programmable processing element . Instruction scheduler of compiler schedules the instructions for execution by the programmable processing element .

An input list comprising a group of machine level or machine executable instructions that are to be scheduled is input to the instruction scheduler . Instructions in an input list that do not depend on or conflict with any other instructions are moved from the input list to a ready list. The ready list stores all instructions that are ready to be scheduled for execution. An instruction is moved from the ready list to an active list when it is scheduled. An active list stores instructions that are currently being executed. An instruction is moved from the active list to a result list when it completes execution. A result list stores instructions that have been scheduled and have completed execution. A result list comprises an output of an instruction scheduler.

Gating conditions that control when instructions are moved from one list to another are calculated using a dependence graph which identifies static latencies. By way of a non limiting example a dependence exists between two instructions I and I if one instruction I relies on the result of the other instruction I or a resource conflict exists between the two instructions. If a dependence exists between the two instructions and instruction I precedes I instruction I is considered to be a predecessor instruction and instruction I is a successor instruction. A dependence graph can be used to designate a dependency between the two instructions.

A predecessor instruction P can have a number n of successor instructions S . . . Sn where n can be greater than or equal to zero. Each successor instruction S can have a number n of predecessor instructions P . . . Pn which include predecessor instruction P.

When a successor instruction s dynamic latency is greater than or equal to one of its static or edge latencies the successor instruction can be removed from the predecessor instruction s successor list and the predecessor instruction can be removed from the successor s predecessor list. As time progresses e.g. execution cycles occur and dynamic latencies increase more successor and predecessor instructions can be removed. An instruction that is on the active list is complete when all of its successors are removed from the successor list and an instruction on the input list is ready to be executed when all of its predecessors are removed. It is therefore beneficial to be able to minimize static edge latencies e.g. to accelerate a timing of execution of a successor instruction. Advantageously a reduction in edge latencies identified using one or more embodiments of the present disclosure improves schedule quality and results in more compact code.

A programming language in which a shader is written can include special language constructs to satisfy special graphics and multimedia needs. The special shader programming languages and the general purpose programming languages e.g. C and the like support similar data types arrays structs statements and functions. While shader programming languages may not be as flexible as general purpose languages and may have some limitations on some general features shader programming languages have some additional features that are not supported in general purpose languages. For example shader languages can provide support for native vectors that consist of multiple components e.g. two three or four components. General purpose programming languages usually do not have native support for such vectors.

Typical primitives used in shaders comprise colors and vertices e.g. vectors such as red green blue R G B or X Y Z W . Use of multiple component vectors makes shader compilers more complex than compilers that compile general purpose language. Embodiments of the present disclosure use the extra information to reduce latency and to improve instruction scheduling. In accordance with one or more such embodiments the features of the shader programming languages involving vectors and their attributes are analyzed to reduce edge latencies such that a timing of execution of an instruction awaiting execution can be reduced scheduling can be improved and code can be more compact for example.

There are a number of types of dependencies between instructions. A flow or true dependency exists between two instructions I and I where I uses the output of I. A true dependency can be determined by examining the register numbers and component indices referenced by the two instructions. By way of a non limiting example instruction I is a successor of instruction I and uses as at least one of its source operands a register and component e.g. X component output by instruction I.

An output dependence exists between instructions I and I in a case that both instructions output to the same register. By way of a non limiting example instructions I and I output to register R. A control dependency exists between instructions I and I in a case that the execution flow is determined by the outcome of a logical operation e.g. if else conditional. An anti dependence exists between instructions I and I in a case that the output of instruction I uses the same register as the input of instruction I.

In accordance with one or more embodiments an initial edge latency can be determined based on a hardware latency associated with the predecessor instruction. In a case that instructions I and I are dependent and the dependence is a true dependence the full hardware latency can be used as the initial edge latency which can be reduced by a determined instruction distance. In accordance with one or more such embodiments additional analysis is performed to determine whether or not the edge latency initially determined to be the hardware latency of the predecessor instruction can be reduced by the determined instruction distance. Embodiments of the present disclosure address can be used to set an edge latency in cases other than a case in which the flow dependence and a fixed hardware latency exists. For example if a false dependence exists such as anti dependence or an output dependence edge latency can be set to one in accordance with one or more embodiments.

A hardware latency is typically identified by hardware designers of the programmable or other processing unit that executes the instruction. The hardware latencies can be provided as part of a latency table that identifies the hardware latency for each of the instructions available for execution by the programmable unit. The following provides a formal equation for determining a hardware latency HARDWARE LATENCY 1 2 latency provided by hardware designers for scalar instructions 1 and 2.

The following provides examples of the above equation where the scalar instructions I and I are both ADD and where I is an ADD instruction and I is a BRANCH instruction. HARDWARE LATENCY ADD ADD 6 HARDWARE LATENCY ADD BRANCH 10

The following provides a non limiting example of an instruction syntax used herein. In this example it is assumed that a flow dependence exists between instructions I and I such that n is the same value for both instructions I and I and that I defines at least one component used in instruction I.

Instruction I above defines register Rn with component index c and the instruction repeats i 1 times. Instruction I uses register Rn with component index d and the instruction repeats j 1 times. The component index can point to one or more of X Y Z or W for example. As part of this non limiting example it is assumed that the operand component index increments each time one or the other of the instructions repeats. Vector forms of the above instructions can be used to determine the dependence cies between the two instructions. The following provides vector forms resulting from a transformation of the above scalar instructions 

Mask and mask identify the components pointed to by the respective component index of instruction I and I. Since both instruction I and I operate on register n an examination of the component masks mask and mask can determine whether or not instruction I depends on instruction I. Component masks can contain one or multiple components. Examples of components include without limitation RGB and XYZW. Examples of components masks include without limitation XYZW YZWX XY Z. If mask and mask overlap in the sense that they share at least one component there is dependence. If there is true or flow dependence the full machine latency is used as the initial edge latency. The initial edge latency of a dependence edge from I to I is INITIAL LATENCY 1 2 HARDWARE LATENCY 1 2 Eq. 1

In accordance with one or more embodiments Equation 1 identifies an initial edge latency which can be reduced by a determined distance an instruction distance between two dependent instructions as illustrated in Equation 2 formalized below EDGE LATENCY 1 2 HARDWARE LATENCY 1 2 INSTRUCTION DISTANCE Eq. 2

In accordance with one or more embodiments instruction distance can be determined using a component mask component string component distance and component mask distance. A component mask is a mask constructed from operands of a compressed scalar instruction. A compressed scalar instruction can repeat itself by incrementing component indices or keeping the indices. The following provides an example of a compressed scalar instruction 

where the 2 following the indicates that the instruction is repeated twice after an initial execution of the instruction i.e. the instruction is executed a total of three times. The associated with the first and second operands R and R indicate that the component indices corresponding to the two operands is to be incremented after the first and second executions of the instruction. In the example the instruction is performed an initial time and is repeated twice. The compressed scalar instruction is an equivalent of the next three uncompressed scalar instructions 

The first execution E of the uncompressed instruction uses registers R R and R and the X Y and X components respectively. The execution E of the uncompressed instruction results in the X and Y component values associated with the R and R registers being added and the result being stored in the X component associated with register R. The component indices associated with the R and R registers are incremented as indicated by the associated with each of R and R registers. In the second execution E of the uncompressed instruction the components associated with the R and R registers are the Y and Z components respectively. The component associated with the R register is unchanged i.e. the X component. The second execution E adds the Z and X component values associated with the R and R registers and the result is stored in the Y component associated with the R register. After incrementing the component indices associated with the R and R registers such that the components associated with the R and R registers are Z and W respectively the third execution E of the uncompressed instruction adds the W and X component values associated with registers R and R and stores the result in the Z component associated with the R register.

The component masks for each of the registers R R and R are XYZ YZW and X respectively. To further illustrate the component mask for the R register is formed using the components of the R register used in each execution E to E of the uncompressed scalar instruction i.e. X Y and Z respectively. Similarly the component mask associated with the R register is formed from the Y Z and W components used in instruction executions E to E and the component mask associated with the R register is formed from use of the register s X component in all three of the instruction executions E to E.

In accordance with one or more embodiments unlike swizzle masks used in vector instructions a mask constructed from scalar instructions having duplicate components in the mask is an invalid component mask. For example and in accordance with such embodiments XXY is a valid swizzle mask but it is not a valid component mask.

A component string is generated by concatenating component masks e.g. two component masks from predecessor and successor instructions. For example the concatenation of component masks XYZW and XY forms a component string XYZWXY. A component distance COMPONENT DIST C S where C represents a component e.g. one of X Y Z or W and S represents the component string can be defined to be the number of component occurrences other than component C between two occurrences of component C in component string S. The distance is positive infinity INF if there is no or one occurrence of the component C in the component string S.

The following provides examples of component distance calculations using component string XYZWXY as S and components X Y Z and W as C COMPONENT 3 COMPONENT 3 COMPONENT COMPONENT 

In the first component distance determination using component X there are two occurrences of X and three components YZW exist or occur between the two occurrences of X in the component string. In the second component distance determination using component Y there are three components YZW that occur between occurrences of Y. In the next two component distance determinations involving Z and W there is only one occurrence of both of these components in the component string. The component distance is therefore set to INF.

A component mask distance can be determined to be the smallest component distance of the component distances determined using the component string formed by concatenating component masks M and M. The following Equation 3 provides a formalization of a component mask distance determination in accordance with one or more embodiments MASK 1 2 smallest where is the concatenation of 1 and 2. Eq. 3

An operand distance can be defined to be a component mask distance determined using the masks associated with a source operand and a destination operand that use the same register e.g. the destination operand used in a predecessor and a source operand in a successor instruction. The operand distance is the mask distance determined using Equation 3. For example M is equal to the concatenation of the component mask associated with the operand in the predecessor instruction and the component mask associated with the operand in the successor instruction.

In accordance with one or more embodiments an instruction distance is defined to be the smallest mask distance or operand distance of the mask distances of operands e.g. each operand that is shared between two dependent instructions. There can be one or multiple source operands in the successor instruction that use the same register that is defined by the predecessor instruction. In a case that there are multiple source operands using the same register multiple mask distances can be calculated and the smallest one is chosen as the distance between the two instructions. In accordance with one or more embodiments an instruction distance between two dependent instructions I and I with I being the predecessor instruction and I being the successor instruction can be formalized as follows 1 2 smallest MASK 1 Eq. 4

The determined instruction distances between the output destination of I R.XYZ and the first and second input sources of I are 2 and 1 respectively. Thus the distance between I and I in the above sample instructions can be expressed as follows INSTR 1 2 1

As discussed above embodiments of the present disclosure reduce an initial edge latency by the instruction distance. The following Equation 5 provides a formalization of an edge latency determination used in accordance with one or more embodiments EDGE LATENCY 1 2 max 1 HARDWARE LATENCY 1 2 1 2 Eq. 5

A programmable shader unit supports a number of instruction types including without limitation ALU ELU FLOW and MEM. ALU instructions comprise arithmetic and logical instructions such as without limitation ADD MUL and MOV. ELU instructions comprise elementary function instructions such as without limitation EXP LOG and COS. FLOW instructions comprise control flow instructions such as without limitation JUMP and BRANCH. MEM instructions comprise memory oriented instructions such as without limitation SAMPLE and LOAD. Some types have deterministic hardware latencies such as without limitation ALU. Other instruction types have nondeterministic hardware latencies such as without limitation MEM. An instruction set typically supports a synchronization mechanism e.g. using a WAIT operation for nondeterministic latencies.

For any two instructions I and I that have a dependent relationship and I precedes I one or more embodiments of the present disclosure define edge latencies as follows EDGE LATENCY 1 2 1 if a false dependence such as without limitation an anti dependence or output dependence. Eq. 6 EDGE LATENCY 1 2 1 if the dependence is flow dependence and 1 has a nondeterministic latency. Eq. 7 EDGE LATENCY 1 2 max 1 HARDWARE LATENCY 1 2 1 2 if the dependence is flow dependence and 1 has a fixed deterministic latency. Eq. 8 EDGE LATECNY 1 2 HARDWARE LATENCY 1 2 Eq. 9

The following provides examples illustrating a use of the above edge latency formalizations. For the sake of the example and for purposes of illustration the ALU type instructions are considered have a fixed latency of 5 and an instruction distance of 2 the ELU type instructions have a nondeterministic latency and FLOW type instructions have a latency of 1. Using the exemplary latencies and instruction distance the following edge latencies are determined using the above formalizations. EDGE LATENCY 3 EDGE LATENCY 3 EDGE LATENCY FLOW 3 EDGE LATENCY 3

In the above examples it is assumed that there is a flow dependence between the two instructions and that Equation 8 therefore applies. In each example instruction I is an ALU type instruction that has a fixed latency of 5 and an instruction distance of 2. Assuming that a flow dependence exists between the two instructions I and I Equation 8 is used to determine the edge latency. The initial edge latency of the ALU instruction which corresponds to the ALU type instruction s hardware fixed latency of 5 which is reduced by the instruction distance between the two instructions of 2 or 5 2 3.

At step a determination is made whether or not a dependence exists between two instructions I and I. If there is no dependence the process ends for the current instruction pair and can performed for a next pair of instructions until there are no more instructions to be examined. If it is determined that a dependence exists between the two instructions processing continues at step to determine whether the dependence is a flow dependence and the predecessor instruction e.g. I has a fixed latency. If not processing continues at step of to set the edge latency associated with the two dependent instructions per Equation 6 7 or 9 and processing for the instruction pair ends.

If it is determined at step that a flow dependence exists between the two dependent instructions and the predecessor instruction has a fixed latency processing continues at step to determine at least one component mask for the predecessor and successor instructions. At step a component string is determined at step using the component masks determined for the predecessor and successor instructions. Processing continues at step to determine the instruction distance using the component string determined at step .

More particularly a determination is made at step whether or not any of the operands that are shared by the predecessor and successor instructions remain to be processed. If so processing continues at step to identify the next operand shared by the predecessor and successor instructions e.g. a register used by the predecessor instruction to store output and used by the successor instruction as input. At step a mask distance is determined for the common operand.

With respect to the first source operand of instruction I at step the component masks are MD and MS e.g. the component mask of the predecessor instruction I and successor instruction I respectively. At step MD and MS are concatenated to yield XYZX. Components X Y Z and W are compared to the concatenated string XYZW in steps and to determine a component distance for each component. Table shows the component distance for each component determined using steps and .

With respect to the second source operand of instruction I at step the component masks are MD and MS e.g. the component mask of the predecessor instruction I and successor instruction I respectively. As shown in Table MD is equal to XYZ and MS is equal to Y. At step MD and MS are concatenated to yield XYZY. Components X Y Z and W are compared to the concatenated string XYZY in steps and to determine a component distance for each component. Table shows the component distance for each component determined using steps and .

If it is determined at step that all of the components are processed to determine a component distance processing continues at step to determine a mask distance from the determined component distances. More particularly at step the smallest component distance of the determined component distances is identified and the smallest component distance identified in step is used to set the mask distance at step .

For example and with reference to and Table the smallest component distance determined for MD and MS is equal to 2. As shown in equation the mask distance of MD and MS is set to 2. By way of a further non limiting example as shown in equation the mask distance of MD and MS is equal to 1 i.e. the smallest component distance shown in Table .

Referring again to if it is determined at step that all of the operands shared between the predecessor and successor instructions have been processed processing continues at step to determine an instruction distance. More particularly at step the smallest mask distance of the determined mask distances is identified. By way of a non limiting example and with reference to equations and of the mask distance that corresponds to the second source operand of successor instruction I is smaller than the mask distance that corresponds to the first source operand of the successor instruction I. At step of the smallest mask distance identified in step is used to set the instruction distance. In the example shown in the instruction distance is set to 1 at step .

Referring again to a difference between a predecessor instruction s hardware latency and a determined instruction distance is determined at step . A determination is made at step whether or not the determined difference exceeds one. If not processing continues at step to set the edge latency to one and processing ends for the current instruction pair. If it is determined at step that the determined difference exceeds one processing continues at step to set the edge latency between the two dependent instructions to the difference between the predecessor instruction s hardware latency and the determined instruction distance.

As shown in the example process flow of embodiments of the present disclosure set an edge latency equal to one in a case that the dependence between the predecessor and successor instructions is other than flow dependence or the predecessor instruction does not have a fixed hardware latency. The following provides some non limiting examples.

In the following example instruction I is an ELU type instruction which has a non deterministic latency in the example. Since instruction I has a non deterministic latency Equation 7 is used in each of the following examples such that the edge latency is set to 1 regardless of the value of the initial edge latency. EDGE LATENCY 1 EDGE LATENCY 1 EDGE LATENCY FLOW 1 EDGE LATENCY 1

In the next example instruction I is a MEM type instruction that is assumed to have a dependence with instruction I. In this example and with these assumptions Equation 6 is used such that the edge latency is set to 1 regardless of the value of the initial edge latency. EDGE LATENCY 1 EDGE LATENCY 1 EDGE LATENCY FLOW 1 EDGE LATENCY 1

In the next example instruction I a FLOW type instruction has a hardware latency of 1 and a control dependence rather than a data dependence. In this example Equation 9 and the hardware latency of instruction I are used such that the edge latency is set to 1 the initial edge latency. EDGE LATENCY FLOW 1 EDGE LATENCY FLOW 1 EDGE LATENCY FLOW FLOW 1 EDGE LATENCY FLOW 1

In accordance with one or more embodiments in a case that there are no useful instructions that can be inserted e.g. an independent instruction that implements a portion of the shader the instruction scheduler inserts a number of NOPs or a WAIT instruction to synchronize instruction execution. The following provides examples of shader code scheduled using the exemplary initial edge latencies instruction distances and dependencies discussed above. In the example involving an ALU instruction discussed above an initial edge latency of 5 is reduced by an instruction distance of 2 such that the resulting edge latency is determined to be equal to 3 using Equation 8 in connection with a first instruction I that is an ALU type instruction and a second instruction I that is one of an ELU FLOW and MEM type instruction. An edge latency of 3 indicates that there are to be three execution cycles before the second ALU instruction is executed. Rather than the 4 NOPs that would have been required for a hardware latency of 5 in cases 1 to 4 below two NOPs are inserted between the two instructions I and I. With the first instruction accounting for one execution cycle the two NOP instructions account for the last two execution cycles so that the edge latency of 3 can be accommodated. This results in a reduction of 2 NOPs which reduces execution time results in fewer instructions that are to be executed etc.

Cases 5 to 8 involve an ELU instruction as the predecessor instruction. In the example the ELU instruction has a non deterministic latency which results in the edge latency being set to 1 per equation 7. Since the latency is non deterministic e.g. there is no determinable number of execution cycles or NOPs that are to be performed before the successor instruction is to be executed the successor instruction awaits completion of execution of the ALU instruction.

In cases 9 to 12 the dependence between the predecessor and successor instructions is considered to be a false dependence which results in the edge latency being set to 1 per Equation 7. Since the dependence between the predecessor and successor instructions is a false dependence the successor instruction awaits completion of execution of the predecessor MEM instruction.

In the example of cases 13 to 16 the dependence is considered to be a control dependence which results in the edge latency being set to 1 per Equation 9.

Embodiments of the present disclosure reduce the initial edge latency and removes unnecessary NOPs. For example in cases 1 to 4 the initial edge latency which is equal to 5 is reduced by 2 to 3. Instead of using 4 NOPs which would be required in a case of the initial edge latency only 2 NOPs are used thereby removing two unnecessary NOPs. Typical shaders are computation intensive and include a significant number of cases 1 to 4. Thus a significant savings in execution resources can be achieved using embodiments of the present disclosure.

In accordance with one or more embodiments of the present disclosure an instruction scheduler compares edge latencies to dynamic latencies in order to remove successors and predecessors. Smaller edge latencies result in early removal of successors and predecessors. The more successors and predecessors that can be removed the more instructions can be considered to be independent and thus ready to be scheduled. The more instructions that are ready to be scheduled the less likely NOPs are needed to be inserted into the code to compensate for hardware latencies. A reduction in the number of NOPs that need to be inserted in the scheduled code results in efficiencies in the code that is scheduled and executed. In a case that the code implements a shader embodiments of the present disclosure can be used to identify reductions in edge latencies to optimize scheduling output of the instruction scheduler and to optimize execution of the shader for example. The example discussed above and reproduced below serves to provide an illustrative example 

In a case that the hardware latency between ADD and MUL is 3 absent use of embodiments of the present disclosure the scheduled code would be as follows 

As discussed above an instruction distance determined using at least one embodiment is 1. Using one or more embodiments of the present disclosure an edge latency can be determined to be the hardware latency reduced by the instruction distance. Thus instead of the two NOPs needed in the above scheduled code example only one NOP is used in the following scheduled code example. As illustrated in the below instruction scheduler output the number of NOPs is reducted to one NOP rather than two NOPs in the above case 

The reduction in the number of NOPs is a result of the application of an instruction distance to an initial edge latency e.g. a hardware latency. As discussed above the instruction distance determined in accordance with one or more embodiments for these two instructions is equal to 1. In accordance with one or more such embodiments the hardware latency of the predecessor instruction is reduced by the determined instruction distance to yield a reduced edge latency between the two instructions. As a result of the reduced edge latency the number of NOPs can be reduced from two to one. The edge latency corresponds to two execution cycles with the execution of I corresponding to one of the two cycles and the NOP corresponding to the second execution cycle. Advantageously embodiments of the present disclosure reduce the number of NOPs determined to be unnecessary such that the instruction scheduler can output no more than those NOPs that are necessary to achieve synchronization between two dependent instructions.

In the examples shown in an instruction scheduler using edge latency reduction in accordance with one or more embodiments of the present disclosure effectively reduces the number of NOPs from 48 in the output shown in and D to 40 in the output shown in a reduction of 8 unnecessary NOPs from the shader instructions output of the instruction scheduler.

Examples of the reduction in the number of NOPs can be seen in connection with instructions and . In each case the number of NOPs is reduced from 3 to 1. To illustrate using instruction without use of edge latency reduction the code fragment output by the instruction scheduler as shown in is as follows 

In code fragment both source operands of instruction use the result of instruction namely r18.z. In a case that the hardware latency of fmac is 4 absent use of one or more embodiments of the present disclosure the initial edge latency of 4 is used to determine that 3 NOPs are to be inserted at instruction in order to ensure that the latency requirement of 4 is met. Instruction executes the first NOP and then two repetitions to yield three execution cycles. With the execution of instruction four execution cycles occur before instruction is executed.

In contrast with one or more embodiments of the present disclosure the edge latency is reduced so that only one NOP is used. Code from is reproduced below as follows 

Instructions and are fmac or floating point multiplication and accumulation. Instruction is dependent on instruction since their component masks Z and YZ share at least one component. When applying one or more embodiments an instruction distance between instruction as instruction I and instruction as instruction I that is dependent and succeeds instruction I is determined. The component distance C S is INF for each of the components except Z which has a component distance of 1. The instruction distance is the smallest of the component distances or 1. The instruction distance is determined to be 1 because MASK DIST Z YZ is 1. The destination mask of fmac is Z not ZW because fmac does not increment a component index. With a useful instruction at only one NOP is needed.

In one or more exemplary embodiments the functions described can be implemented in hardware software and or firmware or any combination thereof. If implemented in hardware the functions can be implemented in one or more microprocessors microcontrollers digital signal processors DSPs application specific integrated circuits ASICs field programmable gate arrays FPGAs or the like. Such components can reside within a communication system data writing and or reading system or other systems. If implemented in software the functions can be stored on or transmitted over as one or more instructions or code on a computer readable medium. Computer readable media includes tangible computer storage media and communication media including any medium that facilitates transfer of a computer program from one place to another. A storage media can be any available media that can be accessed by a computer. By way of example and not limitation such computer readable media can comprise RAM Flash memory read only memory ROM electrically erasable programmable read only memory EEPROM compact disc read only memory CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer. The term computer readable medium can also be defined as a tangible computer program product. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

While the apparatus and method have been described in terms of what are presently considered to be the most practical and preferred embodiments it is to be understood that the disclosure need not be limited to the disclosed embodiments. It is intended to cover various modifications and similar arrangements included within the spirit and scope of the claims the scope of which should be accorded the broadest interpretation so as to encompass all such modifications and similar structures. The present disclosure includes any and all embodiments of the following claims.

