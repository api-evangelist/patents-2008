---

title: Adjusting hardware acceleration for video playback based on error detection
abstract: Adjustment of hardware acceleration level in a video decoder utilizing hardware acceleration is described. Errors are detected in a bitstream as it is decoded using different levels of error detection based on decoding characteristics. A statistical analysis is performed on the error values as they are detected. In one technique, if the bitstream is categorized as fitting a high error rate state in a bitstream model, then hardware acceleration is dropped. In another technique, error statistics based on run-lengths of good and bad bitstream units are kept, and compared to predetermined thresholds. If the thresholds are exceeded, the hardware acceleration level is dropped. The level is dropped in order to take advantage of superior error handing abilities of software-based decoding over hardware-accelerated decoding.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09131241&OS=09131241&RS=09131241
owner: Microsoft Technology Licensing, LLC
number: 09131241
owner_city: Redmond
owner_country: US
publication_date: 20081125
---
Companies and consumers increasingly depend on computers to process distribute and play back high quality video content. Engineers use compression also called source coding or source encoding to reduce the bit rate of digital video. Compression decreases the cost of storing and transmitting video information by converting the information into a lower bit rate form. Decompression also called decoding reconstructs a version of the original information from the compressed form. A codec is an encoder decoder system.

Compression can be lossless in which the quality of the video does not suffer but decreases in bit rate are limited by the inherent amount of variability sometimes called source entropy of the input video data. Or compression can be lossy in which the quality of the video suffers and the lost quality cannot be completely recovered but achievable decreases in bit rate are more dramatic. Lossy compression is often used in conjunction with lossless compression lossy compression establishes an approximation of information and the lossless compression is applied to represent the approximation.

A basic goal of lossy compression is to provide good rate distortion performance. So for a particular bit rate an encoder attempts to provide the highest quality of video. Or for a particular level of quality fidelity to the original video an encoder attempts to provide the lowest bit rate encoded video. In practice considerations such as encoding time encoding complexity encoding resources decoding time decoding complexity decoding resources overall delay and or smoothness in quality bit rate changes also affect decisions made in codec design as well as decisions made during actual encoding.

In general video compression techniques include intra picture compression and inter picture compression. Intra picture compression techniques compress a picture with reference to information within the picture and inter picture compression techniques compress a picture with reference to a preceding and or following picture often called a reference or anchor picture or pictures.

For intra picture compression for example an encoder splits a picture into 8 8 blocks of samples where a sample is a number that represents the intensity of brightness or the intensity of a color component for a small elementary region of the picture and the samples of the picture are organized as arrays or planes. The encoder applies a frequency transform to individual blocks. The frequency transform converts an 8 8 block of samples into an 8 8 block of transform coefficients. The encoder quantizes the transform coefficients which may result in lossy compression. For lossless compression the encoder entropy codes the quantized transform coefficients.

Inter picture compression techniques often use motion estimation and motion compensation to reduce bit rate by exploiting temporal redundancy in a video sequence. Motion estimation is a process for estimating motion between pictures. For example for an 8 8 block of samples or other unit of the current picture the encoder attempts to find a match of the same size in a search area in another picture the reference picture. Within the search area the encoder compares the current unit to various candidates in order to find a candidate that is a good match. When the encoder finds an exact or close enough match the encoder parameterizes the change in position between the current and candidate units as motion data such as a motion vector . In general motion compensation is a process of reconstructing pictures from reference picture s using motion data.

The example encoder also computes the sample by sample difference between the original current unit and its motion compensated prediction to determine a residual also called a prediction residual or error signal . The encoder then applies a frequency transform to the residual resulting in transform coefficients. The encoder quantizes the transform coefficients and entropy codes the quantized transform coefficients.

If an intra compressed picture or motion predicted picture is used as a reference picture for subsequent motion compensation the encoder reconstructs the picture. A decoder also reconstructs pictures during decoding and it uses some of the reconstructed pictures as reference pictures in motion compensation. For example for an 8 8 block of samples of an intra compressed picture an example decoder reconstructs a block of quantized transform coefficients. The example decoder and encoder perform inverse quantization and an inverse frequency transform to produce a reconstructed version of the original 8 8 block of samples.

As another example the example decoder or encoder reconstructs an 8 8 block from a prediction residual for the block. The decoder decodes entropy coded information representing the prediction residual. The decoder encoder inverse quantizes and inverse frequency transforms the data resulting in a reconstructed residual. In a separate motion compensation path the decoder encoder computes an 8 8 predicted block using motion vector information for displacement from a reference picture. The decoder encoder then combines the predicted block with the reconstructed residual to form the reconstructed 8 8 block.

Over the last two decades various video coding and decoding standards have been adopted including the H.261 H.262 MPEG 2 and H.263 series of standards and the MPEG 1 and MPEG 4 series of standards. More recently the H.264 standard sometimes referred to as AVC or JVT and VC 1 standard have been adopted. For additional details see representative versions of the respective standards.

Such a standard typically defines options for the syntax of an encoded video bit stream according to the standard detailing the parameters that must be in the bit stream for a video sequence picture block etc. when particular features are used in encoding and decoding. The standards also define how a decoder conforming to the standard should interpret the bit stream parameters the bit stream semantics. In many cases the standards provide details of the decoding operations the decoder should perform to achieve correct results. Often however the low level implementation details of the operations are not specified or the decoder is able to vary certain implementation details to improve performance so long as the correct decoding results are still achieved. Moreover many standards fail to address in a satisfactory way or only partially address how a decoder should react when it detects errors in a bit stream how the decoder should recover from such errors and how the decoder should conceal such errors.

During development of a standard engineers may concurrently generate reference software sometimes called verification model software or JM software to demonstrate rate distortion performance advantages of the various features of the standard. Typical reference software provides a proof of concept implementation that is not algorithmically optimized or optimized for a particular hardware platform. Moreover typical reference software does not address multithreading implementation decisions instead assuming a single threaded implementation for the sake of simplicity. Often reference software fails to address in a satisfactory way or only partially addresses issues of error detection recovery and concealment especially when such issues surface during multithreaded decoding.

While some video decoding and encoding operations are relatively simple others are computationally complex. For example inverse frequency transforms fractional sample interpolation operations for motion compensation in loop deblock filtering post processing filtering color conversion and video re sizing can require extensive computation. This computational complexity can be problematic in various scenarios such as decoding of high quality high bit rate video e.g. compressed high definition video . In particular decoding tasks according to more recent standards such as H.264 and VC 1 can be computationally intensive and consume significant memory resources.

Some decoders use video acceleration to offload selected computationally intensive operations to a graphics processor or other specialized hardware. For example in some configurations a computer system includes a primary central processing unit CPU as well as a graphics processing unit GPU or other hardware specially adapted for graphics processing. A decoder uses the primary CPU as a host to control overall decoding and uses the GPU to perform simple operations that collectively require extensive computation accomplishing video acceleration.

In a typical software architecture for video acceleration during video decoding a video decoder controls overall decoding and performs some decoding operations using a host CPU. The decoder signals control information e.g. picture parameters macroblock parameters and other information to a device driver for a hardware video accelerator e.g. with GPU across an acceleration interface.

The acceleration interface is exposed to the decoder as an application programming interface API . The device driver associated with the video accelerator is exposed through a device driver interface DDI . In an example interaction the decoder fills a buffer with instructions and information then calls a method of an interface to alert the device driver through the operating system. The buffered instructions and information opaque to the operating system are passed to the device driver by reference and video information is transferred to GPU memory if appropriate. While a particular implementation of the API and DDI may be tailored to a particular operating system or platform in some cases the API and or DDI can be implemented for multiple different operating systems or platforms.

In some cases the data structures and protocol used to parameterize acceleration information are conceptually separate from the mechanisms used to convey the information. In order to impose consistency in the format organization and timing of the information passed between the decoder and device driver an interface specification can define a protocol for instructions and information for decoding according to a particular video decoding standard or product. The decoder follows specified conventions when putting instructions and information in a buffer. The device driver retrieves the buffered instructions and information according to the specified conventions and performs decoding appropriate to the standard or product. An interface specification for a specific standard or product is adapted to the particular bit stream syntax and semantics of the standard product.

Given the critical importance of video compression and decompression to digital video it is not surprising that compression and decompression are richly developed fields. Whatever the benefits of previous techniques and tools however they do not have the advantages of the following techniques and tools.

In summary techniques and tools are described for various aspects of error concealment in video decoder implementations. These techniques and tools help for example to efficiently conceal errors detected during video decoding. For example a video decoder which utilizes adjustment of hardware acceleration level is described. In an implementation the decoder detects errors in a bitstream as it decodes the bitstream using different levels of error detection based on decoding characteristics. The decoder implementation then analyzes the error values statistically statistical analysis is performed on the error values as they are detected. In one technique performed by this example implementation if the bitstream is categorized as fitting a high error rate state in a bitstream model then hardware acceleration is dropped. In another technique error statistics based on run lengths of good and bad bitstream units are kept and compared to predetermined thresholds. If the thresholds are exceeded the hardware acceleration level is dropped. The decoder drops the level in order to take advantage of superior error handing abilities of software based decoding over hardware accelerated decoding.

In one implementation a computer comprising video decoding hardware performs a method for determining when during playback to adjust which video decoding steps are performed by the video decoding hardware based on bitstream quality. The method comprises receiving a video bitstream at the computer the computer configured at the time of decoding to perform variable length decoding and inverse discrete cosine transform decoding using the video decoding hardware. The method comprises then performing a lightweight error detection on pictures in the bitstream as they are received in the bitstream to determine if the pictures have errors computing mean and variance values for lengths of runs of non corrupt pictures computing mean and variance values for lengths of runs of corrupt pictures and computing the probability of good pictures based on pictures received. The method also comprises comparing the computed mean and variance values to predetermined thresholds determining based on the comparing the mean and variance values to pre determined thresholds that variable length decoding should be performed in software and responsive to the determining that variable length decoding should be performed in software adjusting decoding such that variable length decoding is performed on the computer in software and inverse discrete cosine transform decoding is performed in hardware.

In another implementation a method is described for directing video decoding on a computer comprising acceleration hardware for video decoding. The method comprises during decoding of a video bitstream reviewing the video bitstream for errors performing a statistical analysis of errors reviewed in the bitstream to determine error statistics for the bitstream determining based on the error statistics that a level at which hardware acceleration is performed should be adjusted and responsive to determining that a level at which hardware acceleration is performed should be adjusted adjusting the level at which hardware acceleration is performed.

In another implementation one or more computer readable storage media are described which contain computer executable instructions which when executed by a computer comprising hardware based video acceleration cause the computer to perform a method for controlling the hardware based video acceleration. The method comprises determining errors in a video bitstream categorizing the bitstream as fitting a state of an error model the categorizing being based on a statistical analysis of the errors in the bitstream and controlling the hardware based video acceleration to perform different tasks based on the error model to which the bitstream is categorized.

The various techniques and tools can be used in combination or independently. Additional features and advantages will be made more apparent from the following detailed description of different embodiments which proceeds with reference to the accompanying figures.

Acceleration of video decoding often improves computational performance by offloading selected computationally intensive operations. Existing approaches fail to address in a satisfactory way however or only partially address how to handle issues of error recovery and concealment that surface during decoding using video acceleration. Sometimes dedicated hardware does not respond robustly to bitstream errors while for example a decoder running on a CPU may by virtue of running on the CPU allow for more robust error correction. In these cases if system software sends corrupt compressed data to hardware it may cause hardware to crash or hang. One example can be found on typical PC based video decoders such as for MPEG2 or H.264 decoders which use graphics card hardware to decode compressed video and display it on screen. If input MPEG2 or H.264 bitstreams are corrupt because of transmission errors capture issues etc. graphics hardware might not be able to handle these bitstreams properly. This divide between error handling capabilities may be greater or smaller depending on the particular decoding processes that the decoder requests the hardware acceleration solution to perform.

The present application relates to innovations in implementations of error handling and or error concealment in video decoders which utilize hardware acceleration. Many of these innovations improve decoding performance by allocating resources between CPU run software decoder solutions and hardware acceleration such as on a GPU. These innovations include 

2. Using a lower level of hardware acceleration when error rates are higher in order to take advantage of superior error concealment capabilities of software decoding techniques.

3. Parsing bitstreams monitoring bitstream error parameters and statistics and using these values to reduce or increase hardware acceleration.

6. Switching back and forth between hardware accelerated decoding and software only decoding when suggested by bitstream characteristics.

For example in order to conceal errors during video decoding the hardware accelerated decoding processes of a standard such as MPEG 2 MPEG 4 H.264 or VC 1 and implementations thereof are modified to allow for directed hardware acceleration based on bitstream error rate. Specific examples of identified ways of improving error handling are described below.

Collectively these improvements as well as decoding techniques which the improvements operate over are at times loosely referred to as optimizations. As used conventionally and as used herein the term optimization means an improvement that is deemed to provide a good balance of performance in a particular scenario or platform considering computational complexity memory use processing speed and or other factors. Use of the term optimization does not foreclose the possibility of further improvements nor does it foreclose the possibility of adaptations for other scenarios or platforms.

With these innovations efficient decoder implementations have been provided for diverse platforms. The implementations include media players for gaming consoles with complex special purpose hardware and graphics capabilities personal computers and set top boxes digital video receivers.

Various alternatives to the implementations described herein are possible. For example certain techniques described with reference to flowchart diagrams can be altered by changing the ordering of stages shown in the flowcharts by repeating or omitting certain stages etc. while achieving the same result. As another example while several of the innovations described below are presented in terms of MPEG 2 decoding examples the innovations are also applicable to other types of decoders e.g. MPEG 4 H.264 VC 1 that provide or support the same or similar decoding features.

The various techniques and tools described herein can be used in combination or independently. For example although flowcharts in the figures typically illustrate techniques in isolation from other aspects of decoding the illustrated techniques in the figures can typically be used in combination with other decoding techniques e.g. shown in other figures . Different embodiments implement one or more of the described techniques and tools. Some of the techniques and tools described herein address one or more of the problems noted in the Background. Typically a given technique tool does not solve all such problems however. Rather in view of constraints and tradeoffs in decoding time and or resources the given technique tool improves performance for a particular implementation or scenario.

With reference to the computing environment includes at least one CPU and associated memory as well as at least one video hardware acceleration unit and associated memory used for video acceleration. In this most basic configuration is included within a dashed line. The processing unit executes computer executable instructions and may be a real or a virtual processor. In a multi processing system multiple processing units execute computer executable instructions to increase processing power. A host encoder or decoder process offloads certain operations to the hardware acceleration unit . In some implementations these operations may be computationally intensive operations e.g. fractional sample interpolation for motion compensation in loop deblock filtering . In others entire sub processes of the general decoding process may be performed by the video hardware acceleration e.g. variable length decoding inverse transform decoding motion compensation . The memory may be volatile memory e.g. registers cache RAM non volatile memory e.g. ROM EEPROM flash memory etc. or some combination of the two. The memory stores software for a decoder implementing one or more of the decoder innovations described herein for error detection concealment or recovery.

A computing environment may have additional features. For example the computing environment includes storage one or more input devices one or more output devices and one or more communication connections . An interconnection mechanism not shown such as a bus controller or network interconnects the components of the computing environment . Typically operating system software not shown provides an operating environment for other software executing in the computing environment and coordinates activities of the components of the computing environment .

The storage may be removable or non removable and includes magnetic disks magnetic tapes or cassettes CD ROMs DVDs or any other medium which can be used to store information and which can be accessed within the computing environment . The storage stores instructions for the software .

The input device s may be a touch input device such as a keyboard mouse pen or trackball a voice input device a scanning device or another device that provides input to the computing environment . For audio or video encoding the input device s may be a sound card video card TV tuner card or similar device that accepts audio or video input in analog or digital form or a CD ROM or CD RW that reads audio or video samples into the computing environment . The output device s may be a display e.g. monitor display screen or the like printer speaker CD writer or another device that provides output from the computing environment .

The communication connection s enable communication over a communication medium to another computing entity. The communication medium conveys information such as computer executable instructions audio or video input or output or other data in a modulated data signal. A modulated data signal is a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media include wired or wireless techniques implemented with an electrical optical RF infrared acoustic or other carrier.

The techniques and tools can be described in the general context of computer readable media. Computer readable media are any available media that can be accessed within a computing environment. By way of example and not limitation with the computing environment computer readable media include memory computer readable storage media e.g. CDs DVDs diskettes flash drives removable hard drives hard drive arrays and combinations of any of the above.

The techniques and tools can be described in the general context of computer executable instructions such as those included in program modules being executed in a computing environment on a target real or virtual processor. Generally program modules include routines programs libraries objects classes components data structures etc. that perform particular tasks or implement particular abstract data types. The functionality of the program modules may be combined or split between program modules as desired in various embodiments. Computer executable instructions for program modules may be executed within a local or distributed computing environment.

For the sake of presentation the detailed description uses terms like determine compute and categorize to describe computer operations in a computing environment. These terms are high level abstractions for operations performed by a computer and should not be confused with acts performed by a human being. The actual computer operations corresponding to these terms vary depending on implementation.

In general once the hardware based video accelerator reconstructs video information it maintains some representation of the video information rather than passing information back. For example after a video accelerator reconstructs an output picture the accelerator stores it in a picture store such as one in memory associated with a GPU for use as a reference picture. The accelerator then performs in loop deblock filtering and fractional sample interpolation on the picture in the picture store.

In some implementations different video acceleration profiles result in different operations being offloaded to a video accelerator. For example one profile may only offload out of loop post decoding operations while another profile offloads in loop filtering fractional sample interpolation and motion compensation as well as the post decoding operations. Still another profile can further offload frequency transform operations. In still other cases different profiles each include operations not in any other profile.

Returning to the decoder processes video pictures which may be video frames video fields or combinations of frames and fields. The bit stream syntax and semantics at the picture and macroblock levels may depend on whether frames or fields are used. The decoder is block based and uses a 4 2 0 macroblock format for frames. For fields the same or a different macroblock organization and format may be used. 8 8 blocks may be further sub divided at different stages. Alternatively the decoder uses a different macroblock or block format or performs operations on sets of samples of different size or configuration.

The decoder receives information for a compressed sequence of video pictures and produces output including a reconstructed picture e.g. progressive video frame interlaced video frame or field of an interlaced video frame . The decoder system decompresses predicted pictures and key pictures. For the sake of presentation shows a path for key pictures through the decoder system and a path for predicted pictures. Many of the components of the decoder system are used for decompressing both key pictures and predicted pictures. The exact operations performed by those components can vary depending on the type of information being decompressed.

A buffer receives the information for the compressed video sequence and makes the received information available to the entropy decoder . The variable length decoder VLD decodes entropy coded quantized data as well as encoded side information typically applying the inverse of encoding performed in the encoder. A motion compensator applies motion information to one or more reference pictures to form motion compensated predictions of sub blocks blocks and or macroblocks of the picture being reconstructed in a motion compensation MC process. One or more picture stores store previously reconstructed pictures for use as reference pictures.

The decoder also reconstructs prediction residuals. An inverse quantizer inverse quantizes entropy decoded data. An inverse frequency transformer converts the quantized frequency domain data into spatial domain video information. For example the inverse frequency transformer applies an inverse block transform to sub blocks and or blocks of the frequency transform coefficients producing sample data or prediction residual data for key pictures or predicted pictures respectively. In one example the inverse frequency transformer will apply an inverse discrete cosine transform IDCT to discrete cosine transform coefficients. Certain descriptions of the inverse quantization and inverse frequency transform may be referred collectively as IDCT herein but should not be read to require or omit either process or to require particular inverse frequency transformations. The inverse frequency transformer may apply an 8 8 8 4 4 8 4 4 or other size inverse frequency transform.

For a predicted picture the decoder combines reconstructed prediction residuals with motion compensated predictions to form the reconstructed picture . A motion compensation loop in the video decoder includes an adaptive deblocking filter . The decoder applies in loop filtering to the reconstructed picture to adaptively smooth discontinuities across block sub block boundary rows and or columns in the picture. The decoder stores the reconstructed picture in a picture buffer for use as a possible reference picture.

Generally the functions of error detection error concealment and error recovery are distributed among the modules of the decoder shown in . For example the buffer or other module can scan encoded data in decoder buffers for bit flip errors checksum errors or missing subunits of the bitstream such as network abstraction layer units NALUs or other such units. Both terms are described below. The entropy decoder can detect errors e.g. caused by bit flips during entropy decoding. The motion compensator or other module can adjust pictures buffered in the picture buffer s as part of error concealment. A controller not shown or other module in a decoder host can coordinate operations the demultiplexer entropy decoder motion compensator and other modules as part of error detection error recovery and error concealment.

Depending on implementation and the type of decompression desired modules of the decoder can be added omitted split into multiple modules combined with other modules and or replaced with like modules. In alternative embodiments decoders with different modules and or other configurations of modules perform one or more of the described techniques. Specific embodiments of video decoders typically use a variation or supplemented version of the generalized decoder .

For the sake of presentation the following table provides example explanations for acronyms and selected shorthand terms used herein.

As discussed above many modern computers and multimedia playback devices use some hardware acceleration to offload video decoding tasks to specialized decoding hardware. On Windows based computer video decoders talk to graphics hardware using DirectX Video Acceleration APIs to offload compressed video decoding operations onto graphics hardware. Video decoding operations take place when someone is watching DVD TV streaming video etc.

In the second example the decoding hardware might support IDCT and MC stages but not VLD. Or it may support VLD but be set by the decoding software to not perform the processes of that stage. In this case the host software decoder would perform VLD and then send motion vectors and DCT coefficients to the acceleration hardware for performing the rest of the decoding stages.

In the final illustrated example hardware might support only the MC stage or may be set to only perform the MC stage. In this case the software decoder performs VLD and IDCT on the CPU and sends motion vectors to the hardware for performing MC. This is also referred to as the hardware acceleration acting at a low level. In another example not illustrated the software decoder may opt to use no hardware acceleration at all resulting in the lowest level of hardware acceleration.

Because many hardware video accelerators possess the ability to operate at different levels the techniques described herein take advantage of this capability to allow for switching and or adjustment of video acceleration level based on bitstream quality. In particular when decoding software is using high level hardware decoding the software typically has much less control with which it can handle bad bitstreams and not crash or display unacceptably poor video. Thus it is desirable to identify points at which it would be desirable to switch to a lower level of hardware acceleration. The instant techniques identify these opportunities by analyzing errors received in a video bitstream and determining when the bitstream is too corrupt for the current level of hardware acceleration. This allows for the software decoder to perform more robust error correction thus providing higher quality video and preventing crashes or other errors. In other circumstances similar techniques can be used to identify when the bitstream is of a high enough quality that an increase in hardware acceleration quality is acceptable. This allows for better usage of hardware acceleration capabilities at times when they are best used.

The illustrated video decoding system comprise a software decoder which produces decoded video data along with hardware acceleration which can aid in the process. Each of the illustrated system components communicates with the other such as through an API including passing video data instructions and status information between the two. While the software decoder and the hardware acceleration are illustrated as single monolithic entities this should not imply any particular limitation on the makeup or operation of these specific modules. In one implementation the software decoding is performed by executing video decoding software on the CPU of a general purpose computer in other implementations it may be executed on specialized hardware or a special purpose computer.

Similarly while the hardware acceleration typically comprises a GPU or other hardware which is specialized for the purpose of decoding video data various implementations may utilize different hardware and or software running on the hardware for this purpose. This includes but is not limited to video cards on board video hardware integrated graphics chipsets mobile devices etc. The hardware acceleration may in various implementations also provide software. In one implementation the hardware decoder comprises device driver software through which the software decoder and the hardware acceleration communicate. Various driver implementations may allow for direct on the fly adjustment of hardware acceleration level or may provide such capabilities through the stopping of the device driver followed by a starting of a new instance of the driver to control the hardware portion of the hardware acceleration under different settings. Additionally while the software decoder is illustrated separately from the hardware acceleration they may be more or less integrated depending on implementation.

The illustrated software decoder also comprises decoding level adjustment which operates to instruct the hardware acceleration as to how and at what level they are to perform various video decoding stages. In some implementations the hardware acceleration will also communicate with the decoding level adjustment module such as to indicate which decoding stages the hardware acceleration is able to perform. For example some hardware accelerator implementations may only provide acceleration for IDCT and MC stages while not providing VLD support. This allows the decoding level adjustment module to determine if the level of hardware acceleration can be switched in addition to its determination of whether it should be switched. It should also be noted that while the decoding level adjustment is illustrated as a part of the software decoder in alternative implementations the level adjustment techniques may be performed outside of the software decoder and may themselves instruct the software decoding processes on what level to operate at.

Finally the metrics generated through the statistical error analysis are used as input by the adjustment control module to adjust the level of the hardware acceleration. As described below this adjustment may be made in part with reference to information made available by the hardware acceleration . In various situations the adjustment may be made to either increase or decrease the level of the hardware acceleration. In various implementations the adjustment may be made thought output of signals to acceleration hardware or by sending instructions to close a software device driver for acceleration hardware followed by instructions to open a new acceleration device at a different level.

The process begins at block where the software decoder begins receiving a bitstream for decoding. Next at block the decoder for example in the bitstream error detection module reviews the bitstream as it is received to determine if there are errors.

Depending on implementation details and the current decoding status error detection may be performed in different ways. If the software decoder is already performing the majority of the decoding process for example if it is performing all decoding or is only using hardware acceleration for motion compensation then the software decoder may be able to decode the bitstream down to the level of particular image coefficients. In another implementation the video may be looked at on a unit by unit basis such as per block or per macroblock to determine potential errors. In other implementations including those described below bitstream may be inspected at a higher unit by unit level such a on a per frame field picture or NALU basis.

A deep investigation of the bitstream may be desirable when the bitstream is predominately decoded in software since the software is already tasked with the work of computing values for display. However in situations where the software is performing relatively little of the decoding work it may be desirable to avoid such intensive error checking. Indeed when hardware acceleration is being used at a high level to have the software decoder performing extensive decoding work on a CPU has the potential to eat up any efficiencies gained by using the hardware acceleration.

Thus in some implementations when the hardware acceleration is operating at a high level the software decoder performs lightweight error detection on the bitstream. For example the software decoder in addition to sending the bitstream to the video acceleration hardware performs an initial decoding of the bitstream such as the VLD stage and attempts to determine errors from incompletely decoded values. In such an implementation the error detection can still for example inspect headers look for out of bounds transform coefficients or indices check for corrupted syntax and check for lost partial or incomplete packets. Such a process can detect some errors without consuming excess CPU power. While this may provide some decoding redundancy such as in the case that the hardware acceleration is performing VLD it provides an intermediate solution that avoids burning up computing resources while still looking for some errors.

In other implementations even performing the VLD stage in software is too expensive in terms of CPU cycles. For example in H.264 the VLD stage is very complex and requires many CPU cycles. In this case error detection can be performed if the hardware acceleration supports it by monitoring hardware status flags during hardware implemented decode operations. For example in DXVA specification decoding acceleration hardware provides notifications of the status of frames being decoded. As mentioned above these lightweight error detection techniques can be performed on a unit by unit basis such as by frames fields pictures or NALUs. Additionally the data resulting from the error detection can vary in different implementations. In one implementation the error detection simply signals whether an error exists for each unit of the bitstream which is measured such as on a picture by picture basis . In another more detailed statistics are kept such as type of error or level at which each error is found.

Next at block in the statistical error analysis module the software decoder performs an analysis on the errors detected. Particular analysis implementations are discussed in greater detail below. Finally at block in adjustment control module the software decoder adjusts the level of hardware acceleration being used based on metrics produced during the statistical error analysis of block . As a result after adjustment the bitstream will be decoded differently. For example if the adjustment causes less hardware acceleration and displaying decoded video with better error correction as additional decoding stages will be performed in software which typically provides more robust error handling. Particular implementation examples of this adjustment are also discussed below.

The process begins at block where a model is selected based on the incoming video bitstream. In various implementations the model may be selected according to various aspects of the current decoding job such as but not limited to the type of bitstream being decoded the video source bandwidth and the hardware and software being used for decoding. The model may be predetermined before the beginning of decoding or may be selected from a set of predetermined models based on one or more of the aforementioned decoding characteristics.

In one implementation the determination of good vs. bad is based on the level of corruption of units of the bitstream. For example correctable errors may not in a given model lead automatically to a bad state. In various implementations determination of long vs. short is based on units in the bitstream which are used in error detection. Thus for example a different model or classification of bitstream state within the model may vary depending on whether errors are being detected on a deep block by block basis or on a lightweight picture by picture or packet by packet basis or even at the level of NALUs. In one implementation where the errors are detected on a picture by picture basis and an error rate of 10 10is assumed then a contiguous error length of 

The model also shows eight parameters such as parameter p or parameter . These represent two types of probabilities which predict transitions within the model. The first type of parameter such as parameter p indicates for its associated state the current probability that the bitstream will be in that state. The second parameter such as parameter indicates the probability that the bitstream once in its associated state will stay in that state.

At block values for these two types of parameters are computed based on the rate of errors that is occurring as the bitstream is reviewed. Hence in one implementation the bitstream is reviewed and for each unit that is reviewed the decoder determines a state for the bitstream in the model and adjusts the probabilities constituting the model parameters accordingly. For example if the data received from the error detection process is a series of indications of whether each picture has an error or not the error rate assumptions described above can be used to determine the parameters. While this is a direct way of judging the quality of the bitstream and can be utilized it may be computationally expensive. For this reason an alternative implementation discussed below with respect to may be used instead. However the direct computation of model parameters may be used when it does not undesirably slow down decoding.

Finally at block the software decoder characterizes the bitstream according to the model parameters. For example in one DXVA implementation it is desirable to adjust hardware acceleration level when one of the following happens 

Specific implemented values for these probabilities are discussed above. When these conditions are true the software decoder at block will categorize the bitstream as being in a poor enough condition that it is desirable to have the level of hardware acceleration dropped and will indicate that to the adjustment control module . Finally if the process so categorizes the bitstream then at block it indicates to the adjustment control that the hardware acceleration level is to be dropped. While it is not illustrated for the sake of clarity in some implementations a process similar to that of process may be used to determine that the bitstream is in a good enough condition that the level of hardware acceleration may be safely raised. Additionally while it is not illustrated the process of blocks and may then repeat for the next statistics prepared by the error detection.

As discussed above because determining eight constantly changing model parameters may require more computational power than is desired an alternative technique for analyzing errors may be used. is a flowchart of an example process performed by the software decoder for performing statistical error analysis on errors detected using error statistics. In various implementations subprocesses of the process may be combined or split into additional processes and may be performed by separate dedicated software modules or performed by the same modules.

The process of takes advantage of the fact that when sufficient data has been collected the parameters of the four state model discussed above can be estimated using fewer parameters. In particular all eight parameters can be derived from six parameters which are based on variables representing the run length of good and bad runs of bitstream units such as pictures. For the purpose of illustration these variables shall be called xand x. In one implementation these variables are in turn based on a simple binary variable that indicates for each picture or other unit if detection is based on different units whether that picture has an error or not. For the purpose of illustration that variable shall be called simply x and will have a value of 1 when it indicates a picture with an error and 0 when it indicates a picture with no errors. Other implementations may utilize or label variables in different ways.

Based on these variables the three parameters for good run lengths then comprise 1 the mean of the good run lengths E x 2 the variance of the good run lengths var x and 3 the probability of a good unit P x 0 . Similarly the three parameters for bad run lengths comprise similar statistics E x var x and P x 1 . In one implementation these statistics can be based simply on set of data created during the error detection process which indicates for each picture whether or not it had an error. Then the probability of good units can be based on past units by computing a ratio of good units to total units received while the run length statistics are based on runs of good or bad indications for each picture. The statistics for bad units can be computed similarly.

With these six statistical parameters in mind the relationship between these parameters and the earlier discussed model parameters can be stated. For example the relationship between the good parameters is in one implementation as follows 

Thus from these six statistical parameters all parameters in the four state model can be solved numerically. However rather than do that one implementation of the process directly categorizes the bitstream directly using these six parameters. This means that the three conditions discussed above with respect to process can be simply checked by comparing selected parameters out of the six error statistics to pre set thresholds. Thus according to his implementation the conditions for lowering hardware acceleration level comprise 

The process begins at block where the adjustment control detects which hardware tasks are exposed by the acceleration hardware. In some implementations this is done by requesting information from the acceleration hardware to determine which decoding stages are able to be performed by the hardware. In some the software decoder is hard coded to use only software decoding. In one such implementation DXVA is completely disabled and the decoder will not check for capability of the hardware acceleration. Next at block the software decoder determines the level to which hardware acceleration is to be dropped. This may be based simply on the available levels provided by the hardware or may be based on additional considerations such as the types of errors seen during error detection or the processing power available to the software decoder as it will be taking over tasks currently performed by the hardware . In another implementation decisions about adjusting hardware acceleration levels is performed based on permissions granted by content protection rules for the video being decoded. Finally at block the software decoder instructs the acceleration hardware to drop the level of acceleration and the process ends. In some circumstances this instruction may drop all hardware acceleration altogether in effect switching from hardware accelerated decoding to software only decoding. In some implementations the adjustment control may stop and close a hardware device existing at one level and open a new hardware device at a lower acceleration level to effect the adjustment. In another implementation the adjustment instructions may be stored before being sent to the hardware acceleration.

Although many of the innovations described herein are illustrated with reference to examples of MPEG 2 decoding the innovations are typically applicable to decoding according to other standards such as VC 1 and H.264 AVC with corresponding changes to syntax elements.

In view of the many possible embodiments to which the principles of the disclosed invention may be applied it should be recognized that the illustrated embodiments are only preferred examples of the invention and should not be taken as limiting the scope of the invention. Rather the scope of the invention is defined by the following claims. We therefore claim as our invention all that comes within the scope and spirit of these claims.

