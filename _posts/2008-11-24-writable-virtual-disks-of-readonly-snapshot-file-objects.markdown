---

title: Writable virtual disks of read-only snapshot file objects
abstract: A technique enables creation and use of a writable, read-only snapshot of an active file system operating on a storage system, such as a multi-protocol storage appliance. The writable, read-only snapshot comprises a read-only “image” (file) residing in a snapshot and a writable virtual disk (vdisk) residing in the active file system. The writable vdisk is a “shadow” image of the snapshot file image and, as such, includes an attribute that specifies the snapshot file as a backing store.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08423732&OS=08423732&RS=08423732
owner: NetApp, Inc.
number: 08423732
owner_city: Sunnyvale
owner_country: US
publication_date: 20081124
---
This application is a divisional of U.S. Ser. No. 10 412 478 issued as U.S. Pat. No. 7 457 982 on Nov. 25 2008 filed by Vijayan Rajan on Apr. 11 2003 entitled WRITABLE VIRTUAL DISKS OF READ ONLY SHAPSHOT FILE OBJECTS.

The present invention relates to storage systems and more specifically to a storage system configured to generate read only consistent point in time images of a storage element such as an active file system.

A storage system is a computer that provides storage service relating to the organization of information on writable persistent storage devices such as memories tapes or disks. The storage system is commonly deployed within a network attached storage NAS or storage area network SAN environment. A SAN is a high speed network that enables establishment of direct connections between a storage system such as an application server and its storage devices. The SAN may thus be viewed as an extension to a storage bus and as such an operating system of the storage system enables access to stored information using block based access protocols over the extended bus . In this context the extended bus is typically embodied as Fibre Channel FC or Ethernet media i.e. network adapted to operate with block access protocols such as Small Computer Systems Interface SCSI protocol encapsulation over FC or Transmission Control Protocol Internet Protocol TCP IP Ethernet.

SCSI is a peripheral input output I O interface with a standard device independent protocol that allows different peripheral storage devices such as disks to attach to the storage system. In SCSI terminology clients operating in a SAN environment are initiators that initiate requests and commands for data. The storage system is a target configured to respond to the requests issued by the initiators in accordance with a request response protocol. The SAN clients typically identify and address the stored information in terms of blocks situated within target disks or logical units thereof also referred to within the industry as logical unit numbers or luns.

When used within a NAS environment the storage system may be embodied as a file server including an operating system that implements a file system to logically organize the information as a hierarchical structure of directories and files on e.g. the disks. Each on disk file may be implemented as a set of data structures e.g. disk blocks configured to store information such as the actual data for the file. A directory on the other hand may be implemented as a specially formatted file in which information about other files and directories are stored.

The file server or filer of a NAS system may be further configured to operate according to a client server model of information delivery to thereby allow many client systems clients to access shared resources such as files stored on the filer. In the client server model the client may comprise an application executing on a computer that connects to the filer over a computer network such as a point to point link shared local area network wide area network or virtual private network implemented over a public network such as the Internet. The clients typically communicate with the filer by exchanging discrete frames or packets of data according to pre defined protocols such as the TCP IP. NAS systems generally utilize file based access protocols therefore each client may request the services of the filer by issuing file system protocol messages in the form of packets to the file system over the network.

A common type of file system is a write in place file system an example of which is the conventional Berkeley fast file system. In a write in place file system the locations of the data structures such as modes and data blocks on disk are typically fixed. An inode is a data structure used to store information such as metadata about a file whereas the data blocks are structures used to store the actual data for the file. The information contained in an inode may include e.g. ownership of the file access permission for the file size of the file file type and references to locations on disk of the data blocks for the file. The references to the locations of the file data are provided by pointers which may further reference indirect blocks that in turn reference the data blocks depending upon the quantity of data in the file. Changes to the inodes and data blocks are made in place in accordance with the write in place file system. If an update to a file extends the quantity of data for the file an additional data block is allocated and the appropriate inode is updated to reference that data block.

Another type of file system is a write anywhere file system that does not overwrite data on disks. If a data block on disk is retrieved read from disk into memory and dirtied with new data the data block is stored written to a new location on disk to thereby optimize write performance. An example of a write anywhere file system that is configured to operate on a filer is the Write Anywhere File Layout WAFL file system available from Network Appliance Inc. of Sunnyvale Calif. The WAFL file system is implemented within a microkernel as part of the overall protocol stack of the filer and associated disk storage. This microkernel is supplied as part of Network Appliance s Data ONTAP storage operating system residing on the filer.

The WAFL file system has the capability to generate a snapshot of its active file system. It should be noted that snapshot is a trademark of Network Appliance Inc. and is used for purposes of this patent to designate a persistent consistency point CP image. A persistent consistency point image PCPI is a space conservative point in time read only image of data accessible by name that provides a consistent image of that data such as a storage system at some previous time. More particularly a PCPI is a point in time representation of a storage element such as an active file system file or database stored on a storage device e.g. on disk or other persistent memory and having a name or other identifier that distinguishes it from other PCPIs taken at other points in time. A PCPI can also include other information metadata about the active file system at the particular point in time for which the image is taken. The terms PCPI and snapshot may be used interchangeably through out this patent without derogation of Network Appliance s trademark rights.

A file system such as the WAFL file system supports multiple snapshots that are generally created on a regular schedule. Each snapshot is a restorable version of the storage element e.g. the active file system created at a predetermined point in time and as noted is read only accessible and space conservative . Space conservative denotes that common parts of the storage element in multiple snapshots share the same file system blocks. Only the differences among these various snapshots require extra storage blocks. The multiple snapshots of a storage element are not independent copies each consuming disk space therefore creation of a snapshot on the WAFL file system is instantaneous since no entity data needs to be copied. Read only accessibility denotes that a snapshot cannot be modified because it is closely coupled to a single writable image in the active file system. The closely coupled association between a file in the active file system and the same file in a snapshot obviates the use of multiple same files. In the example of a WAFL based file system snapshots are described in TR3002 File System Design for a NFS File Server Appliance by David Hitz et al. published by Network Appliance Inc. and in U.S. Pat. No. 5 819 292 entitled Method for Maintaining Consistent States of a File System and For Creating User Accessible Read Only Copies of a File System by David Hitz et al. each of which is hereby incorporated by reference as though full set forth herein.

Broadly stated a snapshot is stored on disk along with the active file system and is called into a memory of a filer as requested by an operating system. An exemplary file system inode structure is shown in . The inode for an inode file contains information describing the inode file associated with a file system. In this exemplary file system inode structure the inode for the inode file contains a pointer that references points to an inode file indirect block . The inode file indirect block contains a set of pointers that reference inodes which in turn contain pointers to indirect blocks . The indirect blocks include pointers to file data blocks A B and C. Each of the file data blocks A C is capable of storing e.g. 4 kilobytes kB of data. When the file system generates a snapshot of its active file system a snapshot inode is generated as shown in . The snapshot inode is in essence a duplicate copy of the inode for the inode file of the file system that shares common parts such as inodes and blocks with the active file system. For example the exemplary file system structure includes the inode file indirect blocks inodes indirect blocks and file data blocks A C as in

When a user modifies a file data block the file system writes the new data block to disk and changes the active file system to point to the newly created block. shows an exemplary inode file system structure after a file data block has been modified. In this example file data block C is modified to file data block C . As a result the contents of the modified file data block are written to a new location on disk as a function of the exemplary file system. Because of this new location the indirect block must be rewritten. Due to this changed indirect block the inode must be rewritten. Similarly the inode file indirect block and the inode for the inode file must be rewritten.

Thus after a file data block has been modified the snapshot inode contains a pointer to the original inode file indirect block which in turn contains pointers through the inode and indirect block to the original file data blocks A B and C. The newly written indirect block also includes pointers to unmodified file data blocks A and B. That is the unmodified data blocks in the file of the active file system are shared with corresponding data blocks in the snapshot file with only those blocks that have been modified in the active file system being different than those of the snapshot file.

However the indirect block further contains a pointer to the modified file data block C representing the new arrangement of the active file system. A new inode for the inode file is established representing the new structure . Note that metadata not shown stored in any snapshotted blocks e.g. and C protects these blocks from being recycled or overwritten until they are released from all snapshots. Thus while the active file system inode for the inode file points to new blocks A B and C the old blocks and C are retained until the snapshot is fully released.

Snapshots provide a versatile feature that is essential for data recovery operations such as backup and recovery of storage elements. However since snapshots are read only accessible and their contents cannot be modified their use may be somewhat limited particularly for operating systems and applications that do not have a notion of a read only data store file system and that expect to write metadata at any time that the file system is accessible. When a storage element that is held in a snapshot is mapped to an initiator and contains the data for such a problematic file system an issue arises in that the client attempts to write data to the read only image. This is a fundamental issue in the design of a reliable system for backups. In general once a backup image is made via a mechanism like a snapshot that image should be inviolate. Modifying a snapshot backup image could have serious consequences in that the data of the snapshot may no longer be a point in time copy and a consistent image of the storage element data may no longer be available for subsequent recovery operations.

A prior approach to providing modifiable copies of a storage element uses conventional techniques to create mirrored copies of disks that may thereafter be broken split into separate copies and made visible to clients for different purposes such as writable data stores. For example assume a user system administrator creates a storage element such as a database on a database server and through the use of conventional asynchronous synchronous mirroring creates a mirror of the database. By breaking the minor using conventional techniques full disk level copies of the database are formed. A client may thereafter independently write to each copy such that the content of each instance of the database diverges in time.

One restriction associated with the prior approach however is that the number of formed mirrors limits the number of writable copies of the database. The present invention is directed to a technique that enables creation of multiple copies of a consistent storage element image with substantially no restrictions as to the number of writable copies that can be created.

The present invention overcomes the disadvantages of the prior art by providing a technique that enables creation and use of a writable read only snapshot of an active file system operating on a storage system such as a multi protocol storage appliance. The writable read only snapshot comprises a read only image file residing in a snapshot and a writable virtual disk vdisk residing in the active file system. The writable vdisk is a shadow image of the snapshot file image and as such includes an attribute that specifies the snapshot file as a backing store.

In the illustrative embodiment the multi protocol storage appliance serves file and block protocol access to information stored on storage devices in an integrated manner for both network attached storage NAS and storage area network SAN deployments. A storage operating system of the appliance implements a virtualization system that includes the file system and that virtualizes the storage space provided by the devices. This virtualization system allows the file system to logically organize the information as named file directory and vdisk storage objects to thereby provide an integrated NAS and SAN appliance approach to storage by enabling file based access to the files and directories while further enabling block based access to the vdisks.

According to the novel technique a write operation directed to the writable read only snapshot is trapped such that the data associated with the operation is stored on the shadow vdisk image in the active file system. In other words rather than directly accessing the read only snapshot image of a logical unit number lun a client accesses the writable vdisk image which provides a translucent view of the underlying read only snapshot image. The writable vdisk is a sparse file containing only that data written by the client e.g. an initiator in a SAN to the read only snapshot image subsequent to a snapshot operation to a volume underlying the lun vdisk .

To the client the data retrieved from the writable read only snapshot is always the latest data written. The client sees the writable vdisk data first if it exists and is served that data the underlying read only snapshot image being inaccessible for the range of valid data in the writable vdisk. Read only data from the underlying snapshot image is delivered to the client when no valid data overlying the range exists in the writable vdisk. The underlying snapshot image is accessible and recoverable via a non translucent path of directly accessing the snapshot image. By this technique data integrity of a snapshotted lun or vdisk as an inviolate backup is preserved.

Advantageously the inventive technique supports clients having a weak notion of a read only file system while preserving the integrity of a snapshot image of a lun. The novel writable read only snapshot further provides the advantages of writability in addition to reliability on account of inviolability features of snapshots. The writable read only snapshot can be employed using any protocol network file system or block storage.

The multi protocol storage appliance is illustratively embodied as a storage system comprising a processor a memory a plurality of network adapters and a storage adapter interconnected by a system bus . The multi protocol storage appliance also includes a storage operating system that provides a virtualization system and in particular a file system to logically organize the information as a hierarchical structure of named directory file and virtual disk vdisk storage objects on the disks . An example of a multi protocol storage appliance that may be advantageously used with the present invention is described in commonly assigned U.S. Pat. No. 7 873 700 issued on Jan. 18 2011 titled A Multi Protocol Storage Appliance that Provides Integrated Support for File and Block Access Protocols by Brian Pawlowski et al. which is hereby incorporated by reference as though fully set forth herein.

Whereas clients of a NAS based network environment have a storage viewpoint of files within volumes the clients of a SAN based network environment have a storage viewpoint of blocks within disks. To that end the multi protocol storage appliance presents exports disks to SAN clients through the creation of logical unit numbers luns or vdisk objects. A vdisk object hereinafter vdisk is a special file type that is implemented by the virtualization system and translated into an emulated disk as viewed by the SAN clients. The multi protocol storage appliance thereafter makes these emulated disks accessible to the SAN clients through controlled exports.

In the illustrative embodiment the memory comprises storage locations that are addressable by the processor and adapters for storing software program code and data structures associated with the present invention. The processor and adapters may in turn comprise processing elements and or logic circuitry configured to execute the software code and manipulate the data structures. The storage operating system portions of which are typically resident in memory and executed by the processing elements functionally organizes the storage appliance by inter alia invoking storage operations in support of the storage service implemented by the appliance. It will be apparent to those skilled in the art that other processing and memory means including various computer readable media may be used for storing and executing program instructions pertaining to the invention described herein.

The network adapter couples the storage appliance to a plurality of clients over point to point links wide area networks virtual private networks implemented over a public network Internet or a shared local area network hereinafter referred to as an illustrative Ethernet network . For this NAS based network environment the clients are configured to access information stored on the multi protocol appliance as files. Therefore the network adapter may comprise a network interface card NIC having the mechanical electrical and signaling circuitry needed to connect the appliance to a network switch such as a conventional Ethernet switch . The clients communicate with the storage appliance over network by exchanging discrete frames or packets of data according to pre defined protocols such as the Transmission Control Protocol Internet Protocol TCP IP .

The clients may be general purpose computers configured to execute applications over a variety of operating systems including the UNIX and Microsoft Windows operating systems. Client systems generally utilize file based access protocols when accessing information in the form of files and directories over a NAS based network. Therefore each client may request the services of the storage appliance by issuing file access protocol messages in the form of packets to the appliance over the network . For example a client running the Windows operating system may communicate with the storage appliance using the Common Internet File System CIFS protocol over TCP IP. On the other hand a client running the UNIX operating system may communicate with the multi protocol appliance using either the Network File System NFS protocol over TCP IP or the Direct Access File System DAFS protocol over a virtual interface VI transport in accordance with a remote DMA RDMA protocol over TCP IP. It will be apparent to those skilled in the art that other clients running other types of operating systems may also communicate with the integrated multi protocol storage appliance using other file access protocols.

The storage network target adapter also couples the multi protocol storage appliance to clients that may be further configured to access the stored information as blocks or disks. For this SAN based network environment the storage appliance is coupled to an illustrative Fibre Channel FC network . FC is a networking standard describing a suite of protocols and media that is primarily found in SAN deployments. The network target adapter may comprise a FC host bus adapter HBA having the mechanical electrical and signaling circuitry needed to connect the appliance to a SAN network switch such as a conventional FC switch . In addition to providing FC access the FC HBA offloads fiber channel network processing operations for the storage appliance.

The clients generally utilize block based access protocols such as the Small Computer Systems Interface SCSI protocol when accessing information in the form of blocks disks or vdisks over a SAN based network. SCSI is a peripheral input output I O interface with a standard device independent protocol that allows different peripheral devices such as disks to attach to the storage appliance . In SCSI terminology clients operating in a SAN environment are initiators that initiate requests and commands for data. The multi protocol storage appliance is thus a target configured to respond to the requests issued by the initiators in accordance with a request response protocol. The initiators and targets have endpoint addresses that in accordance with the FC protocol comprise worldwide names WWN . A WWN is a unique identifier e.g. a node name or a port name consisting of an 8 byte number.

The multi protocol storage appliance supports various SCSI based protocols used in SAN deployments including SCSI encapsulated over TCP iSCSI and SCSI encapsulated over FC FCP . The initiators hereinafter clients may thus request the services of the target hereinafter storage appliance by issuing iSCSI and FCP messages over the network to access information stored on the disks. It will be apparent to those skilled in the art that the clients may also request the services of the integrated multi protocol storage appliance using other block access protocols. By supporting a plurality of block access protocols the multi protocol storage appliance provides a unified and coherent access solution to vdisks luns in a heterogeneous SAN environment.

The storage adapter cooperates with the storage operating system executing on the storage appliance to access information requested by the clients. The information may be stored on the disks or other similar media adapted to store information. The storage adapter includes I O interface circuitry that couples to the disks over an I O interconnect arrangement such as a conventional high performance FC serial link topology. The information is retrieved by the storage adapter and if necessary processed by the processor or the adapter itself prior to being forwarded over the system bus to the network adapters where the information is formatted into packets or messages and returned to the clients.

Storage of information on the appliance is preferably implemented as one or more storage volumes e.g. VOL that comprise a cluster of physical storage disks defining an overall logical arrangement of disk space. Each volume may be associated with its own file system and for purposes herein volume and file system may be used synonymously. The disks within a volume are typically organized as one or more groups of Redundant Array of Independent or Inexpensive Disks RAID . RAID implementations enhance the reliability integrity of data storage through the writing of data stripes across a given number of physical disks in the RAID group and the appropriate storing of redundant information with respect to the striped data. The redundant information enables recovery of data lost when a storage device fails.

Specifically each volume is constructed from an array of physical disks that are organized as RAID groups and . The physical disks of each RAID is group include those disks configured to store striped data D and those configured to store parity P for the data in accordance with an illustrative RAID 4 level configuration. However other RAID level configurations e.g. RAID 5 are also contemplated. In the illustrative embodiment a minimum of one parity disk and one data disk may be employed. However a typical implementation may include three data and one parity disk per RAID group and at least one RAID group per volume.

To facilitate access to the disks the storage operating system implements a write anywhere file system that cooperates with virtualization modules to provide a function that virtualizes the storage space provided by disks . The file system logically organizes the information as a hierarchical structure of named directory and file objects hereinafter directories and files on the disks. Each on disk file may be implemented as set of disk blocks configured to store information such as data whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization system allows the file system to further logically organize information as a hierarchical structure of named vdisks on the disks thereby providing an integrated NAS and SAN appliance approach to storage by enabling file based NAS access to the files and directories while further enabling block based SAN access to the vdisks on a file based storage platform.

In the illustrative embodiment the storage operating system is preferably the NetApp Data ONTAP operating system available from Network Appliance Inc. Sunnyvale Calif. that implements a Write Anywhere File Layout WAFL file system. However it is expressly contemplated that any appropriate storage operating system including a write in place file system may be enhanced for use in accordance with the inventive principles described herein. As such where the term WAFL is employed it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.

As used herein the term storage operating system generally refers to the computer executable code operable on a computer that manages data access and may in the case of a multi protocol storage appliance implement data access semantics such as the is Data ONTAP storage operating system which is implemented as a microkernel. The storage operating system can also be implemented as an application program operating over a general purpose operating system such as UNIX or Windows NT or as a general purpose operating system with configurable functionality which is configured for storage applications as described herein.

In addition it will be understood to those skilled in the art that the inventive technique described herein may apply to any type of special purpose e.g. storage serving appliance or general purpose computer including a standalone computer or portion thereof embodied as or including a storage system. Moreover the teachings of this invention can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and disk assembly directly attached to a client or host computer. The term storage system should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems.

An iSCSI driver layer provides block protocol access over the TCP IP network protocol layers while a FC driver layer operates with the FC HBA to receive and transmit block access requests and responses to and from the integrated storage appliance. The FC and iSCSI drivers provide FC specific and iSCSI specific access control to the luns vdisks and thus manage exports of vdisks to either iSCSI or FCP or alternatively to both iSCSI and FCP when accessing a single vdisk on the multi protocol storage appliance. In addition the storage operating system includes a disk storage layer that implements a disk storage protocol such as a RAID protocol and a disk driver layer that implements a disk access protocol such as e.g. a SCSI protocol.

Bridging the disk software layers with the integrated network protocol stack layers is a virtualization system . is a schematic block diagram of the virtualization system that is implemented by a file system interacting with virtualization modules illustratively embodied as e.g. vdisk module and SCSI target module . It should be noted that the vdisk module the file system and SCSI target module can be implemented in software hardware firmware or a combination thereof. The vdisk module is layered on the file system to enable access by administrative interfaces such as a streamlined user interface UI in response to a system administrator issuing commands to the multi protocol storage appliance . In essence the vdisk module manages SAN deployments by among other things implementing a comprehensive set of vdisk lun commands cmds issued through the UI by a system administrator. These vdisk commands are converted to primitive file system operations primitives that interact with the file system and the SCSI target module to implement the vdisks.

The SCSI target module in turn initiates emulation of a disk or lun by providing a mapping procedure that translates a lun identifier to a vdisk type file. The SCSI target module is illustratively disposed between the FC and iSCSI drivers and the file system to thereby provide a translation layer of the virtualization system between the SAN block lun space and the file system space where luns are represented as vdisks . To that end the SCSI target module has a set of application programming interfaces APIs that are based on the SCSI protocol and that enable a consistent interface to both the iSCSI and FCP drivers . By disposing SAN virtualization over the file system the multi protocol storage appliance reverses the approach taken by prior systems to thereby provide a single unified storage platform for essentially all storage access protocols.

The file system is illustratively a message based system as such the SCSI target module transposes a SCSI request into a message representing an operation directed to the file system. For example the message generated by the SCSI target module may include a type of operation e.g. read write along with a pathname e.g. a path descriptor and a filename e.g. a special filename of the vdisk object represented in the file system. Alternatively the generated message may include an operation type and file handle containing volume inode information. The SCSI target module passes the message into the file system layer as e.g. a function call where the operation is performed.

The file system provides volume management capabilities for use in block based access to the information stored on the storage devices such as disks. That is in addition to providing file system semantics such as naming of storage objects the file system provides functions normally associated with a volume manager. These functions include i aggregation of the disks ii aggregation of storage bandwidth of the disks and iii reliability guarantees such as mirroring and or parity RAID to thereby present one or more storage objects layered on the file system. A feature of the multi protocol storage appliance is the simplicity of use associated with these volume management capabilities particularly when used in SAN deployments.

The file system illustratively implements the WAFL file system having an on disk format representation that is block based using e.g. 4 kilobyte kB blocks and using inodes to describe the files . The file system uses files to store metadata describing the layout of its file system these metadata files include among others an inode file. A file handle i.e. an identifier that includes an inode number is used to retrieve an inode from disk. As noted the WAFL file system also supports multiple snapshots that are generally created on a regular schedule. A description of the structure of the file system including on disk inodes the inode file and snapshots is provided in U.S. Pat. No. 5 819 292. Notably snapshots are created on the multi protocol storage appliance without the need for prior configuration of the underlying storage. This feature of the appliance simplifies the creation and management of data recovery techniques for business continuance compared to previous block based recovery methods and mechanisms.

Specifically the data section of a regular on disk inode may include user data or pointers the latter referencing 4 kB data blocks on disk used to store the user data. Each pointer is preferably a logical volume block number VBN to thereby facilitate efficiency among the file system and the disk storage RAID layer when accessing the data on disks. Given the restricted size 128 bytes of the inode user data having a size that is less than or equal to 64 bytes is represented in its entirety within the data section of that inode. However if the user data is greater than 64 bytes but less than or equal to 64 kB then the data section of the inode comprises up to 16 pointers each of which references a 4 kB block of data on the disk. Moreover if the size of the data is greater than 64 kilobytes but less than or equal to 64 megabytes MB then each pointer in the data section of the inode references an indirect inode that contains 1024 pointers each of is which references a 4 kB data block on disk. Each data block is loaded from disk into memory in order to access the data. In addition the size field of the metadata section of the inode refers to the size of the file.

Broadly stated all inodes of the file system are organized into the inode file. A file system FS info block specifies the layout of information in the file system and includes an inode of a file that includes all other inodes of the file system. Each volume has an FS info block that is preferably stored at a fixed location within e.g. a RAID group of the file system. The inode of the root FS info block may directly reference point to blocks of the inode file or may reference indirect blocks of the inode file that in turn reference direct blocks of the inode file. Within each direct block of the inode file are embedded inodes each of which may reference indirect blocks that in turn reference data blocks of a file or vdisk.

As noted a vdisk is a special file type in a volume that derives from a plain regular file but that has associated export controls and operation restrictions that support emulation of a disk. Unlike a file that can be created by a client using e.g. the NFS or CIFS protocol a vdisk is created on the multi protocol storage appliance via e.g. a user interface UI as a special typed file object . Illustratively the vdisk is a multi inode object comprising a special file inode that holds data and at least one associated stream inode that holds attributes. The special file inode functions as a main container for storm ing data such as application data associated with the emulated disk. The stream inode stores attributes that among others allow luns and exports to persist over e.g. reboot operations while also enabling management of the vdisk as a single disk object in relation to SAN clients.

In order to access the stream dir inode the pointer of xinode field in lun inode is modified to reference the inode . The stream dir inode comprises a metadata section that includes a type stream dir field and an xinode field that references another on disk inode structure containing e.g. access control such as CIFS permission information associated with the vdisk. The inode also includes a data section containing a pointer that references a stream directory data block associated with the vdisk such as stream directory block . The stream directory block comprises a data section that includes a plurality of entries each containing an external representation of a stream inode along with mapping information i.e. the inode number for that inode. One of those entries entry contains mapping information e.g. a pointer that references an attributes stream inode .

The attributes inode comprises a metadata section that includes a type stream field and a data section that functions as a persistent store for holding various named attributes associated with the vdisk . Attributes are an implementation mechanism that is internal to the file system and not managed by users. An example of an attribute is a snapshot file handle or file handle of a backing store file i.e. the snapshot file . The snapshot file handle includes a snapshot identifier ID which is an identifier pointer to a snapshot containing the snapshot file and a file ID which is an identifier pointer to the snapshot file. As described herein the snapshot file functions as a backing store for the vdisk when the vdisk is used as a writable read only snapshot in accordance with the present invention. The vdisk and its associated inodes are further described in commonly assigned U.S. Pat. No. 7 107 385 issued on Sep. 12 2006 titled STORAGE VIRTUALIZATION BY LAYERING VIRTUAL DISK OBJECTS ON A FILE SYSTEM by Vijayan Rajan et al. which is hereby incorporated by reference as though fully set forth herein.

Referring again to the file system implements access operations to vdisks as well as to files and directories dir that coexist with respect to global space management of units of storage such as volumes and or qtrees . A qtree is a special directory that has the properties of a logical sub volume within the namespace of a physical volume. Each file system storage object file directory or vdisk is associated with one qtree and quotas security properties and other items can be assigned on a per qtree basis. The vdisks and files directories may be layered on top of qtrees that in turn are layered on top of volumes as abstracted by the file system virtualization layer .

While vdisks are self contained objects containing all data necessary for proper operation and authorization a vdisk table of contents VTOC is provided as a performance enhancement to finding and loading vdisks. The VTOC is not necessary for correct operation and can be reconstructed dynamically by a scan of the vdisks. The VTOC is a per volume data structure that is stored in a metadata file and that is used to optimize location determination and initialization of persistent vdisks in a volume . In addition the VTOC facilitates resolution of the location of a file within a particular snapshot i.e. allows efficient resolution of a snapshot file location.

The VTOC comprises one or more records wherein each record includes flags and file entries that can be dynamically recreated from information stored in the encapsulated vdisk storage objects. The file entries in turn include an entry pertaining to a vdisk in the active file system and an entry pertaining to a backing store snapshot file if the vdisk is used as a writable read only snapshot. In particular the file entries of each record contain information such as i a file ID inode number of the vdisk on the volume ii generation number of the vdisk lun inode iii file handle including snapshot ID only valid for the backing store entry of the backing store file and iv directory information. The directory information comprises a file block number in a parent directory qtree root containing an entry for the vdisk along with an index of directory entries in a parent directory block. The directory entry enables determination of the last component of a path to the snapshot file.

In the illustrative embodiment the granularity of a snapshot is a file system however the principles of the present invention apply to snapshot granularities of a file and a vdisk. Since a snapshot is a read only entity a file that resides in the snapshot is a read only file. As noted some operating systems and applications do not support the notion of a read only data store. For example the Windows operating system does not support mounting of a read only file system disk. Therefore it is desirable to enable a read only storage entity such as a snapshot file to be writable. 

The present invention relates to a technique that enables creation and use of including access to a writable read only snapshot of the active file system on the multi protocol storage appliance. The writable read only snapshot comprises a read only image file residing in a snapshot and a writable vdisk residing in the active file system. The writable vdisk is a shadow image of the snapshot file image and as noted includes an attribute that specifies the snapshot file as a backing store. It should be noted that while there are any vdisks in existence in the active file system specifying a file in a snapshot the snapshot file is locked and cannot be deleted.

According to the novel technique a write operation directed to the writable read only snapshot is trapped directed to the vdisk in the active file system such that the data associated with the operation is stored on that shadow vdisk image. In other words rather than directly accessing the read only snapshot image of a lun a client accesses the writable vdisk image which provides a translucent view of the underlying read only snapshot image. The writable vdisk is a sparse file containing only that data written by the client e.g. an initiator in a SAN to the read only snapshot image subsequent to a snapshot operation to a volume underlying the lun vdisk .

Briefly the sparse vdisk in the active file system is translucent i.e. initially the vdisk has a size equal to the size of the snapshot file because there is no data other than the snapshot file data. Since there is no data in the initial instance of the vdisk the vdisk is completely filled with holes. On read operations issued by a client to the writable read only snapshot the file system searches for the requested block in the vdisk of the active file system. If the block is not found the corresponding block from the backing snapshot file is accessed and returned. It should be noted that having writable vdisks backed by a snapshot file does not prevent direct access to the snapshot file for backup or other reasons .

Write operations are only carried out on the sparse vdisk in the active file system i.e. the vdisk in the active file system stores changes write data to the read only snapshot file. For subsequent read operations directed to the writable read only snapshot any modified changed written data blocks are returned. Otherwise the holes in the vdisk result in copies of the read only data blocks being returned from the associated snapshot file thereby providing a space conservative storage entity.

For example assume that a vdisk exists in its original state in the active file system and a snapshot is subsequently taken of the volume underlying that vdisk. Write operations can then be directed to that snapshotted vdisk in accordance with the inventive writable read only snapshot technique. To that end the writable read only snapshot storage entity may be thought of as comprising two storage space layers i an underlying snapshot layer that is frozen in time and that does not change periodically as long as the snapshot file exists and ii an overlaying vdisk layer of the active file system that does change in time as data is written to that layer.

The writable vdisk layer is thus associated with the read only snapshotted file version of the original vdisk. Modifications write data may be subsequently directed to the vdisk layer with new disk blocks being allocated to accommodate those modifications while unmodified blocks of the vdisk layer are shared through the vdisk and underlying read only snapshot layer. As a result there may be various planes of snapshots with various degrees of sharing as the active file system migrates towards subsequent modifications. For example yet another subsequent snapshot will reflect those changes made to the vdisk layer.

In accordance with the inventive technique however a special file in the active file system that is the same special file in the snapshot need not exist i.e. may be deleted. That is even though the special file inode in the active file system is deleted the corresponding snapshot file inode may be accessed by way of an attribute stored within the vdisk structure. The encapsulation property of a vdisk enables association of a snapshot file inode with the vdisk lun inode. Additionally the backing file need not be the same file as that stored in the active file system. Using the teachings described herein any backing file may be utilized. Thus as described in reference to below multiple files in the active file system may be associated with the same backing file. This association is manifested as a file handle of the snapshot file including an indication of the particular snapshot within which the file resides. This association is written into and stored in the attribute inode of the vdisk as a snapshot file handle attribute .

In the illustrative embodiment a writable read only snapshot is created by identifying and associating a snapshot file in a particular snapshot with a vdisk created in the file system via a lun create command. The lun create command provides a human readable form for a user system administrator to specify a particular file in a snapshot that will be bound associated with a newly created vdisk. An example of such a lun create command is 

Specifically the lun create command includes a path descriptor vol vol0 to a named file x in a snapshot snapshot hourly.0 and essentially binds that named snapshot file as a backing store to a newly created vdisk. A new writable snapshot lun path vol vol0 y also needs to be specified. Whereas the user interface uses names of the snapshot file and the vdisk to create the association between those two layers internally within the file system a file handle associated with the snapshot file is used to create the association. Note that in this context the file handle includes among other things the snapshot ID of the particular snapshot.

Therefore the vdisk layer may include multiple vdisk images each of which is backed by a common snapshot file in a particular snapshot layer . Each vdisk image may be written modified independently as denoted by different data blocks being modified in each of the vdisks. For example all data blocks with horizontal lines are shared between an instance of the special file in the active file system and an instance of the same file in the snapshot. Here the VBNs point to i.e. reference the same data block when those blocks are shared between the instances of the active and snapshot file. In contrast those data blocks in the active file system with hash marks indicate blocks that have been modified since the snapshot was taken consequently those blocks are not shared with the instance of the file in the snapshot and are allocated new VBN blocks. In sum each of the modified data blocks in each of the vdisks represents a newly allocated data block whereas the unmodified data blocks of the vdisks are shared with corresponding data blocks in the snapshot file backing store .

Each vdisk of the writable read only snapshot initially has the same content because it has no content of its own that is the writable vdisks initially obtain all of their content from the snapshot backing store file . Notably however each vdisk is not a copy of each other and all unmodified data is shared between the vdisks and the read only snapshot file. Because there is no copying involved a feature of the present invention is instantaneous creation of a writable snapshot despite the size largeness of the vdisk. In addition because all unmodified data is shared between a writable vdisk and the read only backing store the writable snapshot entity is space conservative and space efficient.

Use of a vdisk inode structure for implementing a writable read only snapshot allows the ability to store state e.g. the snapshot file handle within the attributes inode of the vdisk which state is needed to identify the snapshot containing the backing store file in the snapshot . By implementing the writable read only snapshot technique in the context of a vdisk structure which is not a file that structure can efficiently facilitate creation of the binding needed between the shadow copy vdisk and the original copy snapshot file . The snapshot file handle pointer to the snapshot file inode effectively locks the snapshot file inode against deletion until there are no longer any vdisks in existence in the active file system that reference point to that snapshot file inode.

At Step the SCSI target module transposes the SCSI request into a message and passes it to the file system wherein the message illustratively includes an operation read or write and a file handle containing volume inode information. The file system resolves that message to the vdisk at Step by e.g. mapping the file handle to inode structures to obtain a lun inode representative of the vdisk in the active file system. The file system then accesses the requested data block s by converting the lun inode file handle to an inode number and indexing into the inode file using the inode number to retrieve a VBN representative of the requested block. Specifically at Step the inode number and VBN are used to access retrieve from disk the lun inode attributes inode and requested data block from disk which are then loaded into memory in core .

At Step the type of operation requested in the message determines the action taken by the file system . If the requested operation is a write request the write operation is trapped to the writable vdisk at Step and the write data associated with the write operation is stored at a requested block VBN associated with the vdisk in the active file system at Step . The sequence then ends at Step . If the requested operation is a read request a determination is made at Step as to whether the requested read data is present stored in the writable vdisk. If so the requested read data is returned to the client in Step and the sequence ends at Step .

If the data is not present in the writable vdisk then at Step the file system redirects its access to the backing store i.e. snapshot file that is linked bound to the vdisk in the active file system via a snapshot file handle. The snapshot file handle is essentially a pointer to the snapshot file contained in a snapshot as noted the snapshot file functions as the backing store for the writable vdisk. In the illustrative embodiment the snapshot file handle is stored in both the attributes inode of the vdisk and the VTOC . Although the authoritative source of the snapshot file handle is a file entry of the VTOC the snapshot file handle may alternatively be acquired by accessing the attributes inode. Storage of the snapshot file handle in the attributes inode of a vdisk ensures complete encapsulation of the self contained vdisk enabling resilience to data loss in the face of VTOC loss. Thus if the requested read data is not stored in with the lun inode the file system accesses the VTOC or alternatively the attributes inode to acquire the file handle of the backing store Step . The file system and virtualization system thereafter follows uses that file handle to retrieve the backing store file inode and requested data block in Step . A determination is then made in Step as to whether the request block was allocated to the writable read only snapshot or more specifically to the backing store of the writable read only snapshot. If not a block of NULLS is returned to the client in Step . Otherwise the requested read data is then returned to the client in Step and the sequence ends at Step .

It should be noted that to the client the read data retrieved from the writable read only snapshot is always the latest data written. The client sees the writable vdisk data first if it exists and is served that data the underlying read only snapshot image being inaccessible for the range of valid data in the writable vdisk. Read only data from the underlying snapshot image is delivered to the client when no valid data overlying the range exists in the writable vdisk. The underlying snapshot image is accessible and recoverable via a non translucent path of directly accessing the snapshot image. By this technique data integrity of a snapshotted lun or vdisk as an inviolate backup is preserved.

The inventive writable read only snapshot technique enables creation of multiple writable copies of a consistent image of a storage element such as a file or file system which can be diverged for different applications. That is the inventive technique allows the use of multiple writable images in the active file system each of which is backed by a single common file in a snapshot. Unlike the prior art where writable copies of a storage element are limited by the number of mirrors that are configured there are substantially no restrictions to the number of cloned vdisks having a common backing store with the exception of free space reservations in the entire volume . Each vdisk is a separate storage entity even though backed by the same snapshot file. Since they are not the same file there may be multiple vdisk instances of the writable snapshot each of which may be modified independently.

For example assume an application of the writable read only snapshot technique is directed to carrying out multiple independent exploratory tests starting from and sharing the data stored in a single snapshot file image of a vdisk. Assume further that these tests are directed to various approaches to solving a problem. If certain of these approaches do not work then the data information associated with these approaches can be destroyed without consuming multiple copies of the original snapshot file. That is only that data which is destroyed has been consumed with respect to storage capacity.

As another example of an application of the writable read only snapshot assume multiple instances of a file system are needed wherein each instance functions as a boot disk for a particular computer in e.g. a corporation. To efficiently create the boot disk a snapshot of the active file system is taken and a vdisk is created for each instance of the file system. The snapshot file is then used as the backing store for each of the created vdisks such that each vdisk is associated with references a common read only snapshot file. The operator of each computer may thereafter utilize its vdisk without having to make a copy of the original boot file in the active file system. That is each operator can write to the file system boot disk modifying only the front end vdisk and not the shared read only snapshot file.

Yet another application of the writable snapshot may be to clone a database. In this application a snapshot is made of a database in the active file system. Thereafter multiple versions instances of that database file are cloned through the use of the vdisk layer. The vdisk layer enables independent updates to each instance of the database while all non updated data blocks are shared among the vdisk instances. The writable vdisk instances of the database may thereafter be used for e.g. testing and report generation purposes. The novel technique for creating and using accessing writable read only snapshots may be employed in this application.

Advantageously the inventive technique supports clients having a weak notion of a read only file system while preserving the integrity of a snapshot image of a lun. The novel writable read only snapshot further provides the advantages of writability in addition to reliability on account of inviolability features of snapshots. The writable read only snapshot can be employed using any protocol network file system or block storage. The novel technique also allows for a multiple level structure of a backed vdisk to be backed up for data recovery purposes using tools that include but are not limited to SnapMirror and NDMP. On restoration the restored vdisk image reflects all of the valid data previously existing as the multilevel structure.

Moreover since each writable read only snapshot comprises a writable vdisk in the active file system that is backed by a read only snapshot file multiple vdisks can be created each of which references a common read only snapshot file. Each vdisk can be written to independently and thus can have data stored therein that is different from the data stored in the other vdisks. For those data blocks that do not have modified changed data written to the vdisk corresponding data blocks in the read only snapshot file are used to fill those holes in each of the vdisks.

The foregoing description has been directed to specific embodiments of this invention. It will be apparent however that other variations and modifications may be made to the described embodiments with the attainment of some or all of their advantages. Therefore it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.

