---

title: Media streams from containers processed by hosted code
abstract: Described is a technology by which code, such as an untrusted web application hosted in a browser, provides content through an interface for playback by an application environment, such as an application environment running in a browser plug-in. Content may be in the form of elementary video, audio and/or script streams. The content is in a container that is unpackaged by the application code, whereby the content may be packaged in any format that the application understands, and/or or come from any source from which the application can download the container. An application environment component such as a platform-level media element receives information from an application that informs the application environment that the application is to provide media stream data for playback. The application environment requests media stream data (e.g., samples) from the application, receives them as processed by the application, and provides the requested media stream data for playback.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08789168&OS=08789168&RS=08789168
owner: Microsoft Corporation
number: 08789168
owner_city: Redmond
owner_country: US
publication_date: 20080512
---
Contemporary browsers and other applications allow plug ins which in general comprise hosted software code that interacts with the hosting browser application to provide some desired functionality. An important reason for using plug ins is related to security because the hosting browser limits the actions that the hosted code which is generally untrusted can perform.

One such plug in is Microsoft Silverlight which provides a platform that allows for development and hosting of rich web applications that typically include animation vector graphics and or media e.g. audio video content playback. Windows Presentation Foundation WPF is another such platform.

In general to play media on such a platform the platform provides APIs that the hosted application code calls to point the media element at specific media content e.g. by identifying a particular URI location on a server that corresponds to a container in which the media content is packaged. The platform then spawns network requests to start downloading the media. The platform parses the media content by unpacking it to extract the media content streams to provide them to a media pipeline for playback.

While such a plug in based model works very well for its intended purpose there are a number of drawbacks with this design. For one the platform needs to know each type of media container file format so that it can extract and parse the contents however containers pack media streams in various specific ways whereby the unpacking needs to be done in specific ways. At present such unpacking logic is hard coded in the platforms whereby new container formats which appear fairly regularly need to be supported through platform updates.

Another drawback to this plug in platform model is that the protocols transport mechanism used to obtain the content are limited to those the platform knows. Proprietary or other protocols transport mechanisms cannot be used which limits the content provider s flexibility in providing the media content.

This Summary is provided to introduce a selection of representative concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used in any way that would limit the scope of the claimed subject matter.

Briefly various aspects of the subject matter described herein are directed towards a technology by which untrusted application code provides content through an interface for playback by an application environment such as an application environment running in a browser plug in. Content may be in the form of elementary video audio and or script streams a script stream can contain commands and or data . The content may in a container that is unpackaged by the application code whereby the content may be packaged in any format that the application understands and or or come from any source with which the application can communicate.

In one aspect an application environment component receives information from application level code e.g. an application that informs the application environment that the application level code is to provide media stream data for playback. The application environment requests media stream data e.g. samples from the application level code receives them as processed by the application level code and provides the requested media stream data to a media pipeline for playback. The requests for samples may be repeated until some event occurs e.g. the media data is exhausted a stop or pause operation is desired seek operation is desired or an error is encountered by the application or the application environment.

In one example implementation an application environment including a platform component is provided along with an application programming interface API set that couples application level code to the platform component. The application level code downloads and processes a content container including unpacking content from the container to provide at least some of the content to the platform component via communication with the application environment through API calls. The application level code may instantiate a media stream source component from an instance of an abstract class that couples to a platform level media element through the APIs.

Other advantages may become apparent from the following detailed description when taken in conjunction with the drawings.

Various aspects of the technology described herein are generally directed towards decoupling the media content container downloading and unpacking operations from the media stream processing and playback. In general the hosted code performs the downloading and unpacking operations rather than the platform e.g. based upon Microsoft Silverlight or WPF . As one result this allows proprietary container formats such as provided by third parties to be developed out of band with the platform e.g. independent code may unpack WMV and WMA media streams from their own possibly custom container formats and inject those streams for playback. As another result the container may come from any source or sources via any protocols and or transport mechanisms. At the same time security is maintained through a specific set of platform APIs that control the actions that the hosted code performs.

In one example implementation there is provided an application environment running in a browser plug in with an interface to allow untrusted application level code to provide data in the form of elementary video audio and script streams for playback by the application environment. The data may come from any source and may be packaged in any format including formats that previous application environments are not able to process. Note that as used herein application level code refers to code that communicates through API calls to at least one lower level platform component regardless of any actual level.

Although many of the examples herein are described with reference to media content played in a browser Microsoft Silverlight environment it is understood that these are only examples. As can be readily appreciated other hosting programs and or environments may benefit from the technology described herein. As such the present invention is not limited to any particular embodiments aspects concepts structures functionalities or examples described herein. Rather any of the embodiments aspects concepts structures functionalities or examples described herein are non limiting and the present invention may be used various ways that provide benefits and advantages in computing and content processing in general.

Turning to there is shown a media playing device such as a personal computer system arranged with an application level and a platform level . Other examples of media playing devices include a mobile telephone or other digital device.

Application level code such as a web application or other code is hosted in the application level and as described below processes e.g. unpacks extracts and delivers content from a container . The application level code may be any hosted code such as a browser plug in downloaded via any network such as the Internet as represented by the set of available applications . The applications may be any type of code that may be executed including script or other human readable code that is interpreted or compiled binary or intermediate code that may be executed directly or otherwise executed. Note with respect to containers one container option is no container or just raw audio or video in which event the application may process the content as necessary for playback e.g. to decrypt it break it into samples and so forth.

Because the application level code processes the container s content the content may be in any format that the application level code understands allowing a custom application and or container for example to be hosted and have its content used in some way e.g. played back as media. This includes known container packages formats proprietary container packages formats extensions to existing packages formats and future container packages formats not yet developed.

Further the application level code may download a container such as the container from among a set of containers using any suitable protocol or protocols over any suitable network transport e.g. Sockets HTTP. This allows the content provider significant flexibility e.g. content may be distributed among servers including for redundancy load balancing security and so forth. For example a single piece of content may be in different formats in different packages may be separated into different parts may have different security requirements and so forth an application can download the different packages and merge them as needed or select one based upon conditions for providing the content for playback.

A container may comprise many different types of data. While in a typical example the data may correspond to various media such as audio video or image media any data type may be stored in a container. Further a container may have two or more different sets of data such as separate audio video and still image data sets and or each type of supported data may be distributed using different containers. Some containers may be relatively complex and may contain multiple types of data. Some containers may be supported by the application environment while other containers may not be supported even though the data contained in the containers may be compatible with the application environment . Note that because Silverlight code can be factored into code libraries different libraries for downloading and unpacking different formats can be created reused and shared this provides a way to share any different new packaging and container formats that are developed.

Code such as the exemplified application level code hosted in the application level communicates with the platform level through a set of APIs . For example the application level code makes API calls to an application environment corresponding to a media element to provide media content for playback as well as to perform other media related operations such as seek pause stop and so forth. In general regardless of the container format the platform level stays unchanged and independent of any particular application.

The application level code may also communicate with the application environment for other reasons such as to inform the application level code when a license for decrypting protected media e.g. video audio and script stream data is required as well as to enable the application level code to provide the application environment with the necessary license data e.g. for decrypting the streams. In this manner digital rights management DRM may be handled internally not by an external DRM provider e.g. DRM License requests do not need to bubble back through managed web requests or WebClient APIs a DRMInitializationVector provides data about the sample that is needed to decrypt it. However note that the flexibility of the API allows for other rights management systems to be used in conjunction with Silverlight as one example content may be encrypted over the network and then decrypted before passing it through the MediaStreamSource .

The application environment may be a plug in or other type of environment that uses a browser as a user interface. The browser may be a web browser such as an operating system component for example and may serve as a display and human interface mechanism for application level code e.g. that may execute in conjunction with the application environment. The application environment may plug into the browser. As a plug in the application environment may be invoked when the browser detects an application such as the application level code to execute. For example a video element may be created in a web page displayed by a browser. The application level code may perform various actions to retrieve process prepare and cause the video element to be displayed for example. The user may be able to manipulate controls within the user interface to pause the video seek the video to a certain point and perform other operations based on the user input.

By way of example is a flow diagram showing typical playback along with possible other playback related actions such as seek. Step represents the application level code associating a MediaStreamSource with the media element. For example the application may call a set source method pointing a source property to the URI of a container and pass a reference to the concrete CustomMediaStreamSource implementation. This essentially starts a conversation between the media element and the concrete CustomMediaStreamSource .

The media element checks whether it is currently playing media and if so stops that playback as represented by step . In any event at step the media element asks the CustomMediaStreamSource to open its media. If at step there is an error encountered by the CustomMediaStreamSource MSS e.g. the media did not open was corrupt and so forth at step the processing stops and for example the CustomMediaStreamSource can optionally provide a message or the like to report the problem to the media element as well as to the application such as to notify the user of a problem.

In the event that there is not a problem at step the CustomMediaStreamSource informs the media element what type or types of media it Represents e.g. WMA WMV MP3. As represented by step the media element then starts requesting samples.

If media is available at step and there is no error step the media element plays the media sample at step e.g. injects it into the media pipeline such as into a pipeline playback buffer. The process then continues until no more media is available that is the media is exhausted at which time step will branch to step where the media element asks the CustomMediaStreamSource to close the media. In the event an error occurred during the sample playback loop step exits the playback loop so that media processing stops with an optional message step as described above.

Another possibility generally represented by step is that the CustomMediaStreamSource requests another playback operation such as seek pause stop and so forth. As represented in step the media element responds by requesting that the CustomMediaStreamSource take the action as appropriate. Note that with such a mechanism the platform level thus remains in control of the various aspects of the playback operation. The application level is responsible for processing the container content including unpacking extracting selecting a sample and providing the content.

As described above there is provided an abstract base class with which the media element negotiates such as to obtain elementary media streams e.g. WMV WMA and MP3 and diagnostics. Application developers provide concrete implementations of that abstract base class in the CustomMediaStreamSource is a concrete example of the MediaStreamSource abstract base class .

Via the APIs the application level code instances a concrete CustomMediaStreamSource and associates it with a media element by calling a method on Media element which in this example is MediaElement.SetSource MediaStreamSource . After that call normal media pipeline requests for elementary media streams are routed out to the concrete CustomMediaStreamSource . Through exposed APIs such as set forth above the CustomMediaStreamSource provides the media pipeline with these elementary media streams as well as any diagnostics information that the media element requires.

In this example with respect to a media element having a MediaStreamSource set on it when a media element and a CustomMediaStreamSource have been created the application calls ME.SetSource new MSS . The media element then causes MSS.OpenMediaAsync to be raised.

MediaStreamSources such as the CustomMediaStreamSource are disposed of and recreated if necessary after closure. Closure occurs if the media element has its Source set to a new source if the media element has SetSource null called on it and its Source is also null or if an error occurred. Note that in this example implementation an exception is thrown if an attempt is made to set Media element to an already closed MediaStreamSource

When the media element opens and the MediaStreamSource represents a Broadcast the media element causes MSS.OpenMediaAsync to be raised. The CustomMediaStreamSource collects its audio and video streams providing MedaStreamDescriptions for each stream. The CustomMediaStreamSource makes a new mediaSourceAttributes collection with Duration set to zero 0 and CanSeek set to false. The CustomMediaStreamSource calls ReportMediaCompleted media streams attributes .

In an example implementation when the media element opens and the CustomMediaStreamSource represents On Demand content the media element causes MSS.OpenMediaAsync to be raised. The CustomMediaStreamSource collects its audio and video streams making MedaStreamDescriptions for each stream. The CustomMediaStreamSource makes a new mediaSourceAttributes collection with Duration set to the duration and CanSeek set to true. The CustomMediaStreamSource calls ReportMediaCompleted media streams attributes .

The CustomMediaStreamSource may correspond to multiple bit rate streams. Note that in one example implementation for MultipleBitRate implementers a recommendation is to only expose one audio and one video stream through ReportMediaCompleted that declares the highest allowed bit rate and pass samples of different bitrates as needed in ReportGetSampleCompleted. For example content may be encoded multiple times with different bit rates each corresponding to a container cut from a file into URI addressable chunks. The client and or server may alter which chunks it downloads based on conditions e.g. network load client load server load and so forth such as to provide different video quality resolution based upon load conditions rather than pausing playback.

When the CustomMediaStreamSource corresponds to multiple audio streams the media element causes MSS.OpenMediaAsync to be raised. The CustomMediaStreamSource collects its audio stream and video stream making MediaStreamDescriptons for each stream. The CustomMediaStreamSource calls ReportMediaCompleted Audio streams and video MediaStreamDescriptions .

Note that the MediaStreamSource may contain multiple video streams e.g. developers can attempt to switch between multiple video streams although results are not guaranteed in one implementation. To facilitate script commands and markers in one implementation developers use the media element s TimelineMarkers collection.

When the media element has Stop called on it in one typical example the media element stops raising MSS.GetSampleAsync media type . Application developers use the media element s CurrentStateChanged event and CurrentState property in conjunction with a CustomMediaStreamSource to implement this. Library developers may expose a method for an app developer to hook up the CurrentState changes from the media element with their CustomMediaStreamSource s Stop logic.

When the media element has Pause called on it in one typical example the media element stops raising MSS.GetSampleAsync media type . To obtain a notification of state change application developers use a media element s CurrentStateChanged event and CurrentState property in conjunction with a CustomMediaStreamSource. Library developers may expose a method for an application developer to hook up the CurrentState changes from the media element with their MediaStreamSource s Pause logic.

When resuming from a paused state by calling Play on the media element e.g. a video player application causes ME.Playo to be called the media element starts raising MSS.GetSampleAsync media type . When resuming from a Stopped state a video player causes ME.Playo to be called and the media element raises MSS.SeekAsync beginning of stream . The CustomMediaStreamSource calls ReportSeekCompleted very near to the beginning of stream and the media element starts raising MSS.GetSampleAsync media type .

With respect to seeks for a normal seek the video player application sets ME.Position. In response the media element causes MSS.SeekAsync new position as 100 ns ticks to be raised. CustomMediaStreamSource adjusts its streams to the nearest sample to the new location. The CustomMediaStreamSource calls ReportSeekCompleted position of the nearest sample in 100 ns ticks . The media element causes MSS.GetSampleAsync new position as 100 ns ticks to be raised. The CustomMediaStreamSource returns requested sample in MSS. ReportGetSampleCompleted.

For a Seek to the end of the stream a video player application sets ME.Position and the media element causes MSS.SeekAsync new position as 100 ns ticks to be raised. The CustomMediaStreamSource adjusts its streams to the nearest sample to the new location. The CustomMediaStreamSource calls ReportSeekCompleted position of the nearest sample in 100 ns ticks . The media element causes MSS.GetSampleAsync new position as 100 ns ticks to be raised. The CustomMediaStreamSource returns ReportGetSampleCompleted null .

When the media element enters an error state e.g. the media element hits an error from which it cannot recover the media element causes MSS.CloseAsync to be raised. The CustomMediaStreamSource disposes of its internal state as needed and disassociates itself from the CustomMediaStreamSource by internally setting its Source to null. The CustomMediaStreamSource transitions into the closed state.

When the media element switches audio streams e.g. for a scenario such as having multiple language tracks the media player causes ME.AudioStreamIndex to be set. The media element causes MSS.SwtichMediaStreamAsync stream to switch to . The CustomMediaStreamSource switches the stream and adjusts the offset on the new stream to the right time and starts buffering if necessary. The CustomMediaStreamSource calls ReportSwitchMediaStreamCompleted stream switched to 

Whenever the CustomMediaStreamSource cannot complete a media element request or has an error outside of a media element request from which it cannot recover the CustomMediaStreamSource enters an error state and informs the media element by calling ErrorOccurred. If the CustomMediaStreamSource has an unrecoverable internal error the CustomMediaStreamSource calls ErrorOccurred description of error . In response the media element receives a message and starts an internal shutdown raises a MediaFailed event with the description of the error and causes CloseMediaAsyc to be raised. The media element further disposes of any structures it needs to and cleans up and disassociates itself from the CustomMediaStreamSource by setting its internal source to null.

With respect to MediaStreamSource buffering the media element requests a sample by causing GetSampleAsync to be raised. The CustomMediaStreamSource does not have the required sample and enters buffering assuming the buffer is completely empty . The CustomMediaStreamSource attempts to gather the sample from the media file and reports that it is buffering with ReportGetSampleProgress 0 . After some amount of time the media element enters a buffering state whereby the CustomMediaStreamSource will eventually fill some portion e.g. half of its buffer assuming half filled the CustomMediaStreamSource calls ReportGetSampleProgress 0.5 . After some more time the CustomMediaStreamSource has filled the buffer to 90 and calls ReportGetSampleProgress 0.9 . After some additional time the CustomMediaStreamSource has filled the buffer completely and returns a sample by calling ReportGetSampleCompleted next sample . Sometime after receiving the sample the media element transitions back into the playing state.

With respect to a typical Playback operation the media element causes GetSampleAsync Video to be raised whereby the CustomMediaStreamSource gathers the sample and returns it via ReportGetSampleCompleted videoSample . This process is repeated over and over again for each type of sample audio and or video.

The contract between the media element and a CustomMediaStreamSource depends on the set of MediaStreamDescriptions that the MediaStreamSource initially passes to the media element . Communication from the media element to the CustomMediaStreamSource and from the CustomMediaStreamSource to the media element needs to be about this set of MediaStreamDescriptions. In other words there is a constraint for each MediaStreamDescription that the media element may pass to the CustomMediaStreamSource namely that is should equals at least one of the MediaStreamDescriptions that the CustomMediaStreamSource contains. In the opposite direction the CustomMediaStreamSource may know of more extra streams than it tells the media element but it is not to ask the media element about any of those extra streams. One way to avoid such contractual issues is for the CustomMediaStreamSource to hold onto the same collection of descriptions passed during the call to ReportMediaCompleted for its lifetime.

Developers subclass a MediaStreamSource to handle their own container formats. Most of the MediaStreamSource API work in pairs and follow the calling pattern represented in . That is when the media element needs information it makes a request to an internal method on the CustomMediaStreamSource . The CustomMediaStreamSource s internal method calls directly to the protected Async method the CustomMediaStreamSource does some processing and the CustomMediaStreamSource calls the protected Completed method to signal that it has the requested information. The Completed method calls an internal method on the media element to signal it has the information and to pass that information back to the media element .

Note that even though the method names are Async the code may respond synchronously with the corresponding Completed call from within the Async method the Async naming is more of a hint about how the media element calls this method. Further in one example implementation MediaStreamSource subclasses can only call Completed methods in response to matching Async methods calls an exception to this is GetSampleAsync and ReportGetSampleCompleted. In this case the CustomMediaStreamSource may be buffering and may respond with one or more ReportGetSampleProgress calls followed by a ReportGetSampleCompleted call. In this example if a Completed method is called by a CustomMediaStreamSource without the media element first calling the matching Async method an InvalidOperationException is raised with the message Only call Completed in response to a call from Async . The media element only makes one Async call at a time and will wait for the Completed response from the CustomMediaStreamSource before issuing another request. An exception to his is CloseAsync which may be raised after any other Async call if the media element needs to close because of an error or because the media element is being closed.

The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with the invention include but are not limited to personal computers server computers hand held or laptop devices tablet devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The invention may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures and so forth which perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in local and or remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing various aspects of the invention may include a general purpose computing device in the form of a computer . Components of the computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

The computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by the computer and includes both volatile and nonvolatile media and removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can accessed by the computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above may also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media described above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers herein to illustrate that at a minimum they are different copies. A user may enter commands and information into the computer through input devices such as a tablet or electronic digitizer a microphone a keyboard and pointing device commonly referred to as mouse trackball or touch pad. Other input devices not shown in may include a joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . The monitor may also be integrated with a touch screen panel or the like. Note that the monitor and or touch screen panel can be physically coupled to a housing in which the computing device is incorporated such as in a tablet type personal computer. In addition computers such as the computing device may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface or the like.

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include one or more local area networks LAN and one or more wide area networks WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. A wireless networking component such as comprising an interface and antenna may be coupled through a suitable device such as an access point or peer computer to a WAN or LAN. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on memory device . It may be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

An auxiliary subsystem e.g. for auxiliary display of content may be connected via the user interface to allow data such as program content system status and event notifications to be provided to the user even if the main portions of the computer system are in a low power state. The auxiliary subsystem may be connected to the modem and or network interface to allow communication between these systems while the main processing unit is in a low power state.

While the invention is susceptible to various modifications and alternative constructions certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood however that there is no intention to limit the invention to the specific forms disclosed but on the contrary the intention is to cover all modifications alternative constructions and equivalents falling within the spirit and scope of the invention.

