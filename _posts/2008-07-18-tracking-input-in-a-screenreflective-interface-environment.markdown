---

title: Tracking input in a screen-reflective interface environment
abstract: In an example embodiment, a method is adapted to tracking input with a device. The method includes an act of monitoring and acts of activating and displaying if a touch input is detected. The device has a first side and a second side, with the second side opposite the first side. The device has a display screen disposed on the first side, and a screen-reflective interface disposed on the second side. Respective positions on the screen-reflective interface correspond to respective locations of the display screen. The screen-reflective interface of the device is monitored. If a touch input is detected on the screen-reflective interface, the device performs acts of activating and displaying. Specifically, a tracking state is activated for the screen-reflective interface responsive to the detected touch input on the screen-reflective interface. The interface icon is displayed on the display screen to indicate that the tracking state has been activated.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08274484&OS=08274484&RS=08274484
owner: Microsoft Corporation
number: 08274484
owner_city: Redmond
owner_country: US
publication_date: 20080718
---
Many electronic devices today are portable. Notebook computers ultra portable computers mobile phones entertainment appliances and navigational tools are just a few examples of portable devices. Portable devices especially as they become smaller are less likely to include a full size keyboard a tethered remote an attached mouse and so forth. Nevertheless some input interface is typically needed to enable a user to control the device.

Thus most portable devices include some kind of integrated input interface. Example integrated input interfaces include miniaturized keyboards single buttons touch screens track pads dials directional buttons and so forth. Each of these existing integrated input interfaces has drawbacks. For example miniaturized keyboards single buttons and dials are not adept at enabling a user to control a pointer indicator of a graphical user interface GUI . Track pads and directional buttons do enable interaction with a GUI pointer indicator but the former can be imprecise and the latter is usually slow and inconvenient to use.

Moreover each of these integrated input interfaces typically demands additional surface area on and or significant volume of the device both of which result in a larger portable device. With a touch screen on the other hand the face of the device does not need to be increased to accommodate an integrated input interface. Unfortunately when an individual is attempting to interact with a touch screen the user s finger or fingers block the details of the desired screen target. The remaining portion of the user s hand can also obscure other display portions of the touch screen. It is therefore apparent that many deficiencies still exist for conventional integrated input interfaces for portable devices.

For certain example embodiments generally in a screen reflective interface environment a GUI may be manipulated by a user with a touch sensitive integrated input interface that is disposed oppositely to a display screen of a device. Three states may be enabled an out of range state a tracking state and an engaged state. When no contact is detected the interface is in the out of range state. When a touch input is detected the tracking state is activated and an interface icon is displayed on the display screen. When a press input is detected the engaged state is activated and distinct interface functionality is initiated.

In an example embodiment a device has a first side and a second side with the second side being opposite the first side. The device has a display screen disposed on the first side and a screen reflective interface disposed on the second side. Respective positions on the screen reflective interface correspond to respective locations of the display screen. In operation the screen reflective interface of the device is monitored.

During operation if a touch input is detected on the screen reflective interface acts of activating and displaying are performed. A tracking state for the screen reflective interface is activated responsive to the detected touch input on the screen reflective interface. An interface icon is displayed on the display screen to indicate that the tracking state has been activated with the interface icon being displayed at a location of the display screen that corresponds to a position of the touch input on the screen reflective interface.

If a press input is detected at the screen reflective interface while the tracking state is active acts of activating and initiating are performed. An engaged state for the screen reflective interface is activated responsive to the detected press input at the screen reflective interface. Also a distinct interaction functionality for the engaged state is initiated. Alternatively a press input may be detected at a button input of the device during the tracking state to precipitate activation of the engaged state.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. Moreover other systems methods devices media apparatuses arrangements and other example embodiments are described herein.

As explained herein above conventional integrated input interfaces for portable devices have existing deficiencies that have yet to be remedied. With respect to touch screens they do not require that a portion of the front of the device be devoted to the integrated input interface. Unfortunately fingers of the user can block a desired screen target that is to be selected and the hand of the user can also obscure other portions of the touch screen.

The tendency of the fingers and hand to block and obscure a display screen when a conventional touch screen is being used may be remedied by incorporating a touch sensitive panel on the other side of the device opposite the display screen. In other words a display screen may be disposed on a first side of a device and a touch sensitive panel may be disposed on the second side. With this arrangement the first side of the device is opposite the second side.

One approach to implementing a touch sensitive panel on a side opposite the display screen is to introduce a hover state. With a hover state a user moves fingers over the touch sensitive panel without touching the panel. An optical apparatus determines the position of the user s fingers on the touch sensitive panel. When the touch sensitive panel is touched the touch sensitive panel detects the touch. The position of the touch is ascertained based on the position of the fingers as determined by the optical apparatus.

This optical based approach is workable but it does have drawbacks. First the optical apparatus is likely to be large and relatively unwieldy at least for a truly portable device. Second the positional determination is likely to be imprecise. Third users tend to find it difficult to hover their fingers above the touch sensitive panel without actually touching it. Hovering can be difficult when the touch sensitive panel is visible. It is all the more difficult when the touch sensitive panel is out of view on the backside of the device opposite the display screen.

In contrast for an example embodiment that is described herein a user may touch a touch sensitive panel on the backside of a device to activate a tracking state. At least one position that is currently being touched may be tracked. This current touch position is reflected by a current location of an interface icon that is displayed on a display screen. When a press input is detected distinct interface functionality may be initiated.

In an example embodiment a device that is capable of tracking input includes a first side a second side a display screen and a screen reflective interface. The second side is opposite the first side. The display screen is disposed on the first side and the screen reflective interface is disposed on the second side. Respective positions on the screen reflective interface correspond to respective locations of the display screen. The device further includes a detection unit to monitor the screen reflective interface. The detection unit includes a touch detector to detect a touch input on the screen reflective interface. If the touch detector detects a touch input the touch detector is to activate a tracking state for the screen reflective interface responsive to the detected touch input on the screen reflective interface. If the touch detector detects a touch input at a particular position the touch detector is also to indicate that the tracking state has been activated by causing an interface icon to be displayed on the display screen at a particular location that corresponds to the particular position.

By way of example an interface environment for a device having a screen reflective interface may include three states an out of range state a tracking state and an engaged state. When no contact is detected at the screen reflective interface the out of range state is active. During the out of range state no interface icon is displayed at least responsive to or with respect to input received via the screen reflective interface. When a touch input is detected at the screen reflective interface the tracking state is activated and an interface icon is displayed on the display screen. While the tracking state is active the interface icon is moved to locations on the display screen that correspond to positions being touched on the screen reflective interface.

While the tracking state is active if a press input is detected e.g. at the screen reflective interface or a button of the device the engaged state is activated. When the engaged state is activated distinct interface functionality may be initiated. Examples of distinct interface functionality include but are not limited to mouse type clicks drag and drop operations combinations thereof and so forth. Additional example embodiments and implementations are described further herein below.

In an example embodiment physical contact to screen reflective interface may be used to produce interactions with display screen . Physical contact may be for example a touch a press a movement combined with a touch or press etc. by finger . From time to time one or more interface icons are displayed on display screen . For instance interface icon may be displayed when finger is in contact with screen reflective interface . Different interaction states that depend on the presence and or type of contact by finger with screen reflective interface are described herein below with particular reference to .

Positions on screen reflective interface are proportional to locations on display screen . Thus movements on display screen e.g. by an interface icon may be made proportional to movements on screen reflective interface e.g. by a touching finger . A position on screen reflective interface has a corresponding location on display screen . A position in the middle of screen reflective interface corresponds to a location in the middle of display screen .

However the positions of screen reflective interface mirror or reflect the corresponding locations of display screen . A position in the top left of screen reflective interface corresponds to a location in the top right of display screen . Similarly a position in the middle right of screen reflective interface corresponds to a location in the middle left of display screen . Consequently touching a given position on screen reflective interface can cause an interface icon to be displayed in the corresponding location of display screen .

A one to one correspondence between detectable touch positions and displayable pixels locations may be created but such a one to one correspondence is not necessary to establish proportionality. Different touch position granularities and pixel location resolutions may be implemented. For example each detectable touch position may correspond to a block e.g. a 4 4 block of displayable pixel locations. On the other hand the granularity of touch positions may be greater than the resolution of pixel locations.

Screen reflective interface may be any size e.g. height and width relative to display screen but the proportionality of correspondences between positions on screen reflective interface and locations of display screen is maintained. In an example embodiment however a size of screen reflective interface is substantially equal to a size of display screen to facilitate an intuitive feel for the touch position and display location correspondence. This intuitive feel may be maintained even if the relative sizes differ to some degree e.g. by approximately 20 such that a size of screen reflective interface is smaller or larger than a size of display screen . To increase ease of use and precision at the edges of display screen screen reflective interface may be about one half the width of a finger larger than display screen at each of the four edges e.g. left right top and bottom .

For side view C of device is shown as having one or more buttons . In certain embodiments pressing a button in conjunction with contact to screen reflective interface may also enable interaction with device . A button may be a standard binary button with pressed and released positions a directional button including ones that may be used like a standard binary button when pressed in their center a dial that may be used like a standard binary button when pressed and so forth. Although three buttons are shown device may have more or fewer including no buttons. Also one or more buttons may be located on different sides of device .

Device may be by way of example but not limitation a notebook computer an ultra portable computer a mobile phone or other communication oriented device an entertainment appliance e.g. a game player a music player a video player etc. a navigational tool e.g. a GPS capable device some combination thereof and so forth. Also device need not be portable as long as the back side of the device opposite display screen is accessible to a human operator. Display screen may be a liquid crystal display LCD an organic light emitting diode OLED display a digital ink display and so forth. It should be noted that display screen may also be touch sensitive to increase the number of interaction options. An example implementation for a device is described further herein below with particular reference to .

For out of range state A finger has no contact A with screen reflective interface . This is the inactive out of range condition at . The appearance of display screen includes the illustrated background e.g. rolling hills . For no contact A between finger and screen reflective interface no interface icon is displayed at .

For tracking state B finger has a touch type of contact B with screen reflective interface . This touch contact B activates the tracking state at . When the tracking state is activated an interface icon is displayed. The appearance of display screen is therefore updated by displaying at an interface icon . The location at which interface icon is displayed on display screen corresponds to a position at which finger touches screen reflective interface .

For tracking state with movement C finger has a touch plus finger movement type of contact C with screen reflective interface . While the tracking state is active as at movement of finger with continued touch input on screen reflective interface causes a proportional amount of movement to interface icon on display screen . The appearance of display screen is therefore updated by moving at the location of interface icon . More specifically the location on display screen to which interface icon is moved corresponds to the position on screen reflective interface to which finger is moved. The speed or frequency of the location updates of interface icon as the position of finger changes may vary.

For engaged state D finger has a press type of contact D with screen reflective interface . This press contact D activates the engaged state at . When the engaged state is activated distinct interface functionality is initiated at . As shown by the updated display screen a weapon is fired at the current location of interface icon in the example of . The appearance of interface icon may also be changed when the engaged state is activated as shown. Although screen reflective interface is shown in as being locally depressed by the press contact D of finger presses may affect screen reflective interface differently. For example the entirety of screen reflective interface may be depressed uniformly. Also screen reflective interface may not be physically depressed when an electrical scheme is used to detect press contact D. Furthermore press contact D may correspond to a press of a button of the device instead of a press of screen reflective interface .

Generally distinct interface functionality is initiated based on the current location of interface icon and or the current position of the touch input from finger . In other words but by way of example only a press contact D while the tracking state is active may be equivalent to a mouse click that activates an engaged state. Although not shown in if finger is moved during the engaged state e.g. finger is moved while pressing screen reflective interface or while a button is being pressed a dragging operation may be performed based on a location of interface icon when the press contact D commences. Ceasing the press contact D may be equivalent to a drop operation. Also although the engaged state is activated at by a press contact D of screen reflective interface in it may alternatively be activated by a press contact D of a button e.g. of .

In front view A the fingers that are hidden from sight are shown with dashed lines. In front view B images of the fingers D are displayed on display screen . The images of fingers D may be displayed in any of a number of different ways. For example they may be displayed in outline form. They may also be displayed completely but translucently such that the image contents of display screen remain discernable to the user. The images of fingers D may also be displayed translucently so as to look like actual fingers. The user may be given the opportunity to indicate skin color or otherwise select a desired appearance for fingers D. The resulting effect of displaying translucent finger images is that display screen practically appears to be at least partially transparent with the displayed images of fingers D showing thru the transparent display screen.

In an example embodiment with reference to display screen includes one or more interface icons . The appearance of interface icons may change depending on which state is currently active. Specifically an interface icon T is displayed when a tracking state is active. An interface icon E is displayed when an engaged state is active. Although interface icons are shown changing appearance upon a transition from the tracking state to the engaged state the appearance of an interface icon may alternatively be the same for each state.

For front view A of six fingers are in contact with screen reflective interface not shown in . Four fingers are currently touching screen reflective interface on the back side of device as indicated by the four circular interface icons T. Two fingers are currently pressing screen reflective interface on the back side of device as indicated by the two star shaped interface icons E. Because screen reflective interface is capable of discerning whether individual finger s are performing a press type of contact in the example embodiments of screen reflective interface is capable of sensing both multi touch and multi pressure inputs.

For front view B of seven fingers are currently in contact with screen reflective interface . The one finger in back of device that is not in contact with screen reflective interface is hidden and represented by dashed lines. The seven fingers in back of device that are in contact with screen reflective interface are represented by the displayed fingers D. As noted above these displayed fingers D may be produced on display screen in outline translucent or another form. Five fingers are currently touching screen reflective interface as indicated by the five interface icons T. One finger is currently pressing screen reflective interface as indicated by the single interface icon E.

In an example embodiment front view D illustrates a tracking state on display screen and front view E illustrates an engaged state on display screen . An interface icon T for the tracking state is shown. An interface icon E for the engaged state is also shown. An example operation is described with reference to .

Initially an out of range state is in effect in which no interface icon is displayed on display screen of . Next finger touches screen reflective interface at position T. This touch activates the tracking state. As shown with front view D interface icon T is displayed on display screen at a location that corresponds to position T.

While the tracking state is active finger is moved distance to position E. The location of interface icon is moved a corresponding proportional distance on display screen . As shown with front view E the displayed location of interface icon has moved from being over the No visual button to being over the Yes visual button. At position E finger presses screen reflective interface to activate an engaged state. Alternatively pressing a button on any side may activate the engaged state. As shown with front view E interface icon E may indicate activation of the engaged state. For instance the appearance of interface icon may change and or a displayed UI item may change e.g. a visual button may appear to be pressed .

Activation of the engaged state may cause a distinct interaction functionality to be initiated. Examples of distinct interaction functionalities include but are not limited to a mouse type click a mouse type drag operation a mouse type drag and drop operation and so forth. These distinct interaction functionalities can initiate for example a visual button press an item selection firing of a weapon resizing of a window moving an item from one place to another some combination thereof and so forth.

An example UI dragging operation is described with reference to . By way of explanation if finger were pressed at position T and moved to position E while continuously pressing screen reflective interface along distance a dragging operation may be performed in response thereto. The dragging operation is performed on display screen of from the location of interface icon T to the location of interface icon E. Alternatively a dragging operation may be performed with a touch input from position T to position E if a button is pressed and held during the touching and movement.

In an example embodiment screen reflective interface is adapted to be sensitive to both touch and pressure. More specifically touch sensitive component T is adapted to sense which position s on screen reflective interface are currently being touched. Pressure sensitive component P is adapted to sense when pressure is currently being applied to screen reflective interface . Pressure sensitive component P when included as part of screen reflective interface may be capable of sensing where pressure is currently being applied on screen reflective interface or may be merely capable of sensing that pressure is being applied at screen reflective interface .

Detection unit is adapted to process touch and pressure inputs and to ascertain when a touch input or a press input has been detected. Detection unit may be realized as hardware firmware software fixed logic circuitry some combination thereof and so forth. In an example operation touch detector T is to detect a touch input on touch sensitive component T of screen reflective interface . When a touch input is detected by touch detector T during an out of range state a tracking state is activated at . Also touch detector T is to instruct at display screen to display an interface icon to indicate that the tracking state has been activated e.g. via an operating system application programming interface API . The instruction at to display an interface icon may also be provided to the underlying logic for whatever program s are currently being executed e.g. for which images are currently being displayed .

Pressure detector P is to detect when a press input has occurred. The detected press input may be at pressure sensitive component P of screen reflective interface and or at one or more buttons e.g. of FIGS. C and D F . When a press input is detected by pressure detector P while the tracking state is active an engaged state is activated at . Also pressure detector P is to instruct at display screen to initiate distinct interaction functionality to indicate that the engaged state has been activated. The instruction at to initiate distinct interaction functionality may also be provided to the underlying logic for the programs that are currently being executed an OS and so forth. A press input may be deemed to have been detected when the detected force at pressure sensitive component P exceeds a predetermined threshold. The predetermined threshold may be adjustable by the user.

From a hardware perspective screen reflective interface may be implemented using any of many different structures in different combinations. Example structures for implementing screen reflective interface generally and touch sensitive component T and or pressure sensitive component P specifically are described below. However other structures may alternatively be used to implement them.

Screen reflective interface may be implemented with a track pad e.g. a capacitive track pad a resistive screen an optical tracking apparatus e.g. using cameras light emitting diodes and receptors etc. one or more switches elastic material electrical contacts combinations thereof and so forth. A specific example implementation is described herein below with particular reference to .

In an example implementation touch sensitive component T may be a track pad and pressure sensitive component P may be at least one micro switch. The track pad is mounted on the micro switch. If one micro switch is used a lever system may be employed to at least partially equalize the pressure involved in activating the micro switch regardless of where on the track pad the pressure is applied. Alternatively multiple micro switches may be used. For instance one micro switch may be placed at each of the four corners of a rectangular shaped screen reflective interface . Pressure detector P may be calibrated to determine when different sets of forces on different ones of the micro switches are deemed to constitute a press input.

As another example implementation touch sensitive component T may be implemented as a flexible touch pad with a pressure sensitive component P underneath. Also pressure sensitive component P may be implemented as one or more force sensors.

As yet another example implementation screen reflective interface may be implemented with one apparatus. In other words touch sensitive component T and pressure sensitive component P may be realized using a single hardware component. For instance a capacitive track pad is capable of sensing both touch and pressure. A relatively light finger contact registers as a relatively low capacitive increase which may be deemed to equate to a touch input. A relatively heavier finger contact registers as a relatively high capacitive increase which may be deemed to equate to a press input. In other words a capacitive increase that meets a predetermined threshold may be deemed to constitute a press input instead of a touch input.

In another example embodiment screen reflective interface may be capable of sensing multi touch. Examples of multi touch are shown in . Screen reflective interface may be adapted to sense multiple different touch inputs simultaneously. Moreover screen reflective interface may also be adapted to sense a press input at screen reflective interface overall or adapted to sense a potential respective press input at each individual point of detected touch input. The granularity of the pressure sensitivity may be essentially continuous or divided into a grid.

In yet another example embodiment feedback confirmation of a detected press input may be provided by a device. For example visual feedback may be provided via the display screen. Example feedback schemes that involve changing the appearance of the interface icon or other screen elements are shown in A B and E. Other forms of feedback confirmation instead of or in addition to visual forms may be provided. Example other forms include audible feedback and tactile feedback. For audible feedback a beep chime or other sound may be played by the device through a speaker.

With respect to tactile feedback a mechanical hardware apparatus such as a micro switch may intrinsically provide such feedback. For electrically based forms of pressure sensing the tactile feedback may be created when a press input is detected by firing a tactile feedback mechanism . For example a thumper type of tactile feedback mechanism may be coupled to pressure detector P. When a press input is detected by pressure detector P the thumper may be fired to shake vibrate the device.

Detection unit may further provide one or more features to facilitate a user s control of a device with screen reflective interface . For example movements of a touch input may be filtered to smooth their displayed representation as movements to interface icon . More specifically the movement of the location of an interface icon on display screen that is to reflect corresponding positional movements of a touch input on screen reflective interface may be smoothed via a filtering process. The location of interface icon may also be stabilized via the filtering process. An example filter type that may be employed is a Kalman filter but other filter types may be used.

Another example feature that detection unit may provide is temporal position location retrieval upon activation of the engaged state. When pressure detector P detects a press input detection unit may retrieve the position of the touch input on screen reflective interface and or the location of interface icon on display screen at a predetermined period of time in the past. The engaged state may then be activated based on the retrieved position or location. This temporal position location retrieval can compensate for the possible inadvertent movement of the user s finger during the pressing action. An example predetermined period of time is 80 milliseconds but other times may be used instead.

For an example embodiment touch sensitive component T may be a track pad or resistive screen. As illustrated in the middle third of second electrical contact is attached to touch sensitive component T . Elastic material is adhered to touch sensitive component T . Alternatively elastic material may be adhered to support panel or maintained in place with friction when the parts are secured together. Elastic material may be foam a layer of adhesive backed latex and so forth.

As illustrated in the bottom third of first electrical contact is attached to support panel . In operation elastic material biases touch sensitive component T away from support panel such that first and second electrical contacts and do not touch each other. Touch inputs from the user may be sensed by touch sensitive component T without compressing elastic material . When a predetermined amount of force is exerted on touch sensitive component T so that elastic material is compressed and such that first and second electrical contacts and touch on another a press input may be sensed via pressure sensitive component P . Thus a pressure detector P of may detect a press input when electrical contact is made between first and second electrical contacts and

The acts of flow diagram that are described herein may be performed in many different environments and with a variety of different devices such as by one or more processing devices e.g. of . The order in which the method is described is not intended to be construed as a limitation and any number of the described blocks can be combined augmented rearranged and or omitted to implement a respective method or an alternative method that is equivalent thereto. Although specific elements of certain other FIGS. are referenced in the description of this flow diagram the method may be performed with alternative elements.

For example embodiments at block a screen reflective interface is monitored. For example a screen reflective interface may be monitored by a detection unit . At block an inactive or out of range state is maintained. For example out of range state A may be maintained during the monitoring until a touch input is detected at screen reflective interface .

At block it is determined if a touch input is detected. For example it may be determined by touch detector T if a touch input at touch sensitive component T has been detected. If not then the inactive out of range state is maintained at block . If a touch input is detected then the method continues at block .

At block a tracking state is activated. For example a tracking state B may be activated responsive to detection of touch contact B on screen reflective interface . At block an interface icon is displayed. For example an interface icon may be displayed at on a display screen to indicate that the tracking state has been activated at .

At block the touch input is tracked with the interface icon. For example movement of a position of the touch input on screen reflective interface may be tracked while the tracking state is active at by correspondingly moving a location of interface icon on display screen e.g. from the location of interface icon T to the location of interface icon E in . Hence the location of interface icon on display screen may correspond to and reflect the position of touch plus finger movement contact C on screen reflective interface .

At block it is determined if a press input is detected. For example it may be determined by pressure detector P if a press input at a pressure sensitive component P if implemented or at a button if implemented has been detected. If not then the method continues at block to determine if contact is still present at the screen reflective interface. If on the other hand a press input is detected then the method continues at block .

At block an engaged state is activated. For example an engaged state D may be activated at responsive to detection of press contact D. A feedback of an audible visual and or tactile nature may be provided to indicate that the engaged state has been activated.

At block distinct interaction functionality is initiated. For example a click a drag a drag and drop or some other distinct interaction functionality may be initiated at . The distinct interaction functionality may entail clicking a visual button moving or resizing a visual object presenting a menu or other set of options otherwise controlling or adjusting the device via a GUI and so forth.

At block it is determined if the absence of contact is detected. For example it may be determined that either a touch input or a press input or both have ceased being detected at screen reflective interface . If the absence of contact is not being detected i.e. a touch contact B and a press contact D are still being detected then the method may continue at block to continue the distinct interaction functionality e.g. to implement a drag operation .

On the other hand if the absence of contact is detected at block then the method continues at block . At block it is determined if the touch input continues. If the touch input continues and the press input has ceased then the method continues at block to track the touch input with the interface icon. If the touch input does not continue and hence there is neither touch nor press inputs then the method continues at block by activating the out of range state.

For example embodiments device may represent any processing capable device. Example devices include personal or server computers hand held or other portable electronics entertainment appliances network components some combination thereof and so forth. Device and device may communicate over network s . Network s may be by way of example but not limitation an internet an intranet an Ethernet a public network a private network a cable network a digital subscriber line DSL network a telephone network a wireless network some combination thereof and so forth. Person device interface equipment may be a keyboard keypad a touch screen a remote a mouse or other graphical pointing device a display screen e.g. of a speaker a button e.g. of a screen reflective interface e.g. of and so forth. Person device interface equipment may be integrated with or separate from device

I O interfaces may include i a network interface for monitoring and or communicating across network ii a display device interface for displaying information on a display screen iii one or more person device interfaces and so forth. Examples of i network interfaces include a network card a modem one or more ports a network communications stack a radio and so forth. Examples of ii display device interfaces include a graphics driver a graphics card a hardware or software driver for a screen or monitor and so forth. Examples of iii person device interfaces include those that communicate by wire or wirelessly to person device interface equipment . A given interface may function as both a display device interface and a person device interface.

Processor may be implemented using any applicable processing capable technology and one may be realized as a general purpose or a special purpose processor. Examples include a central processing unit CPU a microprocessor a controller a graphics processing unit GPU a derivative or combination thereof and so forth. Media may be any available media that is included as part of and or is accessible by device . It includes volatile and non volatile media removable and non removable media storage and transmission media e.g. wireless or wired communication channels hard coded logic media combinations thereof and so forth. Media is tangible media when it is embodied as a manufacture and or as a composition of matter.

Generally processor is capable of executing performing and or otherwise effectuating processor executable instructions such as processor executable instructions . Media is comprised of one or more processor accessible media. In other words media may include processor executable instructions that are executable by processor to effectuate the performance of functions by device . Processor executable instructions may be embodied as software firmware hardware fixed logic circuitry some combination thereof and so forth.

Thus realizations for tracking input in a screen reflective interface environment may be described in the general context of processor executable instructions. Processor executable instructions may include routines programs applications coding modules protocols objects components metadata and definitions thereof data structures APIs etc. that perform and or enable particular tasks and or implement particular abstract data types. Processor executable instructions may be located in separate storage media executed by different processors and or propagated over or extant on various transmission media.

As specifically illustrated media comprises at least processor executable instructions . Processor executable instructions may comprise for example detection unit of . Generally processor executable instructions when executed by processor enable device to perform the various functions described herein. Such functions include by way of example those that are illustrated in flow diagram of and those pertaining to features illustrated in the various block diagrams as well as combinations thereof and so forth.

The devices acts features functions methods modules data structures techniques components etc. of are illustrated in diagrams that are divided into multiple blocks and other elements. However the order interconnections interrelationships layout etc. in which are described and or shown are not intended to be construed as a limitation and any number of the blocks and or other elements can be modified combined rearranged augmented omitted etc. in many manners to implement one or more systems methods devices media apparatuses arrangements etc. for tracking input in a screen reflective interface environment.

Although systems methods devices media apparatuses arrangements and other example embodiments have been described in language specific to structural logical algorithmic and or functional features it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claimed invention.

