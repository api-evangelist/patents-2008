---

title: Robotics systems
abstract: A method of controlling a robot includes running multiple applications on a processor, where each application has a robot controller and an action selection engine. Each application is in communication with at least one behavior and at least one action model of at least part of the robot. The method includes running periodic action selection cycles on each action selection engine. Each action selection cycle includes selecting a command for each action space of each action model, generating a single overall command based on the accumulated commands for each action model, and sending the overall command to the robot controller for execution on the robot.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08452448&OS=08452448&RS=08452448
owner: iRobot Corporation
number: 08452448
owner_city: Bedford
owner_country: US
publication_date: 20080410
---
This U.S. patent application claims priority under 35 U.S.C. 119 e to U.S. Provisional Application 61 041 707 filed on Apr. 2 2008. The disclosure of the prior application is considered part of and are hereby incorporated by reference in the disclosure of this application.

Behavior based robotics systems grew out of a reactive approach to robot control in order to compensate for limitations lack of state and inability to look into the past or the future while conserving its strengths real time responsiveness scalability and robustness . In the last decade behavior based systems have proven themselves as one of the two favored general methodologies the other being hybrid systems for autonomous system control and as the most popular methodology for physical multi robot system coordination. Effective behavior selection or arbitration is a key challenge in behavior based control as it determines which behavior or subset of behaviors controls the robot at a given time. Current systems run behaviors serially but face myriad issues when given the task of running multiple behaviors at once that require overlapping resources of the robot.

Effective action selection and control arbitration are critical elements to providing high quality behavior based control for robot systems. The system designed must provide coherency of action across many different applications while providing coordination between many competing goals obstacles and physical constraints in a robot system. These mechanisms work together to determine which behavior or subset of behaviors controls the robot at a given time. Current systems for behavioral control fail to simultaneously provide coherency and coordination and they fail to scale up to the large numbers of actuators in modern robot systems often 10 or more DOF .

The robotics system disclosed is designed to be a low overhead in process component API system. The robotics system may include a base framework that is the basis of all other frameworks in a robot and defines how other internal interfaces are defined as well as how to build software modules from reusable units. The base framework provides the necessary infrastructure for principled medium grained software composition of dynamically loaded and configured binary objects within a single process. This feature is included to support the construction of extensible plug in or add on software components of significant internal complexity. The features of the base framework are intended to address the needs of complexity management scaling of system size and dynamic software composition at runtime for interfaces.

The robotics system described herein provides two levels of application structure and are used to cleanly separate roles and responsibilities in the software design of behavior based robots. The robotics system includes a control arbitration layer that allows multiple applications to simultaneously share control of robot actuators in a prioritized fashion. The control arbitration layer provide coherency of robot actuator resource access across the set of applications. The control arbitration layer of the robotics system allows multiple applications to start and stop dynamically at runtime and supports the principled sharing of robot resources actuators between different applications based on a user specified priority ordering between those applications.

The robotics system also includes an action selection layer that allows a hierarchical collection of behaviors within an application to collaboratively generate a coordinated output command for very large numbers of degrees of freedom large number of actuators . The action selection layer allows multiple behaviors to collaborate by evaluating possible outcomes from known feasible robot commands that respect the dynamic limits of the robot system actuators. Behaviors evaluate trajectories of future actuation states called outcomes and provide evaluations of the outcomes. Action models are used to provide the feasible set of commands provide a search heuristic for a specific set of actuators and to simulate the effects of a command forward in time. To reduce the complexity of the search space within the action selection system the entire set of resources actuators on the robot is split in to an ordered collection of sub spaces which are searched for the best available feasible command independently. The behaviors themselves are intended to implement separable portions of the total cognizance of the robot and are often broken down based on a user level problem description where one behavior or one group of behaviors is assigned to each task within the user level description of the robot s overall mission.

The action selection layer also provides an integrated event dispatching loop which is used by outside components of the robot system to coordinate the hierarchical collection of behaviors. The event dispatching and handling elements of the action selection layer can be used to enable disable behaviors and action model elements switch the modes or states within a behavior or any other application defined purpose. The key value of the approach is that this event handling and dispatch are integrated with the basic behavior application programming interface API to simplify the construction of behaviors.

In one aspect a method of controlling a robot includes running multiple applications on a processor where each application has a robot controller and an action selection engine. Each application is in communication with at least one behavior and at least one action model of at least part of the robot. The method includes running periodic action selection cycles on each action selection engine. Each action selection cycle includes selecting a command for each action space of each action model generating a single overall command based on the accumulated commands for each action space and sending the overall command to the robot controller for execution on the robot. One advantage of the action selection engine is its ability to generate an overall command for the robot that is composed of commands for every action space of the robot.

Implementations of this aspect of the disclosure may include one or more of the following features. The action selection cycle in some examples includes three phases nomination action selection search and completion. In the nomination phase each action model and each behavior are informed of the system state and of the start of the action selection cycle. In the action selection search phase the action selection engine uses action models to generate feasible commands and simulated outcomes in each of the action spaces space of available actions . The action selection engine may make multiple calls to evaluation functions while searching for the best possible outcome in the time available for the cycle. The action models generate the feasible commands and corresponding resulting future outcomes that are evaluated by the behaviors. The action selection engine accumulates the outcome evaluations provided by the behaviors for each action space and selects the best outcome and corresponding command for each action space. The action selection engine then generates the overall command for all the robot resources by combining the selected command in each separate action space. In the completion phase the action selection engine sends the overall command to the connected robot controller for execution and sends the overall outcome to all active behaviors and behavior policies as feedback on the cycle allowing behavior policies to adapt if possible .

In some implementations the action selection cycle includes obtaining a system state from the robot controller informing each action model and each behavior of the system state and informing each action model and each behavior of the start of the action selection cycle. Selecting a command for each action space in some examples includes calling the corresponding action model to generate feasible commands for the action space calling the corresponding action model to generate outcomes for the feasible commands calling each behavior to evaluate and provide an outcome evaluation for each outcome accumulating the outcome evaluations of each behavior selecting a winning outcome for the action space and selecting the command corresponding to the winning outcome. The method may include implementing an application priority policy that determines which application has exclusive control of resources of the robot required by that application at a given time. The application priority policy may be implemented by a robot manager in communication with each robot controller.

In another aspect a method of generating a command for a robot controller includes calling at least one action model having at least one action space to generate feasible commands for each action space calling each action model to generate an outcome for each command and sending each outcome to at least one behavior for evaluation. Each behavior provides an outcome evaluation for each outcome. The method includes selecting a winning outcome for each action space based on the at least one outcome evaluation selecting the command corresponding to the winning outcome for each action space generating a single overall command based on the accumulated commands for each action space and sending the overall command to the robot controller. Multiple behaviors in communication with the action selection engine can collaborate by evaluating outcomes simulated by the action models for feasible robot commands that respect the dynamic limits of the robot system actuators. In some implementations the method includes obtaining a system state from the robot controller and informing each action model and each behavior of the system state.

Implementations of the above two aspects of the disclosure may include one or more of the following features. In some implementations calling the action model to generate feasible commands for an action space includes generating a randomized set of commands based on a previously selected command of the robot system and limited to a feasible spread from a current state by the dynamic actuator limits acceleration velocity torque etc. . In examples where the action model heuristic generates commands around a previously selected command the action selection engine may use the set of randomly generated feasible commands to execute a hill climbing randomized search. The search may include a search technique utilizing a command history of the action space and or be a randomized search based on a current command.

Preferably each action model is sequentially called in a predetermined order and each action space within each action model is sequentially called in a predetermined order. The winning outcomes of any preceding action spaces are considered when selecting the winning outcome for each action space. The outcome evaluations can be weighted according to weights associated with each behavior. The method in some examples includes generating an overall outcome for the overall command and sending the overall outcome to each behavior as feedback.

In yet another aspect a robotics system includes multiple robot resources a control arbiter for each robot resource and multiple applications in communication with the control arbiters. Each control arbiter controls its associated robot resources. Each application includes a robot controller in communication with the control arbiters an action selection engine in communication with robot controller at least one behavior in communication with the action selection engine and at least one action model in communication with the action selection engine. The action selection engine periodically executes an action selection cycle to generate an overall command which is sent to the robot controller for execution on the robot resources. Each action model models at least one of the robot resources and has at least one action space. A robot manager communicates with the applications and the control arbiters. The robot manager implements an application priority policy for determining which application has exclusive control of any one or more of the robot resources at a given time. The action selection cycle includes selecting a command for each action space of each action model generating the single overall command based on the accumulated commands for each action space and sending the overall command to the robot controller.

Implementations of this aspect of the disclosure may include one or more of the following features. In some implementations each action model is independently removable from the robotics system and communicates with the action selection engine through an action model application programming interface. The action model application programming interface includes a get action spaces function configured to provide a resource and outcome state space structure of the action model. In some examples the action model application programming interface includes a begin cycle function configured to begin the action selection cycle a generate commands function configured to generate commands for a given action space a simulate command function configured to simulate outcomes for given commands and a notify command function configured to notify the action model of a command chosen for a particular action space.

In some implementations each behavior is independently removable from the robotics system and communicates with the action selection engine through a behavior application programming interface. The behavior application programming interface includes an initialization function configured to initialize the behavior for use a begin cycle function configured to begin the action selection cycle an evaluate function configured to evaluate a collection of outcomes and an end cycle function configured to notify the respective behavior that the action selection cycle is complete.

In some implementations the action selection cycle includes obtaining a system state from the robot controller informing each action model and each behavior of the system state and informing each action model and each behavior of the start of the action selection cycle.

In some examples selecting a command for each action space includes calling the corresponding action model to generate feasible commands for the action space calling the corresponding action model to generate outcomes for the feasible commands calling each behavior to evaluate and provide an outcome evaluation for each outcome accumulating the outcome evaluations of each behavior selecting a winning outcome for the action space and selecting the command corresponding to the winning outcome. The robotics system preferably includes a publish subscribe system configured to provide asynchronous messaging between each robot controller each control arbiter and the robot manager.

In another aspect a robotics system includes multiple robot resources a control arbiter for each robot resource and multiple applications in communication with the control arbiters. Each control arbiter controls its associated robot resource. Each application includes a robot controller in communication with the control arbiters and an action selection engine in communication with the robot controller. A robot manager communicates with the applications and the control arbiters to implement an application priority policy for determining which application has exclusive control of robot resources required by that application at a given time. The action selection engine executes a heuristic search on each action space of each action model which models one or more of the robot resources to identify feasible commands. Each action model provides an outcome for each command. The action selection engine selects one of the commands for each action space based on the outcome evaluations provided by each behavior in communication with the action selection engine. The action selection engine generates an overall command for execution by the robot controller on the robot resources through the control arbiters based on the commands selected for each action space.

Implementations of this aspect of the disclosure may include one or more of the following features. In some implementations the action selection engine accumulates the outcome evaluations for each action space and selects a winning outcome for each action space. The action selection engine selects a command corresponding to the winning outcome for each action space. The action model may provide the heuristic search. Preferably the action selection engine sequentially processes each action model in a predetermined order and each action space within each action model in a predetermined order. The action selection engine select a command for each action space by selecting a corresponding winning outcome based on the outcome evaluations. The outcome evaluations are weighted according to weights associated with each behavior. The action selection engine may use the winning outcomes of any preceding action spaces when selecting the winning outcome for each action space. The action selection engine generates an overall outcome for the overall command and sends the overall outcome to each behavior as feedback.

In another aspect an action selection system for robotics control includes one or more action models one or more behaviors and one or more action selection engines. Each action model includes at least one action space model defining a simulated state propagation for commands for a physical resource a command generating routine that generates a predetermined limited number of feasible commands for the physical resource and a command simulating routine that generates simulated outcomes using a simulated state propagation of a corresponding action space model. Each simulated outcome corresponds to one feasible command. Each behavior includes a routine for collecting sensor data and a routine assigning scores to simulated outcomes using an evaluation routine that considers sensor data current resource state data and predetermined goals associated with the behavior. Each action selection engine includes a routine for sequentially obtaining simulated outcomes from each action space model of each action model object providing the simulated outcomes to each behavior object for assigning scores weighting the scores according to a predetermined weighting among behavior objects comparing the weighted scores to determine one winning outcome for each action space model and then sending the one feasible command corresponding to the one winning outcome for each action space model to the physical resource corresponding to that one feasible command one winning outcome and one action space model.

Implementations of this aspect of the disclosure may include one or more of the following features. In some implementations the command generating routine generates commands throughout the action space model and the command simulating routine generates simulated outcomes from commands distributed throughout the action space model. Preferably the command generating routine generates random commands throughout the action space model. In other implementations the command generating routine generates commands in proximity to a current command in the action space model and the command simulating routine generates simulated outcomes from commands distributed in proximity to a current command in the action space model. Preferably the command generating routine generates random commands in proximity to a current command in the action space model. In some implementations the command generating routine generates commands in proximity to one or more previous commands in the action space model and the command simulating routine generates simulated outcomes from commands distributed in proximity to one or more previous commands in the action space model. Preferably the command generating routine generates random commands in proximity to one or more previous commands in the action space model.

In another aspect an action selection engine for robotics control includes a routine for sequentially i obtaining simulated outcomes from an action space model of an action model object associated with the action selection engine and ii providing the simulated outcomes to behavior objects associated with the action selection engine. The associated action model objects are characterized by at least one action space model defining a simulated state propagation for commands for a physical resource a command generating routine that generates a predetermined limited number of feasible commands for the physical resource and a command simulating routine that generates simulated outcomes each simulated outcome corresponding to one feasible command using a simulated state propagation of a corresponding action space model. The associated behavior objects are characterized by a routine for collecting sensor data and a routine assigning scores to simulated outcomes using an evaluation routine that considers sensor data current resource state data and predetermined goals associated with the behavior. The routine also includes iii weighting the scores according to a predetermined weighting among behavior objects iv comparing the weighted scores to determine one winning outcome for each action space model and then v sending the one feasible command corresponding to the one winning outcome for each action space model to the physical resource corresponding to that one feasible command one winning outcome and one action space model.

In another aspect a behavior for robotics control includes i a routine that collects sensor data and ii a routine that receives a set of simulated outcomes from a connected object assigns scores to the simulated outcomes using an evaluation routine that considers sensor data current resource state data a cascade of previously determined winning outcomes from earlier cycles and predetermined goals associated with the behavior. Each simulated outcome in the set is provided as a simulated state propagation corresponding to one feasible command for a physical resource.

In another aspect an action model for robotics control includes i at least one action space model defining a simulated state propagation for commands for a physical resource ii a command generating routine that generates a predetermined limited number of feasible commands for the physical resource iii a command simulating routine that generates simulated outcomes using a simulated state propagation of a corresponding action space model and iv a routine that responds to messages from a connected object to provide at least a set of simulated outcomes for each action space model of each action model object. Each simulated outcome corresponds to one feasible command. In some examples the action model application programming interface includes an event handler function configured to handle events.

The details of one or more implementations of the disclosure are set forth in the accompanying drawings and the description below. Other features objects and advantages will be apparent from the description and drawings and from the claims.

The present disclosure provides a robotics system that allows separately written and independently deployed programs or applications to run concurrently on and simultaneously control a robot. The independently deployed applications are combined dynamically at runtime and need to be able to share resources of the robot. A low level policy is implemented for dynamically sharing the robot resources among the applications at run time. The policy determines which application has control of the robot resources required by that application e.g. a priority hierarchy among the applications . Applications can start and stop dynamically and run completely independently of each other. The robotics system also allows for complex behaviors which can be combined together to assist each other.

Referring to a robotics system includes a control arbitration system and a behavior system in communication with each other. The control arbitration system allows applications to be dynamically added and removed from the robotics system and facilitates allowing applications to each control the robot without needing to know about any other applications . In other words the control arbitration system provides a simple prioritized control mechanism between applications and the resources of the robotics system . The control arbitration system includes one or more robot controllers a robot manager and one or more control arbiters . These components do not need to be in a common process or computer and do not need to be started in any particular order. This capability allows for different modules e.g. payloads with self contained computing power to be plugged into the robotics systems as well as the ability to plug in a small piece of robot brain providing different capabilities to the overall robotics system while using the same actuator space.

The robot controller component provides an interface to the control arbitration system for applications . There is an instance of this component for every application . The robot controller abstracts and encapsulates away the complexities of authentication distributed resource control arbiters command buffering and the like.

The robot manager coordinates the prioritization of applications by controlling which application has exclusive control of any of the robot resources at any particular time. Since this is the central coordinator of information there is only one instance of the robot manager per robot. The robot manager implements a priority policy which has a linear prioritized order of the robot controllers and keeps track of the resource control arbiters that provide hardware control.

The control arbiter receives the commands from every application and generates a single command based on the applications priorities and publishes it for its associated resources . The control arbiter also receives state feedback from its associated resources and sends it back up to the applications . Robot resources may be a network of functional modules e.g. actuators drive systems and groups thereof with one or more hardware controllers. Each resource has a control arbiter that issues commands to that resource . The robot resources are pluggable and may be dynamically added or removed from the robot system and its network at run time. The commands of the control arbiter are specific to its resource to carry out specific actions.

Still referring to the robotics system for a robot not shown includes a network that provides intra process communication for the control arbitration system via a real time publish subscribe system. Publish subscribe or pub sub is an asynchronous messaging paradigm where senders publishers of messages are not programmed to send their messages to specific receivers subscribers . Rather published messages are characterized into classes without knowledge of what if any subscribers there may be. Subscribers express interest in one or more classes and only receive messages that are of interest without knowledge of what if any publishers there are. This decoupling of publishers and subscribers can allow for greater scalability and a more dynamic network topology. A publication provides a mechanism for updating a specific data item in a distributed database so that the value will be propagated to all interested parties the subscribers without the publication client having any knowledge of subscribers. A subscription provides a mechanism for accessing a specific data item from a distributed database without knowledge of the exact source of that data item the publisher . For example behaviors can collect sensor information published to the publish subscribe system on the local network . In another example the robot controllers can publish commands to shared memory of the pub sub system on the local network that is accessed by control arbiters to pull the commands in any particular order. Preferably the control arbiters pull the commands according to a published priority policy .

In the pub sub model subscribers typically receive only a sub set of the total messages published. The process of selecting messages for reception and processing is called filtering. There are two common forms of filtering topic based and content based. In a topic based system messages are published to topics or named logical channels. Subscribers in a topic based system will receive all messages published to the topics to which they subscribe and all subscribers to a topic will receive the same messages. The publisher is responsible for defining the classes of messages to which subscribers can subscribe. In a content based system messages are only delivered to a subscriber if the attributes or content of those messages match constraints defined by the subscriber. The subscriber is responsible for classifying the messages. Either type of filtering may be used or even a combination of the two.

The robotics system can use any form of conventional real time publish subscribe or its equivalent including real time distributed publish subscribe e.g. Data Distribution Service5 DDS for Real Time Systems standard from Object Modeling Group OMG or NDDS implementation commercially available from Real Time Innovations or open source OCERA ORTE or Real Time Publish Subscribe RTPS from Interface for Distributed Automation IDA or proprietary or purpose built solutions. In preferred implementations of the robotics system the publications and subscriptions are named instances and can be created managed used and connected just like any other component in the system. Adding a communications endpoint is a matter of instantiating a publication or subscription and providing parameters. Client code can then use simple write read APIs for asynchronously sending strongly typed data between multiple threads processes or computer systems. The Publish Subscribe middleware implementation uses type export interfaces provided by a type system as part of a data transport implementation. The basic concept of the Publish Subscribe system is a distributed shared memory space where the slots in this distributed shared memory on the local network support late binding and are strongly typed. There is also network reflection of the state between each machine so that the Publish Subscribe metaphor is maintained across a network of computers.

The Publish Subscribe uses shared memory as the mechanism for transporting data between publishers and subscribers on the same machine. UDP Multicast is used for networking updates between machines. Publishers always write into shared memory with cross network propagation handled by the implementation. Subscribers are unaware of the fact that a published value might be coming from a different machine other than the obvious change in update latency relative to locally available data. Publications and subscriptions are named instances. Usable publications and subscriptions include two objects one in the program using them and an associated endpoint in shared memory. Endpoints are referred to by name and may be either public or private . If a publication or subscription has a public endpoint the name of the endpoint is the pathname of the publication or subscription. The name of a private endpoint is automatically constructed when the endpoint is created and is guaranteed to be unique. Because of this named endpoint model the Publish Subscribe is a topic based system though with each topic having a specific value type. There are strong requirements on the latency and locking behaviors of this inter process communications mechanism in order to permit fast sharing of many disparate pieces of state between processes on the same machine. In particular an attempt to publish a value by writing to a publication should not be blocked by a concurrent write to a different publication nor by a concurrent update of any subscription whether it is subscribed to the publication being written to or not.

A server program the Publish Subscribe Registry Server is responsible for creating and initializing the shared memory. It provides network services for registering and removing endpoints and connections between them and for obtaining information about the set of registered endpoints and connections. These network services include establishing connections between publications one machine and subscriptions on other machines and arranging for locally published data to be sent over the network to remote subscriptions.

A subscription must explicitly request a value update obtaining the current value from the connected publication endpoint in shared memory. This permits the client owning the subscription to explicitly control when value updates occur rather than requiring it to deal with asynchronous arrival of new data. Publish Subscribe also supports waiting for a subscription to have a new value available. This involves attempting to obtain new data from the connected publication and if the most recently published data is the same by timestamp as for the previous subscription update then the update attempt will wait until the publisher writes a new value. This allows an application to poll for new values without either taking up excessive system resources or having large latencies between new values becoming available and their being noticed. Subscriptions may also be created as part of a subscription group. A subscription group provides a convenient mechanism for updating several subscriptions at once. This is a common use case in periodic threads for example with each periodic action consisting of updating several subscriptions and then processing all of them. Subscription groups also support waiting for any of the subscriptions to have a new value providing select like behavior on multiple data sources.

Each publication or subscription has an associated value type. This value type is specified when the publication or subscription is created and specifies the type of data that may be written to or received by the object. This type also specifies the value type for the associated endpoint and a subscription may only be connected to a publication with the same value type. To be publishable such a value type must be exportable as specified by a Type system. Among other things this requires that the type supports being written to a boost serialization archive. The Publish Subscribe uses the binary archives from the boost serialization library to encode the data being written to shared memory by a publisher and to decode that data for subscribers. This transport through shared memory is further optimized when the type in question is fast exportable .

Each control arbiter communicates with the robot manager configuration to learn of all the robot controllers in the robotics system by getting the robot controller list and pulls the commands and statuses from all the robot controller memory blocks . Each control arbiter sequentially pulls the command and status from each robot controller memory block in the order defined by the robot controller list and depending on the robot controller status issues the command to one or more of the uncommitted connected resources e.g. hardware of that control arbiter . Each robot controller has a status of compromising or non compromising. With a status of compromising the robot controller is willing to allow issuance of a partial command . In contrast with a status of non compromising the robot controller is will only allow issuance of a full command .

For example referring to the first control arbiter A controls an arm resource having a turret shoulder elbow 1 and elbow 2. The robot controllers become informed of the first control arbiter A through the nth control arbiter N by getting the control arbiter list from the robot manager configuration . Each active robot controller receives a command from the behavior system for execution by the control arbitration system and publishes its command its respective robot controller memory block . The control arbiters recognize that one or more commands have been published and sequentially pull the commands for execution. The first control arbiter A as designated so by the control arbiter list pulls the command and status of the first robot controller A as designated so by the robot controller list from the respective robot controller memory block which in this case contains a command for the shoulder resource A . The status of the first robot controller A is irrelevant because none of the resources have been committed yet. The first control arbiter A commits the shoulder resource A to the command of the first robot controller A.

Next the first control arbiter A pulls the command and status of the second robot controller B from the respective robot controller memory block which in this case contains a command for the shoulder resource A and the turret resource A and a status of compromising. Since the shoulder resource A was committed to the first robot controller A the first control arbiter A will be unable to issue the full command of the second robot controller B. Nevertheless since the second robot controller B has a status of compromising the first control arbiter A will be able to issue the command partially by committing the currently uncommitted turret resource A for the command of the second robot controller B. The first control arbiter A proceeds to sequentially pull the command and status of each successive robot controller in the robot controller list and commit resources in accordance with the status of the respective robot controller .

In the example of nth robot controller N the first control arbiter A pulls its command and status from the respective robot controller memory block which in this case contains a command for the shoulder resource A the elbow 1 resource A and the elbow 2 resource A and a status of non compromising. Since the shoulder resource A was committed to the first robot controller A the first control arbiter A will be unable to issue the full command of the nth robot controller N. Furthermore since the nth robot controller N has a status of non compromising the first control arbiter A will be unable to issue the command partially to the uncommitted elbow 1 and elbow 2 resources A A . As a result the first control arbiter A commits no resources for the command from the nth robot controller N. The command from the nth robot controller N will unit for another cycle when all of the required resources are uncommitted and available.

The first control arbiter A continues to step through each robot controller until all of its connected resources are committed. Once all of the connected resources are committed the control arbiter sends a coherent command to its resources and updates its corresponding control arbiter memory block with state feedback of the resources . Each robot controller can pull the state feedback e.g. asynchronously of each control arbiter from the corresponding control arbiter memory block .

Referring to the behavior system includes at least one application . Each application has an action selection engine and a robot controller one or more behaviors connected to the action selection engine and one or more action models connected to action selection engine . The behavior system provides predictive modeling and allows the behaviors to collaboratively decide on the robot s actions by evaluating possible outcomes which will be described later. A behavior is a plug in component that provides an evaluation function that can be based on an internal state machine a coupling of sensory feedback from multiple sources to outcomes or a combination of the evaluation functions of other behaviors in a subsequent layer. This allows behaviors to nest hierarchically and form a layered hierarchical and state full evaluation function that maps sensory feedback to outcomes differently in different situations. Since the behaviors are pluggable into the application they can be removed and added without having to modify the application or any other part of the robotics system .

The action selection engine communicates with the robot controller through the robot controller application programming interface API a behavior through a behavior API and an action model through an action model API . Abstraction and encapsulation of each component is accomplished through their respective API which provides a manner in which compliant components communicate with the action selection engine .

An example interface for the behavior API is provided in Table 1 below. A behavior that is capable of communicating with the API communicates using some or all of the functions and data structures as follows.

The action model API allows various action models to communicate configuration setup including names of resources states and the number of actions generated on each action selection cycle to the action selection engine . Action models are event handlers as well so they can coordinate as necessary with any of the event stream information in the behavior system . Example interfaces for the action model API are provided in Tables 2 3 below.

Referring to the action selection engine manipulates events all within one thread so if a behavior were to send an event to the action selection engine when it receives one it would end up in a loop. To break this loop there is an event processor which has an event handler API see . An example interface for the event processor component is shown below in Table 4.

In some implementations the action selection engine does not contain its own thread. Instead it uses a separate thread component containing a thread to run it. This allows other components to be hooked up and run at the same rate. The thread component has a periodic thread to trigger action interfaces. Typically the behavior system should be run at 10 Hz or more and the time horizon explored by the system should extend many cycles often seconds into the future.

The action selection engine is the coordinating element of the robotics system and runs a fast optimized action selection cycle prediction correction cycle searching for the best action given the inputs of all the behaviors . The action selection engine has three phases nomination action selection search and completion. In the nomination phase each behavior is notified that the action selection cycle has started and is provided with the cycle start time the current state and limits of the robot actuator space. Based on internal policy or external input each behavior decides whether or not it wants to participate in this action selection cycle . During this phase a list of active behaviors is generated whose input will affect the selection of the commands to be executed on the robot.

In the action selection search phase the action selection engine generates feasible outcomes from the space of available actions also referred to as the action space . The action selection engine uses the action models to provide a pool of feasible commands within physical actuator limits like position velocity and acceleration and corresponding outcomes predicted to a time horizon in the future. The action models are standalone components connected to the behavior system and represent part of the robot. The action models each model the state propagation of that part of the system and provide dynamic adaptive search windows see for available actions during the action selection search phase. During the action selection search phase each active behavior policy is presented the same set of outcome options simulated by the action models . Behaviors are components that implement an evaluation function based on their specified separable functionality in the robot. This evaluation is reported in the form of a score in the range 1 1 . The value 1 means the behavior thinks that the proposed outcome is the worst possible outcome for the functionality it represents. The value 1 means the behavior thinks that the proposed outcome is the best possible outcome for the functionality it represents and a value of 0 means that the behavior doesn t care either way about this outcome . The other values are gradations between these extremes.

In the completion phase the commands that correspond to the collaborative best scored outcome are combined together as an overall command which is presented to the robot controller for execution on the robot resources via their corresponding resource control arbiters . The best outcome is provided as feedback to the active behaviors to be used in future evaluation cycles.

Referring to action models are plug in components that account for the kinematic and dynamic constraints of all or part of the robot and supports predictions of command outcomes on a local time horizon. Action models generate possible states that the robot can transition to and create the predicted future outcomes . Action models are used or called by the action selection engine to provide feasible commands by modeling the mechanism and corresponding expected outcomes via dynamic modeling for the robot resources as illustrated in which are evaluated by the behaviors to find the best action. The action model is responsible for creating a feasible action space of all or part of the robot. To reduce the complexity of the search space the resources on the robot are separated into smaller action spaces which are independently evaluated.

In the example shown in an action model of a robots arm having a turret a shoulder an elbow 1 and an elbow 2 includes a corresponding turret action space A a shoulder action space B elbow 1 action space C and elbow 2 action space D. The action selection engine calls the action model of a robots arm to provide sets of feasible commands A B C D and corresponding sets of expected sets of outcomes A B C D for each action space A B C D.

For command generation the action model takes in the current state of the system resources controlled by an action space . Given the current resource states the dynamic limits of the resources and the time horizon for which to generate commands the action model generates a dynamic window which is a range of commands that are feasible. Commands are then selected among this feasible range and within the dynamic window using heuristic choosing mechanisms. These mechanisms can include but are not limited to selecting commands from a uniform distribution of feasible commands and selecting commands from an adaptive range around the last commands selected to hill climb toward the command that the behavior system wants to choose where the range adapts based on the deviation of the previous commands chosen. The goal of command generation is to generate commands achievable by the system hardware in the specified time horizon that result in potential state trajectories that are likely to be evaluated highly by the behaviors in the behavior system . The command generation is attempting to guess what the system needs to do based on what it has been doing while providing random commands in case the system s goals change.

Referring to the action selection engine executes a randomized search of an action space using the action model for that action space as the means to generate feasible commands provide a search heuristic e.g. hill climbing and to simulate feasible commands into outcomes . In the example shown the feasible action space surrounds the current command state . The action selection engine uses the action model to predict the expected outcomes of all feasible commands several seconds into the future. When behaviors evaluate these commands e.g. future system trajectories based on their expected outcomes they have access to the predicted state evolution over several seconds in the future. The action selection engine calculates a preferred outcome based on the outcome evaluations and sends the corresponding command to the control arbitration system by interfacing with the robot controller of the application to publish commands to the pub sub system on the network thereby making the commands available to the control arbiters and to receive state feedback . The action selection engine also notifies the action model of the chosen commend as feedback.

Sensors and actuators that make up robotics systems are not deterministic. They are subject to error from a variety of sources whether it be internal estimation error or errors incurred by uncontrolled environments. The behavior system provides a field to model this error with standard deviation for all states in the system . This allows the robot resources to report their uncertainty to the action models through state feedback and allows the behaviors to consider uncertainty when making a decision. For example consider a drive system that naturally slips when it rotates. When the action model for the drive system generates outcome trajectories for a set of commands it can take this rotation uncertainty into account by providing an increased uncertainty for states in trajectories with more rotation. provides simulated trajectories A B C of the movement of the drive system X Y resource for three different outcomes A B C as a result of three different commands A B C. Each trajectory A B C has three time steps t t t each with an uncertainty region A B C that defines a probably space A B C e.g. based on standard deviation in which the drive system X Y resource will be located at the corresponding time step t t t for each outcome A B C.

When a behavior evaluates the trajectories A B C it can consider the uncertainty. For the specific example of a collision avoidance behavior the shortest path to a goal point or state may include more rotation and as a result have more uncertainty. The predicted state may not collide with an object but if the uncertainty is factored in then the trajectory has a chance to collide. The behavior can then choose to take a longer path to the goal that does not have a chance to collide with an obstacle . How to model the uncertainty can be fixed or it can adapt to the environment as the robot gets feedback as to how its commands are relating to its actual state in the world so a robot that travels on cement then transitions to sand may have its model adapt from a low level of uncertainty in command to trajectory relationship to a higher level of uncertainty. With the third outcome C the drive system X Y resource has the possibility of colliding with the obstacle at time step t. When the collision avoidance behavior evaluates the outcomes A B C the behavior will score the third outcome C the lowest since it has the possibility of causing a collision with the obstacle the second outcome B the highest since it leads the drive system X Y resource around the obstacle toward the goal point or state and the first outcome A in between the second outcome B and the third outcome C.

This prediction process is optimized and repeated many times each second e.g. 30 Hz and works like a predictor corrector system for the current command set. Having the time evolution of the trajectory of the current command available to the behaviors allows the behaviors to incorporate both static and dynamic hazards into their evaluations of the outcomes. This combination of reactive and predictive action selection provides safety and responsiveness in the action selection process.

The action selection engine can conduct a cascading closed loop selection of a command within the action space in the sense that it is a periodic cycle tied to the current system state feedback and only uses the predicted outcomes to select commands rather than counting on any real time outcomes. The action selection engine uses the current state of the robot e.g. current position velocity acceleration and or other telemetry of each resource and continuously updates and runs the action selection cycle . A feasible sub region or dynamic window of the action space is computed by the action model based on limits and current state values. This dynamic window is used to constrain the generated commands so that the action selection engine may select the best available feasible command . This command may not be globally optimal but is a locally good solution that respects the dynamic mechanical etc. limits of the system. The action model is adaptive such that the action space to be searched is scaled from a feasible size to an even smaller size based on a command history. As a result the action selection engine will not repeatedly select a command near a limit. For example if the command history includes moving to a certain spot each time the search window is sized to increase a resolution around a region most searched in the past. Consequently the action selection engine is based on forward modeling e.g. non inverting and conducts local path planning. A problem size of the action space is reduced by solving for the best available command in each action space one by one during each cycle instead of solving for the global best available feasible command all at once. For example instead of searching 10 10 10 10 options using 10 4 CPU cycles the action selection engine searches 10 10 10 10 options using 40 CPU cycles. This allows the robot to be relatively smart on small old low capacity embedded processors.

Generally there is not enough time to search the entire action model exhaustively for the best command having the best outcome . The action selection engine performs a heuristic time bounded search over a feasible action space for feasible commands that satisfy the preferences of the connected behaviors . Preferably a search technique known as hill climbing is used based around the previously selected command value for each action space . Many other heuristics may be added over time because action models may be replaced by any component that conforms to the action model API . This also allows new search heuristics to be added without rewriting the behaviors in the system . The action selection engine has multiple degrees of freedom and performs implicit evaluations. The heuristic searches are provided by the plug in action models which allows for new heuristic searches to be added to the robotics system without re writing behaviors .

Referring to the action selection engine acts as a manager or hub of activity in the action selection process. The action selection engine executes a periodic action selection cycle that includes the following steps 1 getting a system state from the robot controller 2 informing all connected action models and behaviors that a cycle will start e.g. by calls their respective APIs and providing them the current system state 3 running an optimization pass for each action space of each action model separately in the order in which they are configured and 4 accumulating the commands for every action model into a single overall command for the entire robot system . The action selection engine executes the optimization pass for each action space by 1 calling the connected action model to generate feasible commands 2 calling the connected action model to generate simulate outcomes from these feasible commands and 3 calling the connected behaviors to evaluate the outcomes and provide a rating or evaluation of each outcome expressing how good or bad those outcomes are based on their preferences on a scale from 1 1 where 1 means highly undesirable 1 means highly desirable and 0 means indifferent. An evaluation function selects an outcome to pick a coherent action of the robot. Although there can be behaviors that combine the outcome evaluations of other behaviors hierarchy using many varied policies the basic policy used by the core action selection engine is one of weighted summation. The action selection engine accumulates the outcome evaluations of the behaviors by a weighted sum of evaluations and selects the best highest rated outcome as the winner. The action selection engine saves the corresponding command of the winning outcome for this particular action model and informs the action model of the selected command as feedback. The action models are configured to generate commands that are both feasible and randomized using a mixture distribution between local and exploration changes from a current command .

The evaluation function s of a behavior may be based on sensor data from a component external to the resources . Generally data inherent to an axis of a resource is passed to the action models and behaviors along with other system state information at the start of an action selection cycle . For example encoder information e.g. position is included in the system state information. However sensor data from external components e.g. a laser range finder or a global positioning system on a mobile robot are accessed by the action models and behaviors through the pub sub system of the local network . Referring back to now include the example of a laser range finder attached to the robot and the collision avoidance behavior connected to the action selection engine . A set of data either raw or processed by another system component providing information from a scan around the robot e.g. 180 is published to the pub sub system of the local network by the laser range finder for access by other components in the robotics system . During an action selection cycle the obstacle avoidance behavior subscribes to the pub sub system of the local network to use the laser range finder data to identify or detect obstacles in the environment about the robot. The obstacle avoidance behavior then evaluates the three provided outcomes A B C in light of its awareness of the obstacle between the robot and the goal position or state . The behavior will score the third outcome C the lowest since it has the possibility of causing a collision with the obstacle the second outcome B the highest since it leads the X Y actuator resource around the obstacle toward the goal point or state and the first outcome A in between the second outcome B and the third outcome C.

In another example for a floor cleaning robot the behavior system may be used to influence the cleaning path of the robot. In one example the cleaning robot includes a robot body carrying a drive mechanism that both drives the robot forward in a drive direction over a support surface. The robot includes a forward obstacle sensor responsive to objects encountered by the robot while moving in the drive direction. A side sensor is positioned to detect proximity of objects on a dominant side of the robot transverse to the direction of travel. The dominant side of the robot is the side that is kept near or in contact with an object or obstacle when the robot cleans the area adjacent to that object or obstacle . The robot body may be asymmetrically shaped to define the dominant side. A surface area processing mechanism such as a side brush is effective on the dominant side of the robot. The side brush extends from the dominant side of the robot and operates to sweep debris from beyond a robot perimeter for collection by the robot. When the forward sensor detects an object in the direction of travel of the robot it publishes sensor data to the pub sub system of the local network . During an action selection cycle a wall following behavior subscribes to the local network to obtain the available forward sensor data for consideration during evaluation of provided outcomes . The goal of the wall following behavior is clean up next to walls. When the behavior learns that the forward sensor has detected an object in the direction of travel of the robot it will score highly outcomes corresponding to drive commands that turn the robot to locate the detected object on the dominant side of the robot and that drive the robot to keep the detected object on the dominant side of the robot while the surface area processing mechanism processes a portion of the support surface adjacent the object on the dominant side.

In the example shown in the action selection cycle includes calling the action models to each generate a default outcome set see . When the behaviors evaluate and rate each outcome their evaluation may refer to or rely on the default outcome set if appropriate for that action space and or behavior . Furthermore the selected winning outcome can be used to update or replace the default outcome set for that action space .

Referring again to after each action model has been processed the action selection engine uses the accumulated chosen commands for each action model to generate a single overall command for the entire robot system . The overall command is sent to the robot controller for communication to the resource control arbiters for execution on the robot resources . The overall command has a simulated overall outcome generated by accumulating the corresponding outcomes of the chosen commands of the action models . This overall outcome is passed along as feedback to all connected behaviors indicating the end of the action selection cycle .

Referring to the action selection engine calls the first action model A to generate feasible commands and corresponding outcomes for each action space . In the example shown in the first action model A has a two dimensional action space that models translate and rotate for a skid steer resource . The action selection engine calls this first action model A to generate feasible commands for the translate and rotate action space . The action selection engine calls this first action model A to generate or simulate outcomes or predicted future states of the skid steer resource that would occur for each feasible command .

Referring to the action selection engine sends the outcomes to each active behavior for evaluation. Each behavior has a status and weight property which indicates whether the behavior is active and its weight. On each action selection cycle behaviors can choose whether or not to participate in the evaluation process of the simulated outcomes . At the beginning of each action selection cycle the action selection engine asks each behavior if it wishes to participate in that cycle. If a particular behavior chooses not to participate its status is set to OFF . For the remaining duration of that action selection cycle the action selection engine only interacts with those behaviors that have decided to participate and are hence active behaviors for the cycle. This provides very easy and flexible mission policy management. The behavior weight is used to increase the influence of the scores or outcome evaluations of that particular instance of the behavior . The behavior weight is not a fixed property of the associated behavior but rather a weight associated with that instance of the behavior . The behavior implements an evaluation heuristic based on a specific end goal and doesn t need to know how important it is. The behavior weight is relevant in the context of the overall design of an application . The same behavior can have a different level of importance or weight for different types of applications .

In the example shown in there are three active behaviors . The first behavior is a lost communications set the brake lost comms behavior A which causes the robot to brake or halt some or all of its actions when it loses communications with an operator controller unit. The second third and fourth behavior B C D are shown as inactive for this action selection cycle . The fifth behavior E is a teleoperation behavior for remote control of the robot. The sixth behavior F is an obstacle avoidance behavior. In the example shown the lost comms behavior A has the highest weight e.g. amongst the other behaviors since it prevents the robot from wandering off when communications fail. The obstacle avoidance behavior F has the next highest behavior weight of half as much as the lost comms behavior A followed by the teleoperation behavior E which has a behavior weight of only a tenth of the lost comms behavior A. The active behaviors A E F evaluate the outcomes and return their weighted scores or outcome evaluations to the action selection engine . The action selection engine selects the outcome having the highest weighted outcome evaluation as the winning outcome for that action space A. The action selection engine stores the command corresponding to the winning outcome for generating an overall command based on the winning commands for each action space of each action model . The action selection engine updates the default outcome set with the winning outcome .

Referring to the action selection engine next calls the second action model B to generate feasible commands and corresponding outcomes for each action space . In the example shown in the second action model B has three one dimensional action spaces that model a turret an elbow and a wrist for an arm resource . The action selection engine calls the second action model B to generate feasible commands for the turret action space first as it is the first ordered action space . The action selection engine calls the second action model B to generate or simulate outcomes or predicted future states of the arm resource that would occur for each feasible command .

Referring to the action selection engine sends the outcomes of the first action space of the second action model B to each active behavior for evaluation. In the example shown in there is only a behavior policy active to receive the outcomes . Behavior policies are used to provide logic to the selection and use of behaviors and will be described in further detail below. The action selection engine selects the outcome having the highest weighted outcome evaluation as the winning outcome for that action space A. The action selection engine stores the command corresponding to the winning outcome for generating an overall command based on the winning commands for each action space of each action model . The action selection engine updates the default outcome set with the winning outcome .

Referring to the action selection engine next calls the second action model B to generate feasible commands and corresponding outcomes for the next action space . In the example shown in the action selection engine has the elbow action space of the second action model B generate feasible commands as well as simulate outcomes or predicted future states of the arm resource that would occur for each feasible command . The action selection cycle loops through this action space and then the wrist action space to complete the optimization pass of the second action model B before looping the optimization pass over the action space s of the next action model in order the camera mast action model C.

Referring to after each action model has been processed the action selection engine uses the accumulated winning commands for each action space of each action model to generate a single overall command for the entire robot system . The overall command is sent to the robot controller for communication to the resource control arbiters for execution on the robot resources . The overall command has a simulated overall outcome generated by accumulating the corresponding outcomes of the chosen commands of the action models . This overall outcome is passed along as feedback to all connected behaviors indicating the end of the action selection cycle .

Referring to the action selection engine can execute a cascading selection of outcomes on multiple action spaces having multi criteria ordering e.g. lexicographic ordering set by the action model within an action model . As the action selection engine chooses a command and corresponding outcome for each action space or action model on an action selection cycle the consequences of this choice in terms of outcomes are propagated forward so that a subsequent action selection cycle passing through the behaviors in subsequent action spaces or action model may observe the results of the command selected in the previous action space by accessing the default outcome set . This reduces the negative consequences from not performing a full exhaustive search of the action spaces or action model . As illustrated the action selection engine steps through each action space individually according to a predetermined order and selects an outcome for each action space . The action spaces are typically ordered according to their level of influence on robot actions. The selection of outcomes follows a progressive commitment where an outcome for each action space is determined based on the outcomes of any preceding action spaces . In each action selection cycle the default outcome set is updated with the winning outcome for each modeled resource . Referring back to which depicts a robot arm having a turret a shoulder an elbow 1 and an elbow 2 . The action model for the arm has a corresponding turret action space A a shoulder action space B elbow 1 action space C and elbow 2 action space D. The action selection engine calls the action model of a robots arm to provide sets of feasible commands A B C D and corresponding sets of expected outcomes A B C D for each action space A B C D. When the action selection engine steps though each action space A B C D it determines their winning outcomes A B C D while referring to the winning outcomes A B C D of any previous action spaces A B C D stored in the default outcome set . For example when the action selection engine steps to the elbow 2 action space D it will consider the winning outcomes A B C of the previous three action spaces A B C when deciding the winning outcome D for the fourth elbow 2 action space D.

Referring to behaviors are used to organize structure and provide logic to the selection and use of behaviors in applications to achieve specific goals while respecting specific constraints including the constraints derived from the actuator systems of the robot. Because the evaluation function of a behavior can be an arbitrary policy that combines the outcome evaluation values from multiple sub behaviors a hierarchical collection of behaviors may be used to allow many new policies of coordination to be added. Typical behavior policies for behaviors that combine the evaluation of sub behaviors include a select behavior policy A a combine behavior policy B a switch behavior policy C and a sequence behavior policy D.

Referring to the select behavior policy A selects the active connected behavior or behavior policy with the highest behavior weight . In the example shown the select behavior policy A selects the active first behavior A having a behavior weigh of 10 to the exclusion of the active second behavior B having a behavior weigh of 1.

Referring to the combine behavior policy B combines the outcome evaluations of the active connected behaviors or behavior policies . In the example shown the combine behavior policy B checks to see which connected behaviors are active. In this case the first and second behaviors A B are active while the third behavior C is inactive for this particular action selection cycle . The combine behavior policy B combines the outcome evaluations of the first and second behaviors A B weighted according to their respective behavior weights while ignoring the inactive third behavior C.

Referring to the switch behavior policy C switches between two or more groups of behaviors based on a switch property C that can be set each action selection cycle e.g. via the event processor . The switch behavior policy C allows a particular group of behaviors to be exclusively available amongst other connected groups of behaviors . In the example shown the switch behavior policy C switches between a first behavior group and a second behavior group Y based on the associated switch property C. In this case the switch behavior policy C has switched to use the second behavior group Y which contains a combine behavior policy B of the active first and second behaviors A B leaving out the inactive third behavior C .

Referring to the sequence behavior policy D sequentially steps through a set of behaviors . The sequence behavior policy D will continue to use the first behavior of the set until it is no longer active at which time the sequence behavior policy D uses the next active behavior until it is no longer active etc. In the example shown the sequence behavior policy D used the first behavior A until it was no longer active stepped to the second behavior B and used the second behavior B until it was no longer active and then stepped to the third behavior C. The sequence behavior policy D will continue to use the third behavior C until it is no longer active at which time it will step to the active fourth behavior D.

Referring back to the example shown in the select behavior policy A selects the combine behavior policy B which has a higher behavior weight than the fourth behavior D. The combine behavior policy B combines the weighted outcome evaluations of the second and third behaviors B C. The combined weighted outcome evaluations are further weighted according to the behavior weight of the combine behavior policy B. Finally the resulting outcome evaluations can be weighted further according to the behavior weight of the select behavior policy A. The action selection engine selects the outcome from the returned set of weighted outcomes from the select behavior policy A having the highest weighted outcome evaluation as the winning outcome .

The robotics system facilitates and allows separate applications to share control of robot resources to effectuate behaviors . As mentioned above the robot manager implements the application priority policy by determining which application has exclusive control of the robot resources required by that application at a given time over other concurrently running applications . The applications exclusively claim resources over other concurrently running applications according to the application priority policy provided by the robot manager and communicated to each control arbiter .

Referring to in a parallel multi core scaled robotics system multiple identical behavior systems A B exist on a multi core computer system . Since the action selection engines determine a command in an action space based on randomization each action selection engine running on a respective parallel network will likely generate a different command . Each command has an associated command morale which is a quantification of a residual behavior evaluation for suitability of the command . A morale command selector selects the command with the highest associated command morale from a group of commands generated simultaneously by the respective action selection engines running on the parallel networks . Although the individual robotics systems are inherently serialized the randomized search techniques in conjunction with the morale command selector provide linear speed up resulting in a parallel system that is only limited by memory space and or bandwidth.

Referring to a robotics framework for controlling the robot system includes a static structure in communication with a dynamic structure . The static structure includes one or more vertical application programming interfaces APIs that provide functionality and performance characteristics of the robot. The APIs of the robotics framework along with other vertical APIs communicate with horizontal interfaces which form a component framework . The dynamic structure includes a metadata module e.g. XML and a scripting module e.g. Python . In some implementations the robotics framework includes a common interfaces API A a behavioral system API B and a local perceptual space API C.

The fundamental requirements satisfied by the base framework can include being able to dynamically create pluggable software components at runtime dynamically load new pluggable software components at runtime dynamically configure software component after instantiation as part of creation and dynamically connect software components as a part of overall configuration. There is complete interface encapsulation so that no implementation instance specific information is seen by clients insulation for scaling system . The framework may provide support for extensible and modular APIs that can be expanded without breaking existing client code interfaces. The framework may provide support for smooth evolution of new interfaces within the system without breaking existing client code interfaces as well as support for multiple different interfaces to the same coherent software component in support of evolution modularity and reusability . The framework may maintain metadata about the structure interfaces and interconnections of running configured components to support detailed interactive testing and diagnosis of complex modules. Called reflection. The framework may provide usable multithreaded environments and usable in real time environments where dynamic reconfiguration is not on a time critical pathway i.e. done at startup or in specific system modes . The framework separates concerns into a collection of small interfaces. The principal design pattern used here is an expansion of the common abstract interface or protocol hierarchy Lakos96 patterns made popular by the original COM model but now commonly used in many commercial and open source software systems. There is additional support and stock interfaces for the core functionalities provided in significantly more heavyweight component models such as the CORBA Component Model CCM approach but implemented in C language specific highly performance conscious manner.

A component is a replaceable part of a system. Examples of components include the robot controller the action selection engine the control arbiters the robot manager the behaviors and the action models . It can be readily swapped out and replaced by an equivalent component without affecting the overall operation of the system. The architecture of the robotics system is based on software components which can be readily replaced without any reworking or recompiling of the source code. To be replaceable a software component must conform to a set of required and provided interfaces. In much the same way that a new stereo receiver needs to provide different types of inputs and outputs so it can be hooked up to older or newer audio visual components the interfaces of a software component must be 100 percent compatible with the interfaces of the other components in the system. More specifically any interfaces that are realized by a software component i.e. the provided interfaces must remain unchanged so that other components which use this interface will not have to be changed to remain compliant. Likewise any interfaces which the component uses to interact with other components i.e. the required interfaces must also remain unchanged. Components can also have properties which are used to describe it. For example a component called Triangle would very likely have a property or set of properties to specify the coordinates of its 3 vertices.

In the robotics system a component is implemented for example as a C class which has properties interfaces and connections that are compatible with a base framework. Instances of the components can be dynamically loaded and unloaded at runtime. Each instance of a component is able to support a set of named interfaces which are derived from a common interface class to support interface navigation by debugging tools.

A property is a specific attribute of a component that is useful in describing it. For example a component called Rocket might have a property called NumStages which represents the number of stages of the rocket. A property in the robotics system is specified using the PropertyVar template inside a component definition. For example since the number of stages in a rocket must be an integer the NumStages property would be declared as such in the Rocket component definition PropertyVar NumStages.

An interface is a named set of operations that provide services for other components. For example a software component which keeps track of appointments might provide an interface that allows another component such as a calendar to get a list of appointments and display them on a calendar. In order for the calendar component to access this list of appointments it must establish a connection to the interface provided by the appointment tracker component and one of the operations provided in that interface must be a method to get the requested appointment data and return it. Thus one might think of an interface as a means by which components communicate with one another. In the robotics system an interface is a named API which provides functionality and data and is implemented for example as a C class. The interface classes have the additional property that they provide full encapsulation and do not expose implementation details to clients. Examples of interfaces in the robotics system include the robot controller API the behavior API and the action model API .

Connections are the wiring that tie components together. While interfaces allow components to talk to one another interfaces are meaningless if there is no way for one component to specify which other component s it wishes to talk to. In order to do this a component must establish a connection to the required interface. To use a familiar analogy consider a telephone communications system. In order for two parties to speak with each other on the phone several things must happen. First each person must provide an interface for having the conversation. This would be the phone itself which includes a speaker and microphone for listening and speaking. As long as both parties have a phone they can talk to each other. However everyone knows that merely possessing a phone does you little good if you do not know the phone number of the person with whom you wish to speak. That is where connections come in. When you pick up the phone and dial someone s number you are establishing a connection with them. Once the connection is established you can talk to each other for as long as the connection is maintained. The robotics system may provide two types of connections single and multiple. Single connections specified by the template ConnectionVar are appropriate when a component needs to access the interface of a single instance of another component. Multiple interface connections specified by the template MultiConnectionVar are appropriate when a component needs to access the interface of multiple instances of another component.

Beyond the basic component structure there may be runtime support in the form of Module and Directory classes. The framework is set up to manage a tree of named component instances that represent the primary functionality of a system. This tree of component instances each support an extensible set of named interfaces. Each instance in the tree is a named instance and has a pathname within the module itself. Object instance names are established by this dynamic instance hierarchy of named instances. Each component instance in the dynamic instance tree can support a connection to the interfaces exported by other instances. This wiring happens at runtime and is used to compose higher level functionality from components within the system. Usage of framework based components happens through the explicit interface connection mechanism in this core module and the exported interface header files for the components in question. No sharing of implementation code is required between components that share an interface however this sharing may be done opportunistically for other reasons.

The base framework defines the interfaces and provides implementations for building reusable dynamically loadable dynamically configurable and dynamically connectable scriptable pieces of performant C software. These pieces are called components in the robotics system. The primary means of interface and API definition at the module executable level is through the definition of new C class interfaces derived from the base framework. The core framework provides the scaffolding for flexible interfaces and evolution of implementation over time for client code. The runtime infrastructure in a Module process or executable scope is initialized by accessing the Module instance s interface for the process. The Module interface then provides the root directory holding other instances within the module as well as the basic resource loading functionality. There can be subdirectories within the module and these nest recursively. These objects implement the Directory interface and provide a hierarchical namespace for component instances within process scope. This hierarchical namespace allows modules to be constructed dynamically and organized logically in packages. This naming is provided to support human inspection and understanding of what is going on in a software module and allow a local namespace to be established that refers to object instances. Furthermore the hierarchical naming can be used to aid programmatic navigation and configuration of the components within a module.

The Module interface can also provide a means to find new factory objects. Each factory instance can create one type of Named object or Component . When the Module interface searches for a factory instance it may load new dynamic libraries to bring in the needed functionality for the module. The createNew function on the Factory interface returns a new Named interface. The Module interface can also lookup and dynamically load new types from libraries as well allowing a process to pick up the type handling code for a type that was defined after the rest of the process components were deployed.

With a component interface the individual services and APIs supported by each component are accessed through the Component get method on the instance. This returns a Named handle to the interface than you can then safely narrow to the specific interface handle type. Once this initial indirection has taken place calls through the new interface operate with the overhead of a virtual function call. When use of the interface is complete the interface is released by assigning 0 to the handle or allowing the handle to exit scope. The automatic reference counting handles is used to maintain the reference count on component instances.

Note that for each interface type there is a matching reference handle type. This reference counting handle is used in the API and provides automatic reference counting support for clients and implementations alike. The reference counting handles can be stored in STL containers passed as arguments created on the stack assigned returned etc. and their semantics insures proper reference counting. These reference handles also provide exception safety for the reference counting when used properly. This mechanism can be bypassed but it is likely to significantly reduce the reference counting reliability of the code.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly other implementations are within the scope of the following claims.

