---

title: Counting instruction and memory location ranges
abstract: Illustrative embodiments cover a data processing system for processing instructions and monitoring accesses to memory location ranges. An instruction for execution is identified. A determination is made as to whether the instruction is within a contiguous range of instructions. Execution information relating to the instruction is identified if the instruction is within the contiguous range of instructions. With memory location accesses, an access to a memory location is identified. A determination of whether the memory location is within a contiguous range of memory locations is made. Access information is identified if the memory location is within the contiguous range of memory locations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08255880&OS=08255880&RS=08255880
owner: International Business Machines Corporation
number: 08255880
owner_city: Armonk
owner_country: US
publication_date: 20080501
---
This application is a continuation of application Ser. No. 10 675 872 filed Sep. 30 2003 now U.S. Pat. No. 7 373 637 B2 issued May 13 2008.

The present invention is related to the following applications entitled Method and Apparatus for Selectively Counting Instructions and Data Accesses Ser. No. 10 674 604 Method and Apparatus for Generating Interrupts Upon Execution of Marked Instructions and Upon Access to Marked Memory Locations Ser. No. 10 675 831 Method and Apparatus for Counting Data Accesses and Instruction Executions that Exceed a Threshold Ser. No. 10 675 778 Method and Apparatus for Counting Execution of Specific Instructions and Accesses to Specific Data Locations Ser. No. 10 675 776 Method and Apparatus for Debug Support for Individual Instructions and Memory Locations Ser. No. 10 675 751 Method and Apparatus to Autonomically Select Instructions for Selective Counting Ser. No. 10 675 721 Method and Apparatus to Autonomically Count Instruction Execution for Applications Ser. No. 10 674 642 Method and Apparatus to Autonomically Take an Exception on Specified Instructions Ser. No. 10 674 606 and Method and Apparatus to Autonomically Profile Applications Ser. No. 10 675 783 filed on Sep. 30 2003 assigned to the same assignee and incorporated herein by reference.

The present invention relates generally to an improved data processing system. In particular the present invention provides a method and apparatus for obtaining performance data in a data processing system. Still more particularly the present invention provides a method and apparatus for hardware assistance to software tools in obtaining performance data in a data processing system.

In analyzing and enhancing performance of a data processing system and the applications executing within the data processing system it is helpful to know which software modules within a data processing system are using system resources. Effective management and enhancement of data processing systems requires knowing how and when various system resources are being used. Performance tools are used to monitor and examine a data processing system to determine resource consumption as various software applications are executing within the data processing system. For example a performance tool may identify the most frequently executed modules and instructions in a data processing system or may identify those modules which allocate the largest amount of memory or perform the most I O requests. Hardware performance tools may be built into the system or added at a later point in time.

One known software performance tool is a trace tool. A trace tool may use more than one technique to provide trace information that indicates execution flows for an executing program. One technique keeps track of particular sequences of instructions by logging certain events as they occur a so called event based profiling technique. For example a trace tool may log every entry into and every exit from a module subroutine method function or system component. Alternately a trace tool may log the requester and the amounts of memory allocated for each memory allocation request. Typically a time stamped record is produced for each such event. Corresponding pairs of records similar to entry exit records also are used to trace execution of arbitrary code segments starting and completing I O or data transmission and for many other events of interest.

In order to improve performance of code generated by various families of computers it is often necessary to determine where time is being spent by the processor in executing code such efforts being commonly known in the computer processing arts as locating hot spots . Ideally one would like to isolate such hot spots at the instruction and or source line of code level in order to focus attention on areas which might benefit most from improvements to the code.

Another trace technique involves periodically sampling a program s execution flows to identify certain locations in the program in which the program appears to spend large amounts of time. This technique is based on the idea of periodically interrupting the application or data processing system execution at regular intervals so called sample based profiling. At each interruption information is recorded for a predetermined length of time or for a predetermined number of events of interest. For example the program counter of the currently executing thread which is an executable portion of the larger program being profiled may be recorded during the intervals. These values may be resolved against a load map and symbol table information for the data processing system at post processing time and a profile of where the time is being spent may be obtained from this analysis.

Creating tools such as these to find answers related to specific situations or problems can take much effort and can be very difficult to calibrate as the software tools themselves affect the system under test. The present invention recognizes that hardware assistance for tool development and problem analysis can significantly ease the amount of effort needed to develop software performance tools. Further with the increasing density of processors hardware assistance can be included to provide additional debug and analysis features.

Therefore it would be advantageous to have an improved method apparatus and computer instructions for providing hardware assistance for performance tools for analyzing the performance of data processing systems.

The present invention provides a method apparatus and computer instructions in a data processing system for processing instructions and monitoring accesses to memory location ranges. An instruction for execution is identified. A determination is made as to whether the instruction is within a contiguous range of instructions. Execution information relating to the instruction is identified if the instruction is within the contiguous range of instructions. With memory location accesses an access to a memory location is identified. A determination of whether the memory location is within a contiguous range of memory locations is made. Access information is identified if the memory location is within the contiguous range of memory locations.

With reference now to a block diagram of a data processing system is shown in which the present invention may be implemented. Client is an example of a computer in which code or instructions implementing the processes of the present invention may be located. Client employs a peripheral component interconnect PCI local bus architecture. Although the depicted example employs a PCI bus other bus architectures such as Accelerated Graphics Port AGP and Industry Standard Architecture ISA may be used. Processor and main memory are connected to PCI local bus through PCI bridge . PCI bridge also may include an integrated memory controller and cache memory for processor . Additional connections to PCI local bus may be made through direct component interconnection or through add in boards. In the depicted example local area network LAN adapter small computer system interface SCSI host bus adapter and expansion bus interface are connected to PCI local bus by direct component connection. In contrast audio adapter graphics adapter and audio video adapter are connected to PCI local bus by add in boards inserted into expansion slots. Expansion bus interface provides a connection for a keyboard and mouse adapter modem and additional memory . SCSI host bus adapter provides a connection for hard disk drive tape drive and CD ROM drive . Typical PCI local bus implementations will support three or four PCI expansion slots or add in connectors.

An operating system runs on processor and is used to coordinate and provide control of various components within data processing system in . The operating system may be a commercially available operating system such as Windows XP which is available from Microsoft Corporation. An object oriented programming system such as Java may run in conjunction with the operating system and provides calls to the operating system from Java programs or applications executing on client . Java is a trademark of Sun Microsystems Inc. Instructions for the operating system the object oriented programming system and applications or programs are located on storage devices such as hard disk drive and may be loaded into main memory for execution by processor .

Those of ordinary skill in the art will appreciate that the hardware in may vary depending on the implementation. Other internal hardware or peripheral devices such as flash read only memory ROM equivalent nonvolatile memory or optical disk drives and the like may be used in addition to or in place of the hardware depicted in . Also the processes of the present invention may be applied to a multiprocessor data processing system.

For example client if optionally configured as a network computer may not include SCSI host bus adapter hard disk drive tape drive and CD ROM . In that case the computer to be properly called a client computer includes some type of network communication interface such as LAN adapter modem or the like. As another example client may be a stand alone system configured to be bootable without relying on some type of network communication interface whether or not client comprises some type of network communication interface. As a further example client may be a personal digital assistant PDA which is configured with ROM and or flash ROM to provide non volatile memory for storing operating system files and or user generated data. The depicted example in and above described examples are not meant to imply architectural limitations.

The processes of the present invention are performed by processor using computer implemented instructions which may be located in a memory such as for example main memory memory or in one or more peripheral devices .

Turning next to a block diagram of a processor system for processing information is depicted in accordance with a preferred embodiment of the present invention. Processor may be implemented as processor in .

In a preferred embodiment processor is a single integrated circuit superscalar microprocessor. Accordingly as discussed further herein below processor includes various units registers buffers memories and other sections all of which are formed by integrated circuitry. Also in the preferred embodiment processor operates according to reduced instruction set computer RISC techniques. As shown in system bus is connected to a bus interface unit BIU of processor . BIU controls the transfer of information between processor and system bus .

BIU is connected to an instruction cache and to data cache of processor . Instruction cache outputs instructions to sequencer unit . In response to such instructions from instruction cache sequencer unit selectively outputs instructions to other execution circuitry of processor .

In addition to sequencer unit in the preferred embodiment the execution circuitry of processor includes multiple execution units namely a branch unit a fixed point unit A FXUA a fixed point unit B FXUB a complex fixed point unit CFXU a load store unit LSU and a floating point unit FPU . FXUA FXUB CFXU and LSU input their source operand information from general purpose architectural registers GPRs and fixed point rename buffers . Moreover FXUA and FXUB input a carry bit from a carry bit CA register . FXUA FXUB CFXU and LSU output results destination operand information of their operations for storage at selected entries in fixed point rename buffers . Also CFXU inputs and outputs source operand information and destination operand information to and from special purpose register processing unit SPR unit .

FPU inputs its source operand information from floating point architectural registers FPRs and floating point rename buffers . FPU outputs results destination operand information of its operation for storage at selected entries in floating point rename buffers .

In response to a Load instruction LSU inputs information from data cache and copies such information to selected ones of rename buffers and . If such information is not stored in data cache then data cache inputs through BIU and system bus such information from a system memory connected to system bus . Moreover data cache is able to output through BIU and system bus information from data cache to system memory connected to system bus . In response to a Store instruction LSU inputs information from a selected one of GPRs and FPRs and copies such information to data cache .

Sequencer unit inputs and outputs information to and from GPRs and FPRs . From sequencer unit branch unit inputs instructions and signals indicating a present state of processor . In response to such instructions and signals branch unit outputs to sequencer unit signals indicating suitable memory addresses storing a sequence of instructions for execution by processor . In response to such signals from branch unit sequencer unit inputs the indicated sequence of instructions from instruction cache . If one or more of the sequence of instructions is not stored in instruction cache then instruction cache inputs through BIU and system bus such instructions from system memory connected to system bus .

In response to the instructions input from instruction cache sequencer unit selectively dispatches the instructions to selected ones of execution units and . Each execution unit executes one or more instructions of a particular class of instructions. For example FXUA and FXUB execute a first class of fixed point mathematical operations on source operands such as addition subtraction ANDing ORing and XORing. CFXU executes a second class of fixed point operations on source operands such as fixed point multiplication and division. FPU executes floating point operations on source operands such as floating point multiplication and division.

As information is stored at a selected one of rename buffers such information is associated with a storage location e.g. one of SPRs or carry bit CA register as specified by the instruction for which the selected rename buffer is allocated. Information stored at a selected one of rename buffers is copied to its associated one of GPRs or CA register in response to signals from sequencer unit . Sequencer unit directs such copying of information stored at a selected one of rename buffers in response to completing the instruction that generated the information. Such copying is called writeback. 

As information is stored at a selected one of rename buffers such information is associated with one of FPRs . Information stored at a selected one of rename buffers is copied to its associated one of FPRs in response to signals from sequencer unit . Sequencer unit directs such copying of information stored at a selected one of rename buffers in response to completing the instruction that generated the information.

Processor achieves high performance by processing multiple instructions simultaneously at various ones of execution units and . Accordingly each instruction is processed as a sequence of stages each being executable in parallel with stages of other instructions. Such a technique is called pipelining. In a significant aspect of the illustrative embodiment an instruction is normally processed as six stages namely fetch decode dispatch execute completion and writeback.

In the fetch stage sequencer unit selectively inputs from instruction cache one or more instructions from one or more memory addresses storing the sequence of instructions discussed further hereinabove in connection with branch unit and sequencer unit .

In the dispatch stage sequencer unit selectively dispatches up to four decoded instructions to selected in response to the decoding in the decode stage ones of execution units and after reserving rename buffer entries for the dispatched instructions results destination operand information . In the dispatch stage operand information is supplied to the selected execution units for dispatched instructions. Processor dispatches instructions in order of their programmed sequence.

In the execute stage execution units execute their dispatched instructions and output results destination operand information of their operations for storage at selected entries in rename buffers and rename buffers as discussed further hereinabove. In this manner processor is able to execute instructions out of order relative to their programmed sequence.

In the completion stage sequencer unit indicates an instruction is complete. Processor completes instructions in order of their programmed sequence.

In the writeback stage sequencer directs the copying of information from rename buffers and to GPRs and FPRs respectively. Sequencer unit directs such copying of information stored at a selected rename buffer. Likewise in the writeback stage of a particular instruction processor updates its architectural states in response to the particular instruction. Processor processes the respective writeback stages of instructions in order of their programmed sequence. Processor advantageously merges an instruction s completion stage and writeback stage in specified situations.

In the illustrative embodiment each instruction requires one machine cycle to complete each of the stages of instruction processing. Nevertheless some instructions e.g. complex fixed point instructions executed by CFXU may require more than one cycle. Accordingly a variable delay may occur between a particular instruction s execution and completion stages in response to the variation in time required for completion of preceding instructions.

Completion buffer is provided within sequencer to track the completion of the multiple instructions which are being executed within the execution units. Upon an indication that an instruction or a group of instructions have been completed successfully in an application specified sequential order completion buffer may be utilized to initiate the transfer of the results of those completed instructions to the associated general purpose registers.

In addition processor also includes performance monitor unit which is connected to instruction cache as well as other units in processor . Operation of processor can be monitored utilizing performance monitor unit which in this illustrative embodiment is a software accessible mechanism capable of providing detailed information descriptive of the utilization of instruction execution resources and storage control. Although not illustrated in performance monitor unit is coupled to each functional unit of processor to permit the monitoring of all aspects of the operation of processor including for example reconstructing the relationship between events identifying false triggering identifying performance bottlenecks monitoring pipeline stalls monitoring idle processor cycles determining dispatch efficiency determining branch efficiency determining the performance penalty of misaligned data accesses identifying the frequency of execution of serialization instructions identifying inhibited interrupts and determining performance efficiency. The events of interest also may include for example time for instruction decode execution of instructions branch events cache misses and cache hits.

Performance monitor unit includes an implementation dependent number e.g. 2 8 of counters labeled PMC and PMC which are utilized to count occurrences of selected events. Performance monitor unit further includes at least one monitor mode control register MMCR . In this example two control registers MMCRs and are present that specify the function of counters . Counters and MMCRs are preferably implemented as SPRs that are accessible for read or write via MFSPR move from SPR and MTSPR move to SPR instructions executable by CFXU . However in one alternative embodiment counters and MMCRs may be implemented simply as addresses in I O space. In another alternative embodiment the control registers and counters may be accessed indirectly via an index register. This embodiment is implemented in the IA 64 architecture in processors from Intel Corporation.

Additionally processor also includes interrupt unit which is connected to instruction cache . Additionally although not shown in interrupt unit is connected to other functional units within processor . Interrupt unit may receive signals from other functional units and initiate an action such as starting an error handling or trap process. In these examples interrupt unit is employed to generate interrupts and exceptions that may occur during execution of a program.

The present invention provides an ability to monitor the execution of specific instructions as well as the access of specific memory locations during the execution of a program. Specifically a spare field may be used to hold an indicator that identifies the instruction or memory location as one that is to be monitored by a performance monitor unit or by some other unit in a processor. Alternatively the indicator may be stored in another location in association with the instruction or memory location. In the case in which the indicator is placed in the instruction a spare field is typically used but in some cases the instruction may be extended to include the space needed for the indicator. With this case the architecture of the processor may require changes. For example a 64 bit architecture may be changed to a 65 bit architecture to accommodate the indicator. With respect to accesses of data an indicator may be associated with the data or memory locations in which the data is located.

Turning now to a diagram illustrating components used in processing instructions associated with indicators is depicted in accordance with a preferred embodiment of the present invention. Instruction cache receives bundles . Instruction cache is an example of instruction cache in . A bundle is a grouping of instructions. This type of grouping of instructions is typically found in an IA 64 processor which is available from Intel Corporation. Instruction cache processes instructions for execution.

As part of this processing of instructions instruction cache determines which instructions are associated with indicators. These indicators also are referred to as performance indicators in these examples. Signals have been associated with performance indicators. As a result signals for the instructions are sent to performance monitor unit . Performance monitor unit is an example of performance monitor unit in .

When instruction cache determines that an instruction associated with an indicator is present a signal is sent to indicate that a marked instruction is being executed. In these examples a marked instruction is an instruction associated with a performance indicator. Alternatively a performance indicator may indicate that all items or instructions in a bundle are marked to be counted. Additionally signals for these instructions are sent by instruction cache to the appropriate functional unit. Depending on the particular implementation a functional unit other than performance monitor unit may count execution of instructions. In the case that the performance indicators are in the instructions or in the bundles the cache unit instruction cache detects the indicators and sends signals to performance monitor unit .

When signals for these instructions are received by performance monitor unit performance monitor unit counts events associated with execution of instructions . As illustrated performance monitor unit is programmed only to count events for instructions associated with performance indicators. In other words an indicator associated with a instruction or memory location is used to enable counting of events associated with the instruction or memory location by performance monitor unit . If an instruction is received by instruction cache without a performance indicator then events associated with that instruction are not counted. In summary the performance indicators enable the counting on a per instruction or per memory location basis in a processor.

Performance monitor unit counts events for instructions associated with performance indicators if performance monitor unit is set in a mode to count metrics enabled for these types of marked instructions. In some cases performance monitor unit may be set to perform some other type of counting such as counting execution of all instructions which is a currently available function.

With respect to the accessing of data in memory locations the data and indicators are processed by a data cache such as data cache in rather than by an instruction cache. The data cache sends signals indicating that marked memory locations are being accessed to performance monitor unit . Marked memory locations are similar to marked instructions. These types of memory locations are ones associated with a performance indicator.

Turning next to a diagram illustrating one mechanism for associating a performance indicator with an instruction or memory location is depicted in accordance with a preferred embodiment of the present invention. Processor receives instructions from cache . In this example the indicators are not stored with the instructions or in the memory locations in which data is found. Instead the indicators are stored in a separate area of storage performance instrumentation shadow cache . The storage may be any storage device such as for example a system memory a flash memory a cache or a disk.

When processor receives an instruction from cache processor checks performance instrumentation shadow cache to see whether a performance indicator is associated with the instruction. A similar check is made with respect to accesses of memory locations containing data. In one embodiment a full shadow word is provided for each corresponding word that does not affect the actual data segments. In other words processor allows for the architecture or configuration of cache to remain unchanged. In these examples the mapping described is word for word. However some other type of mapping may be used such as a shadow bit per data word in which a bit in performance instrumentation shadow cache corresponds to one word of data.

With respect to this type of architecture the compilers using this feature create the debug information in a separate work area from the data area themselves in a manner similar to debug symbols. When a module is loaded the extra information performance indicators is prepared by the loader so that it will be available to incorporate into performance instrumentation shadow cache when instructions are loaded into cache . These cache areas may be intermingled and either marked as such or understood by the mode of operation. Processor uses the performance indicators to determine how the related data accesses and instruction executions are to be counted or made to take exceptions. In these examples the process is programmed by a debugger or a performance analysis program to know whether to use the shadow information while it is executing instructions.

Turning next to a diagram illustrating a bundle is depicted in accordance with a preferred embodiment of the present invention. Bundle contains instruction slot instruction slot instruction slot and template . As illustrated bundle contains 128 bits. Each instruction slot contains 41 bits and template contains 5 bits. Template is used to identify stops within the current bundle and to map instructions within the slots to different types of execution units.

Spare bits within bundle are used to hold indicators of the present invention. For example indicators and are located within instruction slots and respectively. These indicators may take various forms and may take various sizes depending on the particular implementation. Indicators may use a single bit or may use multiple bits. A single bit may be used to indicate that events are to be counted in response to execution of that instruction. Multiple bits may be used to identify a threshold such as a number of processor or clock cycles for instruction execution that may pass before events should be counted. Further these bits may even be used as a counter for a particular instruction. A similar use of fields may be used for indicators that mark data or memory locations.

Alternatively template may be used to contain a bundle of related indicators so that one bit is used to identify all of the instructions in a bundle. Also the bundle itself could be extended to be 256 bits or some other number of bits to contain the extra information for the performance indicators.

Turning next to diagrams of a subroutine containing performance indicators and data containing performance indicators are depicted in accordance with a preferred embodiment of the present invention. In this example subroutine in includes a number of instructions in which instructions and are associated with performance indicators. These instructions also are referred to as marked instructions. When these instructions are executed events associated with those instructions are counted to obtain data for software tools to analyze the performance of a data processing system executing a subroutine .

Data or memory locations containing data may be marked with indicators in a similar manner. These indicators are used in counting accesses to the data or memory locations in these examples. In data includes data associated with performance indicators. Data and data are sections of data that are associated with performance indicators. These sections of data which are associated with performance indicators also are referred to as marked data.

Turning now to a flowchart of a process for processing instructions containing performance indicators is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in an instruction cache such as instruction cache in .

The process begins by receiving a bundle step . In these examples each bundle has a format similar to bundle in . An instruction in the bundle is identified step . A determination is made as to whether a performance indicator associated with the instruction is present step . This determination may be made by examining an appropriate field in the instruction or bundle. Alternatively a performance instrumentation shadow cache such as performance instrumentation shadow cache in may be checked to see if a performance indicator is associated with the instruction.

If a performance indicator is present a signal is sent to a performance monitor unit step . Upon receiving this signal the performance monitor unit will count events associated with the execution of the instruction. Additionally the instruction is processed step . Processing of the instruction includes for example sending the instruction to the appropriate functional unit for execution.

Thereafter a determination is made as to whether additional unprocessed instructions are present in the bundle step . If additional unprocessed instructions are present in the bundle the process returns to step as described above. Otherwise the process terminates. Turning back to step if the performance indicator is not present the process proceeds directly to step .

Turning now to a flowchart of a process for selectively sending signals to an interrupt unit is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in an instruction cache such as instruction cache in . This process is employed in cases in which monitoring events using a performance monitor unit may miss certain events. For example a performance monitor unit counts events. When a cache miss occurs a signal is sent to the performance monitor unit. When the meta data for a corresponding cache line is loaded into the cache the appropriate signal or signals also are raised. If the meta data indicates that an exception is to be raised then a signal is sent to the interrupt unit in which the signal indicates that an exception is to be raised.

The process begins by receiving a bundle step . An instruction in the bundle is identified step . A determination is made as to whether a performance indicator associated with the instruction is present step . The signal sent to the interrupt unit to indicate an exception is to be raised is different from the signal sent to the performance monitor unit. For example an instruction may be associated with a specific performance indicator having a first value that causes a signal to be sent to the interrupt unit. A second value for a performance indicator may be used to send a different signal to the performance monitor unit. If a performance indicator having the first value is present the signal is sent to an interrupt unit step . Upon receiving this signal the interrupt unit initiates appropriate call flow support to process this interrupt. The call flow support may for example record cache misses that may be missed by a functional unit trying to access instructions or data in a cache.

Additionally the instruction is processed step . Processing of the instruction includes for example sending the instruction to the appropriate functional unit for execution.

Thereafter a determination is made as to whether additional unprocessed instructions are present in the bundle step . If additional unprocessed instructions are present in the bundle the process returns to step as described above. Otherwise the process terminates. Turning back to step if the performance indicator is not present the process proceeds directly to step .

With reference now to a flowchart of a process for generating an interrupt in response to an access of a memory location associated with a performance indicator is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in a data cache such as data cache in .

The process begins by identifying a request to access a memory location step . In response to identifying this request a determination is made as to whether a performance indicator is associated with the memory location step . If a performance indicator is associated with the memory location an interrupt is generated by sending a signal to the interrupt unit step . Thereafter the access to the memory location is processed step with the process terminating thereafter.

In a flowchart of a process for counting events is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in a performance monitor unit such as performance monitor unit in .

The process begins by receiving a signal from an instruction cache indicating that an instruction with a performance indicator is being processed step Next events associated with the instruction being processed are counted step with the process terminating thereafter. The counting of events may be stored in a counter such as counter in .

With reference next to a flowchart of a process for selective counting of instructions is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in an instruction cache such as instruction cache in .

The process begins by determining whether an instruction associated with a performance indicator has been received step . In this example the indicator causes counting of events for this instruction and all subsequent instructions executed by the processor. Alternatively the indicator could be an instruction itself which indicates the new mode of counting is to be started. If an instruction with an indicator has been received a flag is set to start counting events for instructions step . This flag indicates that counting events for instructions should start.

Next a determination is made as to whether an instruction with an indicator has been received step . Alternatively the indicator could be an instruction itself which indicates the new mode of counting is to be stopped. If an instruction with an indicator is received the flag is unset to stop counting the events step with the process terminating thereafter.

The indicator in step and step may be the same indicator in which the indicator toggles the setting and unsetting of the flag. In another implementation two different indicators may be used in which a first indicator only sets the flag. A second indicator is used to unset the flag. Communication between a cache unit such as an instruction cache or a data cache and the performance monitor unit to indicate a mode of counting may be implemented simply with a high signal when counting is to occur and a low signal when counting is no longer enabled.

With reference next to a flowchart of a process for selective counting of instructions is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in an instruction cache such as instruction cache in .

The process begins by checking a flag step . A determination is made as to whether the flag is set step . If the flag is set a signal is sent to the performance monitor unit to enable this unit to count events step with the process terminating thereafter. Otherwise a signal is sent to the performance monitor unit to disable the counting of events step with the process terminating thereafter.

The processes illustrated in count events for all instructions after an instruction is associated with a performance indicator. In this manner fewer bits may be used to toggle counting of events. Further with the counting of all instructions events associated with calls to external subroutines may be counted.

Turning now to a flowchart of a process for identifying instructions exceeding a threshold is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in an instruction cache such as instruction cache in .

The process begins by receiving an instruction associated with a performance indicator step . A threshold is identified for the instruction step . In these examples the threshold relates to a number of processor or clock cycles needed to complete an instruction. If the cache latency or amount of time needed to access the cache exceeds the threshold value that event is counted. The threshold value is set within the indicator in these examples.

For example three bits may be used to set eight different values for the threshold. For example xx 10 cycles xx 50 cycles and xx 100 cycles. Some combination of these three bits may be used to set values for the threshold. More or fewer bits may be used and different values may be assigned to the bits depending on the specific implementation. The meaning of the bits may also be controlled through an interface such as a set of registers that may be used to set the meaning of each of the bits. These registers are ones that are added to the processor architecture for this specific purpose.

Cycles for executing the instruction are monitored step . A determination is made as to whether the threshold has been exceeded for this instruction step . If the threshold has been exceeded then a selected action is performed step . This selected action may take different forms depending on the particular implementation. For example a counter may be incremented each time the threshold is exceeded. Alternatively an interrupt may be generated. The interrupt may pass control to another process to gather data. For example this data may include a call stack and information about the call stack. A stack is a region of reserved memory in which a program or programs store status data such as procedure and function call addresses passed parameters performance monitor counter values and sometimes local variables.

A determination is made as to whether monitoring is to end step . Step may be implemented one instruction at a time. When an instruction is executed or the threshold is exceeded a signal is sent. In this example execution of a single instruction results in one signal being sent. In the case in which multiple instructions may be executed at the same time multiple signals may be needed to indicate the execution of each instruction. In some embodiments a sampling approach may be supported where the threshold is only supported for one instruction at a time. This may be done by only supporting thresholds for those instructions that are in a particular position in the processor s instruction queue. In other embodiments one signal may be sent if at least one of the marked instructions exceeds the threshold. For each instruction in which a threshold is exceeded a separate signal is raised or generated for that instruction.

If the monitoring is to end the collected information is sent to a monitoring program step with the process terminating thereafter. Otherwise the process returns to step as described above. In step if the threshold is not exceeded for the instruction the process proceeds directly to step .

A similar process may be implemented in a data cache such as data cache in to monitor accesses to memory locations. The process illustrated in may be adapted to identify the cycles needed to access data in a memory location. As with the execution of instructions counting occurs or an interrupt is generated when the amount of time needed to access the data in a memory location exceeds a specified threshold.

As with the other examples these indicators may be included as part of the instruction or with the data in a memory location. Alternatively these indicators may be found in a performance instrumentation shadow cache or memory in association with the instruction or data.

With reference to a flowchart of a process for monitoring accesses to a memory location is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in a data cache such as data cache in . This process is used to count accesses to data in a memory location.

The process begins by receiving data associated with a performance indicator step . A determination is made as to whether a memory location for the data has been accessed step . If the memory location has been accessed then a counter is incremented step . A determination is made as to whether monitoring is to end step . If monitoring of the memory location is to end the process terminates. Otherwise the process returns to step . In step if the memory location is not accessed then the process proceeds to step .

Turning to a block diagram illustrating components used for generating meta data such as performance indicators is depicted in accordance with a preferred embodiment of the present invention. The compiler supports directives embedded in the source that indicate the meta data to be generated. Compiler may generate instructions for execution and meta data for monitoring. As instruction or data cache pages are loaded into memory the operating system program loader linker and or the performance monitoring program reads the meta data generated by compiler and loads the meta data into memory such as performance monitor section in these examples. The section itself is marked as meta data . The processor may accept meta data in the format of the compiler generated section data in performance monitor section and populate processor s internal performance instrumentation shadow cache with the data. A block oriented approach is described with reference to below.

In one embodiment the format simply has a performance instrumentation shadow cache entry for each of its block or sector references and moves meta data to its corresponding shadow entry or entries. Instead of having a performance instrumentation shadow cache the internal format of the cache itself may be modified to contain meta data . In embodiments where the instruction stream itself is modified to contain the meta data then either the loader updates the instruction stream to contain the appropriate indicators and work areas or compiler has generated the code to contain meta data . In either case after the code is loaded the processor receives the meta data .

In addition meta data may be placed into performance instrumentation shadow memory in association with instructions . Compiler produces information in a table or debug data section. The performance monitoring program loads this information into shadow data areas in performance instrumentation shadow memory . Alternatively the debug areas may be automatically populated by the operating system and the processor working together.

Instructions may then be executed by processor . Compiler may set a register such as mode register in processor . When this register is set processor looks at meta data in performance instrumentation shadow memory when executing instructions to determine whether performance indicators in meta data are associated with instructions that are being executed in instructions . These performance indicators are handled using processes such as those described above with reference to . If mode register is not set then meta data is ignored when instructions are executed.

A similar process may be performed with respect to data in memory location . Depending on the particular implementation meta data may be placed within the instruction or within the data rather than in performance instrumentation shadow memory . However by placing meta data in performance instrumentation shadow memory the generation of meta data may be performed dynamically when meta data is placed in performance instrumentation shadow memory .

This feature allows for selection and monitoring of instructions to occur without having to modify the program. In other words compiler may generate meta data after instructions have been compiled for execution by processor . Setting mode register causes processor to look for meta data in performance instrumentation shadow memory without having to modify instructions . In these examples meta data take the form of performance indicators that tell processor how to handle the execution of instructions and or data accesses to memory location .

Turning next to a diagram illustrating meta data is depicted in accordance with a preferred embodiment of the present invention Meta data is an example of meta data in . This meta data is generated by a compiler such as compiler .

In this example meta data includes 5 entries entry and as indicated by line in meta data . Each of these entries includes an offset a length and a flag for describing the instrumentation of code in this example.

Entry has an offset of 0 with an entry length of 120 bytes. Flag indicates that all instructions within the range indicated by entry length need to be counted. In these examples each instruction has a length of 4 bytes. Entry has an entry length of 4 bytes which corresponds to an instruction. Flag indicates that an exception should be generated upon execution of this instruction.

In entry an instruction beginning at an offset of 160 bytes is associated with flag . This flag indicates that the instruction should be counted if the threshold 100 cycles is exceeded.

Flag in entry indicates that tracing should start at the instruction having an offset of 256 bytes. Tracing stops as indicated by flag in entry which has a flag for the instruction at an offset of 512 bytes.

These flags are used to generate the performance indicators that are associated with the instructions. The operating system moves this meta data generated by the compiler and processes the meta data into a performance instrumentation shadow memory such as performance instrumentation shadow memory in . Alternatively this meta data may be placed into fields within the instructions depending on the particular implementation.

With reference now to a diagram illustrating components involved in loading and maintaining a performance instrumentation shadow cache are depicted in accordance with a preferred embodiment of the present invention. In this example existing cache contains primary segment . Primary segment includes blocks and . Translation table is used to provide a mapping for blocks in primary segment to blocks in perfinst segment . The data in this segment is placed into new performance instrumentation shadow cache .

At program compile time the compiler generates a new performance instrumentation data section as previously described. At program load time the loader queries the processor to determine cache line size. The loader parses perfinst segment and constructs a shadow segment in the format required by the processor for any text or data segment that the loader loads. This shadow segment is placed into new performance instrumentation shadow cache .

Each block in the shadow segment contains meta data for instructions or data in the corresponding primary cache block. This meta data includes for example flags tag fields threshold and count fields for each tagged item in a block in primary segment . This meta data also may include a flag that represents all the instructions or data in the block.

The loader constructs a table mapping translation table for each block in primary segment to a corresponding perfinst block such as block and in perfinst segment . Further the loader registers the head of this table translation table and the location and size of primary segment with the processor.

At page replacement time paging software provides a new interface to associate perfinst segment with the corresponding primary segment primary segment . When primary segment pages in or out perfinst segment pages in or out as well.

At cache line replacement time the processor contains new performance instrumentation shadow cache with cache frames directly associated with the frames in the existing data and instruction caches such as existing cache . When the processor s instruction or data cache loads a new line the cache also must load the corresponding perfinst block into the performance instrumentation shadow cache new performance instrumentation shadow cache . The processor sees from the registration data given by the loader at program load time that the processor is bringing a block into its cache that has an associated perfinst segment perfinst segment . The processor looks in translation table associated with this segment finds a reference to the perfinst block corresponding to the block it is about to load and loads the perfinst block into new performance instrumentation shadow cache . In these examples cache misses associated with meta data are not signaled or are treated differently from cache misses associated data in a primary cache block such as in primary segment .

With reference now to a flowchart of a process for generating meta data for instructions is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented by a performance monitoring program.

The process begins by identifying an instruction for profiling step . This instruction may be for example one that has been executed more than a selected number of times. Meta data is generated for the identified instruction step . This meta data takes the form of a performance indicator. The performance indicator may for example increment a counter each time the instruction is executed increment a counter if the number of cycles needed to execute the instruction exceeds a threshold value toggle counting of events for all instructions for all events after this instruction or count events occurring in response to executing the instruction. In a preferred embodiment the counters are in the associated performance instrumentation shadow cache and take some number of bits to allow for a one to one correspondence between the data or instructions in the cache and the bits reserved for counting.

The meta data is then associated with the instruction step . Next a determination is made as to whether more instructions are present for processing step . If additional instructions are present the process returns to step . Otherwise the process terminates. A similar process may be used to dynamically generate meta data for data in memory locations.

With reference now to a flowchart of a process for generating meta data for memory locations is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in a compiler such as compiler in .

The process begins by identifying a memory location for profiling step . Step occurs by detecting access to a marked location. Meta data is generated for the identified memory location step . This meta data takes the form of a performance indicator. The performance indicator may for example increment a counter each time the memory location is accessed increment a counter if the number of cycles needed to access the memory location exceeds a threshold value or toggle counting of all accesses to memory locations. The meta data is then associated with the memory location step . Next a determination is made as to whether more memory locations are present for processing step . If additional memory locations are present the process returns to step . Otherwise the process terminates.

Turning now to a flowchart of a process for counting execution for particular instructions is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in an instruction cache such as instruction cache in .

The process begins by executing an instruction step . A determination is made as to whether a counter is associated with the instruction step . The counter may be included in a field within the instruction or may be in a performance instrumentation shadow memory. If a counter is associated with the instruction the counter is incremented step with the process terminating thereafter. Otherwise the process terminates without incrementing the counter. The counter may be reset if the counter exceeds a threshold value.

When the counter is implemented as part of the instructions the counter may be of limited size. In this case a threshold value for the counter may be set to indicate when the counter is in danger of overflowing. The counter may then be reset after the value has been read. This value may be read by a performance monitor unit or by a program used to analyze data. APIs may be implemented to access this data.

Turning now to a flowchart of a process for counting accesses to a particular memory location is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in a data cache such as data cache and instruction cache in .

The process begins by detecting access to a memory location step . A determination is made as to whether a counter is associated with the memory location step . The counter may be included within the memory location or may be in a performance instrumentation shadow memory. If a counter is associated with the memory location the counter is incremented step with the process terminating thereafter. Otherwise the process terminates without incrementing the counter.

With reference next to a diagram illustrating components used in accessing information collected with respect to the execution of instructions or the access of memory locations in accordance with a preferred embodiment of the present invention. In this example instruction unit executes instruction and increments counter . This counter is incremented each time instruction is executed. In this example instruction unit may be implemented as instruction cache in .

When the instruction or data cache pages are loaded into memory the operating system program loader linker and or the performance monitoring program reads the meta data generated by the compiler and determines that counting is associated with instruction or data access then the loading process allocates data areas to maintain the counters as part of its perfinst segment. The size of the counters and the granularity of the data access determine the amount of work area to be allocated.

In a simple case the granularity of the data or instruction access could be word size so that an access to any byte in the word is considered an access and the counts could also be a word size. In this case one to many mapping is present between the primary segment and the perfinst segment a full word to contain the counts or threshold is not required . The loading process allocates a shadow page or pages and tells the processor to use the shadow page s to contain the counts. Details of this mapping are described above with reference to . The cache unit in the processor maintains a shadow block entry to indicate the corresponding page to contain the count information. Different mapping and different levels of support could be provided.

In an alternative embodiment the compiler allocates the work areas to maintain the counts and indicates the placement of these work areas in its generated data areas. An entry in the meta data could indicate the start of the data the number of bytes of data granularity of the data the start of the count area and the granularity of each counting unit. In either case the meta data is loaded into the processor and the processor populates its internal shadow cache with the meta data. In illustrative embodiments in which the instruction stream itself is modified to contain the meta data then either the loader updates the instruction stream to contain the appropriate indicators and work areas or the compiler has generated the code to contain the meta data. In either case after the code is loaded the processor receives the meta data.

Data unit may be implemented as data cache in . In this example each time data is accessed counter is incremented. Data and counter are both located in a particular memory location. In these examples a new instruction may be employed in which the instruction is called ReadDataAccessCount RDAC that takes a data address and a register and puts the count associated with that data address in the register.

Each of these events instruction execution and data access results in incrementing of a counter. The mechanism of the present invention provides an interface hardware interface to access this collected data. In these examples hardware interface takes the form of an application programming interface API for operating system . In this way analysis tool may obtain data from counter and counter . Analysis tool may take many forms such as for example Oprofile which is a known system wide profiler for Linux systems. Although the examples in illustrate providing an interface to an instruction unit and a data unit hardware interface may be implemented to provide access to information from other units in a processor. For example APIs may be created for hardware interface that allows for accessing information located in counters in a performance monitor unit such as counter and in performance monitor unit in .

In a block diagram of components used in autonomically modifying code in a program to allow selective counting or profiling of sections of code in accordance with a preferred embodiment of the present invention. In this example profiler is a program such as tprof that may be used to identify routines of high usage in a program such as program . In these examples tprof is a timer profiler which ships with the Advanced Interactive Executive AIX operating system from International Business Machines IBM Corporation. This program takes samples which are initiated by a timer. Upon expiration of a timer tprof identifies the instruction executed. Tprof is a CPU profiling tool that can be used for system performance analysis. The tool is an example of an analysis tool and based on the sampling technique which encompasses the following steps interrupt the system periodically by time or performance monitor counter determine the address of the interrupted code along with process id pid and thread id tid record a TPROF hook in the software trace buffer and return to the interrupted code.

Alternatively a fixed number of counts of a performance monitor counter may be used instead of a timer. This program profiles subroutines that are used to indicate where time is spent within a program. A program having usage over a certain threshold also is referred to as being hot . By using information from profiler routines of interest such as subroutine in program may be identified.

With this information the instructions in subroutine may be autonomically modified by analysis tool to allow counting of the execution of subroutine . Additional routines may be identified for modification by analysis tool . For example subroutine also may be identified as a routine of interest with the instructions of this routine being modified to allow counting of the execution of subroutine . The modification of the code in these routines includes associating performance indicators with one or more instructions within each of these subroutines.

After the instructions in these routines have been modified by analysis tool program is then executed by processor . Processor executes program and provides counts for these routines. For example the counting of instructions executed and the number of cycles used in executing a routine may be performed by processor using the mechanisms described above.

With reference to a flowchart of a process for dynamically adding or associating performance indicators to an instruction is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in a program such as analysis tool in . An analysis tool is a program that is used to obtain metrics about the execution of a program. These metrics may be any measurable parameter such as execution time routines executed particular instructions executed and memory locations accessed.

The process begins by identifying instructions of interest using data from a profiler step . This profiler may be for example a timer profiler found in AIX. An instruction from the identified instructions is selected for modification step . Thereafter a performance indicator is dynamically added to the selected instruction step .

In step the instruction may be added in a manner such that the instructions do not need to be modified for execution. A performance instrumentation shadow memory such as performance instrumentation shadow memory in may be employed to hold the performance indicators. In this situation a register is set in the processor to indicate that the performance instrumentation shadow memory should be checked for performance indicators when executing instructions.

A determination is then made as to whether additional identified instructions are present for modification step . If additional instructions are present for modification the process returns to step . Otherwise the process terminates.

Turning next to a diagram illustrating components used to scan pages through associating performance indicators with instructions in a page is depicted in accordance with a preferred embodiment of the present invention. The mechanism of the present invention uses performance indicators to allow instrumenting or modifying of instructions in a program one page at a time.

In this example program contains three pages page page and page . Scanning daemon associates performance indicators with instructions in program one or more pages at a time. For example the instructions in page may be associated with performance indicators by scanning daemon . Program is then executed by processor . Data from the execution of program may then be collected This data includes for example counts of events occurring in response to instructions in page counting the number of times each instruction in page is executed and or identifying the number of visits to page .

Next scanning daemon may remove the performance indicators from instructions in page and associate performance indicators with instructions in page . Program is then executed again by processor and data from execution of this program is collected. Then instructions in page may be modified in program executed to collect data on that page.

In this manner usages of routines typically not recorded by programs such as a timer profiler may be identified. A timer profiler may not record some usages of routines because interrupts may be inhibited or the timing of samples may cause synchronous non random behavior. By modifying instructions in program counting a routine or other modules may be obtained in which the counts are unbiased and the system is unperturbed. In this manner interrupt driven counting is avoided. Further although the instrumenting of code is one page at a time other groupings of instructions may be used in scanning a program such as modules that form the program. For example the grouping may be a single executable program a library a group of selected functions and a group of selected pages.

Turning next to a flowchart of a process for adding indicators to instructions in a page is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in a program such as scanning daemon in .

First a selection of pages is identified step . In this example the pages are those in the program that are to be scanned or instrumented. Next a page within the selection of pages is selected for modification step . Indicators are then associated with all of the instructions in the selected page step . The program is then executed step . Next a determination is made as to whether all the pages with the selection have been scanned step . If all of the pages have been scanned the process terminates thereafter. However if not all pages have been scanned the next page to be scanned is selected step with the process returning to step as described above.

The process illustrated in shows scanned groupings of instructions as pages. Depending on the particular implementation other types of groupings of instructions such as modules that form a program may be scanned or instrumented in this manner.

A program is employed to identify a caller from a routine from the information found in a call stack. This program allows for an identification of what has occurred in a routine and provides a summary of what has occurred in a program by identifying function calls that have been made. This program however requires instructions inserted in the code to obtain this information.

The mechanism of the present invention allows for identifying calls and returns without having to perform special code instrumentation. In particular the function of generating an interrupt on a specific set of instructions may be used to gather information about the system and applications. In these examples instructions for calls and returns are associated with a performance indicator that generates an interrupt.

By walking back up the call stack a complete call stack can be obtained for analysis. A stack walk may also be described as a stack unwind and the process of walking the stack may also be described as unwinding the stack. Each of these terms illustrates a different metaphor for the process. The process can be described as walking as the process must obtain and process the stack frames step by step or frame by frame. The process may also be described as unwinding as the process must obtain and process the stack frames that point to one another and these pointers and their information must be unwound through many pointer dereferences.

The stack unwind follows the sequence of function method calls at the time of an interrupt and is generated in response to execution of an instruction associated with a performance indicator. A call stack is an ordered list of routines plus offsets within routines i.e. modules functions methods etc. that have been entered during execution of a program. For example if routine A calls routine B and then routine B calls routine C while the processor is executing instructions in routine C the call stack is ABC. When control returns from routine C back to routine B the call stack is AB. For more compact presentation and ease of interpretation within a generated report the names of the routines are presented without any information about offsets. Offsets could be used for more detailed analysis of the execution of a program however offsets are not considered further herein.

Thus during interrupt processing or at post processing initiated by execution of an instruction associated with a particular performance indicator the generated sample based profile information reflects a sampling of call stacks not just leaves of the possible call stacks as in some program counter sampling techniques. A leaf is a node at the end of a branch i.e. a node that has no descendants. A descendant is a child of a parent node and a leaf is a node that has no children.

With reference now to a diagram depicting call stack containing stack frames is depicted in accordance with a preferred embodiment of the present invention. A stack is a region of reserved memory in which a program or programs store status data such as procedure and function call addresses passed parameters and sometimes local variables. A stack frame is a portion of a thread s stack that represents local storage arguments return addresses return values and local variables for a single function invocation. Every active thread of execution has a portion of system memory allocated for its stack space. A thread s stack consists of sequences of stack frames. The set of frames on a thread s stack represent the state of execution of that thread at any time. Since stack frames are typically interlinked e.g. each stack frame points to the previous stack frame it is often possible to trace back up the sequence of stack frames and develop the call stack . A call stack represents all not yet completed function calls in other words it reflects the function invocation sequence at any point in time.

Call stack includes information identifying the routine that is currently running the routine that invoked it and so on all the way up to the main program. Call stack includes a number of stack frames and . In the depicted example stack frame is at the top of call stack while stack frame is located at the bottom of call stack . The top of the call stack is also referred to as the root . The interrupt found in most operating systems is modified to obtain the program counter value pcv of the interrupted thread together with the pointer to the currently active stack frame for that thread. In the Intel architecture this is typically represented by the contents of registers EIP program counter and EBP pointer to stack frame .

By accessing the currently active stack frame it is possible to take advantage of the typical stack frame linkage convention in order to chain all of the frames together. Part of the standard linkage convention also dictates that the function return address be placed just above the invoked function s stack frame this can be used to ascertain the address for the invoked function. While this discussion employs an Intel based architecture this example is not a restriction. Most architectures employ linkage conventions that can be similarly navigated by a modified profiling interrupt handler.

When an interrupt occurs the first parameter acquired is the program counter value. The next value is the pointer to the top of the current stack frame for the interrupted thread. In the depicted example this value would point to EBP in stack frame . In turn EBP points to EBP in stack frame which in turn points to EBP in stack frame . In turn this EBP points to EBP in stack frame . Within stack frames are EIPs which identify the calling routine s return address. The routines may be identified from these addresses. Thus routines are defined by collecting all of the return addresses by walking up or backwards through the stack.

Obtaining a complete call stack may be difficult in some circumstances because the environment may make tracing difficult such as when an application having one call stack makes a call to a kernel having a different call stack. The hardware support provided by the mechanism of the present invention avoids some of these problems.

Turning next to a flowchart of a process for identifying events associated with call and return instructions in which data is collected from a performance monitor unit is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may also be implemented for an analysis tool such as analysis tool in .

The process begins by identifying call and return instructions step . The instructions for calls and returns are ones of interest for determining when a routine has been called and when a routine completes. This may be accomplished for interrupts interrupt returns system calls and returns from system calls.

Next performance indicators are associated with the identified call and return instructions step . The program is then executed step and data is collected from the performance monitor unit step with the process terminating thereafter. This information may be collected through interfaces such as hardware interface illustrated in in which APIs are employed to obtain data collected by the different functional units in a processor.

With this data identifications of callers of routines may be made. This information may be used to generate data structures such as trees to track and present information regarding the execution of the program. This generation of data structures may be implemented using processes similar to those provided in analysis tools.

Turning next to a flowchart of a process for identifying routines that have been executed more than a selected number of times is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be implemented in a functional unit within a processor such as instruction cache in . This process is used to identify counts of instructions that are executed and to generate an interrupt when these instructions have occurred more than some selected number of times.

First a determination is made as to whether an execution of a selected instruction is detected step . This determination is made by examining each instruction that is executed to see whether a performance indicator is associated with the instruction. These performance indicators may be associated with the instructions through different tools such as compiler in or analysis tool in .

If execution of an instruction containing a performance indicator is not identified the process returns to step until a selected instruction is detected. If a selected instruction is identified as being executed a counter with a set threshold is incremented for that selected instruction to count how often that particular instruction is executed step . In these examples each instruction identified for monitoring is assigned a counter.

Next a determination is made as to whether the set threshold has been reached step . Threshold values are initially determined by using documented cache miss times for each of the cache levels. However increasing times are used to determine problems caused by cache interventions accesses from other processors . Repeated runs with different values may be made to identify the areas with the worst performance.

In these examples the instruction may be associated with an indicator that includes an indication that execution of the instruction is to be monitored as well as providing a counter. Further count criteria may be included to identify when an interrupt is to be generated. For example an interrupt may be generated when the instruction has been executed more than thirteen times.

If the threshold has not been reached the process returns to step as described above. If the set threshold has been reached an interrupt is sent to the monitoring program step with the process terminating thereafter. This interrupt may be sent to an interrupt unit such as interrupt unit in which passes control to the appropriate procedure or process to handle the interrupt.

This process may be especially useful for routines with many branches. In this case all branch instructions would be flagged for counting. Information derived by this type of counting may be useful for identifying improvements for compiler and just in time JIT code generation by minimizing branches or adjusting hint flags supported in the instruction architecture of the processor that is used.

Turning next to a flowchart of a process for examining a call stack and identifying a caller of a routine when a particular instruction is executed more than some selected number of times is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in may be initiated by an interrupt unit such as interrupt unit in . This process is used to identity a call in a routine and may be used to recursively obtain information for callers.

First a call stack is examined and the caller of a routine is identified step . Next a count of the number of instructions executed is captured from the instruction cache step . The count is for a counter used in step in . The counter is then reset step with control thereafter returned from the interrupt step . The information obtained in the process in may be used to identify additional routines for monitoring to recursively identify callers of routines.

Turning next to a diagram illustrating ranges of instructions and data that has been selected for monitoring is depicted in accordance with a preferred embodiment of the present invention. In this example program includes instruction range and . Each of these ranges has been identified as ones of interest for monitoring. Each of these ranges is set within an instruction unit such as instruction cache in . Each range is used to tell the processor the number of instructions executed in a range as well as the number of times a range is entered during execution of program .

Instruction cache uses range registers to define instruction ranges. These registers may be existing registers or instruction cache may be modified to include registers to define instruction ranges. These ranges may be based on addresses of instructions. Additionally range registers may be updated by various debugger programs and performance tools.

If an instruction is executed in a range such as instruction range or instruction range a counter is incremented in instruction cache . Alternatively the instruction may be sent to a performance monitor unit such as performance monitor unit in . The performance monitor unit tracks the count of the number of instructions executed within the range and the number of times the instruction range is entered in these examples.

Data accesses may be monitored in a similar fashion. For example data includes data range . Data accesses to data range may be counted in a similar fashion to execution of instructions within instruction range or instruction range . These ranges may be defined in registers within a data unit such as data cache in . These ranges for data may be defined in the register as a range of memory locations for the data.

Turning next to a flowchart of a process for counting the number of visits to a set range as well as the number of instructions executed within a set range is depicted in accordance with a preferred embodiment of the present invention. The process illustrated in FIG. may be implemented in an instruction unit such as instruction cache in .

First an instruction is identified for execution step . Next a determination is made as to whether the instruction is within a set range of instructions step . The range may be identified by examining registers defining one or more instruction ranges. If the instruction is not within a set range of instructions the process returns to step as described above. If the instruction is within a set range of instructions a determination is made as to whether the previous instruction was within the set range of instructions step . If the previous instruction was not within the set range of instructions a visit counter is incremented to tell the processor how many times the instruction range is entered step . Additionally an execution counter is incremented to count the number of instructions executed within the set range of instructions step with the process returning to step thereafter.

With reference again to step if the previous instruction was within the set range of instructions the process proceeds to step as described above.

A similar process to the one illustrated in may be implemented for access to data. In this case the process would typically be implemented in a data unit rather than in an instruction unit.

Thus the present invention provides an improved method apparatus and computer instructions for providing assistance in monitoring execution of programs. The mechanism of the present invention includes employing an indicator that is recognized by the processor to enable counting the execution of an instruction associated with the indicator. Various types of counting as described above are enabled through this mechanism. Further with the information provided through the use of associating indicators with particular instructions the mechanism of the present invention also provides for various types of adjustments to programs in monitoring and analyzing performance of programs. Further as described above programs may be automatically adjusted to allow for monitoring of selected instructions and even routines and modules without having to modify the program.

It is important to note that while the present invention has been described in the context of a fully functioning data processing system those of ordinary skill in the art will appreciate that the processes of the present invention are capable of being distributed in the form of a computer readable medium of instructions and a variety of forms and that the present invention applies equally regardless of the particular type of signal bearing media actually used to carry out the distribution. Examples of computer readable media include recordable type media such as a floppy disk a hard disk drive a RAM CD ROMs DVD ROMs and transmission type media such as digital and analog communications links wired or wireless communications links using transmission forms such as for example radio frequency and light wave transmissions. The computer readable media may take the form of coded formats that are decoded for actual use in a particular data processing system.

The description of the present invention has been presented for purposes of illustration and description and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. For example instead of using a field in an instruction or in a bundle a new instruction or operation code may be used to indicate that a subsequent instruction or a subsequent set of instructions are marked instructions. Also the architecture of a processor may be changed to include additional bits if spare fields for performance indicators are unavailable in the case in which it is desirable to include performance indicators within fields in the instructions. Also although examples of events such as execution of the instruction time such as clock or processor cycles needed to execute an instruction time to access data entry into a section of code have been given these examples are not meant to limit the present invention to the types of events that can be counted. Any event relating to execution of an instruction or access to a memory location may be counted using the mechanisms of the present invention.

The illustrative embodiments were chosen and described in order to best explain the principles of the invention the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

