---

title: System and method of distributing multimedia content
abstract: In accordance with one embodiment of the present invention, multimedia content may be streamed, together with associated timing information, to various users, who may provide feedback data in response to the multimedia content; the feedback data may be related to the multimedia content using the associated timing information, and then stored to some medium.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08620878&OS=08620878&RS=08620878
owner: UStream, Inc.
number: 08620878
owner_city: San Francisco
owner_country: US
publication_date: 20080721
---
Aspects of the present invention relate generally to capturing and storing the experience of a live event and reproducing that experience at a later date.

Currently there exists no system that allows users to not only react to live multimedia content in real time but to have those reactions shared with the other users who are participating in the same live event true real time interaction. The ability to share the experience of a live event with others who may or may not be in the same physical space as any other user greatly enhances both the users and the broadcaster s experiences the interactivity transforms the act of watching multimedia content from passive consumption to active participation. In addition the information culled from the real time reactions of the participating audience when analyzed in the aggregate can help to monetize and organize the associated multimedia content and determine at what points in time within the multimedia stream the content is the most interesting and compelling.

Furthermore there currently exists no mechanism by which the total experience of watching a live event as interpreted and recorded by those participating in its consumption can be reproduced at will and experienced in its entirety by users who did not participate in the original event.

So while methods currently exist for streaming live multimedia content they are inherently limited by the fact that they cannot take advantage of in real time the audience s reaction and participation level. Thus it is desirable to provide a system by which broadcasters and consumers of multimedia content can interact in real time with the content and each other and can see the reactions of the other users. It is also desirable to leverage the information gleaned by the reaction data provided by the users so as to enable discovery in real time of content that users may find interesting the aggregated information can also help advertisers and users determine the most compelling content within a particular stream. It is further desirable to enable the reproduction at a later date of the original multimedia stream together with the associated feedback data such a facility enables a user to experience the event as if it were occurring live.

In light of the foregoing it is a general object of the present invention to provide a useful and novel way of synchronizing real time interactivity with a live multimedia stream such that the users actions are mapped to specific time segments of the multimedia stream thus allowing for aggregation of response data. The aggregated experience data can then be forwarded in real time to the various users thereby enabling them to feel as though they are a part of the virtual crowd i.e. they can monitor how the audience as a whole is reacting in real time to the multimedia stream they are all interacting with .

It is another object of the present invention to use the aggregated data to self organize and monetize the associated multimedia content. By monitoring the various data being sent by the users the system can determine various properties of the multimedia content e.g. user engagement topics being discussed segments of particular interest etc. at very specific points in time and can use that data to put the multimedia content into topical categories determine the best time to display advertisements auto compile highlights etc.

It is still another object of the present invention to make available after the fact the total experience of the original live multimedia stream. This is accomplished by saving the original multimedia stream together with synchronized experience data sent by its users because all of the data is synchronized the original experience can be had again by simply re streaming the multimedia content and presenting the stored experience data as it was originally created i.e. at the correct point in time .

In accordance with one embodiment of the present invention multimedia content may be streamed together with associated timing information to various users who may provide feedback data in response to the multimedia content the feedback data may be related to the multimedia content using the associated timing information and then stored to some medium.

Aspects of the present invention are described below in the context of capturing and storing the experience of a live event and reproducing that experience at a later date. Throughout this description reference is made to multimedia data and experience data. Multimedia data may generally comprise any data related to the multimedia content being streamed the multimedia stream by a broadcaster multimedia data may be implemented through and represented by various protocols and codecs e.g. MPEG MPEG 1 Audio Layer 3 Flash QuickTime etc. and may be any combination of graphic images audio video etc. Experience data may generally comprise real time feedback data related to the streaming multimedia data as supplied by the various users interacting with the multimedia data such data may take various forms including but not limited to numerical data audio signals etc.

Broadcast client and user client may be any application capable of interfacing with server such as for example a web browser. Generally user client will be an end user computer which is capable of receiving among other things the streaming multimedia data and supporting tools e.g. widgets for interacting with it. Generally broadcast client may comprise for example a camera for capturing a live event and a computer for relaying that event over network to telemetry engine .

Telemetry engine integrates experience data received from for example experience widgets it is a scalable process that manages the reception aggregation redistribution and recording of real time experience data provided by for example experience widgets which may be embodied in or generally comprise software modules that run on both broadcast client and user client . Experience widgets allow both the broadcaster and the users to interact with the multimedia stream so as to simulate a wide variety of in person audience reactions such as for example applause boos jeers taunts excited screams etc. Experience widgets report in real time the experience data received by them back to telemetry engine where they are aggregated and then forwarded to all users as appropriate i.e. aggregated data from a particular experience widget would not be forwarded to a user client that was not running a particular experience widget .

The real time experience data produced by the users received by experience widgets and aggregated by telemetry engine are the various feedback data generated during a live broadcast and can be thought of as streams of data that exist parallel to the multimedia stream. Examples of real time experience data include chat streams i.e. textual information entered by users through either a broadcast client or a user client as the video is being streamed chat velocity e.g. the overall frequency of the chat messages entered during a given time domain or the frequency of a particular word or phrase at a given time or over a specified time domain etc. user information e.g. number of users average time users actually received a particular multimedia stream aggregate amount of time users watched or were engaged with a particular multimedia stream etc. polling data e.g. do those shoes go with those pants should we play a song off our first album etc. audience approval data as discussed in more detail below etc.

One experience widget that may have particular utility in certain implementations is a shout meter providing an indication of audience approval. A shout meter aims to simulate the roar of the crowd as it would usually occur if the users were actually there in the presence of whatever is being displayed through the multimedia stream. A user can shout in any number of ways and shouts can be aggregated with other user s shouts so as to provide the users and advertisers a sense of which multimedia stream segments the audience is most engaged. As a user shouts real time feedback data may be provided representative of both the user s shouting and the aggregate shouting of the other users. The more powerfully a user wants to shout the more input he needs to provide to the shout meter. Similar to applause other actions may be simulated as well such as for example booing heckling cheering etc.

In one embodiment a shout meter may simply be an interface consisting of a graph chart etc. and a button used for clapping and or booing etc. if a user wanted to shout loudly he would rapidly click the button and if he wanted to shout softly he might only press the button once or twice. In another embodiment the shout meter may utilize the user s microphone or other peripheral device in such a case the user may clap or boo cheer etc. as he normally would and experience widget would send the action to the telemetry engine either as a data structure s representative of the clap or as the clapping sound itself i.e. an audio signal just as the microphone receives it. In the foregoing manner when the aggregated experience data is returned to the various users in real time the now combined audio signals may either inform a graph chart meter etc. as to the overall applause or may simply be routed to the users speakers so that they may hear the actual crowd noise. Additionally the meter itself i.e. the mechanism by which users can observe a representation of their own shouts and or the aggregated shouts of everyone else may be implemented in a variety of ways including as a gravity meter which requires the user to constantly provide input in order to maintain weight in the aggregate.

The more accurately the experience data is synchronized with the multimedia content the more effective and usable the experience data will be. To that end telemetry engine and experience widgets can take into account various network operational characteristics e.g. speed latency etc. that uniquely influence or otherwise affect each user by time stamping the experience data with the time relative to the multimedia stream telemetry engine can then normalize the data thereby compensating for the network operational characteristics. In one embodiment the time stamping is realized by having experience widgets utilize key frame information as defined by either telemetry engine or streaming engine together with the experience data being sent from experience widgets to telemetry engine synchronization of experience data with such a key frame at clients and may allow telemetry engine to identify exactly where in the multimedia stream a user currently is so as to facilitate association of experience data with the portion of the multimedia stream the user intends.

In certain instances where a key frame synchronization approach is not feasible or economical telemetry engine may implement a server based timestamp solution which may provide reasonable accuracy but may require compensation strategies to account for deleterious network effects. For example if latency is not accounted for as in a server based timestamp approach then it may be the case that a user s experience data is off with respect to the multimedia stream for a period equal to or greater than the latency i.e. the experience data may not be synchronized with exactly what the user intended .

Using the experience data enabled and provided by experience widgets telemetry engine can dynamically categorize live multimedia streams. Consider the example of a broadcaster hosting a talk show. Without the ability to categorize the show in real time it may initially exist in only a single category e.g. talk show etc. . However by using the experience data telemetry engine can deduce e.g. from chat stream text parsing etc. that certain topics are being discussed and based on this topical information can assign the show to various other categories e.g. cars watches etc as appropriate. Further it may be the case that a multimedia stream belongs to certain categories only at certain points in the stream. For example the talk show host may discuss cars in the first half of the show but make no mention of them in the second half. In that case the show may be put in the car category only for the first half. The ability to dynamically assign categories to certain parts of a multimedia stream may enable future users to go directly to the content they are interested in and not have to sift through the entire multimedia stream to find it. In one embodiment telemetry engine may simply parse the parallel chat stream to realize the topics being covered. In another embodiment the broadcaster may make available an experience widget that contains tags describing or otherwise categorizing the stream the tags can be selected by users of the stream. In addition an option may exist for users to create their own tags and apply them to different points in the show. It may be the case that the tags themselves are the categories or they may simply inform the categorization decision.

To allow for the re experiencing of a live multimedia stream the data integrated by telemetry engine may be stored to experience archive which is the synchronized storage of recorded elements of the interactive experience and allows for the reproduction at a time after the live event of the live experience in the same interactive form as was present during the original live stream. In addition to the reproduction of the experience a user attending the event as it is being replayed may also participate in those experience widgets that were available during the live stream similar to video editing software the user can dub additional data back into the original experience.

The additional data provided by a user as he is experiencing an event after it has already been streamed live can be associated with the event in experience archive in various ways. In one implementation the additional data may be added to the information corresponding to the event and previously stored to experience archive so that a user who experiences the event going forward sees the original data and the additional data either inline with the original data or distinguished from it . In another implementation the additional data may be sectioned off from the information originally stored to experience archive and seen only if requested by a future user e.g. the user may request to see the additional data that was added in the last 10 days etc. .

In light of the all encompassing way in which events are stored in experience archive broadcasters those people or companies that stream events can exploit the rich analytics associated with their event as provided by telemetry engine . For example a comic may use experience archive to experience as a member of the audience a set he performed he may pay close attention to the experience data provided by the audience e.g. boos laughter applause comments etc. to fine tune future performances. As another example advertisers may wish to examine a recorded event to determine which multimedia streams and where in those streams advertisements may be most effective.

The system may also contain a discovery engine which users can use to find content that may interest them. Discovery engine identifies in real time those shows that are deemed interesting and compelling based on audience reactions as relayed through the experience data aggregated by telemetry engine . Discovery engine can identify patterns and deviations from those patterns within the experience data and deduce from those findings certain useful information about the multimedia streams. For example discovery engine may provide a search mechanism that allows users to search for particular content e.g. accessed by most users most highly rated topic etc. . As another example discovery engine may be used to generate program guides through which various programs may be displayed and sorted according to various criteria. As yet another example discovery engine may generate syndication feeds using for example any of a number of Extensible Markup Language XML based formats e.g. Rich Site Summary RSS Atom etc. etc. These feeds may be routinely updated as discovery engine has new data to work with and these updates will be syndicated to users subscribed to the various feeds. Similarly discovery engine may provide alerts updates to users signaling that new multimedia content is available that they may be interested in the alerts updates can be sent through e mail instant message etc.

Finally a streaming engine may be utilized to enable a one to many broadcast of the multimedia stream. Streaming engine may use any number of technologies to deliver the multimedia content to user clients such as for example Content Delivery Networks CDNs Peer to Peer P2P systems etc. The present disclosure is not intended to be limited to any particular streaming technology or communication protocol implemented by streaming engine .

At block the multimedia content is streamed together with associated timing information. As discussed above the multimedia content may be streamed in any number of ways including P2P CDN etc. and may or may not require a dedicated streaming engine and or server s depending on the number of users the quality of the video or a combination of these and other factors.

The associated timing information may be any information that is used to help synchronize the experience data with the multimedia stream including but not limited to the key frame solution described above. Such associated timing information may facilitate the mapping of experience data to points in the multimedia stream.

The multimedia stream and associated timing information are received by the experience widgets running on the user clients. The experience widgets are aware of and understand the timing information and use it to synchronize with the multimedia stream the experience data generated each time a user takes some action on a widget. For example if the multimedia stream is presented along with a shout meter widget used to measure shouts then each time the user shouts that action is recorded together with the timing information so as to note that the shout took place at a certain point in the multimedia stream.

The experience data is received e.g. by the telemetry engine as indicated at block . The experience data includes not only the actions taken by the user and through what experience widget but also information specifying the point in the multimedia stream that those actions took place.

The telemetry engine may be receiving experience data from a plurality of users as the multimedia stream plays and may be aggregating in real time this data as indicated at block . At block the telemetry engine may use the experience data and its included associated timing information to determine what multimedia stream the experience data belongs to which experience widget provided the data and at what point within the stream the data corresponds. As the experience data is culled the telemetry engine can develop metrics that describe the activity of the used widgets on an audience wide scale this information can then be forwarded to all of the users and displayed by the respective experience widgets so as to give the users an idea of the overall real time crowd reaction participation excitement emotion etc.

Finally as indicated at block all or a selected portion of the experience data aggregated and parsed by the telemetry engine may be stored in some manner such as for example to an experience archive. Because the multimedia stream can be stored along with the synchronized experience data it may be reproduced in the future in exactly the same form as it was originally presented. As explained above this may enable a future user to look in on the experience or interact with it as if it were happening live i.e. the same experience widgets will be available to the user as were available to those who experienced it live .

The sequence and numbering of blocks depicted in is not intended to imply an order of operations to the exclusion of other possibilities. It will be appreciated by those of skill in the art that the foregoing systems and methods are susceptible of various modifications and alterations. For example it may not be the case that the storing of an experience to an experience archive happens only after the multimedia stream is complete the experience data may be stored to the experience archive in real time at block as the telemetry engine sifts through it.

Several features and aspects of the present invention have been illustrated and described in detail with reference to particular embodiments by way of example only and not by way of limitation. Those of skill in the art will appreciate that alternative implementations and various modifications to the disclosed embodiments are within the scope and contemplation of the present disclosure.

