---

title: System, method, and computer program product for generating a single software code based on a description of a distributed architecture
abstract: The present invention relates to a system, method, and computer program product for generating a single software code based on a description of a distributed architecture. The present invention introduces a BICA-SMART development framework that implements a distributed architecture in a flexible, parallel and scalable implementation that is embodied by a single software code. Thus, using the present invention, a user can input a description of the architecture into the system, with the system automatically generating the software code to implement the architectural description.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09600767&OS=09600767&RS=09600767
owner: HRL Laboratories, LLC
number: 09600767
owner_city: Malibu
owner_country: US
publication_date: 20081230
---
The present application is a Continuation in Part patent application of U.S. application Ser. No. 11 801 377 filed on May 9 2007 entitled Cognitive Architecture for Learning Action and Perception. The present application is also a Continuation in Part patent application of U.S. patent application Ser. No. 11 973 161 filed Oct. 4 2007 entitled Visual Attention and Object Recognition System which is a non provisional patent application claiming the benefit of priority of U.S. Provisional Application No. 60 849 975 filed on Oct. 6 2006 entitled A Bio Inspired Vision System for Object Recognition and of U.S. Provisional Application No. 60 903 241 filed on Feb. 23 2007 entitled A Bio Inspired Vision System for Object Recognition. 

The present invention relates to an artificial intelligence system and more particularly to a computational systems modeling and architecture development framework that implements an artificial intelligence system for generating a single software code based on a description of a distributed architecture.

Artificial Intelligence AI is a branch of computer science that deals with intelligent behavior learning and adaptation in machines. Research in AI is traditionally concerned with producing machines to automate tasks requiring intelligent behavior. While many researchers have attempted to create AI systems there is very limited prior work on comprehensive cognitive architectures.

For example there is no comprehensive brain like architecture that links physiology with anatomy and the derived functionalities. However numerous neuroscience inspired modal architectures have been proposed such as those cited as literature reference numbers 1 2 3 4 5 6 7 8 9 10 and 11 See the List of Cited References below . Functional characterizations of these architectures typically use aspects from very different levels of biologically inspired descriptions. For example connectionists often base their architectural proposal on some abstract properties assumed to be involved in the information processing of the brain. Others are more biological in terms of their underlying modeling however they do not explain the wide body of experimental data.

A description of psychology based architectures is provided since these represent the state of the art in cognitive architectures. While several cognitive architectures have been proposed and implemented two popular and commonly used architectures are ACT R see literature reference no. 12 and Soar see literature reference no. 13 . ACT R is a parallel matching serial firing production system with a psychologically motivated conflict resolution strategy. Soar is a parallel matching parallel firing rule based system where the rules represent both procedural and declarative knowledge. However several limitations of these traditional cognitive architectures exist see literature reference no. 18 .

Implementing such a complex system of neural like components is a major challenge and as such there is very little existing work to draw on. Hecht Nielsen and Lansner see literature reference nos. 14 and 15 have built large systems though not as all encompassing in size and complexity as the present invention. Additionally Spoms see literature reference no. 16 work on motifs in brain networks is a mathematical optimization technique to obtain network topologies that resemble brain networks across a spectrum of structural measures. Further Andersen see literature reference no. 17 has suggested building brain like computers via software development using models at a level between low level network of attractor networks and associatively linked networks. However it is not clear how the above are neuromorphic architectures or that they support the large body of neuroscience data.

The computer program language that is a part of the present invention shares some features with the so called skeleton parallelism programming languages such as P3L and Ocam1P3L see literature reference nos. 23 24 and 25 . However such languages are general purpose programming languages that are not in any way optimized for the programming of the brain like systems and they are not a part of a comprehensive suite of tools and technologies embodied in the present invention.

Research in neuroscience and cognitive psychology over the last several decades has made remarkable progress in unraveling the mysteries of the human mind. However the prior art is still quite far from building and integrating computational models of the entire gamut of human like cognitive capabilities. As discussed above very limited prior art exists in building an integrated and comprehensive architecture.

A challenge present in the art is to develop a cognitive architecture that is comprehensive and covers the full range of human cognition. Current approaches are not able to provide such a comprehensive architecture. Architectures developed to date typically solve single and multiple modal problems that are highly specialized in function and design. In addition there are often very different underlying theories and architectures for the same cognitive modal problem. This presents a significant challenge in seamlessly integrating these disparate theories into a comprehensive architecture such that all cognitive functionalities can be addressed. Computational design and implementation of these architectures is another major challenge. These architectures must be amenable to implementation as stand alone or hybrid neuro AI architectures via software hardware and evaluation in follow on phases.

Thus a continuing need exists for a computational systems modeling and architecture development framework for rapid prototyping and implementing of biologically inspired computing modules in a flexible extensible adaptable scalable and modular manner.

The present invention relates to a computational systems modeling and architecture development framework that implements an artificial intelligence system for learning action and perception. More specifically the present invention is related to a method system and computer program product for generating a single software code based on a description of a distributed architecture. The method includes an act of receiving a description of an architecture having a set of functional modules with data flows specified between the functional modules the data flows having data flow specifications . One or more processors are used to generate a BrainML file describing the architecture and generate code for each functional module. The term BrainML file refers to a computer readable data file containing one or more BrainML descriptions and possibly containing other related content. The code includes initialization code and module wrapper code. The initialization code is code selected from a group consisting of code for starting the functional module code for communicating with other functional modules and code for controlling the functional module. The module wrapper code is then subsequently filled with implementation code. A build specification is generated that is needed by build tools to compile and link all functional modules into a single software code. A communication style is described for data flow between the functional modules of the architecture. Communication code is also generated to support the communication style. The module wrapper code is filled with the implementation code to create a filled wrapper code. Finally the single software code is generated using the filled wrapper code the communication code initialization code and build specification.

In another aspect the description is converted into a graphical layout of the architecture. The graphical layout uses Brain Markup Language BrainML to specify information about the functional modules and the data flows between the functional modules.

In yet another aspect code is generated for collecting and visualizing statistics as the single software code is running to facilitate debugging and performance evaluations.

In another aspect in receiving a description of an architecture having a set of functional modules with data flows specified between the functional modules the function modules include a primary input and auxiliary input channels and primary output and auxiliary output channels. Arrival of new data on a primary input channel causes the functional module to initiate a compute function and perform a round of computation on the new data. Alternatively arrival of new data on an auxiliary channel is saved and utilized later when a new round of computation is triggered by an input arriving on a primary input channel.

In yet another aspect a parser and syntax checker is implemented for grammar. Further consistency criteria is formulated for determining if all the data flows for each of the functional modules are satisfied. A checker is implemented for the consistency criteria. A compiler module is implemented that takes the data flow specifications for a specific functional module and creates a stub header for an appropriate compute function.

Finally as noted above the present invention also comprises a computer program product and system. The computer program product comprises computer readable instruction means stored on a computer readable medium. The instruction means are executable by a computer having a processor for causing the processor to perform the described operations. In another aspect the instruction means can be executable by a cluster or a network of multiple computers i.e. multiple processors . The system comprises one or more processors that are configured to perform the operations described herein.

The present invention relates to an artificial intelligence system and more particularly to a computational systems modeling and architecture development framework which implements an artificial intelligence system for generating a single software code based on a description of a distributed architecture.

The following description is presented to enable one of ordinary skill in the art to make and use the invention and to incorporate it in the context of particular applications. Various modifications as well as a variety of uses in different applications will be readily apparent to those skilled in the art and the general principles defined herein may be applied to a wide range of embodiments. Thus the present invention is not intended to be limited to the embodiments presented but is to be accorded the widest scope consistent with the principles and novel features disclosed herein.

In the following detailed description numerous specific details are set forth in order to provide a more thorough understanding of the present invention. However it will be apparent to one skilled in the art that the present invention may be practiced without necessarily being limited to these specific details. In other instances well known structures and devices are shown in block diagram form rather than in detail in order to avoid obscuring the present invention.

The reader s attention is directed to all papers and documents which are filed concurrently with this specification and which are open to public inspection with this specification and the contents of all such papers and documents are incorporated herein by reference. All the features disclosed in this specification including any accompanying claims abstract and drawings may be replaced by alternative features serving the same equivalent or similar purpose unless expressly stated otherwise. Thus unless expressly stated otherwise each feature disclosed is one example only of a generic series of equivalent or similar features.

Furthermore any element in a claim that does not explicitly state means for performing a specified function or step for performing a specific function is not to be interpreted as a means or step clause as specified in 35 U.S.C. Section 112 Paragraph 6. In particular the use of step of or act of in the claims herein is not intended to invoke the provisions of 35 U.S.C. 112 Paragraph 6.

Before describing the invention in detail first a list of cited references is provided. Next a glossary of terms and table of abbreviations that are used in the description and claims is presented. Following the glossary a description of various principal aspects of the present invention is provided. Subsequently an introduction provides the reader with a general understanding of the present invention. Next details of the present invention are provided to give an understanding of the specific aspects. Finally a summary is provided as a synopsis of the present invention.

The following references are cited throughout this application. For clarity and convenience the references are listed herein as a central resource for the reader. The following references are hereby incorporated by reference as though fully included herein. The references are cited in the application by referring to the corresponding literature reference number.

Before describing the specific details of the present invention a glossary is provided in which various terms used herein and in the claims are defined. The glossary provided is intended to provide the reader with a general understanding of the intended meaning of the terms but is not intended to convey the entire scope of each term. Rather the glossary is intended to supplement the rest of the specification in more accurately explaining the terms used.

Adaptive Resonance Theory The term Adaptive Resonance Theory ART is used for stable construction of declarative and procedural memory within the sensory and cognitive processes based on winner take all and distributed computational mechanisms. Stable learning implies that the system can retain not forget large amounts of knowledge.

Adaptive Timing Circuits The adaptive timing circuits refers to the interactions between the sensory and cognitive processes with spatial and motor processes via adaptive timing circuits to enable stable construction of action plans that lead to cognitive behaviors. The adaptively timed circuits can function at both micro and macro time scales thereby providing the ability to enact a wide range of plans and actions for a continuously changing environment.

BLB The term BLB refers to a Biologically Inspired Cognitive Architecture BICA for integrated LEarning Action and Perception LEAP Brain B . The BLB is a single software code that is generated as the output of the present invention based on a description of a distributed architecture.

Brain Markup Language BrainML The term BrainML refers to a specially designed programming language for describing the high level structure of the BLB. BrainML is a declarative language for formulating the high level structure of the BLB by describing the high level functional modules and connections between them.

BrainML file The term BrainML file refers to a computer readable data file containing one or more BrainML descriptions and possibly containing other related content.

Complementary Computing The term complementary computing refers to complementary pairs of parallel processing streams wherein each stream s properties are related to those of a complementary stream e.g. the What and Where streams . Complementary computing is needed to compute complete information to solve a given modal problem e.g. vision audition sensory motor control . Hierarchical and parallel interactions between the streams can resolve complementary deficiencies.

Instruction Means The term instruction means as used with respect to this invention generally indicates a set of operations to be performed on a computer and may represent pieces of a whole program or individual separable software modules. Non limiting examples of instruction means include computer program code source or object code and hard coded electronics i.e. computer operations coded into a computer chip . The instruction means may be stored in the memory of a computer or on a computer readable medium such as a floppy disk a CD ROM and a flash drive.

Laminar Computing The term laminar computing refers to a unified laminar format for the neural circuits that is prevalent in the various regions of the cerebral cortex. It is organized into layered circuits usually six main layers that undergo characteristic bottom up top down and horizontal interactions. Its ubiquity means that the basic function of the cortex is independent of the nature of the data that it is processing. Specializations of interactions in different modalities realize different combinations of properties which points to the possibility of developing Very Large Scale Integration VLSI systems.

Linking Affordances and Actions The term linking affordances and actions refers to extracting general brain operating principles BOPs from studies of visual control of eye movements and hand movements and the linkage of imitation and language. It also refers to the integration of parietal affordances perceptual representation of possibilities for action and frontal motor schemas coordinated control programs for action and subsequent interactions.

Spatio Temporal Pattern Learning The term spatio temporal pattern learning refers to working memory models such as STORE and TOTEM for stable construction of temporal chunks or events that will be used to construct plans and episodic memory. STORE refers to a Sustained Temporal Order Recurrent network as described in literature reference no. 28 TOTEM refers to a Topological and Temporal Correlator network as described in literature reference no. 29 Temporal chunking allows multimodal information fusion capability. This is used for storage of event information and construction of stable action plans.

Topographic Organization The term topographic organization refers to organizations that are observed in both the sensory e.g. retina cochlea and motor cortex where world events that are neighbors in some sense are also represented in neighboring patches of the cortex. The topographic organization has strong implications for the details of connectivity within given brain areas in particular as it emphasizes local connectivity over long range connectivity

The present invention uses several analogies to anatomical structures and pathways many of which are abbreviated for brevity. The abbreviations and their corresponding definitions of the anatomical structures pathways are as follows THAL Thalamus SC Somatosensory Cortex AC Auditory Cortex VC Visual Cortex NC Neocortex MC Motor Cortex TC Temporal Cortex PC Parietal Cortex PFC Prefrontal Cortex HS Hippocampal System HT Hypothalamus CC Cingulate Cortex PLC Prelimbic Cortex AM Amygdala BG Basal Ganglia CBL Cerebellum and SCL Superior Colliculus.

The present invention has three principal aspects. The first is a learning system. The learning system is typically in the form of a computer system operating software or in the form of a hard coded instruction set. This system may be incorporated into a wide variety of devices that provide different functionalities. The second principal aspect is a method typically in the form of software operated using a data processing system computer . The third principal aspect is a computer program product. The computer program product generally represents computer readable instructions stored on a computer readable medium such as an optical storage device e.g. a compact disc CD or digital versatile disc DVD or a magnetic storage device such as a floppy disk or magnetic tape. Other non limiting examples of computer readable media include hard disks read only memory ROM and flash type memories. These aspects will be described in more detail below.

A block diagram depicting basic components of the learning system of the present invention is provided in . The learning system comprises an input for receiving information from at least one sensor for use in detecting an object and or event. Note that the input may include multiple ports. Typically input is received from at least one sensor non limiting examples of which include video image sensors. An output is connected with the processor for providing action information or other information regarding the presence and or identity of object s in the scene to other systems in order that a network of computer systems may serve as a learning system. Output may also be provided to other devices or other programs e.g. to other software modules for use therein. The input and the output are both coupled with a processor which may be a general purpose computer processor or a specialized processor designed specifically for use with the present invention. The processor can also be formed as clusters and or networks of multiple computers and multi core and multi CPU computers. The processor is coupled with a memory to permit storage of data and software that are to be manipulated by commands to the processor .

An illustrative diagram of a computer program product embodying the present invention is depicted in . The computer program product is depicted as an optical disk such as a CD or DVD. However as mentioned previously the computer program product generally represents computer readable instructions stored on any compatible computer readable medium.

The present invention addresses the implementation and integration of computational models of human cognition based on neuroscience inspired systems. A previous patent application to which this application is a Continuation in Part application described a Biologically Inspired Cognitive Architecture for integrated LEarning Action and Perception BICA LEAP . BICA LEAP is a neuroscience inspired learning system that seamlessly integrates perception memory planning decision making action self learning and affect to address the full range of human cognition. The present invention introduces a BICA Systems Modeling and ARchiTecture development framework or BICA SMART . BICA SMART is a modeling and architecture development system that implements BICA LEAP in a flexible parallel and scalable implementation. The output of BICA SMART is an implementation e.g. software of BICA LEAP that will be henceforth referred to as the BICA LEAP Brain BLB .

The present invention implements the BICA LEAP in a flexible adaptive and scalable way. In addition it facilitates testing development and validation of BICA LEAP as well as allows transfer of parts subsystems of the architecture to other applications as stand alone components such as scene understanding navigation etc. Although the BICA LEAP is particularly suitable for the present invention it should be noted that the present invention is not limited to implementing BICA LEAP and can be applied to any distributed architecture to generate the BLB or a single software code implementing the distributed architecture.

As noted above the present invention is a BICA SMART. BICA SMART is a modeling and architecture development system that implements BICA LEAP in a flexible parallel and scalable implementation. For clarity BICA LEAP will be described first to provide the foundational support for the present invention. Thereafter BICA SMART is described.

 5.1 Biologically Inspired Cognitive Architecture for Integrated Learning Action and Perception BICA LEAP .

BICA LEAP is a neuroscience inspired comprehensive architecture that seamlessly integrates perception memory planning decision making action self learning and affect to address the full range of human cognition. BICA LEAP was originally disclosed in U.S. application Ser. No. 11 801 377 which is incorporated by reference as though fully set forth herein. BICA LEAP is based on the concept of brain operating principles and computational paradigms to realize structural functional and temporal modularity and also integrate the various neural processes into a unified system that can exhibit a wide range of cognitive behaviors. A single comprehensive architecture that covers the full range of human cognition provides a basis for developing cognitive systems that can not only successfully function in a wide range of environments but also thrive in new environments. BICA LEAP and its adaptive self organizing hierarchical architecture and integration methodology can lead to practical computational models that scale with problem size. Additionally BICA LEAP includes a framework to implement computational models of human cognition that could eventually be used to simulate human behavior and approach human cognitive performance in a wide range of situations. The BICA LEAP can be integrated into a variety of applications and existing systems providing support or replacement for human reasoning and decision making leading to revolutionary use in a variety of applications. Non limiting examples of such applications include exploration systems intelligence gathering analysis autonomous systems cognitive robots smart sensors etc.

As briefly described above an improvement over the prior art is that BICA LEAP provides a single comprehensive architecture based on core Brain Operating Principles BOPs and Computational Paradigms CPs that realize structural functional and temporal modularity. BICA LEAP also integrates the various neural processes into a unified system that can exhibit wide range of cognitive behaviors to solve modal problems. The architecture is fully distributed in its structure and functional capabilities and lends itself to practical computational architectures. It is an inherently nonlinear and parallel architecture that offers a powerful alternative to the probabilistic and linear models of traditional AI based systems.

The comprehensive architecture of the present invention addresses all of the issues described above in the background section. It also provides a representation of complex information in forms that make it easier to perform inference and organized self learning that makes it applicable to various domains without extensive programming or reprogramming. It can therefore be the basis of future efforts to simulate and develop truly cognitive systems as well as interface to conventional AI systems for application in diverse domains e.g. augmenting human performance across a range of intelligence domains .

Such a single comprehensive architecture that covers the full range of human cognition provides a basis for developing cognitive systems that not only successfully function in a wide range of environments but also thrive in new environments.

This architecture is fully distributed in its structure and functional capabilities. One of its key BOPs is complementary processing which postulates several complementary and hierarchically interacting processing streams and sub regions that cooperate and compete in parallel. This interaction helps overcome informational uncertainty in order to solve problems in perception and learning. One key CP of the architecture is laminar computing which postulates a uniform layered format structure for neural circuitry in various brain regions. This CP offers a unique and explicit formulation of the brain s approach to reusable computing with sharing of neural resources for perception and action. Yet another key theme of the present invention is that the brain has evolved to carry out autonomous adaptation in real time to a rapidly changing and complex world. Use of Adaptive Resonance Theory ART as an underlying mechanism in the architecture of the present invention explains this autonomous adaptation. This architecture also integrates learning mechanisms adaptively timed neural circuits and reinforcement learning based neural circuits that model emotional and motivational drives to explain various cognitive processes including reasoning planning and action. The above key BOPs and CPs enable the present invention to control a flexible repertoire of cognitive behaviors that are most relevant to the task at hand. These characteristics are realized using an inherently nonlinear and parallel architecture and offers a powerful alternative to the probabilistic and linear models of traditional Artificial Intelligence AI based systems.

The architecture of BICA LEAP is described as modules or systems that correspond to various cognitive and motor features. As shown in the BICA LEAP system includes three basic modules a sensory and perception module a cognitive module and an execution module . The large dashed arrows indicate a distributed set of links between any two structural entities to perform match learning based on ART like circuits described below while the small dotted arrows indicate a distributed set of links between any two structural entities to perform mismatch learning described below .

The modules are described by providing an account of functional roles at various stages as data is processed from the bottom to the top of the cortex. At the lowest level of the architecture is the sensory and perception module . The sensory and perception module includes a set of peripheral sense organs including vision auditory and somatosensory sensors to sense the state of the external world. In other words the sensory and perception module is configured to receive and process external sensory input s from an external world and extract sensory specific features from the external sensory input. The cognitive module is configured to receive the sensory specific features and identify a current context based on the sensory specific features. Based on the current context and features the cognitive module learns constructs or recalls a set of action plans. The cognitive module then evaluates the set of action plans against any previously known action plans in a related context. Based on the evaluation the cognitive module selects the most appropriate action plan given the current context. Finally the execution module is configured to carry out the action plan. The execution module includes motor organs to perform actions based on the perception of the world including occulomotor eyes to saccade and fixate on targets articulomotor mouth to produce speech and limbs to move reach for objects in space grasp objects etc. . For clarity each of the basic modules and their corresponding sub modules will be described in turn.

The sensory and perception module generates and processes external sensory inputs from an external world and extracts sensory specific features from the external sensory inputs.

The next step in processing is to abstract relevant information from the filtered and normalized input data. This abstraction process is initiated in a neocortex module NC and propagates throughout cognitive module. The neocortex module extracts sensory specific features from the external sensory inputs after they have been filtered and or normalized by the thalamus module . The neocortex module includes a somatic cortex SC module an auditory cortex AC module and a visual cortex VC module . The SC module extracts somatic features from the scene such as touch and odor. Additionally the AC module extracts auditory features while the VC module extracts visual features.

The neocortex module is a modular structure that has the ability to integrate information from a remarkably diverse range of sources bottom up signals stemming from the peripheral sense organs top down feedback carrying goal related information from higher cortical areas as explained later and intrinsic horizontal signals carrying contextual information from neighboring regions within the same cortical area. These three distinct types of signals not only coexist within a single cortical area but also interact and mutually shape each other s processing.

The present invention addresses these interactions based on laminar computing. Laminar computing concerns the fact that the cerebral cortex the seat of all higher biological intelligence in all modalities is organized into layered cortical circuits usually six main layers with characteristic bottom up top down and horizontal interactions. Specializations of these interactions in the different cortical areas realize different combinations of properties. Thus the layered cortical circuit that processes information in the sensory cortex of a human when his her hand is touched is the same circuit that processes information in the frontal cortex of a human when it thinks about a calculus problem. This incredible ubiquity means that the basic function of cortex is independent of the nature of the data that it is processing. The existence of such a unified laminar format for many different tasks also points to the possibility of developing very large scale integration VLSI systems for intelligent understanding and control.

In the present invention the notion of perception for different modalities is realized by integrating lower level features into a coherent percept within the neocortext module . This integration process is incorporated using the idea of complementary processing streams. In the present architecture several processing stages combine to form a processing stream much like that in the brain. These stages accumulate evidence that realize a process of hierarchical resolution of informational uncertainty. Overcoming informational uncertainty utilizes both hierarchical interactions within the stream and the parallel interactions between streams that overcome their complementary deficiencies. For example visual perception of form in the present architecture occurs via an ensemble of processing stages that interact within and between complementary processing streams. Boundary and surface formation illustrate two key principles of this capability. The processing of form by the boundary stream uses orientationally tuned cells to generate emergent object representations as supported by several psychophysical and neurophysiological experiments. Precise orientationally tuned comparisons of left eye and right eye inputs are used to compute sharp estimates of the relative depth of an object from its observer and thereby to form three dimensional boundary and surface representations of objects separated from their backgrounds. Similarly there exist such complementary properties in the form motion interactions of the architecture for visual perception of moving objects. The orientationally tuned form system that generates emergent representations of forms with precise depth estimates is complementary to the directionally tuned motion system that can generate only coarse depth estimates on its own.

As described above the cognitive module receives the sensory specific features identifies a current context and ultimately selects the most appropriate action plan given the current context. The cognitive module utilizes several sub modules to select the most appropriate action plan.

In the present invention the complementary form and motion processing is part of a larger design for complementary processing whereby objects in the world are cognitively recognized spatially localized and acted upon. As shown in the object and event learning system learns to categorize and recognize what objects are in the world i.e. declarative memory or memory with record . In other words the object and event learning system is configured to use the sensory specific features to classify the features as objects and events. The object and event learning system operates as a classification system.

Another module the novelty detection search and navigation module described below determines if the sensory specific features match previously known events and objects by comparing the sensory specific features against features corresponding to known objects and events. If there is no match then the object and event learning system stores the features as new objects and events. Alternatively if there is a match then the object and event learning system stores the features as updated features corresponding to known objects and events. The object and event learning system is analogous to the inferotemporal cortex TC and its cortical projections in a human s brain. As can be appreciated by one skilled in the art the TC is the object and event learning system and the TC is referred to herein interchangeably with the said system .

The object and event learning system is to be contrasted with the spatial representation module which learns to determine where the objects are and how to deal with them by locating them in space i.e. procedural memory or memory without record tracking them through time i.e. when and directing actions toward them. The spatial representation module is configured to establish space and time attributes for the objects and events. The spatial representation module uses any suitable device or technique for establishing space and time attributes given objects and or events a non limiting example of such a technique includes using the technique as described by G. A. Carpenter S. Grossberg and G. W. Lesher in The What and Where Filter vol. 69 no. 1 pp. 1 22 1998.

The spatial representation module transmits the space and time attributes to the novelty detection search and navigation module . The novelty detection search and navigation module is also configured to use the space and time attributes to construct a spatial map of the external world. The novelty detection search and navigation module constructs a spatial map using any suitable technique for converting space and time attributes into a spatial map non limiting examples of which include the techniques described by S. Grossberg and J. W. L. Merrill G. A. Carpenter and S. Grossberg G. A. Carpenter and S. Grossberg and G. A. Carpenter and S. Grossberg in literature reference nos. 30 31 32 and 33 respectively.

The detection search and navigation module is analogous to the Hippocampal System HS and as can be appreciated by one skilled in the art the HS is referred to herein interchangeably with the said module . Additionally the spatial representation module is analogous to the parietal cortex PC and its cortical projections in a human s brain and as can be appreciated by one skilled in the art the PC is referred to herein interchangeably with the module .

The cortical projections mentioned above are realized using ART circuits within the architecture of the present invention dashed lines between modules in see literature reference nos. 32 37. These circuits are supported by neurophysiological data. Additionally variants of ART have been used in several technological applications. ART circuits facilitate complementary interactions between the attentional subsystem in the TC and the spatial representation module or the detection search and navigation module . The ART circuits enable the present invention to discover and stably learn new representations for novel objects in an efficient way without assuming that representations already exist for as yet unseen objects.

In the present invention auditory and speech percepts are emergent properties that arise from the resonant states of the ART circuits. For example the present invention can use ARTSTREAM see literature reference no. 38 to separate distinct voices such as those in a cocktail party environment into distinct auditory streams. Resonant dynamics between a spectral stream level at which frequencies of the sound spectrum are represented across a spatial map and the pitch stream level that comprise a given pitch helps separate each auditory stream into a unique spatial map. Similarly resonant waves between bottom up working memory that represents the individual speech items and a top down list categorization network that groups the individual speech items into learned language units or chunks is modeled in ARTPHONE described in literature reference no. 39 to realize phonemic restoration properties.

In addition to what and where streams there is a how processing stream that operates in parallel and provides the capability to take actions based on the sensed world. First as shown in the signals from the muscles that control the motors are filtered in the thalamus module . In order to effectively realize its actions such as visually guided reaching of targets or grasping the system uses the how stream to map the spatial representation of targets in the PC into a head centered representation and eventually a body centered representation. This representation is invariant under rotations of the head and eyes e.g. sensors such as a camera . Intrastream complementarity occurs during this process wherein vergence of the two eyes cameras as they fixate on the object is used to estimate the object s radial distance while the spherical angles that the eyes make relative to the observer s head estimate the object s angular position. The head centered representation of targets is used to form a spatial trajectory from the current position to the target position.

The inverse kinematics problem is solved when the spatial trajectory is transformed into a set of joint angle commands via information available during action perception cycles. The inverse dynamics problem is solved by the invariant production of commanded joint angle time courses despite large changes in muscle tension.

Similarly neural circuits exist in the architecture to model other modalities such as the act of speaking that utilizes perceptual information from the auditory cortex during action perception cycles. These neural circuits with a unified format learn all these sensory motor control tasks based on interactions between the PC the motor cortex MC module described below the external valuation module described below and the cerebellum CBL module described below . For these basic sensory motor control tasks the architecture of the present invention does not need to know what that target is. It relates to the target object as a set of possible affordances or opportunities for reaching and grasping it.

In higher cortical areas as the signals move higher up in complexity space time differences in neuronal firing induced by the input patterns become important. These higher areas model the relationships between high level representations of categories in various modalities using temporal information such as temporal order of objects words smells in the TC . The present architecture achieves this temporal learning capability using a combination of ART category learning working memories associative learning networks and predictive feedback mechanisms to learn event categories.

As shown in the prefrontal cortex PFC serves as a working memory where information converges from multiple sensory modalities which interacts with subcortical reward mechanisms as in the amygdala AM module and hypothalamus HT module of the internal valuation module described below to sustain an attentional focus upon salient event categories. The PFC is analogous to the behavior planner module and as can be appreciated by one skilled in the art the PFC is referred to herein interchangeably with the said module . Essentially the behavior planner module is configured to receive information about the objects and events the space and time attributes for the objects and events and the spatial map. The behavior planner module uses those inputs to learn construct or recall a set of action plans. Additionally the behavior planner module uses the status of the internal state provided by the internal valuation module to sub select the most appropriate action from the set of action plans.

Multimodal information distributed across the PFC is integrated using ART see literature reference no. 40 that is designed to selectively reset input channels with predictive errors and also selectively pay attention ignore to event categories that have high low salience due to prior reinforcement. The interactions between the TC and the PFC are a type of macro timing process that integrates information across a series of events. The architecture of the present invention models the TC HS interactions as a type of micro timing process using an adaptive timing model that controls how cognitive emotional and sensory motor interactions are coordinated based on the interactions of the sensory representations in TC the drive representations in the internal valuation module and the motor representations in the external valuation module and the cerebellum CBL module . The motor representations also contribute to the modulation of declarative memory by motivational feedback and to the learning and performance of procedural memory.

The present invention is also capable of exhibiting complex task driven visual behaviors for the understanding of scenes in the real world. Given a task definition the architecture of the present invention first determines and stores the task relevant salient entities in working memory using prior knowledge stored in the long term memory of ART circuits. For a given scene the model then attempts to detect the most relevant entity by biasing its visual attention with the entity s learned low level features. It then attends to the most salient location in the scene and attempts to recognize the object in the TC using ART circuits that resonate with the features found in the salient location. The system updates its working memory with the task relevance of the recognized entity and updates a topographic task relevance map in the PC with the location of the recognized entity. The stored objects and task relevance maps are subsequently used by the PFC to construct predictions or plans for the future.

For more complex sensory motor coordination tasks such as speaking and language understanding the present invention capitalizes on the unified format of the above mentioned neural circuitry. The present invention integrates the PC and the coordinated control plans for action or frontal motor schemas including the PC s interaction with recognition TC planning PFC and behavioral control systems external valuation module . This architecture is grounded in the use of mechanisms of vocal facial and manual expressions that are rooted in the human s praxic interactions with the environment. The present invention incorporates spatial cues to aid audition speech comprehension temporal chunking phonemic restoration and speech production models see literature reference nos. 41 and 42 .

Because humans are physiological beings humans have basic motivations that demand satisfaction e.g. eating drinking sleeping etc. . Each behavior can either satisfy or not satisfy one of these motivations. The present invention includes an internal valuation module to mimic basic human motivations. The internal valuation module is configured to evaluate the value of the sensory specific features and the context. For example the internal valuation module values the sensory specific features and context such that they are modeled mathematically to have a value in a range between zero and one where zero is the least valuable and one is the most valuable.

The internal valuation module is also configured to generate a status of internal states of the system and given the context associate the sensory specific features to the internal states as either improving or degrading the internal state. As a non limiting example the system is incorporated into a mobile robot. The robot determines that it is currently raining and that it is wet. Based on its knowledge of electrical systems the robot determines that it would be best to seek cover to avoid the rain. Since the robot is currently traveling in a direction away from cover the robot determines that to continue in its current trajectory will increase its wetness or time being wet and thereby degrade its internal state increasing its wetness which is contrary to its desire to be dry .

In other words when an ongoing behavior perceptual state enters the prelimbic cortex PLC as an input a correlated emotional response is generated. The PLC is analogous in function to the internal valuation module and as can be appreciated by one skilled in the art the PLC is referred to herein interchangeably with the said module .

The internal valuation module includes two sub modules the AM module and the HT module . The AM module is a reward punishment center that generates a reward or punishment for certain actions. The rewards or punishments are defined as valuations of the internal state of the system and whether or not certain actions degrade or improve the internal state. The HT module learns to correlate these behavior patterns with feedback signals to the behavior planner module and the novelty detection search and navigation module that map the sensory representations using ART circuits. Emotions are produced in response to behaviors that impact currently active actions or motivational drives. Each cortical plan prediction of behavior from the behavior planner module enters the internal valuation module as spatio temporal patterns that produce as output the emotional reaction to each plan. The output of the behavior planner module describes what is going to happen while the output of the internal valuation module describes what should happen. Mismatches between the behavior planner module and the internal valuation module are used by the external valuation module to compute expected utility of the currently active action plan. If the mismatch is large then the external valuation module will inhibit attentional blocking of the current behavior action plan and a new one is selected.

In other words the external valuation module is configured to establish an action value based purely on the objects and events. The action value is positively correlated with action plans that are rewarding to the system based on any previously known action plans. The external valuation module is further configured to learn from the positive correlation to assess the value of future action plans and scale a speed at which the action plans are executed by the execution module element in . Finally the external valuation module is configured to open a gate in a manner proportional to the action value such that only action plans that exceed a predetermined action value level are allowed to proceed to the execution module .

In the architecture of the present invention this inhibition is modeled as an on center off surround within the external valuation module . This will enable the architecture to model decision making for complex spatial and motor processes such as planned eye camera saccades and control of catching a target object. Once the decision to act is made by the external valuation module the complex motor sequences for the selected or contextually appropriate behaviors plan available in the behavior planner module are reinforced at the internal valuation module . As shown in the selected motor plans are used by a timing control module to execute a set of adaptively timed actions movements until the goal is reached.

As can be appreciated by one skilled in the art the present invention includes a system method and computer program product that is configured to perform the various cognitive functions using a corresponding module pathway.

As described above and shown in the execution module is configured to carry out the action plan. Actions are manifested in the form of motor plans action plans non limiting examples of which include running yelling etc. The selected action plans are used by the CBL and SC to execute a set of adaptively timed actions movements until the goal is reached. Here the CBL serves as an organ for adaptive control real time control circuits that can use the information about the evolving sensory perceptual context and about errors in realization of the desired goal to continually correct itself until the desired goal state is achieved.

More specifically the execution module includes a queuing module to receive the action plans and order them in a queue sequentially according to their action value. Additionally the timing control module determines the speed at which to execute each action plan. A motor action module is included that integrates the order and speed at which to execute the action plans. The motor action module then sends a signal to the corresponding motor to sequentially execute the action plans according to the order of the queue and the determined speed. Based on the sequential execution the timing control module learns the timing of the sequential execution for any given action plan in order to increase efficiency when executing similar action plans in the future.

In the architecture of the present invention all resonant states are conscious states. If a particular region module is strongly resonating with the bottom up stimuli the system is more conscious of those events. Any learned spatio temporal pattern is determined partly by bottom up data and partly by top down selection. The degree to which the system is conscious of particular actions is determined by how much the representation was formed by top down selection in the TC HS and PFC or degree of resonance as opposed to being determined by bottom up data. Thus firing patterns in sensory and cognitive areas that are directly selected by attention have the most meaning in the architecture and it is most conscious of its activity at that time. When the models described above are combined into the comprehensive system architecture for intelligent behavior the sensory and cognitive match based networks in the What processing stream provide self stabilizing representations with which to continually learn more about the world without undergoing catastrophic forgetting. The Where How processing stream s spatial and motor mismatch based maps and gains can continually forget their old parameters in order to instate the new parameters that are needed to control the system in its present form. Since the spatial and motor or procedural memory processes are often based on inhibitory matching it does not support excitatory resonance and hence cannot support consciousness in the architecture. The complementary match and mismatch learning mechanisms within this larger architecture combined with the adaptive timing circuits that mediate their interactions illustrates how circuits in the self stabilizing match based sensory and cognitive parts of the brain can resonate into consciousness even while they are helping to direct the contextually appropriate activation of spatial and motor circuits to perform cognitive actions. The mechanisms that unify these effects within the architecture are inherently nonlinear and parallel and offer a powerful alternative to the probabilistic and linear models currently in use.

BICA SMART is a suite of systems embodied in software programming interfaces libraries and tools designed to facilitate software implementation of biologically inspired algorithms and architectures by providing support for rapid prototyping modular development debugging and visualization. As shown in the BICA SMART is a computational architecture development framework that facilitates development of a software implementation of the BICA LEAP architecture. As stated earlier the biologically inspired software implementation of BICA LEAP is the BICA LEAP brain BLB . A specially designed language i.e. brain markup language BrainML is used to describe the high level structure of BLB . Automated tools take such description and produce appropriate glue and module stubs code providing the requisite software infrastructure allowing the module implementers to concentrate on the development of the appropriate biologically inspired algorithms. The module stubs are intended to be filled in with appropriate implementations resulting in a library of biologically inspired functional modules. BrainML is the XML specification of the BLB. BrainML is a concept that becomes essential for making this approach scale to larger architectures and more complex data flows.

The low level communications is abstracted by a specially designed programming interface that would afford a variety of implementations ranging from highly generic to highly optimized ones that can be transparently swapped for one another without having to change the code for the functional modules. A build specification is created automatically from the BrainML specification and the complete BLB binaries will be generated from the relevant components. The whole process of maintaining the BrainML representation building the BLB from it running and debugging the resulting BLB will be controlled from a graphical configuration visualization and control tool . Key innovations of the BICA SMART include 

Most key principles of the BICA LEAP cognitive architecture directly translate into design principles of BLB. For example following the biological inspiration the high level organization of BLB will be fully decentralized and asynchronous. BLB will consist of a number of functional modules each corresponding to an area of the primate brain identified in the BICA LEAP architecture. The modules will all be running in parallel and communicating via messages. As in the biological brain where signals not only serve to propagate data but also act as a control mechanism the messages communicated between modules in the present invention will act as a decentralized control mechanism.

In other words one of the core concepts of BICA SMART is that the high level control structure in BLB will be fully defined by the data flow. This data flow is organized into a set of channels each propagating a data of a specific kind from one set of modules to another. Most of the channels will have a single sender and a single receiver but in some cases several recipients will receive the information sent on a particular channel. The channels are implemented by the underlying communication infrastructure provided by the BICA SMART BICA Comm which is described in further detail below.

As shown in the control structure for each functional BLB module is defined by its input channels. depicts an abstract BLB module illustrating data flow for a single functional module. In general the computation in each BLB module will happen in asynchronous rounds where the BLB module would consume the data received on some of its input channels and potentially produce a set of output data for some of its output channels.

In most cases the arrival of data on an input channel would cause the receiving module to perform the new round of computation on the newly received data. For example the arrival of a new feature vector to the object recognition module of the BLB the TC module module would trigger the computation where the new feature vector is classified and the corresponding object is recognized. For illustration purposes such a channel will be referred to as a primary channel illustrated as a solid line .

In addition to primary channels there are auxiliary channels illustrated as a dashed line . When new data arrives on an auxiliary channel it does not immediately trigger any computation. Instead the data is saved and then utilized later when a new round of computation is triggered by an input arriving on a primary channel . For example when a top down biasing data arrives at the object recognition module it will be saved and then utilized later when a new feature vector triggers a new round of computation.

Each module will have a number of primary input and primary output channels and a number of auxiliary input and auxiliary output channels. Each module will have at least one primary input channel and at least one output channel either a primary output or an auxiliary output channel . Note however that the primary auxiliary classification is only important for the receiving module while the sending module does not necessarily need to know how the data it outputs will be used. Modules that have more than one primary input channel may perform different computations depending on which channels have triggered it. Some may even have parallel threads reacting to different channels in parallel.

The primary input channels of each BICA LEAP module are further classified depending on the module s behavior in cases when data is received while the module is already computing for example processing a data packet it had previously received . These would be examples of control information since it controls the behavior of the BICA LEAP module .

In some cases modules need to abort the current computation and restart with new data. One example is that the spinal circuits may need to abort the current motor control when data arrives from the hypothalamus freezing startling reaction .

In other cases modules may need to queue the new data for later processing. For example if the pre motor cortex receives a new step of the motor plan from the Dorsolateral Prefrontal Cortex DLPFC while it is still processing the previous step this new step will need to be queued.

In yet other cases some modules may need to suppress the output until all the inputs are exhausted. For example when new emotional stimuli arrive at the amygdale from the thalamus the amygdala will cease outputting its drive state until it has a chance to update it based on the new emotional stimuli.

Finally some modules can simply discard inputs when busy. For example sensory processing might discard some stimuli when overloaded.

BICA SMART includes a specially designed programming language for describing the high level structure of the BLB the BrainML Brain Markup Language .

BrainML is a declarative language for formulating the high level structure of the BLB by describing the high level functional modules and connections between them. BrainML has facilities for specifying the basic information about the functional modules in BLB including 

To create a suitable BrainML language a plurality of acts are performed. The acts for creating a suitable BrainML language include 

Referring again to the BrainML specification of the BLB would serve as a central hub for a suite of tools. The suite contains a BrainML checker capable of detecting inconsistencies in BrainML specifications. The BrainML checker is configured to check that all the dataflow e.g. input output requirements for each of the functional modules e.g. element in are satisfied. For example the BrainML checker is configured to detect inconsistencies in the BrainML file to determine if all the data flow requirements for each of the functional modules are satisfied and if an inconsistency is detected alert a user of the inconsistency to enable the user to use the graphical configuration tool to correct the BrainML file . The BrainML checker repeats the processing until the BrainML file has no inconsistencies

The suite also contains a BrainML compiler capable of producing all the relevant glue code automatically. For each functional module the module implementation library contains a compute function to produce the glue code. In general the module implementation library is a module that a user can write and generate manually since it contains specific code to do the computations. Thus some of the code is generated by the system while other code can be input by a user. For example a user can generate the implementation code to fill the module wrapper code and create a filled wrapper code. Thus with the code generated the module implementation library will be expected to provide a compute function that would perform a single round of computation or possibly several different compute functions for the modules that are supposed to perform different computations when triggered by different input channels . Namely the compute function would take the data received on the input channels and produce the data to be sent on the output channels. The BrainML compiler would then generate the rest of the code.

In other words the BrainML compiler generates code for each functional module that includes initialization code and a module wrapper code that is subsequently filled with implementation code provided by the module implementation library . The initialization code includes code for starting the module code for communicating with other modules communication code or layer and code for controlling the module function operation.

In the example illustrated in the code is necessary to initialize the BLB the communication layer and wrappers for actual modules that implement each function. As a non limiting example and as used in the prototype of an example of code that will initialize the BLB and communication layer is given below 

Each wrapper serves as interface between the implementation of a functional module and the rest of the system and contains a communication layer that provides the implementation code module a communication independent interface to the underlying communication implementation e.g. the code module implementing VC does not need to know if the communication is based on PVM or MPI . An example of the module wrapper code for the Basal Ganglia BG module that was used in the prototype i.e. the robot arm depicted in is given below.

With respect to filling the module wrapper code with implementation code this can be done using standard C C code that performs various functions or any other suitable language. Provided below is a skeleton of the final module wrapper code that was used in the prototype illustrated in . Note that the statement the actual implementation of the pfc module is where a user will insert the code that implements PFC functionality and can be an existing library of software for various modules that someone has written. It is straightforward C C code but not limited to that as one can write in Java or other languages . The code is provided as 

The BrainML compiler also generates a build specification that is needed by build tools to compile and link all functional modules into a single software code BLB . The build tool generates the single software code BLB using the filled wrapper code the communication code initialization code and build specification. Once the system has all of the above e.g. the code provided above and below and any other needed information the BLB can be generated by running omake to compile and build the software executable. Omake is publicly available as a software tool.

To create a suitable BrainML compiler and checker a plurality of acts are performed. The acts for creating a suitable BrainML compiler and checker include 

While the BrainML specifications are designed so that it is easy to create and manipulate them by hand which might be sufficient for a lightweight BICA SMART a complete BICA SMART contains an integrated graphical visualization tool that can be used to 

Further the graphical configuration tool is operable for converting the description into a graphical layout of the architecture. The graphical layout uses the BrainML to specify information about the functional modules and the data flows between the functional modules and generate a single BrainML file describing the architecture.

BICA SMART includes a simple abstract application programming interface API for the low level communication in BLB BICA Comm API . The main goals of the BICA Comm API include 

Thus the BICA Comm API generates a communication style for data flow between the functional modules of the architecture. The communication style is an implementation of the communication that includes generated communication code to support the communication style.

In the prototype example illustrated in the communication style is implemented using a PVM group communication service. Provided below is a specific implementation of the communication using PVM. The code provided below is a skeleton of the communication code the actual code would be filled in between the curly brackets for each function such as BICA Join BICA Send etc. . Note that communication style refers to how the modules will talk to each other a non limiting example of which includes using standard tools such as PVM group communication service. The communication code is written and generated using standard syntax from the communication style e.g. PVM service which is clearly understood by one skilled in the art e.g. an artisan familiar with C C code. The example communication code is as follows 

As explained earlier the distinction between the primary and auxiliary channels exists only at the receiving module while the sending module does not need to be concerned about it. Similarly one of the main design principles of the BICA Comm API is that the sending module implementation does not need to know which modules will want to receive the data it generates where those modules are located and so on. In order to support self optimization and run time reconfiguration to the maximal extent possible it is desirable to have an implementation where the nature and location of the receiving modules may change dynamically over time.

These goals and requirements made the reliable group communication paradigm a natural choice for the BICA Comm API . In a group communication systems processes form groups where any process is free to join and leave any groups it wishes at any point . A sender of a message would simply direct its messages to a specific group and the underlying group communication system would make sure that all the current members of the corresponding group would receive that message. In general the sender does not need to know anything about a group other than its name. This way a visual object classification module may send its output to a group named visual object classification and all the modules that are interested in receiving such output will only need to join that group in order to start receiving the classification data.

Following the choice to use the reliable group communication paradigm the BICA Comm API includes the usual group communication operations join the group send a message to a group receive a message sent to a specific group etc.

There are a number of off the shelf implementations of the group communication paradigm for example the group communication layer in the parallel virtual machine PVM which make it easy to implement quick prototypes of the BICA Comm API . PVM is a software package that permits a heterogeneous collection of Unix and or Windows computers hooked together by a network to be used as a single large parallel computer. Thus large computational problems can be solved more cost effectively by using the aggregate power and memory of many computers. The software is very portable and is available through the netlib repository.

To create a complete BICA Comm API a plurality of acts are performed. The acts for creating a complete BICA Comm API include 

One of the main goals of this prototype implementation was to test the process of embedding the biologically inspired vision and control algorithms into the BICA SMART framework. The prototype included a simulated environment where the BLB learned on line how to control a simple robotic arm in order to reach a given goal in a two dimensional 2D space. In other words a prototype was generated that simulated the control of a robotic arm.

A structural overview of the prototype implementation is shown in . The prototype implementation includes a world simulator that receives the motor controls from the BLB translates them into the actions and renders a simple 2D view of a robotic arm. The world simulator also acts as the graphical interface providing the visualization and control capabilities.

For further explanation the image on the world simulator of is passed over a primary BICA Comm API channel to the saliency module that finds the salient points of the image. For each salient point the saliency module computes the point s coordinates and extracts a portion of the image at those coordinates.

The visual processing can be done in a monolithic fashion one big visual processing module or through three separate submodules i.e. the salience module the feature extraction module and the recognition module . Thus a user can refine a big module replacing it with a collection of smaller submodules.

The sub images generated by the saliency module are then passed to a feature extraction module over a primary BICA Comm API channel. The feature extraction module is configured generate feature vectors that represent relative weights of the features in the input image. A non limiting example of such a feature extraction module is described in U.S. patent application Ser. No. 11 973 161 filed Oct. 4 2007 entitled Visual Attention and Object Recognition System which is incorporated by reference as though fully set forth herein. As another non limiting example oriented Gabor filters are a traditional choice for obtaining localized frequency information and they have been widely used to model the receptive fields of simple cells. While popular Gabor filters have two main limitations. The maximum bandwidth of a Gabor filter is limited to approximately one octave and Gabor filters are not optimal if one is seeking broad spectral information with maximal spatial localization. These problems can be eliminated through the use of the Log Gabor function which can be constructed with arbitrary bandwidth and the bandwidth can be optimized to produce a filter with minimal spatial extent. For less than one octave the shapes of Log Gabor and Gabor functions are virtually identical. Additionally Log Gabor filters provide a better description of simple cell receptive fields. The present invention uses a bank of Log Gabor filters at different resolutions and orientations to extract a variety of simple shape features from the input. Using the output of the filter bank feature combinations are extracted using spatial pyramid matching see literature reference no. 26 . This approach partitions the extracted Log Gabor features into increasingly fine subregions and computes conjunctions of the features in each region using histograms.

The feature vectors generated by the feature extraction module are then passed over a primary BICA Comm API channel to a recognition module that operates as an object classifier. Using the feature vectors the recognition module is able to classify the object. A non limiting example of such a recognition module is described in U.S. patent application Ser. No. 11 973 161. The recognition classification module uses the k Nearest Neighbor KNN to learn data. This is an online classifier meaning it can easily learn additional data without extensive retraining. For classification the neighbors that are within a certain distance of the input are identified. If these neighbors mostly agree then the same class of the majority of neighbors is ascribed to the input. If the neighbors do not predominantly contain one particular class then these neighbors are used to train a support vector machine SVM using the one versus all rule on the fly or using a cached one if possible which is used to classify the data. By combining KNN and SVM in a way similar to that of Zhang et al. see literature reference no. 27 the present invention can achieve fast accurate and online classification. The functionality of the KNN algorithm is similar to that of a region of primate inferotemporal cortex IT called TEQ which is very active during initial object classification. A region of IT called TE appears to perform fine grained object classification slightly after the activation of TEO which is functionally similar to the SVM component of the present invention.

The coordinates of the salient points from the saliency module and the corresponding results of the recognition module that would output either goal or hand or not recognized are passed to a prefrontal cortex PFC module over two primary BICA Comm API channels and . The two channels and are coupled so that the PFC module would only be activated upon receiving inputs on both of the channels. The PFC module also receives the current joint angles from a motor cortex MC module over an auxiliary channel . Based on these inputs the PFC module then performs the following operations 

Another module the basal ganglia BG module receives the angle deltas from the PFC module over a primary BICA Comm API channel and computes the Go signal which acts as a multiplier for the deltas. The MC module then receives the adjusted joint angles from the BG module over a primary BICA Comm API channel and computes the new joint positions taking into account joint limits and other factors and sends them both to the PFC module over the auxiliary channel already mentioned above and to the world simulator over a primary channel .

Several variations of the present invention have been tested. The simplest version had only the PFC module the BG module the MC module and the world simulator module . In this aspect the world simulator module sends the hand and goal coordinates directly to the PFC module bypassing any attempt at visual recognition. Another version of the present invention included a preliminary version for the saliency code module as well as stub versions mimicking the expected computational complexity of the feature extraction module and the object classification module . The proper versions of the feature extraction module and object classification module were also implemented.

The different prototypes were tested under a variety of conditions including running all the modules in parallel on a single computer running a distributed version where every module is running on a separate computer and variations therebetween. It was observed that the overall BICA Comm based communication and control infrastructure performs well and delivers all the expected benefits both from the standpoint of the ease of implementation of the functional modules and from the point of providing effective decentralized asynchronous communication and control functionality for the prototype.

It was also observed that the framework works well under various conditions. Different initialization approaches provide flexibility in choosing different levels of parallelization depth for the prototype. For example if the prototype is initialized and started up by introducing a single message on the MC to Word Simulator channel then the prototype would work in a mostly synchronous manner where only one module would be active at a time. This mode of operation is particularly useful for debugging.

Additionally if more than one message e.g. three messages is introduced on the MC to World Simulator channel at startup then the prototype would have several modules running in parallel most of the time. This results in significantly decreased delays in fact it was observed that in this mode the world simulator module was busy almost all the time which means that it almost never had to wait for the BLB and significantly increased throughput of the prototype. One potential downside to the increased asynchrony introduced by this initialization approach is that some of the modules mainly the PFC module end up computing based on data that might be slightly out of date and potentially slightly out of sync. It was also noted that the biologically inspired algorithms tolerate this well.

The asynchronous execution is illustrated in . The asynchronous execution which is enabled by initializing the system with three messages and on channels A and B is a form of pipelining where different modules i.e. the PFC module the BG module the MC module and the world simulator module work in parallel based on the data generated during a few of the recent time steps . The ability to pipeline the execution as demonstrated by this prototype is also a fundamental property of BICA SMART.

