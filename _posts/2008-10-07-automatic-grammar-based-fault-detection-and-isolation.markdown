---

title: Automatic grammar based fault detection and isolation
abstract: The present disclosure relates to automated testing of hardware and software systems. In some embodiments, a testing framework that generates a set of test cases for a system under test using a grammar is disclosed. The grammar may include terminal and nonterminal symbols with tags that describe a test sequence. The testing framework can use the grammar to generate a set of test cases. The testing framework can then receive feedback about the execution of the set of test cases from the system under test. In response to the feedback, the testing framework can generate a new set of grammars by automatically modifying or inserting tags in the original grammar. The new set of grammars can then be used to generate further test cases that intelligently explore the system under test for correctness, conformance, performance, security, or reliability.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08006136&OS=08006136&RS=08006136
owner: Wurldtech Security Technologies
number: 08006136
owner_city: Vancouver
owner_country: CA
publication_date: 20081007
---
This application claims the benefit of U.S. Provisional Patent Application No. 60 978 364 entitled SYSTEM AND METHODS FOR AUTOMATED GRAMMAR BASED FAULT DISCOVERY AND ISOLATION filed Oct. 8 2007 and U.S. Provisional Patent Application No. 61 077 458 entitled AUTOMATIC GRAMMAR BASED FAULT DETECTION AND ISOLATION filed Jul. 1 2008 there entireties of which are incorporated herein by reference.

This disclosure generally relates to testing of systems. More specifically this disclosure relates to automatically generating test cases that reveal faults of a system.

Generally described computing devices can be utilized in a variety of contexts such as for exchanging information facilitating communication between users facilitating the operation and control of a wide variety devices and processes and the like. In the context of a manufacturing or production environment a computing network made up of a number of computing devices including personal computing devices server computing devices programmable logic controllers PLCs and or other networked devices can be utilized in conjunction with a communication network such as a wide area network WAN to facilitate the operation and control of various devices processes. For example a networked PLC may be utilized to control the operation of physical manufacturing or processing equipment such as controllers for valves power supplies pumps machinery etc. Similarly a software application or suite of software applications may be hosted on a networked computing device such as a server or personal computing device to receive instructions regarding the operation of various equipment and transmit the appropriate respective instructions to the appropriate equipment such as through a PLC .

In the event of fault in one or more networked computing devices such a fault in a computing device can lead to the failure of associated equipment loss of manufacturing production time property damage and the like. Accordingly computing devices including hardware and software aspects can be designed with redundant components to avoid fault conditions during execution in a manufacturing production environment. Additionally computing systems can be tested to verify that requirements for safety and redundancy are met and to discover errors in design implementation. For example a testing system can be implemented such as in a laboratory that attempts to emulate various commands instructions or other environmental information and then measure the response generated by the computing device s being tested. The emulated commands instructions or other environment information can be embodied as a test case or testing procedure that can be executed by a testing system.

One approach to the generation of test cases and or testing procedures for computing device testing involves the utilization of testing grammars from which test cases testing procedures can be derived. Generally described grammar based test generation involves a grammar that describes a set of strings. The grammar can be processed by a testing system and utilized to derive test cases corresponding to the set of strings in the grammar. However traditional approaches to testing grammars generally described too large of a set of strings. Accordingly the resulting test cases from such testing grammar are often too large and require too much testing system resources to effectively test devices.

The present disclosure generally relates to the automated testing of a system that includes software or hardware components referred to herein as the system under test or device under test . In some embodiments a testing framework generates a set of test cases for a system under test using a grammar. Each test case may perform an action such as provide an input to the system and result in an output from the system under test. The output can then be compared to the expected result to determine whether the system under test is performing correctly.

In an illustrative embodiment the grammar may include terminal and nonterminal symbols with attributes that describe a test sequence for the set of test cases. The testing framework can use the grammar to generate a corresponding set of test cases based on the attributes of the grammar. Additionally the testing framework can then receive feedback that includes results of the processing of inputs generated by the testing framework from the set of test cases and sent to the system under test. In response to the feedback the testing framework may automatically modify the set of test cases as a function of the feedback. For example the testing framework can modify attributes of the grammar or create new grammars to broaden or narrow the set of test cases generated by the testing framework.

The present disclosure relates to testing of a system that may comprise hardware or software. The system can be tested using a framework that automatically generates test cases using context free grammars. The grammars describe a set of test cases that can be utilized by the testing framework to generate a set of inputs to a system under test or a device under test to verify that such system under test or device under meets requirements or to detect errors in the system under test or device under test.

In contrast to testing frameworks in which grammars are edited manually the testing framework modify an existing grammar or create a new grammar by controlling grammar attribute tags. The modification of the attribute tags results in the selection creation of a subset of test cases generated by the previous version of the grammar or previous grammar. In an embodiment a method is provided that generates a new set of grammars by automatically modifying or inserting tags in an original grammar. The automatic modification and or insertion is based on feedback obtained from the system under test or device under test from inputs corresponding to the previous set of test cases.

In accordance with an illustrative embodiment the testing framework can be used to assess specific vulnerabilities and security threats to control system devices and networks. The present disclosure may be particularly beneficial for systems such as process control and supervisory control and data acquisition SCADA systems that have traditionally used closed proprietary architectures. However one skilled in the relevant art will appreciate that the disclosed testing framework operating environment test cases and grammars are illustrative in nature and should not be construed as limiting. Additionally the present disclosure should not be construed to be applicable to any particular system under test or device under and that all disclosed embodiments are also illustrative in nature.

Embodiments of the disclosure will now be described with reference to the accompanying figures wherein like numerals refer to like elements throughout. The terminology used in the description presented herein is not intended to be interpreted in any limited or restrictive manner simply because it is being utilized in conjunction with a detailed description of certain specific embodiments of the invention. Furthermore embodiments of the invention may include several novel features no single one of which is solely responsible for its desirable attributes or which is essential to practicing the inventions herein described.

Client application may be an application running on a computing device that allows a user to select configuration and test procedures to run on system under test . In an embodiment where client application resides on a computer separate from testing framework client application may send data to testing framework that specifies the user selected configuration and test procedures to run. After tests have been run on system under test client application can receive results from testing framework and generate reports based on the results. In an alternative embodiment the client application may be hosted as a network provided service.

Testing framework may be an application running on a computer server that generates and executes tests on system under test based on the configuration and test procedures selected by the user with client application . For example testing framework can include a web service component running on a computer server or distributed across one or more computers and operative to exchange information via an application programming interface API . When test results are received from system under test testing framework may refine a testing strategy and create a second set of tests that are broader or narrower than the original tests run on system under test .

For example in one embodiment testing framework may test system under test using a grammar that generates a set of test cases that causes the testing framework to provide all numbers from one to six digits i.e. 0 to 999 999 as input to system under test . In one embodiment feedback received from the system under test may be used to narrow the set of test cases such that only the inputs that created a fault in the system under test remain in the set of test cases. With reference to the previous example the testing framework can modify the grammar such that the set of test cases would cause the testing framework to provide as inputs to the system under test all numbers from one to five digits i.e. 0 to 99 999 as input. In another embodiment feedback received from the system under test may be used to expand the set of test cases to increase the inputs sent to the system under test to elicit a fault or error condition. With reference again to the previous example the testing framework can modify the grammar such that the set of test cases would cause the testing framework to provide as inputs to the system under test all numbers from one to seven digits i.e. 0 to 9 999 999 as input.

As previously described the testing framework may generate a first set of test cases from a first set of grammars. The first grammar may be created by for example with aid of client application . Using first grammar testing framework can then generate a first set of test cases to run on system under test . An artisan will recognize that there a variety of ways to generate test cases from a grammar including conventional parsing techniques. Based on the results of the first set of test cases testing framework can then automatically create a second grammar by modifying or inserting tags and tag values into the first grammar that widen or constrict the set of test cases. With testing framework more focused testing of the system under test can occur. This may be advantageous given the high costs associated with hardware and software testing.

System under test may comprise a computer program hardware device and or a combination of one or more hardware device s and computer program s . For example the system under test can include an operating system or software application. In another example the system under test may be a hardware device such as a programmable logic controller or supervisory control and data acquisition system. As previously discussed the system under test may be a combination of hardware or software components such as a computing device executing one or more computer programs. In some embodiments the system under test may be a database user interface computer network and embedded or industrial device. One skilled in the relevant art will appreciate that additional or alternative configurations of the system under test will be considered to be within the scope of the present disclosure. Additionally although the system under test is referred to as a computer system the system under test may correspond to a single computing device or computer program.

Grammar processing engine may receive results from tests run on system under test from test engine . The results may include an actual output from system under test that results from an input being applied to system under test . The actual output may be compared to an expected output to determine whether system under test operates as expected. Grammar processing engine can use the results to create a second new set of one or more grammars by modifying or inserting tags attributes or annotations into one or more grammars of the first original set of grammars according to different strategies. For example grammar processing engine may generate tag combinations that reveal faults. Further grammar processing engine can generate tags that reduce the total number of test cases generated by finding a smaller set of tags that reveal the already existing faults that have been exposed by the original set of grammars. Additionally grammar processing engine can perform a neighborhood search by for example generating grammars that create a new set of test cases near the original set of test cases.

The grammar framework may typically include a grammar with attributes. The grammar with attributes may describe a set of one or more test cases. Of note grammar framework may parse the grammar and generate a set of test cases that can be run on the system under test . Further grammar framework can then execute the test cases on system under test . As shown the results of the test cases can also be gathered by grammar framework from system under test to coordinate execution of the test cases.

As further illustrated monitoring subsystem receives results from executing the test cases on system under test . Monitoring subsystem can then use one or monitors to correlate results from the execution of test cases with for example the health or status of the system under test . This may be advantageous for understanding the effects of test cases on for example available memory processing resources network response time and other specific process functionality of system under test . Further monitoring subsystem allows the results of tests to be interpreted in a reliable repeatable and affordable manner.

Monitor may use a variety of techniques to observe the environment or health of system under test during testing for example. As shown there may be one or more types of monitors. Additionally there can be one or more instances of each type of monitor in a test environment. Monitors may also correspond to external software or hardware components for observing the system or system under test .

In an exemplary embodiment monitor may receive output from system under test in real time for example. This may be particularly helpful where the system under test is a device controller. In this situation a device that is operated by system under test may exhibit normal behavior in response to an erroneous input from system under test often the result of the device entering a fail safe mode. As a result it may be improperly assumed that system under test is operating correctly as well. A monitor that examines the output of system under test such as step function would expose this flawed assumption and can therefore be particularly advantageous for ascertaining whether the system under test is actually functioning correctly. To determine whether the system under test is performing as expected for example monitor may compare the actual step function to an expected step function. A discrepancy between the step functions can indicate that a test case resulting from a grammar has exposed a fault of system under test .

Additionally monitor may be useful for determining network connectivity. For example monitor may determine whether system under test is connected to a network or in communication with a device such as a computer server running a component of testing framework . In this embodiment monitor may use internet control message protocol ICMP messages to determine whether the system under test is connected to the network. Alternatively monitor can use an open connectivity interface to ascertain whether system under test is communicating with other devices.

With continued reference to an interaction of the components of the grammar framework will be described with an illustrated embodiment. The grammar and associated attributes or tags along with corresponding tag values can represent one or more test cases. The grammar can then be passed as an input to code generator . Of note although grammar may initially be created manually by for example a software developer to describe an initial set of test cases its subsequent modification may be completely automated by testing framework using for example grammar processing engine .

The code generator may parse grammar and create test case generator . In an embodiment test case generator comprises an executable program. Test case generator can be supplied with an initialization file such as generator configuration file which sets various configuration options and parameters for testing. For example generator configuration file may control the number and types of test cases that are generated by assigning values to grammar tags. Generation configuration file may be updated by grammar processing engine to attempt different combinations of grammar tags in order to widen or constrict the test cases to for example find or pinpoint a cause of failure. When supplied with generator configuration file test case generator may then write out test cases that are described and or can be derived by the grammar to the test cases file .

Test case executor can read in the test cases file . Depending on the embodiment test case executor may also read in the executor configuration file which may include information about system under test . This information can be used to set various options for testing system under test . An artisan will recognize that lexical analysis and or parsing can both be used to process the information contained in test cases file and executor configuration file . Test case executor may then set any options specified by the executor configuration file and execute the test cases in any order report and record the test results .

Beginning in block an original grammar G is tagged with a set of one or more tags or attributes. In an embodiment the grammar may further include corresponding tag values. The grammar may describe one or more test cases that can be run on for example system under test . The original grammar may initially be developed by for example a tester using a manual process. Alternatively original grammar may be a grammar that was automatically created by for example grammar processing engine to generate a set of test cases.

At block an original set of test cases such as T T and Tare created from the original grammar. The original set of test cases can be generated by the grammar framework described herein. In an embodiment a parser such as CUP Parser Generator for Java can be used to generate the set of test cases that are described by the original grammar. A test case may be an event action or input such as executable code values etc. that are applied to system under test . Typically each test case has an expected result.

At block the original set of test cases are applied to a system under test . For example a set of input values can be supplied as input to system under test . System under test may comprise any number of hardware components or may include software such as an operating system or an application. In some embodiments the system under test may include a real time operating system support various networking protocols and services such as FTP or have sparse resources.

The set of test cases may present situations that test various software or hardware configurations to determine open ports and vulnerable services residing on a system under test . Further the set of test cases may check for flaws known to exist in the system under test . In an embodiment the set of test cases may request a vast amount of resources to determine how the system under test responds. Additionally the set of test cases may be used to analyze network security by for example gathering network addresses checking available services and protocols used checking credentials for system under test and selectively targeting and determining other vulnerabilities of the system under test .

At block output from the system under test is received using for example a network. The output may be analyzed by monitoring subsystem . As described above monitoring subsystem can quantify the effect of test cases on the system under test by for example comparing the actual output from system under test with the expected output for each test case. In some embodiments one or more monitors can be utilized to observe the system under test during testing.

Continuing to block a new second set of grammars is created that isolate causes of failure of system under test . The new set of grammars can be created by grammar processing engine using the techniques described above. For example tags of the original grammar may be modified based on test case results so that the resulting test cases apply input values within a narrower range to system under test . Alternatively more grammars can be created that result in test cases that apply a wider range of input values to system under test . Of note grammar processing engine may use feedback from monitoring subsystem to modify generator configuration file .

In certain embodiments the feedback may include pass or fail information after a test case has run. The feedback may be received by grammar processing engine after a specified post test period has passed. This period of time may be the period needed for monitors that were enabled to observe system under test adequately and determine the effects of a test case. The feedback information may indicate a pass when the status of all or some monitors remained normal during execution of the test case which may indicate that the test case did not negatively impact the system under test . Alternatively the feedback information may indicate a failure when the status of some monitors indicate a problem such as a warning or alarm during test case execution.

As noted based on the feedback from test case execution grammar processing engine may modify generator configuration file . Generator configuration file may then be used to create a second new set of test cases when grammar framework is executed. Thus the feedback information can be used to control and modify grammar tags to create a new set of grammars that search for faults of the system under test .

As depicted in the grammar may include one or more rules such as Book. A rule specifies a symbol substitution that can be recursively performed to create new sequences of symbols. Each rule may include a nonterminal symbol followed by a separator such as the symbol and one or more nonterminal symbols and or one or more terminal symbols . A terminal symbol can form parts of strings such as test cases generated by the grammar. A nonterminal symbol generates strings by substituting nonterminals or terminals for itself or a combination of nonterminal or terminal symbols.

For example the Book rule includes nonterminal symbols TitlePage and Chapters and terminal symbols and . Typically one of the nonterminal symbols in the grammar is designated as a starting nonterminal symbol by for example placing it first. In the embodiment shown the starting nonterminal symbol is Book.

As further shown the grammar includes a depth tag with a value of 10. Depth tag may be used to limit the number and type of test cases that can be derived from the grammar by limiting the depth of the language tree that represents the syntactic structure of strings such as test cases that can be derived. For example depth tag with value of 10 in the illustrated grammar limits the total number of test cases to 750 and still exposes the fault of the word processing application when the last chapter of the book does not include any sections. In an embodiment when depth tag has a value of 10 the height which can correspond to the number of levels in the tree is limited to 10. Without depth tag the grammar would describe an infinite number of test cases that may be too long to run.

As noted above grammar processing engine of testing framework can generate tags that reduce the total number and length of test cases produced by finding a smaller set of tags that reveal already existing faults. shows an example of such a test case. As can be seen the test case can reveal the fault that occurs when the last chapter of a document does not include any sections. In this embodiment grammar processing engine has reduced depth tag to a value of 1. This can have numerous advantages. First the number of derivations trees that correspond to the number of test cases derived from the grammar has been reduced. Second the number of derivations has been limited. Thus the number and size of the test cases has been substantially reduced from when depth tag had a value of 10. In an illustrative embodiment the number of derivations corresponds to a derivation tree.

Of note various tags can be used to automatically control the generation of test cases. In some embodiments a tag that controls recursion by controlling the number of levels in a language tree corresponding to test cases can be generated by grammar processing engine . Further a tag that controls balance by for example limiting the difference between path lengths in the language tree can be used. Additionally a tag that uses rule weights can be employed to allow statistical control over the selection of rules with the same left hand side or nonterminal. In one embodiment tags with covering arrays can be generated to allow combinatorial selection from the combinations generated by the right hand side of a rule including terminal or nonterminal symbols. In some embodiments general rule guards may be utilized to allow for activation and or deactivation of rules based on a condition such as a Boolean. Further in an embodiment embedded code that allows for the insertion of arbitrary software code that can be executed during test case generation or execution may be used.

All of the foregoing approaches may be utilized in the present disclosure to test a system that can include hardware or software. The tags and tag values disclosed can be selectively chosen by grammar processing engine based on a testing strategy such as a neighborhood search. For example in some embodiments the tags and tag values may be used to isolate one of a plurality of test cases that may have triggered a fault of the system. Further the tags and tag values can be used to generate other test cases that are near test cases that reveal faults of the system. Thus the automatic modification or insertion of grammar tags and tag values may greatly improve testing of the system.

Although TCP packets with any illegal flag settings should be discarded often the state of a TCP session influences whether packets with illegal flag combinations are forwarded in a network for example. Because the state of a TCP session can greatly affect whether a fault is revealed the grammar of can generate a large set of test cases. This set of test cases may be too large to run if grammar tags are not used to control the generation of test cases. With a total of 7 places to insert the 46 illegal combinations of control flags over 400 Billion test cases that correspond to TCP sessions may be generated by the grammar of .

Advantageously the grammar shown uses a depth tag to control the number of test cases. In the illustrated embodiment depth tag has a value of 4 however other types of tags and tag values are possible. Thus the tagged grammar of which can be automatically generated by grammar processing engine can enable effective and repeatable testing within a large search space.

Notably grammar processing engine may use a search strategy that varies a single depth tag and flag list at a time. In one embodiment a flag list in each generated grammar can include all 46 illegal flag values bad flags and vary a value of depth tag from 4 to 6. It is worth noting that these values indicate 1 2 or 3 bad flag packets. In this embodiment there are 3 values for depth tag and 7 total bad flag rules which yields 21 grammars that can be created for each bad flag by grammar processing engine for example. Because there are 7 bad flags 147 total grammars may be generated by grammar processing engine .

In one embodiment a fault of the firewall may be revealed when the inbound packet is forwarded on to LAN client on the other side of the firewall. In some embodiments a fault can also be revealed when an outbound packet that includes a bad flag not shown is forwarded on from LAN client to internet server by firewall instead of being dropped. It is worth noting that other test cases may be derived from the grammar of which may reveal faults of firewall .

All of the methods and processes described above can be embodied in and fully automated via software code modules executed by one or more general purpose computers. The code modules can be stored in any type of computer readable medium or other computer storage device. Some or all of the methods can alternatively be embodied in specialized computer hardware.

Although this invention has been described in terms of certain embodiments and applications other embodiments and applications that are apparent to those of ordinary skill in the art including embodiments which do not provide all of the features and advantages set forth herein are also within the scope of this invention. According the scope of the present invention is intended to be defined only by reference to the following claims.

