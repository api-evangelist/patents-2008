---

title: Multi-video synthesis
abstract: Embodiments that provide multi-video synthesis are disclosed. In accordance with one embodiment, multi-video synthesis includes breaking a main video into a plurality of main frames and break a supplementary video into a plurality of supplementary frames. The multi-video synthesis also includes assigning one or more supplementary frames into each of a plurality of states of a Hidden Markov Model (HMM), where each of the plurality of states corresponding to one or more main frames. The multi-video synthesis further includes determining optimal frames in the plurality of main frames for insertion of the plurality of supplementary frames based on the plurality of states and visual properties. The optimal frames include optimal insertion positions. The multi-video synthesis additionally includes inserting the plurality of supplementary frames into the optimal insertion positions to form a synthesized video.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08207989&OS=08207989&RS=08207989
owner: Microsoft Corporation
number: 08207989
owner_city: Redmond
owner_country: US
publication_date: 20081212
---
The popularity of video capture devices and the Internet has caused a dramatic increase in the amount of online available video data as well as the number of video data users. As the technology of video presentation becomes more and more important such technology may be used for summarizing videos for efficient browsing automatic new video generation for marketing and gaming as well as other applications.

This Summary is provided to introduce a selection of concepts in a simplified form that is further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Described herein are embodiments of various technologies for integrating one or more supplementary videos into one or more suitable space time holes i.e. insertion positions within a main video. Suitableness is characterized by the least intrusive viewing experience. This integration process may take visual properties such as informativeness consistency and naturalness into consideration in the determination of suitability. In at least one embodiment multi video synthesis includes breaking a main video into a plurality of main frames and break a supplementary video into a plurality of supplementary frames. The multi video synthesis also includes assigning one or more supplementary frames into each of a plurality of states of a Hidden Markov Model HMM with each of the plurality of states corresponding to one or more main frames. The multi video synthesis further includes determining optimal frames in the plurality of main frames for insertion of the plurality of supplementary frames based on the plurality of states and visual properties. The main frames include optimal insertion positions. The multi video synthesis additionally includes inserting the plurality of supplementary frames into the optimal insertion positions to form a synthesized video. Other embodiments will become more apparent from the following detailed description when taken in conjunction with the accompanying drawings.

This disclosure is directed to embodiments that enable the integration of one or more supplementary videos into one or more suitable space time holes within a main video. For example one or more supplementary advertising videos may be integrated into a video or a video clip in a video game for the purpose of product or service promotion. The suitableness of a supplementary video that is integrated into the main video is characterized by the provision of a least intrusive viewing experience. The integration process to achieve least intrusive viewing experience may take visual properties such as informativeness consistency and naturalness into consideration.

The embodiments described herein are directed to technologies for achieving multi video synthesis that is the integration of one or more supplementary videos into one or more suitable space times holes within a main video. As described the multi video synthesis mechanisms may determine the suitability of an integration based on the intrusiveness of the one or more supplementary videos in the main video when the videos are observed together. In this way the embodiments described herein may enable video content providers to maximize the delivery of video content and information in a limit time and or content space. For example the embodiments described herein may be used to integrate advertising videos into a primary video. Various examples of multi video synthesis in accordance with the embodiments are described below with reference to .

The multi video synthesis engine of the exemplary system may receive one or more supplementary videos from supplementary video providers . The supplementary video providers may include professional and amateur artists who are willing to disseminate video content to the public. In some embodiments the one or more supplementary videos may include one or more advertisements that is at least one image that is intended to generate viewer interest in particular goods services or points of view. The one or more supplementary videos may also include machine readable works that contain a plurality of images such as movies video clips homemade videos etc. In various embodiments the durations of the one or more supplementary videos are generally shorter than the durations of the one or more main videos .

In the exemplary system the one or more main videos and the one or more supplementary videos may be transferred to the video synthesis engine via one or more networks . The one or more networks may include at least one of wide area networks WANs local area networks LANs and or other network architectures. However in other embodiments the one or more main videos and or the one or more supplementary videos may also reside within a memory of the video synthesis engine . Accordingly in these embodiments the video synthesis engine may access the one or more main videos and or the one or more supplementary videos without using the one or more networks .

The video synthesis engine may be generally configured to integrate one of the main videos with the one or more supplementary videos . According to various embodiments the video synthesis engine may integrate one or more supplementary videos into suitable space time holes in the particular main video . The integration of one or more supplementary videos and the particular main video may produced a synthesized video .

Suitableness of integration may be characterized by the provision of a least intrusive viewing experience following the integration. The video synthesis engine may take visual properties such as informativeness consistency naturalness and stability into consideration when determining suitability.

In various embodiments the visual property of informativeness may facilitate minimizing the loss of space time information from a main video during the synthesis of a synthesized video . Accordingly the use of informativeness may facilitate the selection of the space time holes from the main video by helping to locate least informative segments of the main video .

The visual property of consistency refers to whether the composed frames of a synthesized video is consistent in appearance with the frames of the main video and the supplementary videos . Accordingly consistency may facilitate the insertion of one or more supplementary frames into a main frame based on the visual similarity between the frames.

The visual property of visual naturalness may refer to whether the connecting boundary areas between frames of the main video and the one or more supplementary videos are visually nature or smooth. Additionally the visual property of stability may refer to whether the frames of the one or more supplementary videos are presented continuously or orderly and whether their spatial positions are stable relative to the main video in the synthesized video .

The memory may store program instructions. The program instructions or modules may include routines programs objects components and data structures that perform particular tasks or implement particular abstract data types. The selected program instructions may include a detection module a modeling module an informativeness measurement module a consistency measurement module a visual naturalness module a blend module a user interface module and a data storage module .

The division module may be implemented to break one or more videos into frames. In various embodiments the division module may break a main video such as main video into its constituent video frames which may be referred to as main frames. Likewise the division module may break a supplementary video such as supplementary video into its constituent frames which may be referred to as supplementary frames.

The detection module may be implemented to find the optimal insertion positions in main video for the insertion of one or more supplementary videos . Optimal insertion positions may refer to spatial insertion positions that are spatially stable or substantially spatially stable that is positions that enable the supplementary videos to be presented in a visually and continuously manner with the main video . In other words the detection module may determine the spatial temporal positions of the region centers in the main video and the corresponding supplementary frames that are to be simultaneously inserted into the regions. Accordingly the detection module may employ the division module to break the main video and the one or more supplementary videos into frames. The detection module may further measure the visual properties of the frames in a probabilistic form and formulate the detection of insertion holes as a Maximum a Posterior MAP problem where the solution may determine a sequence of insertion positions for frames of each supplementary video . An exemplary probabilistic formulation for the detection of insertion holes is illustrated in .

Further supplementary video may be represented by S by which T may represent the number of supplementary frames in the supplementary video.

The detection module may be configured to determine the optimal insertion positions I lfor frames S where l x y t may be the position in x y t 3 dimensional space and t may represent a time coordinate. If z represents the optimal properties of the synthesized video and P z as the measurement of probability that the synthesized video contains the desired properties the detection module may obtain optimal Iby maximizing a posterior probability 

In at least one embodiment the detection module may be configured to use the Viterbi algorithm which is designed for finding an optimal sequence of states for the likelihood measurement. In the Viterbi algorithm process a stability property may be considered by limiting the search paths extension of spatial position.

Generally speaking the Viterbi algorithm is a dynamic programming algorithm that discovers the most likely explanation of a hidden states sequence for an observation. The Viterbi algorithm is an efficient recursive algorithm that performs an optimal exhaustive search along a time line. In the Viterbi algorithm the computing of the most likely sequence up to a certain time point t depends only on the observation at point t and the most likely sequence at point t 1 . Thus the Viterbi method may search every possible path to yield global best results. However since the number of possible paths increases exponentially as the length increases the Viterbi method may cause heavy computation and storage loads for long sequential data.

Accordingly in some embodiments the detection module may apply a beam search method or a particular type of the Vertibi algorithm that reduces the size of the search space during an optimal insertion path search. In at least one embodiment the beam search method may define a pruning beam width relative to the most probable path likelihood P t at frame t. Thus the beam search method may prune hypotheses that are outside of the pruning beam i.e. with likelihoods less than P t from the search.

Returning to the description of the modeling module may be employed by the detection module to model one or more supplementary videos. In various embodiments the modeling module may model a supplementary video using a discrete left to right Hidden Markov Model HMM which is illustrated in . Subsequently the detection module may apply a Viterbi algorithm to the HMM model of the supplementary video . In this way the detection module may use the Viterbi algorithm to find an optimal insertion path in the main video for the insertion of the supplementary video .

Additionally each state may also correspond to three insertion positions with the same spatial coordinates in three continuous main frames such as frames and of the main video . Because of the temporal continuous property of the main video assigning a plurality of supplementary frames to one state has almost no influence on the fitness of various inserting paths. However such an assignment may improve the efficiency of the video stability. It will be appreciated that in other embodiments the number of supplementary frames assigned to each state as well as the number of main frames that correspond to each state may vary in the same manner e.g. two assigned supplementary frames and two corresponding main frames as long as the fitness of the inserting paths are not adversely affected.

In at least one HMM structure if a current state is right arrow over S the next candidate states to be inserted may be represented as right arrow over S and right arrow over S . Accordingly the transition probability may be represented as 1.0 0.9 4 Thus some states may be jumped over. In this way some parts of the supplementary video that are inserted into the main video may be accelerated and better visual effects may be achieved without the loss of information from the supplementary video .

Accordingly to find the insertion positions for the HMM states sequence the detection module may extend possible paths along a time line of the main video . Each path X may contain a historic list of the insertion positions I and a historic list of states right arrow over S . The probability of the path Xup to state t whose state right arrow over S may be assigned to a position Iis max 10 where Xis the path at state t 1 whose likelihood is P X and P X I right arrow over S is the transition probability of extending to the next state to I right arrow over S and where Sdenotes the current corresponding frames of the supplementary video .

At each possible insertion position the detection module may initialize the paths from the beginning state of the supplementary video . Paths that reach the end of the supplementary video may be saved to the output and deleted from the current path list. Finally the path with the highest likelihood in the output list may be obtained as the optimal solution.

In order to implement the spatial stability property of the synthesized video the detection module may limit the HMM state extension of I in a spatial neighboring area of a current position. Lower transition probabilities may be set to farther positions in the neighborhood and vice versa while probability for the same position may be maximized.

In various embodiments the detection module may keep only a path list of the current frame in a memory e.g. data storage module . For example for a T frame supplementary video which has Nstates and a T frame main video that has L possible insertion positions in each frame the maximal paths number that the detection module may need to keep is N L . If the number of extension candidates for a state is limited to E the size of paths searching space may be at most N L E . Thus computation in accordance with these embodiments is generally efficient and practical for long videos and online video processing.

Returning to the description of the insertion module may be employed to insert supplementary frames of a supplementary video such as the supplementary video into one or more main frames of the main video . Accordingly once the optimal insertion positions in the optimal frames are determined by the detection module the detection module may activate an insertion module to integrate the supplementary video into the main video .

The informativeness measurement module may be employed by the detection module to minimize the loss of information from the main video when one or more supplementary videos are inserted in the main video . In at least one embodiment the informativeness is a probability factor for insertion positions Idefined in terms of the saliency measurement P I and the smoothness measurement P I as shown below 5 To minimize the informational loss of the main video and the intrusiveness of the supplemental video insertion highly smooth areas may be provided more insertion while areas containing salient parts may be provided with less insertion.

To measure the saliency and smoothness of the insertion area defined by a particular position in a frame the informativeness measurement module may first calculate a saliency map for each main frame using a visual attention model that combines static and temporal saliency maps. In various embodiments the static contrast based saliency map may be configured to investigate the effects of contrast in human perception while the temporal saliency map may integrate the motion inductors.

The saliency measurement of Imay be calculated over the insertion area centering at a particular position in a frame. Since high saliency of even a small part of this area causes information loss the informativeness measurement module may measure this informativeness using the highest J saliency value in the area.

In at least one embodiment J may be defined as of the area size according to viewing experience and lmay be defined as the highest J saliency values where Iranges over 0 255 as shown below 

The consistency measurement module may be employed by the detection module to compute the consistency between a main video and one or more supplemental videos . In various embodiments the consistency measurement module may use the combination of color similarity P M S and texture similarity P M S to measure the consistency between a main frame Mti of the main video and a supplementary frame S of a supplementary video 8 

The color similarity may be calculated using the color histogram correlation. For each pixel of color R G B the consistency measurement module may calculate the pixel s chromaticity color g b 16 G R G B 16 G R G B based on which a 16 16 color histogram Hfor a main frame and Hfor a supplementary frame can be obtained by accumulating the points. Accordingly the color relevance likelihood may be obtained by 

For texture following a texton histogram representation a set of filter banks may be applied to each frame using the intensity value of each pixel. The filter banks may include three Gaussians with the scale parameter 1 2 4 four Laplacian of Gaussians with 1 2 4 8 and four order 1 derivatives of Gaussians with 2 4 and x y directions . Therefore each pixel may be associated with an 11 dimensional texture feature vector. In various embodiments the consistency measurement module may be provided with random selected training pixel features from the main frames that are clustered to a vocabulary of texton by k means. By mapping each pixel to one texton in the vocabulary and accumulating a texton histogram may be obtained for each frame. Additionally the texture relevance P M S may be calculated using the same histogram correlation method as used for color relevance.

The visual naturalness module may be employed by the detection module to ensure that the connecting boundary areas across different videos are visually natural or smooth. Inconsistent appearance between connecting boundaries of the main video and the supplementary video in the synthesized video may cause visual unnaturalness. Accordingly the visual naturalness module may minimize the contrast between the connecting boundary area of a main frame and a supplementary frame in each synthesized frame of the synthesized video . The naturalness can be evaluated by judging the consistency in appearance between first area of a main frame and a second area of a supplementary frame that are adjacent a connecting boundary. An example of the areas of the main frame and the supplementary frame is shown in

As shown in to consider the naturalness in different directions of the inserting area the visual natural module may evenly divide each of the boundary areas Oand Winto eight sub areas Oand W respectively. The boundary areas of Oare illustrated as areas and the boundary areas of Oare illustrated as areas .

The visual naturalness module may extract color and texture features from each of the sub areas and consistency may be measured between a corresponding sub inside area Wand sub outside area O. In various embodiments the visual naturalness module may further use the same feature extraction and relevance calculation methods as the consistency measurement module . Accordingly based on supplementary frame Sand insertion position I the visual naturalness module may obtain the naturalness measurement P I S by summing the consistency measurements of the sub areas 8 10 whereby the method for calculating Pmay be defined as 

It will be appreciated that while the previously described techniques for multi video synthesis are described with respect to frames from a single main video and a single supplementary video the techniques may be applied to the insertion of a plurality of supplementary videos into a main video . In such embodiments the detection module may keep an individual path for each supplementary video when searching along the time lines. Accordingly the detection module may compute an optimal solution with no overlap between the inserting paths of different supplementary videos and compute the relative highest overall likelihood.

Further the blend module may be employed by the detection module to enhance the appearance of the synthesized video that includes main video and one or more supplemental videos . To this end the blend module may implement a seamless blending algorithm to create smooth transitions in a frame of a synthesized video that includes a main frame from main video and a supplementary frame from supplementary video . In various embodiments the blending algorithm may use a probabilistic matting approach for videos. Specifically the blending algorithm may be applied on an extended area which covers both an insertion area and its neighboring area. For example For each pixel e a vector P M P S may represent a probability the pixel belongs to a main frame and supplementary frame. The output value of this pixel may be obtained by 1 12 whereby eand erepresent the corresponding pixel value in the original main frame and supplementary frame respectively. It will be appreciated that in each blending step only a main frame and a supplementary frame are processed. Accordingly frames from different supplementary videos can be inserted one by one by using the previous integrated frame as the main frame. The blend module may take an iterative process to distribute each pixel s probabilities equally to its four connected neighboring pixels so that the neighboring pixels are driven have a similar probability vector. The resulted probabilities may be used as alpha values for alpha matting between the inserted supplementary frame and the extended inserting area of the main frame.

In at least one embodiment the probability that a pixel belongs to the supplementary frame P S may be associated according to its information i.e. saliency value in the supplementary video. In such an embodiment the probability P S is set to 1 if its saliency value Iis above a threshold Th or

Returning to the description of the user interface module may interact with a user via a user interface not shown . The user interface may include a data output device such as a display and one or more data input devices. The data input devices may include but are not limited to combinations of one or more of keypads keyboards mouse devices touch screens microphones speech recognition packages and any other suitable devices or other electronic software selection methods.

The user interface module may be configured to enable a user to provide input to select one or more supplementary videos for integration with a main video to create a synthesized video . Additionally the user interface module may be further configured to cause the display to output synthesized videos such as the synthesized video to the user.

The data storage module may be configured to store data in a portion of memory e.g. a database . In various embodiments the data storage module may be configured to store one or more main videos and one or more supplementary videos . The data storage module may also be configured to store the synthesized videos derived from the main videos and supplementary videos such as any intermediary products produced by the various modules of the video synthesis engine .

At block the video synthesis engine may break a main video such as a main video into a plurality of main frames. At block the video synthesis engine may also break a supplementary video such as a supplementary video into a plurality of supplementary frames.

At block the video synthesis engine may assign supplementary frames of the supplementary video to states in a Hidden Markov Model HMM . In at least one embodiment each state in the HMM may be assigned to three continuous supplementary frames. The states in the HMM may be assigned in this manner until all supplementary frames in the supplementary video are paired with a particular state.

In other embodiments each state in the HMM may be assigned to any number of supplementary frames as long as the number of supplementary frames does not affect the fitness of inserting paths e.g. a series of insertion position in the main 3 dimensional space i.e. x y and t of the main video .

Each state of the HMM may also correspond to insertion positions in the main video where each of the corresponding insertion positions being in a main frame of the video . The corresponding insertion positions may share the same spatial coordinates i.e. x and y coordinates in the main frames. In various embodiments the main frames that include the insertion positions for each state are continuous and the number of insertion positions is equal to the number of supplementary frames assigned to the state. For example in the embodiment where each state of the HMM is assigned three continuous supplementary frames each state of the HMM may also correspond to three continuous main frames in the main video where each main frame includes an insertion position.

At block the video synthesis engine may determine the optimal insertion positions in the optimal frames in the main video for the insertion of the supplementary frames of the supplementary video . In various embodiments the video synthesis engine may apply a Vertibi algorithm e.g. beam search algorithm to the HMM states of the supplementary video and corresponding insertion positions in the main video . In various embodiments the Viterbi algorithm may be applied by the video synthesis engine to find an optimal insertion path in the main video that enable the insertion of the supplementary video into the main video to achieve the least intrusive viewing experience. The optimal insertion path in the main video including optimal insertion positions for the frames of the supplementary video .

Accordingly the video synthesis engine may achieve this least intrusive viewing experience by accounting for visual properties that includes informativeness consistency visual naturalness and stability through the application of the Viterbi algorithm. In at least one embodiment the Vertibi algorithm may be a Vertibi beam search method.

At block following the determination of the optimal insertion path by the video synthesis engine the engine may insert the frames of the supplementary video into the main video at the optimal insertion positions that is optimal frames. The optimal insertion positions being designated by the optimal insertion path.

At block the video synthesis engine may blend the supplementary frames that are inserted into corresponding main frames of the main video . In various embodiments the blending algorithm may use a probabilistic matting approach. Thus the video synthesis engine may produce a synthesis video such as synthesized video from the main video and supplementary video .

At decision block the video synthesis engine may determine whether there is an additional supplementary video to be inserted into the main video . If the video synthesis engine determines that there is an additional supplementary video for insertion yes at decision block the process may loop back to block where the video synthesis engine may repeat the integration. However if the video synthesis engine determines that there is no additional supplementary video to be inserted no at decision block the process may terminate at block .

Nevertheless it will be appreciated that in some embodiments the integration of multiple supplementary videos into the main video may be carried out simultaneously rather than sequentially. In such embodiments the video synthesis engine may keep an individual path for each supplementary video when searching along the time lines. Accordingly the video synthesis engine may compute an optimal solution with no overlap between the inserting paths of different supplementary videos and compute the relative highest overall likelihood.

In a very basic configuration computing device typically includes at least one processing unit and system memory . Depending on the exact configuration and type of computing device system memory may be volatile such as RAM non volatile such as ROM flash memory etc. or some combination of the two. System memory typically includes an operating system one or more program modules and may include program data . The operating system includes a component based framework that supports components including properties and events objects inheritance polymorphism reflection and provides an object oriented component based application programming interface API such as but by no means limited to that of the .NET Framework manufactured by the Microsoft Corporation Redmond Wash. The device is of a very basic configuration demarcated by a dashed line . Again a terminal may have fewer components but will interact with a computing device that may have such a basic configuration.

Computing device may have additional features or functionality. For example computing device may also include additional data storage devices removable and or non removable such as for example magnetic disks optical disks or tape. Such additional storage is illustrated in by removable storage and non removable storage . Computer storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. System memory removable storage and non removable storage are all examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media may be part of device . Computing device may also have input device s such as keyboard mouse pen voice input device touch input device etc. Output device s such as a display speakers printer etc. may also be included. These devices are well known in the art and are not discussed at length here.

Computing device may also contain communication connections that allow the device to communicate with other computing devices such as over a network. These networks may include wired networks as well as wireless networks. Communication connections are some examples of communication media. Communication media may typically be embodied by computer readable instructions data structures program modules etc.

It is appreciated that the illustrated computing device is only one example of a suitable device and is not intended to suggest any limitation as to the scope of use or functionality of the various embodiments described. Other well known computing devices systems environments and or configurations that may be suitable for use with the embodiments include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor base systems set top boxes game consoles programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and or the like.

The least intrusive integration of one or more supplementary videos into a main video may enable the production of a synthesize video that conveys the maximum amount of information in a relatively short period of time. Thus embodiments in accordance with this disclosure may provide synthesized videos that may be used for product or service promotion in video clips and video games as well other information presentation purposes.

In closing although the various embodiments have been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended representations is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as exemplary forms of implementing the claimed subject matter.

