---

title: Distributed global object cache
abstract: A method is disclosed. The method includes receiving an object at a first image transform within a control unit, the first image transform searching for the object in a local cache, retrieving the object from a second image transform upon a determination that the object been previously received at the control unit and processed at the second image transform; and the first image transform performing a raster image process on the object upon a determination that the object has not been previously received at the control unit.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08314949&OS=08314949&RS=08314949
owner: InfoPrint Solutions Company LLC
number: 08314949
owner_city: Boulder
owner_country: US
publication_date: 20081223
---
This invention relates generally to the field of printing systems. More particularly the invention relates to image processing in a printing system.

Print systems include presentation architectures that are provided for representing documents in a data format that is independent of the methods that are utilized to capture or create those documents. One example of an exemplary presentation system which will be described herein is the Advanced Function Presentation AFP system developed by International Business Machines Corporation. According to the AFP system documents may include combinations of text image graphics and or bar code objects in device and resolution independent formats. Documents may also include and or reference fonts overlays and other resource objects which are required at presentation time to present the data properly.

Once the documents are received at a printer processing is performed to convert a document into a printable format. However processing high resolution images in an incoming data stream into a printable format typically involves highly compute intensive operations e.g. scaling rotation decompression color conversion etc. .

Further it is common for a printer to frequently process repetitive images throughout a print job. For instance a print job may include a full page background image or a company logo that appears on every printed page. While some data streams such as AFP allow a print job generator to explicitly identify such an image download the image once and then reuse it some other data streams do not. Moreover the print job generators may not use the capability even if present. Therefore inefficiency occurs in having to repeatedly process the same images into a printable form.

In one embodiment a method is disclosed. The method includes receiving an object at a first image transform within a control unit the first image transform searching for the object in a local cache retrieving the object from a second image transform upon a determination that the object been previously received at the control unit and processed at the second image transform and the first image transform performing a raster image process on the object upon a determination that the object has not been previously received at the control unit.

In another embodiment a printing system is disclosed. The printing system includes a print server and a printer. The printer includes a print head and a control unit having a cache master transform a second image transform and a first image transform. The first image transform searches for a received object in a local cache retrieves the object from the second image transform upon a determination that the object been previously received at the control unit and processed at the second image transform and performs a raster image process on the object upon a determination that the object has not been previously received at the control unit.

A further embodiment discloses an article of manufacture comprising a machine readable medium including data that when accessed by a machine cause the machine to perform operations comprising receiving an object at a first image transform within a control unit the first image transform searching for the object in a local cache retrieving the object from a second image transform upon a determination that the object been previously received at the control unit and processed at the second image transform and the first image transform performing a raster image process on the object upon a determination that the object has not been previously received at the control unit.

A mechanism to efficiently process images in a print system is described. In the following description for the purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent however to one skilled in the art that the present invention may be practiced without some of these specific details. In other instances well known structures and devices are shown in block diagram form to avoid obscuring the underlying principles of the present invention.

Reference in the specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

In other embodiments print application may also provide PostScript P S and PDF files for printing. P S and PDF files are printed by first passing them through a pre processor not shown which creates resource separation and page independence so that the P S or PDF file can be transformed into an AFP MO DCA data stream prior to being passed to print server .

According to one embodiment the AFP MO DCA data streams are object oriented streams including among other things data objects page objects and resource objects. In a further embodiment AFP MO DCA data streams include a Resource Environment Group REG that is specified at the beginning of the AFP document before the first page. When the AFP MO DCA data streams are processed by print server the REG structure is encountered first and causes the server to download any of the identified resources that are not already present in the printer. This occurs before paper is moved for the first page of the job. When the pages that require the complex resources are eventually processed no additional download time is incurred for these resources.

Print server processes pages of output that mix all of the elements normally found in presentation documents e.g. text in typographic fonts electronic forms graphics image lines boxes and bar codes. The AFP MO DCA data stream is composed of architected structured fields that describe each of these elements.

In one embodiment print server communicates with control unit via an Intelligent Printer Data Stream IPDS . The IPDS data stream is similar to the AFP data steam but is built specific to the destination printer in order to integrate with each printer s specific capabilities and command set and to facilitate the interactive dialog between the print server and the printer. The IPDS data stream may be built dynamically at presentation time e.g. on the fly in real time. Thus the IPDS data stream is provided according to a device dependent bi directional command data stream.

According to one embodiment control unit process and renders objects received from print server and provides sheet maps for printing to print engine . In such an embodiment control unit includes a multitude e.g. ten of compute node machines with each node having two or more parallel page output handlers POH s . In one embodiment each POH includes a separate transform that processes received objects. In such an embodiment the transforms process image objects. However in other embodiments the transforms may process any type of data object received at control unit .

In one embodiment the control information is relatively small e.g. less than 200 bytes and describes the object s dimensions and placement. Since the control information is relatively small the control information and UID for an object is stored in the local cache associated with the transform processed the object. Meanwhile the object data is stored at a disk database since the data is typically large. Disk database is central to each of the transforms at node and thus stores data for objects processed by all of the transforms .

According to one embodiment control unit implements a global caching mechanism to enable local caches to globally share information and cached objects with other transforms within a node as well as other nodes . Referring back to for example local cache may share with either transform or transform . In order to implement the global caching mechanism a transform is designated as a master or cache master e.g. transform in . The cache master maintains a master database which stores a type and UID for each object in addition to location information.

In one embodiment the cache master knows all objects that have been received or seen at least once at control unit . This information is stored at master database . Thus if an object is cached or is being cached the cache master knows which transform has the object in its cache or is currently caching it. In a further embodiment the cache master also knows which transforms are located on the same compute node based on their IP numbers. This knowledge can be used to speed the cache sharing since all of the transforms on the same node share the same disk cache .

In one embodiment each transform remains ready to share its resource in order to share information. Thus each transform includes sharing logic that listens to a port and waits for sharing requests. In one embodiment the transform performs synchronization after listening is started. If the transform is not the cache master the transform opens a socket to the cache master on the sharing port and sends a registration message with its IP number and sharing port. This socket will remain open to query and inform the cache master regarding objects that the transform has seen.

According to one embodiment the cache master initiates a master thread. In such an embodiment the master thread may be started either if the cache master determines that it is the master e.g. based on the synchronization or if the cache master receives a first master connection from a non master. In a further embodiment the master cache is also a non master meaning that the cache master also operates as a regular transform that needs to communicate with master database . In still a further embodiment the cache master uses direct application programming interface API calls to communicate with the master database rather than via a socket.

In one embodiment a select call is used to wait for data on the open sockets one per transform . Once there is data available the master cache checks each socket in turn and processes the requests before blocking on select again. If the other transform is located at the same node there is no need to send the data since the object is already available on the local disk servicing each transform on the node.

Upon startup neither the cache master nor any of the transforms knows how many transforms that are available in control unit . Thus in one embodiment the cache master relies on control unit to not process any jobs until all the POHs are operating. As a result the first time the cache master receives a message indicating that an object has been seen it can assume that all the transform instances have registered with it.

If the object is not stored in local cache transform transmits a message to the cache master including the object type and UID processing block . Subsequently the cache master communicates with the transform instructing the transform as to how to proceed. At decision block the transform determines whether this is the first time that any transform controlled by the cache master has received the object. If so the transform processes the object by performing a raster image process RIP to produce a bitmap processing block . Additionally a record of the object is stored at master database .

If it is not the first time the object has been seen it is determined whether the object has been cached at another transform decision block . If the object has not been cached at another transform e.g. this is the second time the object has been seen the cache master instructs the transform to RIP and store the object at its local cache processing block . The transform will report that it has the object it available in the local cache once the caching is completed.

If while the caching is in progress another transform reports the same object it will be told to RIP the object rather than caching it since the first transform is currently caching it and writing to a disk . If the object has been cached at another transform the information is retrieved from the other transform and used at the current transform processing block .

Since the object may located at a transform at the same node or a transform at another node the current transform receives a message from the cache master indicating which transform the object is to be retrieved from. In either scenario the current transform opens a socket connection to the transform that has the object in its local cache . The current transform receives the control information over the socket.

If the other current transform is not located at the same node the current transform receives the data over the socket as well. The data is subsequently cached on the local disk . In one embodiment the master will use a least recently used algorithm to assign the other transform for which a current transform is to retrieve an object if multiple transforms have the object stored in cache. The recently used algorithm chooses a transform that has least recently shared any object to share the object. If however a transform located on the same node has the object in its cache that transform will be used in preference to one on another node .

According to one embodiment a transform sends a message to the cache master if the transform needs to delete a resource from the cache to free up space. The cache master may respond by indicating that the object can be deleted or by indicating that the transform can delete the control information at the local cache but that the data on disk should not be deleted because the object is also used by another transform at the same node that has not yet asked to delete the object. The cache master may also respond with an indication that the transform is not to delete the object since the cache master has told another transform to retrieve the object from the transform .

In a further embodiment cache availability and caching in progress data are used to manage any requests to erase. If multiple transforms on the same node need to erase an object the last transform to get permission to erase will be instructed to erase the disk cache as well.

Additionally master database is periodically cleansed of objects that are not in any transform cache e.g. they have either been seen once or erased . The size of master database is large enough to include the union of all the transform databases since the worst case is that each instance has seen completely different set of objects.

According to one embodiment the master thread in the cache master operates serially on socket connections though multiple threads could be used as well. Therefore record locking is implemented to enable the local transform e.g. the same process space as the master thread to access the global database from a different thread. The global cache data is thus locked before use.

The above described mechanism enables the efficient processing of repeatedly used image objects at a printer.

Embodiments of the invention may include various steps as set forth above. The steps may be embodied in machine executable instructions. The instructions can be used to cause a general purpose or special purpose processor to perform certain steps. Alternatively these steps may be performed by specific hardware components that contain hardwired logic for performing the steps or by any combination of programmed computer components and custom hardware components.

Elements of the present invention may also be provided as a machine readable medium for storing the machine executable instructions. The machine readable medium may include but is not limited to floppy diskettes optical disks CD ROMs and magneto optical disks ROMs RAMs EPROMs EEPROMs magnetic or optical cards propagation media or other type of media machine readable medium suitable for storing electronic instructions. For example the present invention may be downloaded as a computer program which may be transferred from a remote computer e.g. a server to a requesting computer e.g. a client by way of data signals embodied in a carrier wave or other propagation medium via a communication link e.g. a modem or network connection .

Throughout the foregoing description for the purposes of explanation numerous specific details were set forth in order to provide a thorough understanding of the invention. It will be apparent however to one skilled in the art that the invention may be practiced without some of these specific details. Accordingly the scope and spirit of the invention should be judged in terms of the claims which follow.

