---

title: Multi-touch input platform
abstract: This document describes tools having or interacting with a touch-sensitive device with one or more contact detectors that detect a tactile input from a user making contact with the contact detectors and an input/output module that persistently identifies contact data representing the detected tactile input. This identification is unique, thereby differentiating one or more tactile inputs from other current tactile inputs represented in the contact data. Using this unique identification, the input/output module can initiate an application to provide a function, such as data entry or a mapped function, associated with the detected tactile input. These data or mapped functions may, in many instances, provide a greater depth or breadth of functions by which users may interact with applications and computer systems.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09268483&OS=09268483&RS=09268483
owner: Microsoft Technology Licensing, LLC
number: 09268483
owner_city: Redmond
owner_country: US
publication_date: 20080516
---
Touch sensitive devices permit users to interact with applications running on a computing system. While users appreciate the ability to intuitively interact with the computing system through these touch sensitive devices in many instances the applications offer more functions or more complex functions than touch sensitive devices are configured to detect. As a result a user is often forced to interact with graphical objects or drop down menus that detract from the touch sensitive device s intuitive nature.

This document describes tools having or interacting with a touch sensitive device with one or more contact detectors that detect a tactile input from a user making contact with the contact detectors and an input output module that persistently identifies contact data representing the detected tactile input. This identification is unique thereby differentiating one or more tactile inputs from other current tactile inputs represented in the contact data. Using this unique identification the input output module can initiate an application to provide a function such as data entry or a mapped function associated with the detected tactile input. These data or mapped functions may in many instances provide a greater depth or breadth of functions by which users may interact with applications and computer systems.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. The term tools for instance may refer to systems modules APIs methods computer readable instructions e.g. one or more computer readable storage media having executable instructions and or techniques as permitted by the context above and throughout the document.

Some touch sensitive devices such as some touch pads and touch screens are unable to detect and or track multiple tactile inputs. A touch sensitive device that cannot detect multiple tactile inputs is of limited use because many applications provide robust and numerous functions. Thus a computing system or other electronic device with a single input touch sensitive device may lose out in the marketplace over other computing systems that include a multi input touch sensitive device. Computing systems and electronic devices that are enabled to detect multiple tactile inputs however are often complex in order to handle these multiple inputs.

Consider for example a user named Emily who is using her smart phone with a multi input touch sensitive device to surf the Internet to find a nearby clothing store. In this situation Emily may want to access functions such as pan zoom or scroll a web page. These functions do not correspond well to a single tactile input. Thus if Emily would like to zoom in on a map to find a nearby clothing store she may be obligated to interact with a displayed graphical object e.g. a tool bar if her phone is not multi touch enabled. If Emily s smart phone is capable of identifying multiple tactile inputs it and its accompanying hardware software firmware or application program interface API may be significantly more complex than a touch sensitive device that detects but one tactile input. A multi touch enabled device may be complex because the included hardware and software should account for concurrent tactile input scenarios as well as single touch scenarios. A single touch scenario occurs when for instance Emily draws the letter L on her touch device to enter a letter L into an instant messaging IM application on her smart phone.

In the following discussion an example environment is first described in which the tools enable a touch sensitive device to detect multiple tactile inputs intended for raw data entry. Sample multi touch and single touch scenarios are then described. Another example environment follows in which the tools detect multiple tactile inputs that are associated with a mapped function. Example techniques are also described. Although these tools are described as employed within particular kinds of computing environments in the following discussion it should be readily apparent that these tools may be incorporated within a variety of environments without departing from the spirit and scope thereof.

Other electronic devices can benefit from the described tools. Example other electronic devices include media players remote controls smart phones personal digital assistants personal audio devices global positioning systems Internet appliances wireless connectivity devices vehicle control systems vehicle entertainment systems tablet computers laptop computers standalone input and or output devices and the like.

The touch sensitive device includes one or more contact detectors capable of detecting concurrent tactile inputs. Although touch sensitive device is shown separate from a display the touch sensitive device may also be integrated with a display. In these embodiments the contact detectors included in the touch sensitive device may be aligned with the pixels of the display. The contact detectors output represents or otherwise reflects the tactile input detected.

In some embodiments an input controller is included in the touch sensitive device to convert the contact detector output into contact data that is useable by other components in the computing system . The input controller may be a separate module or implemented within computing system .

The input controller may combine output from multiple contact detectors output from different types of detectors and or other data previously generated by the input controller into contact data. This contact data represents the detected tactile inputs. Various kinds of information may be included about the tactile inputs such as pressure height and width of contact speed angle and the like. The input controller may also index or insert a time stamp in the contact data to indicate what timeframe is associated with the contact data or replace a contact detector s output with an x y position e.g. an x y pair based on the input controller s knowledge of the location of the contact detectors .

A multi touch platform with an input output module is included in the computing system and interacts with an application . The application provides or performs a function initiated by the input output module based on the contact data obtained from the input controller . The multi touch platform comprises or has access to computer readable media CRM on which various applications modules applets and the like may be stored. In some embodiments the touch sensitive device includes the multi touch platform or the multi touch platform s functions are provided by general purpose resources included in the computing system . In further embodiments the input output module and the input controller are incorporated in a common module. The multi touch platform may also be an implementation of an application program interface API that is suitable for use with the application .

The input output module in some embodiments or the touch sensitive device in some other embodiments is capable of persistently identifying contact data and or a tactile input with a unique identification that persist as long as the tactile input is represented in the contact data. Thus in some cases the touch sensitive device detects and tracks tactile inputs it ensures that a contact with the device has a same input output module for the duration of its existence e.g. contact down then contact moves then contact removed . When the touch sensitive device provides the data here the tactile input to the input output module it provides it with a unique identifier. From this point the input output module may know which data is for which contact and thus the tactile input for that contact is not confused with data from some other contact.

The input output module however may map each tactile input to cursor IDs which are then provided to the application . The input output module may re use its IDs for example with IDs and for a device capable of detecting five inputs e.g. five fingers five styluses or some combination of these . This enables the input output module to address several scenarios. In a first scenario the input output module exposes the application and the computing system s platform including the computing system s operating system OS to contact data or contact inputs representing multiple tactile inputs thereby permitting a user to interact and so cause the application to enter raw data via the touch sensitive device . In this way the application enters the raw data as initiated by the input output module . The raw data may be obtained from the contact data or the contact input recognized by the input output module . For example a painting application may accept x y data included in the contact data when a user makes three tactile inputs three are shown a first tactile input a second tactile input and a third tactile input via the touch sensitive device .

In another scenario the input output module the computing system with a gesture module therein acting between the input controller and the application or the application can recognize gestures that are mapped to functions. Some gestures are mapped to functions provided or known by the computing system e.g. pan zoom rotate and the like in which case the computing system may recognize gestures based on contact data. In some other cases gestures are provided by the application in which case the application may recognize the gestures using contact data. A gesture may be a combination of tactile inputs as electronically represented in contact data. As noted a function mapped to a gesture can be application specific or OS specific. When OS specific the computing system may include the gesture module with communications marked with dotted arrows.

When the application is entering raw data the input output module can handle the individual tactile inputs e.g. a first second and third tactile inputs respectively and represented in the contact data as cursors that enter the data in the application . Thus if a user is attempting to paint a picture using three fingers the input output module uniquely identifies the contact data representing the individual tactile inputs with an individual cursor identification cursor ID to detect and track the data. As noted above the input output module may receive an identifier from the touch sensitive device and then provide a cursor ID that the input output module ensures is unique. For example the input output module may identify x y positions with a cursor ID e.g. and so that the application is informed as to what x y data is associated with the cursor. The cursor ID persists for so long as the device recognizes the contact e.g. at least until a user removes his her finger .

When the input output module is handling raw data the behavior of the contact inputs may mimic input events such as stylus or mouse events like pen down pen up pen move or mouse up mouse down mouse move mouse click and the like. As a result the input output module initiates the application to enter the raw data. In this embodiment the input output module passes cursor IDs as an argument or a parameter to a notification so that the application is made aware of which cursor e.g. contact input or contact data is entering the data. In this manner the multi touch platform may implement an API configured for multiple tactile inputs. In some embodiments this API is semantically similar to a single mouse or single stylus API and includes a particular cursor ID in the notification passed by the input output module to the application .

In a single tactile input scenario the input output module may include the cursor IDs in the notification communicated to the painting application even though the remaining cursor IDs are not associated with active cursors e.g. not providing data . For example the input output module s notification includes a cursor ID even though the input output module has identified only one tactile input. In other words the input output module still provides a cursor ID in the notification associated with a single tactile input even though the touch sensitive device has failed to detect additional tactile inputs. In this manner additional tactile inputs are added without having to uniquely identify the original cursor when the additional tactile inputs are added.

In an embodiment of a stylus down notification including a cursor ID for a real time stylus API is described directly below the StylusInfo argument includes the cursor ID 

In the above embodiment the input output module makes the painting application aware of which cursor e.g. tactile input should provide a stylus down function by including the cursor ID in the StylusInfo argument above as part of handling the raw data so that the application enters the data correctly.

When recognizing gestures associated with certain types of tactile inputs the input output module initiates a function that is mapped to the gesture. The input output module may recognize or identify gestures based on single or combinations of tactile inputs including by recognizing individual tactile inputs represented in the contact data in accordance with the input output module s input mode. The input mode directs what gestures can be recognized. In this manner the input output module can detect and track a tactile input from beginning to end e.g. from a finger starting at position x yon a touch sensitive device moving along other positions and ending at position x y . The input output module may do so for individual tactile inputs in a multi touch scenario. Thus the input output module can recognize individual inputs in a multi touch scenario without interfering with single touch scenarios in which a single tactile input mimics computer mouse type behavior.

In some embodiments the input output module determines or the application may inform the input output module as to whether the input output module is to initiate data entry or recognize gestures that are mapped to functions. If for instance the application is a painting application the input output module may handle the contact data as data that is to be communicated to the painting application with a cursor ID and paint flows from all contacts. When the input output module is interacting with an Internet browser application the input output module recognizes gestures that are mapped to a function e.g. pan rotate primary select route find copy store and the like performable by an Internet browser application.

Further still in some embodiments a raw data mode may be used which may be selected or otherwise opted into by an application the input output module or a user. In the context of a painting application for example the painting application e.g. application may inform the platform that a raw data mode is desired. The platform may then disable gesture detection and create instances of a state machine or other entity capable of handling tactile input for each contact e.g. one for each of five fingers . Input from each contact may then be handled separately and in a manner directed to the application s needs. In the painting context for example each finger may have single finger events such as tap drag hold to enter right drag and right tap. Each of these events may then map to functions used by the application and or specific to the application.

As shown in and returning again to the example of Emily surfing the Internet consider multi touch enabled touch sensitive device . Emily s phone should address the above scenarios so that Emily is satisfied with the features of her smart phone. To do so Emily s phone should be capable of detecting and tracking a sufficient number of tactile inputs a first tactile input and a second tactile input are shown so that Emily can intuitively surf the Internet.

When surfing the Internet Emily may perform gestures that result in tactile inputs rather than interacting with a graphic user interface GUI such as a toolbar. If Emily is typical of most users she may become dissatisfied with her smart phone s features if she cannot intuitively interact with her touch sensitive device . The tools described herein permit Emily access to a wide variety of functions including entering data manipulating data performing tasks and the like.

For example after surfing the Internet for a nearby clothing store Emily may wish to Instant Message IM her friend Kira to see if she would like to join her on a shopping trip. The input output module is assumed to be included in Emily s phone not shown and it in conjunction with one or more applications in her phone is configured to recognize when Emily is attempting to initiate a function using multiple tactile inputs and when she is entering raw data. The input output module in conjunction with a painting application for example may recognize raw data as a paint stroke. The input output module in conjunction with a word processing application also for example may recognize raw data as a gesture. Many current phones and computing devices however cannot recognize when Emily is attempting to initiate a mapped function using two or more fingers from a scenario in which Emily is attempting to initiate a function using a single finger.

The tools described herein however use the input output module to enable Emily to intuitively use her phone. The input output module for example can be configured to persistently identify contact data or portions thereof that electronically represent tactile inputs with a unique identification unique among other currently used identifications. In at least this way the tools differentiate between multiple tactile inputs thereby enabling functions having a greater depth or additional functions by which users may interact with applications and computer systems.

For instance when Emily is surfing the Internet using an Internet browser application she may access a route find function by touching her thumb and forefinger to the touch sensitive device . In this case the contact detectors that Emily individually touched with her thumb or forefinger generate output based on the detected physical contact a first tactile input and a second tactile input . The output is converted into contact data that represents the tactile inputs e.g. the physical contact between Emily s thumb or forefinger and the contact detectors generating the output .

The input output module may persistently identify the contact data representing the contact between Emily s thumb and the touch sensitive device as 0 a zero identification while the input output module may persistently identify contact data representing the physical contact between Emily s forefinger and the touch sensitive device as 1 a one identification . In this example the input output module persistently identifies two portions of contact data with particular tactile inputs based on the contact detectors providing the output. The input output module may initiate a route find e.g. a map application to provide a visual display of a picture of the clothing store and a route find display providing directions from Emily s current location to the clothing store.

This persistent identification associated with the forefinger contact endures even though Emily removes her thumb e.g. one contact input is removed the input output module switches input mode or the computing system reboots. Thus when Emily removes her thumb from the touch sensitive device the contact data representing the forefinger is still persistently identified as 1 even though she removed her thumb. The input output module continues to persistently identify contact data representing the tactile input between Emily s forefinger and the touch sensitive device as 1 a one identification as long as the input output module links contact data or a contact input with the forefinger tactile input e.g. the input output module continues to receive contact data representing the tactile input . The identification of the tactile input associated with Emily s forefinger may persist until the forefinger tactile input is no longer represented in the contact data. This may permit for example Emily to place her thumb down on Kira s location on the map to generate a second route find. This route find function maps Kira to Emily note that Emily is located at the forefinger on the map .

As shown in once Emily is done surfing the Internet the input output module initiates the IM application to display a Unicode character y based on the input output module recognizing a single tactile input shaped like the letter y that is mapped to a Unicode character y to be provided by the IM application e.g. a mapped function . In this situation the input output module may persistently identify the contact data representing the y shaped tactile input with a zero identification. In this way the input output module can persistently identify the contact input representing the forefinger tactile input even though Emily subsequently touches her thumb to the touch sensitive device to initiate a send function that is mapped to two contact inputs.

In this embodiment the input output module uniquely identifies the contact inputs with persistent identifications that are unique among the current contact inputs rather than being entirely unique e.g. among current one or more identifications . For example the input output module may be configured to persistently identify a first contact input as 0 while subsequent contact inputs are numbered 1 through 4 .

The input output module may initiate a mapped function in part because a multi touch platform is interacting with an Internet browser application that is configured to provide mapped functions. Thus the input output module may initiate the Internet browser application to provide a scroll function upon recognizing gestures that are mapped to the scroll function . For example the input output module may access a lookup table include in a library that associates the scroll function with a first contact input and a second contact input that perpendicularly diverge from a common axis. In this case the input output module may persistently identify the first contact input as 0 and the second contact input as 1. The first and second contact inputs represent a first tactile input and a second tactile input that were detected by one or more contact detectors included in the touch sensitive device .

In some embodiments the input output module is messaging the application such as when initiating a mapped function in such a case the input output module reports on the available identifications even though no contact data is associated with the identification. A message is a notification that is passed to the application to initiate the function that is mapped to the identified contact input. By way of example when the touch sensitive device and input output module are configured to detect and identify respectively five contact inputs that represent five tactile inputs the input output module message includes updates for the five input output modules even though only two input output modules are currently associated with active contact data.

In other embodiments the application with which the multi touch platform is interacting updates the input output module with gesture context specific to the application . If the application is a photo editing application the application may update or otherwise inform the input output module of specific gestures or functions that are relevant to the application . Thus as the user interacts with a photo displayed on a display screen the gesture context enables a transformation e.g. an affine transformation to permit the photo editing application to display the photo s current size rotation position and the like. A gesture context may be established as part of initiating communication between multi touch platform and application .

In some other embodiments the application may have functions that use cached data such as that from a dragging finger the cached data being from where the finger was previously placed . In some inking contexts e.g. with a painting application for example the platform puts into a queue data from a first tactile input received from the contact detectors . The platform then waits on additional data from the touch sensitive device . If the first tactile input starts to drag move from its first location a single finger inking mode may be used. In this case the cached data is replayed and future tactile inputs e.g. are ignored. If before the first tactile input starts to move a second tactile input is received the cached data is discarded and another mode is instead used such as one for multi touch gestures.

The components modules functions and techniques discussed above may be implemented singly or in combination. Generally any of the tools and functions described herein can be implemented using software firmware hardware e.g. fixed logic circuitry manual processing or a combination of these implementations. Additionally these functions and tools can be embodied as executable instructions that are included in one or more computer readable storage media e.g. multi touch platform and input controller and and input output module and . The features of the techniques described below are platform independent meaning that the techniques may be implemented on a variety of platforms having a variety of processors and memory.

The following discussion describes techniques that may be implemented utilizing the previously described systems and devices and may be implemented in hardware firmware software or a combination thereof. The procedure is illustrated as a set of blocks that specify acts performed by one or more devices and are not necessarily limited to the order shown. A variety of other examples and sub techniques are also contemplated.

Block detects tactile inputs from an object e.g. a user s finger or stylus contacting a touch sensitive device. The tools produce output from a user touching his her finger to one or more contact detectors included in the touch sensitive device. In some embodiments the tools detect concurrent tactile inputs. The output represents the tactile input such as the detected characteristics of the tactile input. For example the output reflects the location of a tactile input the force of a tactile input the duration of the tactile input and the like.

Block converts the output to contact data. Contact data may include the location of the tactile input the duration of the tactile input movement tactile input pressure and the like. The tools may concurrently convert output from multiple tactile inputs. In some embodiments the tools convert contact data for multiple tactile inputs by converting output as it arrives or by sampling contact detectors.

Block determines whether the tools are handling data for entry in an application e.g. initiating a raw data entry function or are initiating a mapped function. The tools determine whether data is being entered or a mapped function is to be initiated based on the application that is interacting with the tools. For instance if the tools are interacting with a word processing application the tools may access a lookup table or other library for mapped functions. When the tools are interacting with an application that accepts or enters raw data the tools initiate the application to enter and display x y data obtained from the contact data. The tools determination may be made as part of an initiation procedure with the application. The tools proceed to block if raw data or block if a gesture has a mapped function.

Block persistently identifies the contact data and or the contact input with a cursor ID when the tools are interacting with an application that accepts raw data. The tools persistently identify contact data with a cursor ID so that the application enters the x y data as if the data was provided by a cursor. The tools identify the raw data with a cursor ID that is unique among the current cursor IDs. In this manner the tools individually detect and or tract multiple tactile inputs as cursors that mimic the tactile inputs as represented by the contact data. The tools identify additional contact data in a similar manner.

Block passes the cursor ID as an argument to the notification. The tools may pass the cursor ID as an argument to a notification communicated to the application. For example a pen up notification includes the cursor ID as part of the argument so that the application is informed as to which contact input is providing the data.

Block provides the raw data entry function using the cursor ID. The tools communicate x y data identified with a cursor ID to the application that enters the raw data. For instance a drawing application enters the x y data and displays a cursor that mimics the tactile input as initiated by the tools.

If the tools determine that the tactile input is not intended for entry of raw data the tools proceed to block which persistently identifies contact data that represents a tactile input. When the tools are configured to initiate mapped functions the contact data representing a tactile input is identified with an identification that is unique among the current tactile inputs represented in the contact data. In this manner the tools detect and track the tactile input as represented by the contact data from other tactile inputs that are represented in the contact data.

Block identifies one or more gestures. The tools may recognize the gestures by accessing a library or lookup table that maps tactile inputs associated functions. A persistent identification is used to identify individual inputs when the tools are recognizing multiple inputs. For example when a user is making a pinching motion the two diverging or converging tactile inputs are represented with a 0 a zero identification and with a 1 a one identification respectively. In this manner the tools track the uniquely identified first and second inputs as they move. This may permit the tools to continue to identify the second input with a 1 even though the first tactile input is removed.

When the tools recognize the gesture associated with a mapped function block initiates the mapped function. For instance if the tools identify two side by side taps identified as tactile input 0 and tactile input 1 the tools initiate the application to double click on a graphical object. Mapped functions include but are not limited to storing data zooming panning scrolling entering Unicode text and the like.

Block messages the application with an update of the available identifications. The tools may send a message that includes an update for the available identifications even though some of the identifications are not linked to active contact data. After block the tools proceed to block which provides the mapped function that is initiated by the tools.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

