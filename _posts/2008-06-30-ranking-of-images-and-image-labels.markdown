---

title: Ranking of images and image labels
abstract: The subject matter of this specification can be embodied in, among other things, a method that includes determining a score for an image of a plurality of images with respect to each of one or more terms, identifying one or more of the terms for each of which the score for the image with respect to the respective identified term satisfies a criterion, and associating the identified terms with the image. Determining the score for the image with respect to a respective term includes determining probabilities of navigating between images in the plurality of images and determining the score for the image with respect to the respective term based on the probabilities.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07961986&OS=07961986&RS=07961986
owner: Google Inc.
number: 07961986
owner_city: Mountain View
owner_country: US
publication_date: 20080630
---
Image search engines have become a popular tool on the Internet. These search engines help users find images that match their criteria. Some of these search engines index images by keywords or labels. Such image search engines retrieve images by matching users search queries against these keywords or labels.

The keywords or labels for indexing an image can be drawn from text surrounding the image in a web page or other text associated with the image e.g. the filename of the image metadata associated with the image for example. The keywords or labels can provide some indication of the content of an image. For example an image of a horse can be associated with the keyword horse. In some cases the keywords for an image that are extracted from the text may be uninformative or not useful. For example words such as cool and wow generally are uninformative with regard to the content of an image. Poorly labeled images can degrade the quality of an image search result.

In a first general aspect a method is described. The method includes determining a score for an image of a plurality of images with respect to each of one or more terms identifying one or more of the terms for each of which the score for the image with respect to the respective identified term satisfies a criterion and associating the identified terms with the image. Determining the score for the image with respect to a respective term includes determining probabilities of navigating between images in the plurality of images and determining the score for the image with respect to the respective term based on the probabilities.

In a second general aspect a system is described. The system includes a computer readable medium one or more processors and instructions stored in the computer readable medium and configured for execution by the one or more processors. The instructions include instructions to determine a score for an image of a plurality of images with respect to each of one or more terms identify one or more of the terms for each of which the score for the image with respect to the respective identified term satisfies a criterion and associate the identified terms with the image. The instructions to determine the score for the image with respect to a respective term comprises instructions to determine probabilities of navigating between images in the plurality of images and determine the score for the image with respect to the respective term based on the probabilities.

In a third general aspect a system is described that includes means for determining a score for an image of a plurality of images with respect to each of one or more terms means for identifying one or more of the terms for each of which the score for the image with respect to the respective identified term satisfies a criterion and means for associating the identified terms with the image. The means for determining the score for the image with respect to a respective term includes means for determining probabilities of navigating between images in the plurality of images and means for determining the score for the image with respect to the respective term based on the probabilities.

In another general aspect a method is described that includes identifying a set of images. One or more of the images are associated with a set of one or more terms. The method also includes determining probabilities of navigating between images in the set of images ranking each term in the set of terms with respect to an image of the set of images based on the probabilities and associating with the image a term of the set of terms that has a highest ranking with respect to the image.

In yet another general aspect a method is described. The method includes identifying a set of images. At least a subset of the images is associated with a term. The method also includes determining probabilities of navigating between images in the set of images ranking each of the set of images with respect to the term based on the probabilities and selecting an image of the set of images that has a highest ranking with respect to the term.

Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages. The importance and relevance of terms with respect to an image can be determined. The most relevant term for an image can be identified. Terms whose relevance level with respect to an image is above a threshold is associated with the image.

The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features aspects and advantages of the subject matter will become apparent from the description the drawings and the claims.

Content hosts host content. The hosted content can include text images audio video and so forth. In some implementations a content host hosts one or more images. An image hosted by the content host can be downloaded by or pushed to a user device . The image may be downloaded or pushed in a web page written in the Hypertext Markup Language HTML or any other suitable language for authoring web pages. In some implementations content host is a web server that hosts web pages and images.

The environment includes one or more user devices . The user device can include a desktop computer laptop computer a media player e.g. an MP3 player a streaming audio player a streaming video player a television a computer a mobile device etc. a mobile phone or other device that can access content via network .

A content host can allow a user device to access images hosted by the content host . In some implementations a user at a user device can access images at a content host through a web browser application for example.

A search system indexes content e.g. web pages images etc. hosted by content hosts . The search system also receives search queries for content and returns search results drawn from the indexed content in response to the received queries.

The search system includes an image search system . An image search system indexes images receives search queries for the images and returns results in response to the queries. In some implementations a crawler associated with the image search system crawls the content hosts for images and indexes the crawled images. In some implementations the image search system stores copies of the crawled images.

The image search system can receive search queries for images from user devices . An image search query can include one or more terms. A term can include one or more words phrases numbers characters and so forth. In some implementations a user at a user device accesses a user interface of the image search system and enters a search query through for example a browser application at the user device . For an image search query the image search system finds the indexed images that satisfy the query and return the search results to a user device for presentation to the user. The search results for an image search can include thumbnails of the images that satisfy the query and hyperlinks to the images or web pages that include the images. In some other implementations a user at a user device accesses a user interface of the search system and enters a query for images. The search system finds the images that satisfy the query using the image search system . The search system returns the search results to the user device for presentation to the user.

The image search system can associate terms with images and index the images based on the associated terms. A term can include one or more words phrases numbers characters and so forth. In some implementations an image satisfies an image search query if the query matches the terms associated with the image and optionally other criteria. A term associated with an image can also be referred to as a label or a keyword. 

In some implementations the image search system associates terms with an image that are derived from metadata of the image. For example the metadata of a JPEG image file can include terms that indicate a title a description categories keywords and the like. In some implementations the image metadata is data embedded in an image file in accordance with the Exchangeable Image File Format EXIF specification. The image search system can read the metadata of the image as well as the filename of the image and extract terms from the metadata or the filename.

In some implementations the terms that are associated with an image can be determined by the image search system . The image search system can extract one or more terms associated with content related to the image and associate the terms with the image. For example the image search system can extract terms from text from a web page in which the image appears anchor text of links to the image text from a web page to which the image links if the image is an anchor for a hyperlink to the web page and so on.

In some implementations the image search system can determine terms to be associated with an image based on user testing. For example the image search system can show a population of users an image and ask the users to specify terms that come to mind when they see the image and optionally order them. The terms entered by the users provide an indication of what users believe the subject matter topics or concepts of the image are. The image search system can select the most popular of the user specified terms to associate with the image.

The image crawling module crawls content hosts for images. The image crawling module accesses content at the content hosts such as images and any other content associated with the images. The crawling module receives copies of the crawled images e.g. by downloading and other content for further processing by the image search engine .

The image terms module determines what terms are associated with an image. The image terms module extracts terms from metadata associated with an image e.g. filename EXIF metadata and so on . The image terms module can also determine the terms that may be associated with an image from other content associated with the image e.g. a text of a web page in which the image is associated anchor text of hyperlinks to the image or text of a web page to which the image links .

The image features module identifies features of the images. The image features module can determine for an image one or more features. The image similarity module determines a degree of similarity for pairs of images. The image similarity module compares for any pair of images within a repository or set of images the features of the images in the pair as identified by the image features module and determines a value representing a degree of similarity between the two images in the pair. Further details regarding the identification of features and the determination of the degree of similarity are described below.

The probabilities module determines estimated transitional probabilities for pairs of images. A transitional probability between images is a probability that a user will select an image given another image under particular conditions. Further details regarding transitional probabilities are described below.

Image indexing module indexes images according to the terms associated with an image. The indexing enables searching of the images based on the terms and in particular using queries that contain terms.

The image search server processes search queries for images and returns search results in response to the queries. A search query for images can include one or more terms. The image search module receives a query from a user device for example finds images e.g. images from content hosts and indexed in image repository index that satisfy the search query and returns the search results. In some implementations the search results are returned in a web page that shows thumbnails of the images that satisfy the query and information related to the images e.g. image file size and file type image dimensions or domain or content host at which the image is located .

Information regarding the images crawled by the image crawling module and optionally copies of the crawled images can be stored in an image repository index . In some implementations the image repository is a database e.g. a MySQL database of images and image information. The image repository index also stores an index of images that have been crawled or received by the image search engine . The images are indexed by the terms associated with the images. A copy of an image does not have to be stored in the image repository index to be in the index.

The image search engine can communicate with a user device over one or more networks . In some implementations the user device is an implementation of user device . The user device can include an application . In some implementations the application is a web browser. A user using the user device can access a user interface of the image search engine through the application .

As described above image search engine uses terms to index images. Thus the relevance of a term to a document affects the quality of the search results returned by the image search engine . Rankings can be calculated for terms associated with images according to an image term ranking function.

In some implementations the image term ranking function TRA I Q is a probability distribution that represents a likelihood that a user selects e.g. clicks on a particular image I given a query Q which includes one or more terms and an image repository D under the following scenario 

2 given image A the user can request additional images similar to image A and the user is given the top N image results based on similarity between image A and the remainder of the images in D 

3 the user will select an image from those top N results image B with transitional probability P A B and

In some other implementations the image term ranking function TRB I Q is a probability distribution that represents a likelihood that a user selects e.g. clicks on a particular image I given a query Q which includes one or more terms and an image repository D under the following scenario 

2 given image A the user can request additional images similar image A and the user is given the top N image results based on similarity between image A and the remainder of the images in D 

3 the user will select an image from those top N results image B with transitional probability P A B however the user has some probability of selecting an image that is associated with query Q and

Multiple images are received . In some implementations the images can be received as part of a crawl by image crawling module for example of content hosts hosting the images. In some implementations the images can also or alternatively be received from an upload of images to the system. In some implementations content associated with the images e.g. web pages in which the images are located is also received. These received images are indexed by the image indexing module .

A received image can be associated with one or more terms. For example the image search engine can read the metadata of the image for an image and extract any title description category keyword or other terms from the metadata and associate the terms with the image. As another example terms that can be associated with the image can be determined from other content associated with the image e.g. web page in which the image is located or anchor text of hyperlink to the image . Any number of the images can be associated with a particular term and an image can be associated with multiple terms.

In some implementations the terms are extracted from the metadata or other content associated with the image without any discrimination as to whether a term is useful. In some other implementations a metric can be determined for terms and terms with values for the metric that are above a threshold or satisfy some criterion are selected and associated with the image. In some implementations the metric is the term frequency inverse document frequency TFIDF of the term. For example say that an image is included in a web page that includes terms X and Y. If term X has a TFIDF with respect to the web page that is above a predefined threshold and the TFIDF for term Y is not above the threshold then term X and not term Y is associated with the image. Using the TFIDF as a metric can be useful for removing relatively uninformative terms e.g. a the prepositions etc. from consideration.

Similarity scores are determined for pairs of images . For example an image can be paired with one or more of the remaining images and for each pair image similarity module can determine a degree of similarity between the image pair. Further details regarding the determination of a degree of similarity between a pair of images are described below in reference to .

Probabilities of navigation between the images are determined . For any two images A and B probabilities module can determine a transitional probability P A B i.e. the transitional probability as described in relation to the image term ranking functions TRA or TRB described above . In some implementations P A B is approximated using the similarity between images A and B and exploiting the insights that 1 the user is likely to navigate to an image that is more similar to A than to an image that is less similar to image A and 2 the user is likely to ignore images that are too similar to image A. In some implementations the transitional probability is estimated by defining a beta distribution over the image similarity. An example beta distribution is illustrated in graph in . In graph the x axis is the image similarity 0 1 between two images and the y axis is the corresponding transitional probability. In the beta distribution illustrated in graph the transitional probability increases monotonically as the image similarity increases up to a certain point. After the image similarity has reached a certain point the transitional probability decreases monotonically. In other words the transitional probability decreases when the two images are too similar to each other.

Other functions or distributions for expressing the transitional probability as a function of image similarity can also be used. For example the function can be linear. The function can also be specified explicitly by the user diversity etc or estimated and learned from how user interacts with the images from usage data. The function can be estimated learned for each user or for a collection of users those fit into one demographic group .

In some implementations the determination of the transitional probability can be augmented by including one or more additional factors. In some implementations a metric of the quality of image B is included. For example image quality can be measured using one or more query independent indicia of image quality e.g. color depth of the image how much of the image is in focus level of saturation in the image and so on . In some implementations the image quality metric is a score between 0 and 1 inclusive that is a function of the one or more indicia of image quality.

In some implementations another additional factor is a similarity of images A and B based on a relationship between pages or locations from which images A and B were crawled e.g. pages or locations where images A and B are hosted . For example images crawled from related web pages e.g. same blog same website pages in the same social network can be considered to be more similar than images from unrelated web pages. An example of a relationship based similarity is a structural context similarity which is disclosed in Jeh et al. SimRank A Measure of Structural Context Similarity Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining July 2002 pages 538 543. A score for the relationship based similarity e.g. a structural context similarity score can be calculated and used as an additional factor in the approximation of the transitional probability. Click data can also be used to enhance the transitional probability estimate. For example co click data may measure the likelihood that an image is viewed before or after another image. Given a sufficient amount of co click data then transitional probability can be computed from it. Given limited co click data then it can be used to refine an estimation of image transition from similarity measurements.

It should be appreciated that the additional factors described above are examples. Other additional factors can be used.

As described above the additional factors can be used along with the image similarity to approximate estimate or otherwise determine the transitional probability. In some implementations the probability P A B is a function of a product of the image similarity and the additional factors. For example P A B can be proportional to the product of the image similarity score between images X and Y the image quality score of image Y and the relationship based similarity score between images X and Y. In some other implementations the probability P X Y is a function of a linear combination of the image similarity and the additional factors. For example P X Y can be proportional to a linear combination of the image similarity score between images X and Y the image quality score of image Y and the relationship based similarity score between images X and Y.

More generally any suitable function can be used to derive a transitional probability value from an image similarity metric and any number of additional factors.

In some implementations for a pair of images whose similarity is below a predetermined threshold the transitional probability is 0.

For each image in the multiple images scores with respect to each of one or more terms are determined . The scoring and ranking module for example can determine a score under image term ranking function TRA or TRB for an image with respect to each of one or more terms. The output is one or more scores for an image where each score is with respect to a respective term. Thus for example for an image I the output is a score for I with respect to a term M a score for I with respect to a term N and so on. The algorithms for determining the scores are described in further detail below.

Terms for which the score for the image with respect to the term satisfies a criterion are identified . The scoring and ranking module can identify terms for which the score for an image with respect to the term satisfies one or more particular criteria. The particular criteria depend on the particular objective. For example if the objective is to identify a single best term for an image then a criterion can be that the score for the image with respect to the term is the highest among the scores for the image with respect to each of one or more terms. As another example if the objective is to identify one or more good terms for the image then a criterion can be that the score for the image with respect to the term is greater than a predetermined threshold and or that the score be in the top N among the scores for the image with respect to each of one or more terms where N is a natural number greater than 0.

The image search engine associates the identified terms with the image . For example the image indexing module can add the identified terms as keywords for the image in the index . When a user enters a query that includes the identified terms the image can be included as a search result.

Process determines scores for an image with respect to each of one or more terms and identifies terms for which the scores for the image with respect to the terms satisfy a criterion. In some implementations the reverse i.e. determining scores for one or more images with respect to a term and identifying images whose scores with respect to a term satisfy a criterion can be performed. In these implementations the objective can be the identification of a most relevant image or relatively more relevant images for a term among one or more images the criteria for identifying images can be the image with the highest score with respect to the term or images whose scores with respect to the term are above a predetermined threshold and or are in the top N respectively. Further details regarding determining scores for one or more images with respect to a term are described below.

One or more global and or local features of Image A and one or more global and or local features of Image B are identified . Examples of image features that may be used include image features based on for example intensity color edges texture or other aspects of the image. Features can be extracted using wavelet transforms or other convenient techniques. For example regarding intensity each image may be divided into small patches e.g. rectangles circles or polygons and an intensity histogram computed for each patch. Each intensity histogram may be used as a feature for the image. Similarly as an example of a color based feature a color histogram may be computed for each patch or for different patches within each image. A color histogram can be similarly computed to obtain a color based histogram. The color histogram may be calculated using any color space e.g. the RGB red green blue color space YIQ luma and chrominance or another color space.

Histograms can also be used to represent edge and texture information. For example histograms can be computed based on patches of edge information or texture information in an image. For wavelet based techniques a wavelet transform may be computed for each patch and used as an image feature.

The features discussed above represent an exemplary list of possible image features that may be used for determining similarities between images. Other image features may be used. In some implementations the features are identified using the known scale invariant feature transform SIFT . An examples of the SIFT technique is described in Lowe Distinctive Image Features from Scale Invariant Keypoints Vol. 60 Issue 2 2004 pp. 91 110.

In some implementations a global feature is a feature that is identified for the image as a whole. For example a color or intensity histogram of the entire image is a global feature. A local feature is a feature that is identified for a portion of the image. For example a color or intensity histogram of a patch in the image is a local feature.

In some implementations to improve computation efficiency features may be computed only for certain areas within images. For example objects of interest within an image may be determined and image features may only be computed for the objects of interest. For example if the image feature being used is a color histogram a histogram may be computed for each patch in the image that includes an object of interest. Objects of interest within an image can be determined in a number of ways. For example for color objects of interest may be defined as points where there is high variation in color i.e. areas where color changes significantly . Objects of interest can be determined mathematically in a variety of ways and can be based on determining discontinuities or differences from surrounding points. In some implementations the objects of interest are determined based on points of interest or keypoints identified in the image. The SIFT technique is an example of one technique for locating keypoints and objects of interest and features for these keypoints. In some implementations the computed image features are features that are local to the keypoints or objects of interest.

In some implementations a feature identified for a keypoint includes a position e.g. X Y coordinates of the image orientation and scale e.g. radius of a patch centered on the keypoint . When these image features are compared for a pair of images as described below the orientations and scales of the features can be compared as a geometrical verification between the two images in the pair.

As an example of the use of keypoints say that Image A is an image of the Eiffel Tower where the Eiffel Tower takes up a large portion of the image and that Image B is an image of a tourist with the Eiffel Tower in the background where the Eiffel Tower takes up a small portion of the image. Using keypoint identification points on the Eiffel Tower in Image A and on the Eiffel Tower in Image B can be identified as keypoints. The comparison of these features may indicate that Image B contains an object Eiffel Tower that is in Image A and vice versa.

Additionally in some implementations the various features described above may be computed using different image scales. For example an image can be examined and features computed in its original scale and then features may be successively examined at smaller scales. Additionally or alternatively features may be selected as features that are scale invariant or invariant to affine transformations. The SIFT techniques for example can be used to extract distinctive invariant objects from images. The extracted objects are invariant to image scale and rotation.

The identified features are compared the features of Image A are compared to the corresponding features of Image B . A degree of similarity or a similarity score between Image A and Image B is determined based on the comparison . For each feature that is to be used a comparison function may be selected. A number of different comparison functions may be used to compare images. The particular comparison function to use may be decided offline or in non realtime operation. The output of the comparison function can be used to determine the similarity. For example the similarity can be a linear combination of the outputs of the comparison functions.

In general a comparison function may operate to generate a value defining a similarity measure between a particular feature in one image and the corresponding feature in another image. As an example of a possible comparison function consider a simple histogram comparison function which is described in pseudo code in Table I below. As shown in Table I the histogram comparison function returns a value that is the sum of the absolute values of the differences between corresponding bins in the input histograms. Smaller values returned from this function indicate greater similarity between the input histograms.

The histogram comparison function of Table I is exemplary and other comparison functions can be used to compare histograms. For example squared differences may be used rather than absolute differences bin correlations may be taken into account instead of absolute differences or percent differences may be used instead of absolute differences. Additionally for image features other than those based on histograms different comparison functions may be used.

The selection of the image features to use and the comparison functions to use may be performed offline or in non realtime operation. For example image features module and image similarity module can be initially configured to use one or more image features and one or more comparison functions. After these initial acts image features module and image similarity module may function in a realtime mode to determine pairwise degrees of similarity for a set of input images such as images received from a crawl by image crawling module .

In some implementations the similarity between Image A and Image B is a linear combination of scores from comparisons between corresponding features of Image A and Image B. An example algorithm for calculating the image similarity is shown in pseudo code in Table II below.

In the algorithm shown in Table II each feature Fof Image A is compared with every feature Fof Image B that is the same feature type. In other words if Fis a color histogram then the comparison is performed with the color histogram features of Image B if Fis an edge histogram then the edge histogram features of Image B are compared etc.

In the operation shown in Table II each image feature is weighted equally. In some implementations different features may be weighted differently. For example color based features may be less important than intensity or edge based features. Accordingly a features similarity score may be multiplied by a weight that reflects the importance of the particular feature.

In some other implementations the degree of similarity between two images is calculated as the number of shared keypoints i.e. keypoints whose feature s match divided by the total number of keypoints.

The operation shown in Table II can be relatively computationally expensive if repeated for many images as it requires Ncomparisons for a set of N images and for each comparison M Mfeature comparisons for Mand Mlocal features in each image. Techniques are known that may accelerate this type of operation. For example one such technique is described in Grauman et al. The Pyramid Match Kernel Discriminative Classification with Sets of Image Features Tenth IEEE International Conference on Computer Vision October 2005 Vol. 2 pp. 1458 1465.

Process above describes determining scores for an image with respect to a term. The method of calculating the score depends on the desired image term ranking function TRA or TRB.

In some implementations for ranking function TRA the method of calculating the score labeled as TR is as follows. Given a set of images M with images M M M. . . Mand their pairwise transitional probabilities P TR M Q for an image Mand term Q can be calculated recursively as described below.

First for a collection of images M which is a subset of all of the images known to the image search engine which consists of the images stored and or indexed in the image repository index that are associated with term Q the TRfor each image in Mis initialized as follows number of times appears in the set of terms associated with number of times appears in image index 214 if is associated with 0 otherwise Equations I 

After the initialization of the TRvalues the following set of calculations are repeated until convergence . . . . . . . . . . . . Equations II 

For each of the equations above the sum of the transitional probabilities e.g. P M M P M M P M M . . . P M M in the equation for TR M Q is equal to 1.

In some other implementations for TRB the method of calculating the score labeled as TR is as follows. Given a set of images M with images M M M. . . Mand their pairwise transitional probabilities P TR M Q for an image Mand term Q can be calculated recursively as described below.

First for a collection of images M which is a subset of all of the images known to the image search engine which consists of the images stored and or indexed in the image repository index that are associated with term Q the TRfor each image in M is initialized as follows TR M Q TR M Q . . . TR M Q 1 n where n is the number of images in M.

After the initialization of the TRvalues the following set of calculations are repeated until convergence 1 . . . 1 . . . . . . 1 . . . Equations III where M Q is 1 if term Q is associated with image Mand 0 otherwise. d is a predefined value. In some implementations d is 0.85. In some implementations a desirable number of iterations for Equations I and II above are based on experiment or on domain knowledge.

Example calculations of TRand TRwill now be illustrated using . illustrates an example similarity graph of images. The nodes and represent images A B C and D respectively. The edges between the nodes represent similarities between images that are above a predefined threshold and corresponding non zero transitional probabilities. For example graph includes no edge between nodes and their pairwise similarity is below the threshold and their transitional probability A D or D A is 0. Graph also includes terms and that are associated with images A B C and D respectively.

Thus for example the transitional probability from A to B P A B is 0.75000 and the transitional probability from B to A P B A is 0.25000.

In Table I each of the images has a non zero 0.25 probability of transitioning to itself. Further the sum of the transitional probabilities from an image is 1. Thus for example the sum of the transitional probabilities from A is 0.25000 0.75000 0 0 1 and the sum of the transitional probabilities from B is 0.25000 0.25000 0.25000 0.25000 1.

The calculation of TRusing the transitional probabilities of Table I will now be described. As an example the calculation of TRA I eiffel tower for I images A B C and D will be illustrated. As described above the first step in the calculation of TRis the initialization of TRusing Equations I eiffel tower 0 eiffel tower is not associated with image eiffel tower eiffel tower appears once in the terms associated with image and appears 3 times among the terms associated with images or eiffel tower eiffel tower appears once in the terms associated with image and appears 3 times among the terms associated with images or eiffel tower eiffel tower appears once in the terms associated with image and appears 3 times among the terms associated with images or 

With the TRvalues initialized Equations II can be iterated using the initialized values and the transitional probabilities eiffel tower 0.25 0 0.25 0.333 0 0.333 0 0.333 0.08333 eiffel tower 0.75 0 0.25 0.333 0.25 0.333 0.25 0.333 0.25000 eiffel tower 0 0 0.25 0.333 0.25 0.333 0.50 0.333 0.33333 eiffel tower 0 0 0.25 0.333 0.50 0.333 0.25 0.333 0.33333 Iteration 1 eiffel tower 0.25 0.08333 0.25 0.25000 0 0.333 0 0.333 0.08333 eiffel tower 0.75 0.08333 0.25 0.25000 0.25 0.333 0.25 0.333 0.29167 eiffel tower 0 0.08333 0.25 0.25000 0.25 0.333 0.50 0.333 0.3125 eiffel tower 0 0.08333 0.25 0.25000 0.50 0.333 0.25 0.333 0.3125 Iteration 2 . . . eiffel tower 0.09912 eiffel tower 0.29915 eiffel tower 0.30086 eiffel tower 0.30086 Iteration 6 

The example above illustrates calculating the TRvalues for the images with respect to a particular term. Equations I and II can also be used to calculate TRvalues of an image with respect to each of multiple terms. For example TR A Q for Q arc de triomphe France Paris eiffel tower street scenes and uncle bob can be calculated to score and rank the terms with respect to image A.

The calculation of TRusing the transitional probabilities of Table I will now be described. As an example the calculation of TR I eiffel tower for I images A B C and D will be illustrated. The first step in the calculation is the initialization of the TRvalues. Thus TR A eiffel tower TR B eiffel tower TR C eiffel tower TR D Eiffel tower 0.25.

With the TRvalues initialized Equations III can be iterated using the initialized values and the transitional probabilities with d 0.85 eiffel tower 0.15 4 0 0.25 0.25 0.25 0.25 0 0.25 0 0.25 0.10625 eiffel tower 0.15 4 1 0.75 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.35625 eiffel tower 0.15 4 1 0 0.25 0.25 0.25 0.25 0.25 0.5 0.25 0.25 eiffel tower 0.15 4 1 0 0.25 0.25 0.25 0.5 0.25 0.25 0.25 0.25 Iteration 1 eiffel tower 0.15 4 0 0.25 0.10625 0.25 0.35625 0 0.25 0 0.25 0.098281 eiffel tower 0.15 4 1 0.75 0.10625 0.25 0.35625 0.25 0.25 0.25 0.25 0.287188 eiffel tower 0.15 4 1 0 0.10625 0.25 0.35625 0.25 0.25 0.5 0.25 0.272578 eiffel tower 0.15 4 1 0 0.10625 0.25 0.35625 0.5 0.25 0.25 0.25 0.272578 Iteration 2 . . . eiffel tower 0.07000 eiffel tower 0.25121 eiffel tower 0.26154 eiffel tower 0.26154 Iteration 6 

As shown for the Equation III above in some implementations the iterations converge to a stable distribution regardless of an initial starting point. The example above illustrates calculating the TRvalues for the images with respect to a particular term. Equations III can also be used to calculate TRvalues of an image with respect to each of multiple terms. For example TR A Q for Q arc de triomphe France Paris eiffel tower street scenes and uncle bob can be calculated to score and rank the terms with respect to image A.

An image can be associated with multiple terms where some of the terms may be noisy terms that provide little or no information. Examples of noisy terms include and www and so on. The noisy terms also tend to be terms that appear very often in documents. In some implementations the initial value of TRfor an image with respect to a term can be normalized to account for the degree of rarity of the term in documents by multiplying the initial TRA value by the inverse document frequency i.e. number of documents in a corpus e.g. web pages that include the term divided by the total number of documents in the corpus . In some implementations this can also be performed for TRvalues.

In some implementations the set of images for which and based on which the scores are calculated can be limited in scope. For example the set of images can be limited to indexed images from a particular web site to images associated with a particular term images having particular characteristics e.g. black and white at least 10 green etc. or images having any combination of these and any additional criteria.

The memory is a computer readable medium such as volatile or non volatile memory that stores information within the system . The memory could store data structures representing image repository for example. The storage device is capable of providing persistent storage for the system . The storage device may be a floppy disk device a hard disk device an optical disk device or a tape device or other suitable persistent storage means. The input output device provides input output operations for the system . In some implementations the input output device includes a keyboard and or pointing device. In some other implementations the input output device includes a display unit for displaying graphical user interfaces.

The disclosed and other embodiments and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. The disclosed and other embodiments can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter effecting a machine readable propagated signal or a combination of one or more them. The term data processing apparatus encompasses all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user the disclosed embodiments can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

The disclosed embodiments can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of what is disclosed here or any combination of one or more such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN e.g. the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

While this specification contains many specific implementation details these should not be construed as limitations on the scope of what being claims or of what may be claimed but rather as descriptions of features specific to particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a subcombination or variation of a subcombination.

Similarly while operations are depicted in the drawings in a particular order this should not be understand as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system components and modules in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components modules and systems can generally be integrated together in a single software product or packaged into multiple software products.

Particular embodiments of the subject matter described in this specification have been described. Other embodiments are within the scope of the following claims. For example the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example the processes depicted in the accompanying figures do not necessarily require the particular order shown or sequential order to achieve desirable results. In certain implementations multitasking and parallel processing may be advantageous.

