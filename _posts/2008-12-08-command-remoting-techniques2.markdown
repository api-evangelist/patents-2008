---

title: Command remoting techniques
abstract: Techniques for improved command level remoting are disclosed. In embodiments of the invention, commands to generate vertices are sent in a terminal service session. As commands to draw vertices are generated by a server to be sent to a client to display, they are analyzed by the server. Where some of those vertices have been previously sent to the client, such as to generate a previous bitmap image, the server determines not to send those vertices to the client, and sends the client the new vertices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09639963&OS=09639963&RS=09639963
owner: Microsoft Technology Licensing, LLC
number: 09639963
owner_city: Redmond
owner_country: US
publication_date: 20081208
---
Terminal services provide techniques for allowing access to applications and data stored on servers. User input is sent over a network connection to a server and audio and graphics are sent from the server to a client. Over the years different techniques have been developed to remote graphics such as command level remoting and bitmap level remoting.

Bitmap level remoting is generally considered to be the easier of the two techniques to implement. In bitmap remoting the graphics processing is performed on the terminal server and the final image e.g. an array of pixel values that forms a bitmap is compressed and sent over the network to the client. This technique requires a server that has enough computational power to render images for one or more clients.

Command level remoting on the other hand offloads the graphics processing to the client. Primitives e.g. vertices that can be processed by a driver and executed by a graphics processor can be captured and sent to the client. This reduces the processing power required to remote graphics however more bandwidth is needed to transport the data representing the 3D graphics primitives than using bitmap remoting. Accordingly techniques for reducing the bandwidth required to effectuate command level remoting are desirable.

An example embodiment of the present disclosure describes a method. In this example the method includes but is not limited to storing vertices for a plurality of primitives in memory determining that at least a portion of the vertices have not been sent to a terminal server client and sending the determined portion of the vertices to the terminal server client. In addition to the foregoing other aspects are described in the claims drawings and text forming a part of the present disclosure.

An example embodiment of the present disclosure describes a method. In this example the method includes but is not limited to storing vertices for a plurality of primitives each primitive defined by at least one vertex encoding the vertices with a move to front coder and sending the encoded vertices to a terminal server client. In addition to the foregoing other aspects are described in the claims drawings and text forming a part of the present disclosure.

An example embodiment of the present disclosure describes a method. In this example the method includes but is not limited to storing graphics data in memory the graphics data including textures and vertices determining based on a comparison between the graphics data stored in memory and graphics data that were previously sent to a terminal server client that at least a portion of the graphics data in the memory have changed preconditioning at least a portion of the graphics data that have changed and sending the graphics data that have changed to a terminal server client. In addition to the foregoing other aspects are described in the claims drawings and text forming a part of the present disclosure.

It can be appreciated by one of skill in the art that one or more various aspects of the disclosure may include but are not limited to circuitry and or programming for effecting the herein referenced aspects of the present disclosure the circuitry and or programming can be virtually any combination of hardware software and or firmware configured to effect the herein referenced aspects depending upon the design choices of the system designer.

The foregoing is a summary and thus contains by necessity simplifications generalizations and omissions of detail. Those skilled in the art will appreciate that the summary is illustrative only and is not intended to be in any way limiting.

Embodiments of the present disclosure may execute on one or more computers. and the following discussion is intended to provide a brief general description of a suitable computing environment in which the disclosure may be implemented. One skilled in the art can appreciate that the computer system of can in some embodiments effectuate the server and client of . In these example embodiments the server and client can include some or all of the components described in and circuitry configured to instantiate specific aspects of the present disclosure.

The term circuitry used through the disclosure can include hardware components such as hardware interrupt controllers hard drives network adaptors graphics processors hardware based video audio codecs and the firmware software used to operate the hardware for example. In the same or other embodiments circuitry can include microprocessors configured to perform function s by firmware or by set switches. In the same or other example embodiments circuitry can include one or more logical processors e.g. one or more cores of a multi core general processing unit. The logical processor s in this example can be configured by software instructions embodying logic operable to perform function s that are loaded from memory e.g. RAM ROM firmware and or virtual memory. In example embodiments where circuitry includes a combination of hardware and software an implementer may write source code embodying logic that is subsequently compiled into machine readable code that can be processed by the logical processor. Since one skilled in the art can appreciate that the state of the art has evolved to a point where there is little difference between hardware software or a combination of hardware software the selection of hardware versus software to effectuate specific functions is a design choice. More specifically one of skill in the art can appreciate that a software process can be transformed into an equivalent hardware structure and a hardware structure can itself be transformed into an equivalent software process. Thus the selection of a hardware implementation versus a software implementation is one of design choice and left to the implementer.

Referring now to an exemplary general purpose computing system is depicted. The general purpose computing system can include a conventional computer or the like including a general purpose processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The system memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within the computer such as during start up is stored in ROM . The computer may further include a hard disk drive for reading from and writing to a hard disk not shown a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM or other optical media. In some example embodiments computer executable instructions embodying aspects of the present disclosure may be stored in ROM hard disk not shown RAM removable magnetic disk optical disk and or a cache of general purpose processing unit . The hard disk drive magnetic disk drive and optical disk drive are connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The drives and their associated computer readable media provide non volatile storage of computer readable instructions data structures program modules and other data for the computer . Although the exemplary environment described herein employs a hard disk a removable magnetic disk and a removable optical disk it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer such as magnetic cassettes flash memory cards digital video disks Bernoulli cartridges random access memories RAMs read only memories ROMs and the like may also be used in the exemplary operating environment.

A number of program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . A user may enter commands and information into the computer through input devices such as a keyboard and pointing device . Other input devices not shown may include a microphone joystick game pad satellite disk scanner or the like. These and other input devices are often connected to the general purpose processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port game port or universal serial bus USB . A display or other type of display device can also be connected to the system bus via an interface such as a video adapter . In addition to the display computers typically include other peripheral output devices not shown such as speakers and printers. The exemplary system of also includes a host adapter Small Computer System Interface SCSI bus and an external storage device connected to the SCSI bus .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be another computer a server a router a network PC a peer device or other common network node and typically can include many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in can include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer can be connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer can typically include a modem or other means for establishing communications over the wide area network such as the Internet. The modem which may be internal or external can be connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used. Moreover while it is envisioned that numerous embodiments of the present disclosure are particularly well suited for computerized systems nothing in this document is intended to limit the disclosure to such embodiments.

Referring now to it generally illustrates an example operating system including a terminal service session that can be used in embodiments. One skilled in the art can appreciate that the example operating system can be effectuated by a computer such as computer of . As shown by the figure underlying hardware storage device e.g. hard drive network interface card NIC graphics processing unit at least one logical processor and RAM can be provided.

Terminal services can be provided to at least one client such as client while one client is depicted terminal services can be provided to more clients in embodiments. The example client can include a computer terminal that is effectuated by hardware configured to direct user input to the terminal server session and display user interface information generated by the session. In another embodiment client can be effectuated by a computer that includes similar elements as those of computer . In this embodiment client can include circuitry configured to effect operating systems and circuitry configured to emulate the functionality of terminals e.g. a remote desktop client application that can be executed by one or more logical processors . One skilled in the art can appreciate that the circuitry configured to effectuate the operating system can also include circuitry configured to emulate a terminal.

Operating system can include instructions that can configure a processor to generate sessions. Briefly a session can generally include user mode processes applications such as videogames word processing programs web browsers user interfaces windows dialog boxes desktop etc. media players and the like. Applications can be effectuated by various subsystems e.g. executing processes that can provide a platform for applications to execute and interact with a kernel . One such subsystem e.g. instructions is environment subsystem that will be explained in more detail below. A session can include a shell and a user interface rendered by a user interface process the subsystems that track mouse movement within the desktop the subsystems that translate a mouse click on an icon into commands that effectuate an instance of a program etc.

Generally a session can be generated on a user by user basis when for example the operating system receives a connection request over a network connection from a client such as client . Generally a connection request can first be handled by a transport stack e.g. a remote desktop protocol stack RDP . The transport stack can include instructions that can configure processor to listen for connection messages on a certain port and forward them to engine . When sessions are generated the transport logic can be executed and remote desktop protocol stack instances for each session such as stack instance can be instantiated. Generally remote desktop protocol stack instance can be configured to route output to client and route client input to environment subsystem .

During the session creation process a session manager can be executed by logical processor and the processor can initialize and manage each session by for example generating a session identifier for a session space adding the session identifier to a table assigning memory to the session space and generating system environment variables and instances of subsystem processes in memory assigned to the session space.

As shown by the figure in an embodiment applications can execute within user mode of the session and can use two distinct rendering techniques such as bitmaps generated by a graphics display interface GDI 3D graphics or a combination of both. The GDI is useful for generating 2D images such as text and windows. The GDI can be associated with a display driver that can generate bitmap images in response to receiving an array of bits from applications . For example an application may emit an array that can be processed by the display driver and used to render pixels representing color values. As is shown by the figure a remoting component can capture the bitmap output by the GDI and can send it to the stack instance .

Continuing with the description of applications may additionally take advantage of 3D graphics supported by a graphics processing unit made by made by one of a plurality of hardware vendors. Since different hardware vendors use different architectures and commands a graphics driver architecture can be made that abstracts the hardware so that developers can write a single application that works with any graphics card. In this example the application may access the features of the graphics processing unit of the client via an application programming interface API such as Direct3D from Microsoft . The API primitives can be sent to the client translated by a driver of the client into commands that can be executed by the GPU of the client and executed by the GPU of the client. Generally the API outputs graphics data e.g. values vertices 32 bit values that represent vertices of triangles and or textures e.g. digital representations of surfaces of objects that can have 3D properties such as how transparent and reflective the objects are. Generally the textures can be considered bitmaps that can be applied to primitives. That is an application can create an object that looks like a tree and apply a texture to the tree to make it appear to have bark. Another example could include applying grass dirt and rocks to a set of 3D primitives that form a hill.

Graphics data can be generated by the API and stored in buffers e.g. pages of memory and textures can be loaded from art files and stored in other pages of memory. When an application executes it can request memory to use as vertex buffers and memory used to store textures. The application can also declare how it is going to use the memory e.g. what type of data it is going to store in the buffer. For example an application such as a videogame may use a dynamic vertex buffer to store vertices for an avatar and a static buffer for storing data that will not change often such as building data.

In a terminal server embodiment a remoting component can be used to capture the graphics data output by the API and various techniques can be used in order to reduce the amount of graphics data sent over the network to the client such as for example optimizer a delta preconditioner a move to front encoder one or more texture compressors a mesh compressor and one or more escapes . In example embodiments the various components can be effectuated by instructions that can be executed by one or more logical processors. Also while components are shown as separate in one or more embodiments the components can be a single software component. Additionally in one or more embodiments each component can be executed on one or more threads of the application or the stack instance not shown . Moreover while certain components are show in parallel the disclosure is not limited to such an arraignment and in other embodiments one or more components may be in series with other components. As graphics data is generated by the API it can be processed by one or more of the preceding components depending on the type of graphics data and then sent to a bulk compressor . The bulk compressor can be configured to compress the graphics data and then the compressed data can be sent to a client via the NIC .

The following are a series of flowcharts depicting implementations of processes. For ease of understanding the flowcharts are organized such that the initial flowcharts present implementations via an overall big picture viewpoint and subsequent flowcharts provide further additions and or details.

Referring now to it depicts an operational procedure for practicing aspects of the present disclosure including the operations and . As shown by the figure operation begins the operational procedure and operation shows storing vertices for a plurality of primitives in memory. Referring to vertex data e.g. 32 bit values indicative of vertices can be stored in a vertex buffer e.g. one or more pages of memory in RAM and or memory of the graphics processor . In an embodiment the vertex data can be generated by for example the API in response to receiving API constructs from an application such as for example a videogame media player CAD program user interface etc. That is an application could pass the API one or more constructs and the API could generate thousands of primitives and store them in one or more vertex buffers.

Continuing with the description of operation shows determining that at least a portion of the vertices have not been sent to a terminal server client. For example and continuing with the previous example when applications map vertex buffers a process such as for example the optimizer can be executed by the logical processor and the processor can discover that at least a portion of the vertices stored in the vertex buffer have not been sent to a terminal server client . For example a huge amount of data may have been generated by the application e.g. thousands and thousands of primitives in between client updates and the optimizer can be configured to determine what portion of the data is needed to render the difference between what has been sent to the client and what has changed.

As way of example an application when mapping a vertex buffer may operate in very different ways depending on how it was coded by a developer. For example it is perfectly acceptable for an application to map a portion of the buffer then add to the buffer then overwrite a portion of the data in the buffer then completely overwrite the contents of the vertex buffer. The application can issue draw commands for the contents of the entire buffer or for a subset of the buffer. Or put another way it is difficult to estimate how an application will behave. Since the behavior of the application is not predictable a na ve approach would involve sending all the vertices in the buffer after each un map operation. However in this example the optimizer can after an un map operation for example determine which portion of the vertices in the vertex buffer have changed.

Continuing with the description of operation shows sending the determined portion of the vertices to the terminal server client. For example and referring to the network interface card can send the vertices in the buffer that have changed to the terminal server client . In this example since the amount of vertices that need to be sent over the network has been reduced the total bandwidth necessary to effectuate command remoting has been decreased.

Referring now to it shows an alternative embodiment of the operational procedure of including the additional operations and . Referring to operation it shows determining that a user space application has requested a range of memory addresses that is larger than a predetermined range prior to determining that at least a portion of the vertices have not been sent to the terminal server client. Referring to the optimizer can be configured to scan the vertex buffers after it is determined that the user space application is using more than a predetermined amount of address spaces. For example scanning vertex buffers costs computer cycles and if the application indicates that it will send small amounts of data e.g. 20 bytes it is more efficient to send the bytes instead of identifying the changed portion of data during each update. For example the application can create a buffer of a specified amount during an initialization process and set the size and how the buffer will be used. The processor can execute the optimizer and check the size and usage pattern. In this example the processor can discover that the size of the buffer is set to be greater than a predetermined amount and determine to scan the contents of the buffer. In the same or other embodiments the size and type of buffer can be used to determine which optimizations are turned on. For example depending on the size of the buffer the optimizer may enable page level scanning byte level scanning SIMD scanning etc.

As one of skill in the art can appreciate the predetermined threshold can vary based on the capabilities of computer system . For example the predetermined threshold can be set at the bit level and the optimizer can be used to scan every bit generated by the API . This would reduce the bandwidth used to transport changes to the client however this would be cost an unacceptable amount of computer cycles for the benefit actually obtained. On the other hand when most changes are not detected the amount of bandwidth needed to transport the data is increases. Thus as one of skill can appreciate the exact values can be set based on a tradeoff of bandwidth used vs. computer cycles used. Since memory and computational power is increasing values used today may not be relevant in the future thus the exact thresholds are left to an implementer.

Continuing with the description of operation shows preconditioning the determined portion of the vertices. For example in an embodiment of the present disclosure the vertices can be preconditioned for being compressed. In this example the values e.g. the bits that represent the vertices used to generate primitives can be translated into a different form such that the bulk compressor can more easily identify patterns and thus give the bulk compressor more opportunity to compress.

Referring again to operation shows sending a determined delta between each successive vertex in the determined portion of the vertices. For example in an embodiment a delta preconditioner can be used to precondition the vertices. For example a determination can be made to process the vertices by the delta preconditioner based on when vertices are detected and or when an application sets a flag on the API . As was stated in previous paragraphs each vertex can be represented as a value e.g. a 32 bit float for example and the preconditioner can execute an operation e.g. add subtract multiply divide on each successive vertex based on the previous vertex and output the deltas. As one of skill in the art can appreciate subtraction of a 32 bit float from another 32 bit float is still a 32 bit float thus the amount of data remains the same. However by selectively preconditioning the data can be placed into a format that can be more easily compressed by the bulk compressor . For example if an array of vertices was 2 4 6 8 10 12 the delta preconditioner could send the first value and the successive deltas namely an array of 2 2 2 2 2 2 . While the bulk compressor may be able to compress the first array by preconditioning the data the bulk compressor will probably be able to pick up more repeated patterns and thereby compress more data.

This technique is particularly useful in Direct2D a Microsoft set of APIs built on top of Direct3D that uses 3D hardware to draw 2D images such as text e.g. buttons menus etc. The application using D2D can fill up the vertex buffers with line segments representing horizontal spans. Since the vertices are packed together to render a letter in a specific font the distance between each successive vertex may be very similar.

Referring again to operation shows determining by an operating system that a user space application accessed the memory the memory including a plurality of pages and determining by the operating system that the user space application accessed a specific page of the plurality of pages. According to an embodiment that executes operation the operating system can determine that a user space application e.g. a videogame accessed a specific page of memory that stores vertices. For example the processor can track each page of memory that it accesses and this information can be exposed to for example a memory manager of the kernel . In an embodiment the applications using API can be identified and when an application maps a vertex buffer backed by pages of memory the pages that are accessed can be identified and reported to the optimizer .

In a specific example a vertex buffer could be for example 16 k bytes and the buffer could be backed by 4 pages each page being 4 k bytes. In this example if the application maps the buffer e.g. writes to the first page the processor can report this information to the operating system and the specific page e.g. the first page can be reported to the optimizer . The optimizer could determine based on the info passed from the operating system that the specific page includes vertices that have not been sent to a terminal server client.

Referring now to it shows an alternative embodiment of the operational procedure of including operation that illustrates comparing the specific page to a copy of the page that was previously sent to the terminal server client and determining based on the comparison that at least a portion of the vertex data in the specific page has changed. In the same or other embodiment once a page is identified it can be further scanned by the optimizer . For example the optimizer can be executed by the processor and the processor can compare the accessed page or pages to previous copies of the page or pages. For example the optimizer can have access to a copy of the most recent data that was sent to the client or put another way the optimizer can have a view of the data that the client currently has. The optimizer can be executed and a comparison can be made between the contents of the accessed pages and the old copy of the page. If there is a difference the page and or the changed bytes can be sent to the client .

Referring now to it illustrates a further refinement to the operational procedure of including operation that shows that the comparison operation can further include scanning using at least one instruction from a single instruction multiple data set of instructions the specific page. For example in a specific embodiment logical processor can be an x86 based processor having streaming single instruction multiple data SIMD extensions. In this example the at least one SIMD instruction can scan a page of memory in chunks at a time and compare the copy of the bytes in the old page to the current bytes in the current page. In a specific SIMD embodiment the processor can be configured to scan 16 bytes at once. Groups of 16 bytes can be loaded into the SIMD registers and a comparison can be made to the previous values e.g. values that have been sent to the client of the 16 bytes and a determination can be as to whether any of the bytes in the group have changed. In an alternative embodiment once the optimizer identifies that a group of bytes includes a change the processor can execute the optimizer and the processor can be configured to run a comparison between each byte in the group using regular x86 instructions to identify the specific byte or bytes of data that has or have changed in the group.

Referring now to it illustrates a further refinement to the operational procedure of including operation that shows that the comparison operation using SIMD instructions can additionally include the operations of scanning from the beginning of the page to the end until a change is detected and scanning from the end of the page to the beginning until a change is detected. For example the logical processor can step through the identified pages in groups of bytes. The optimizer in this example can be configured to search for bytes until a change is detected. In this example embodiment since applications tend to modify vertices in large groups the optimizer can be configured to look until it finds the beginning and end of a group of changes instead of searching through every byte. By configuring the optimizer in this manner the optimizer will only spend cycles looking for differences in proportion to the amount of changes that are actually made. That is if the application modifies a large group of vertices the processor would not have to spend a lot of cycles trying to identify all the changes.

In this alternative refinement the processor can step through the page starting from the beginning e.g. the first address of the page comparing bytes in groups to previous groups. If for example a change is detected that is if a value indicative of a vertex has changed the processor can stop record the memory address of the value and start scanning from the end of the page e.g. the last address in the page to the beginning until a change is detected. In this example the processor can select the addresses in between the two changed values as portion of the vertices that have not been sent to the terminal server client .

Referring now to it illustrates a further refinement to the operational procedure of including an additional operation that shows overwriting the copy of the page that was previously sent to the terminal server client with the specific page. In embodiments that include operation once processor executing the optimizer instructions identifies the portion of the vertices that have not been sent to the terminal server client the processor can cache the page that it just scanned by overwriting the old copy of the page in a memory area e.g. area of RAM that is configured to store a copy of the graphics data that has been sent to the terminal server client . For example if the cache includes 4 pages of vertices and the optimizer determines that a change was made in the 3page the optimizer can overwrite the 3page with the page that was just scanned. After the overwrite operation the optimizer has a current view of the data that has been sent to the client .

Referring now to it illustrates a further refinement to the operational procedure of including an additional operation that shows compressing the preconditioned determined portion of the vertices. In this refinement after the portion of the vertices that have not been sent to the terminal server client have been preconditioned they can be compressed using the bulk compressor . Generally the bulk compressor is a standard compressor that is configured to identify patterns in a run and compress them. Since the bulk compressor is customized to compress diverse data e.g. all data that is sent to the client such bitmaps generated by the GDI audio clipboard data USB devices etc. it is not configured to compress any specific type of data. Thus in this example the vertices sent to the client can be preconditioned that is placed into a format that enables the bulk compressor to more easily identify patterns.

Turning now to it illustrates an operational procedure that can be used in aspects of the present disclosure. The operational procedure begins with operation and includes operations . As shown by operation the procedure includes storing vertices for a plurality of primitives each primitive defined by at least one vertex. Referring to vertex data e.g. 32 bit values indicative of vertices can be stored in a vertex buffer e.g. one or more pages of memory in RAM and or memory of the graphics processor . In an embodiment the vertex data can be generated by for example the API in response to receiving API constructs from an application such as for example a videogame media player CAD program user interface etc. That is an application could pass the API one or more constructs and the API could generate thousands of primitives and store them in one or more vertex buffers.

The operational procedure continues and shows encoding the vertices with a move to front coder. For example a processor can execute instructions indicative of a move to front coder MTF encoder and can encode the vertices. In this example the MTF encoder can be configured to encode at the level of granularity that represents the data element that is being sent to the client. That is in an example using 32 bit floats the MTF encoder can be configured to encode 32 bits at a time. By encoding at the data element level the known properties of the vertices can be exploited. That is instead of having the MTF encoder encode every bit it can be configured to encode every 32 bits because an implementer knows that the data represents a 32 bit vertex. Generally the MTF encoder includes a list of values and an index. As the MTF encoder processes the vertices the most common values percolate to the top of the list and instead of emitting the values the MTF encoder can output the index value which can be encoded in fewer bits than a vertex . Overtime the MTF encoder may oscillate between the more common values thereby generating a run that the bulk compressor may easily pick up and compress.

In a specific example the list can have 4 slots however this is a configurable amount of slots. The MTC encoder could receive vertex values of 137 16 128 137 137 128 . When the MTF encoder encounters the first value 137 the list can be checked to determine whether to emit the index value or the vertex value. Since in this example the list is empty the 137 value can be stored in the 0 index slot and the MTF encoder can emit the value 137. When the next value 16 is encountered the MTF encoder can store the 16 in the 0 index slot and shift the 137 to the 1 slot and emit the value 16. When the third value is encountered 128 the contents of the list can be shifted and the 128 can be emitted. When the fourth value is encountered the MTF encoder can determine that the 137 is already in the 2 slot and instead of emitting 137 the MTF encoder can emit the index value 2 and information e.g. a bit that identifies that this is an index value. In this example the index value can be encoded with a fewer number of bits than the vertex thus compressing the vertex value. Moreover at this point the MTF encoder can swap or rotate the list such that the 137 placed in the 0 index and the 128 is either placed in the 2 index slot or if rotated the 1 index slot. Continuing with the example as more of the same values start to appear the more the MTF encoder will be able to emit index values and oscillate between commonly encountered values. Or put another way the MTF encoder can compress the vertices by sending index values and precondition the vertices by sending a run that can be further compressed by the bulk compressor .

Continuing with the description of operation shows sending the encoded vertices to a terminal server client. For example and referring to the network interface card can send the encoded vertices e.g. the output emitted by the MTF coder to a terminal server client . In this example the amount of data that needs to be sent to represent the vertices has been reduced thereby decreasing the total bandwidth necessary to perform command remoting.

Turning now to it illustrates an alternative embodiment of the operational procedure of including the operations and . As shown by operation in an embodiment the operational procedure can include an operation that includes compressing the encoded vertices. In embodiments that include this refinement the encoded vertices can be compressed using the bulk compressor . In this example the vertices received by the bulk compressor may include index values that are oscillating between a couple of values and the bulk compressor may be able to identify a run and compress the data.

In addition also depicts operation that shows comparing vertices in a specific page of memory to vertices that were previously sent to the terminal server client and identifying based on the comparison the vertices for the plurality of primitives in the specific page. For example the vertices that the MTF encoder receives could be received from the optimizer . In this configuration the optimizer could be configured to identify changes to vertices made by applications and send the changes to the MTF encoder for further compression. Similar to that described above the optimizer can be executed by the processor and the processor can compare a page or pages to previous copies of the page or pages. The optimizer can be executed and a comparison can be made between the contents of the accessed pages and the old copy of the page. If there is a difference the page and or the changed bytes can be sent the MTF coder .

Referring now to it shows operation which is a refinement to operation . As shown by the figure operation shows scanning from the beginning of the specific page to the end until a change to a vertex is detected and scanning from the end of the specific page to the beginning until a change to a vertex is detected. For example in an embodiment the logical processor can step through the specific pages in groups of bytes.

Referring now to it shows an operation that shows a further refinement to the operational procedure of . In this embodiment the instructions for scanning the specific page include at least one instruction from a single instruction multiple data set of instructions. For example the logical processor can be an x86 based processor having streaming single instruction multiple data SIMD extensions. In this case the SIMD instructions can scan a page of memory in chunks at a time using a single processor instruction.

Referring now to it shows an operational procedure including operations . Operation beings the procedure and operation shows storing graphics data in memory the graphics data including textures and vertices. Referring to in an embodiment vertex data e.g. 32 bit values indicative of vertices can be stored in a vertex buffer e.g. one or more pages of memory in RAM or memory of the graphics processor and textures e.g. surface properties such as surface normals can be stored in pages of RAM . In an embodiment the vertex data can be generated by for example the API in response to receiving a construct from an application such as for example a videogame media player CAD program user interface. The application via the API could map one or more pages of memory with vertices or textures. Or put another way the application can invoke one or more functions of the API to write a plurality of vertices to memory that can be used by a driver to direct a graphics processor to generate a plurality of primitives. Similarly the application can send constructs to the API and the API can generate commands to map textures to primitives that can be stored in memory along with the texture.

Continuing with the description of operation shows determining based on a comparison between the graphics data stored in memory and graphics data that were previously sent to a terminal server client that at least a portion of the graphics data in the memory have changed. For example in an embodiment the API can map vertex buffers e.g. pages of memory and store textures in memory and the optimizer can be executed by the processor in order to determine whether any of the data stored by the application has changed since a previous map operation. For example the optimizer can have access to a copy of the most recent data that was sent to the client or put another way the optimizer can have a view of the data that the client currently has.

The optimizer can additionally compare the textures to textures sent to the client to determine whether any data has changed. For example the textures are essentially arrays of pixel values e.g. bitmaps and the optimizer can scan the pages of memory that store the textures to determine whether any textures have changes. If the processor detects that a page of memory including a texture or a portion of a texture that has been touched that is accessed then the optimizer can determine to send the page to client . In another example embodiment the optimizer can scan the contents of the page that has been touched to identify what bytes have changed. In this example instead of starting from the beginning or end of the page the optimizer can scan the page starting from the middle address and expand outwards like a rectangle.

The optimizer can be executed and a comparison can be made between the contents of the accessed pages and the old copy of the page. If there is a difference the page and or the changed bytes can be sent to the client . In certain embodiments the processor can step through the page comparing bytes or groups of bytes using SIMD instructions.

Continuing with the description of operation shows preconditioning at least a portion of the graphics data that have changed. For example in an embodiment of the present disclosure the graphics data can be preconditioned for being compressed. In this example the values e.g. the bits that represent the vertices and or textures can be translated into a different form such that the bulk compressor can more easily identify patterns and thus give the bulk compressor more opportunity to compress.

Continuing with the description of operation depicts compressing at least a portion of the graphics data that have changed. In this example the graphics data can be compressed using for example bulk compressor .

Continuing with the description of operation depicts sending the graphics data that have changed to a terminal server client. For example and referring to the network interface card can send the graphics data that have changed to the terminal server client . In this example since the amount of graphics data that need to be sent over the network has been reduced the total bandwidth necessary to perform command remoting has been decreased.

Turning now to it shows an alternative embodiment of the operational procedure of including the operations and . Referring now to operation it shows a refinement to operation namely applying a move to front encoder to the vertices in the portion of the graphics data that have changed. Similar to operation in an embodiment processor can execute instructions indicative of a move to front coder and can encode vertices texture values and or commands for mapping textures to primitives. In this example the MTF encoder can be configured to encode on the data element level in order to exploit known properties of the graphics data.

Continuing with the description of operation shows a refinement to operation showing applying a mesh compressor to compress at least a portion of the vertices in the portion of the graphics data that have changed. For example in an embodiment the API can be configured to include a flag that can be set by the application which indicates that certain vertex data is part of a mesh e.g. a collection of connected primitives that form a 3D object. In this case the same flag or a different flag can be used to indicate to the API that lossy compression techniques can be used on the mesh. In this example if the flag is set the vertices associated with the flag can be passed to the mesh compressor and the vertices can be compressed.

In an embodiment a mesh optimizer can execute on the client and can be used to reconstruct the compressed vertices. One such example mesh optimizer could execute on the client to recreate the vertices that were lost in the lossy compression operation.

Turning to operation in an embodiment the operation can be further refined by applying an image compressor to texture data in the portion of the graphics data that have changed. For example one of a plurality of image compressors can be used to compress texture data. Since textures are essentially bitmap images in certain embodiments different compressors can be used to reduce the amount of bandwidth needed to send the textures. In certain embodiments the compressor can be lossless or lossy depending on the textures and how the application intends to use the texture. In this embodiment the API could expose a flag that can be set by the application to indicate that lossy compression is acceptable for textures in certain pages of memory otherwise a lossless compressor may be used to compress the texture. In this example the appropriate compressor can be dynamically selected based on the available CPU cycles and the selection of the flag. Some example compressors could include but are not limited to run length encoders JPEG compressors or DirectX compressors.

Referring now to operation it shows receiving by an escape an application construct for text and sending the construct to the terminal server client. Generally it cost less bandwidth to send API constructs instead of the multitude of API primitives that result from processing constructs. In certain cases high level escapes can be added to the API that can improve the ability to remote primitives such as the primitives that form Direct2D text. Generally when a D2D application such as a word processor passes the API a construct to generate the letter A the API generates primitives from the construct and stores them in a vertex buffer. The construct that is passed to the API represents an A however the information that identifies the A is lost in the vertices that are generated by the API . Thus in this example embodiment when the API receives such a construct the escape can capture the construct and send it to the client via the NIC . The client can in this case receive the construct and use it to reconstruct the vertex buffer. In the same or other embodiments the construct can be compressed or preconditioned using one of the previously disclosed techniques.

The foregoing detailed description has set forth various embodiments of the systems and or processes via examples and or operational diagrams. Insofar as such block diagrams and or examples contain one or more functions and or operations it will be understood by those within the art that each function and or operation within such block diagrams or examples can be implemented individually and or collectively by a wide range of hardware software firmware or virtually any combination thereof.

While particular aspects of the present subject matter described herein have been shown and described it will be apparent to those skilled in the art that based upon the teachings herein changes and modifications may be made without departing from the subject matter described herein and its broader aspects and therefore the appended claims are to encompass within their scope all such changes and modifications as are within the true spirit and scope of the subject matter described herein.

