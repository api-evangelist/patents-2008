---

title: System and method for structuring an A-buffer to support multi-sample anti-aliasing
abstract: One embodiment of the present invention sets forth a technique for efficiently creating and accessing an A-Buffer that supports multi-sample compression techniques. The A-Buffer is organized in stacks of uniformly-sized tiles, wherein the tile size is selected to facilitate compression techniques. Each stack represents the samples included in a group of pixels. Each tile within a stack represents the set of sample data at a specific per-sample rendering order index that are associated with the group of pixels represented by the stack. Advantageously, each tile includes tile compression bits that enable the tile to maintain data using existing compression formats. As the A-Buffer is created, a corresponding stack compression buffer is also created. For each stack, the stack compression buffer includes a bit that indicates whether all of the tiles in the stack are similarly compressed and, consequently, whether the GPU may operate on the stack at an efficient per pixel granularity.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08553041&OS=08553041&RS=08553041
owner: NVIDIA Corporation
number: 08553041
owner_city: Santa Clara
owner_country: US
publication_date: 20080910
---
The present invention relates generally to the field of graphics processing and more specifically to a system and method for structuring an A Buffer to support multi sample anti aliasing.

One task that a graphics processing unit GPU may perform when transforming 3 D images into 2 D images is to determine the visible color of each pixel in the image. Each pixel may include multiple samples wherein each sample corresponds to a different location within the image covered by the pixel. To determine the color at each pixel each sample intersected by an object may be evaluated to create a portion of the overall color of the pixel that includes a variety of effects such as transparency and depth of field. For example suppose each pixel includes four samples and two objects abut in a particular pixel. One of the samples may reflect the color of the first object and three of the samples may reflect the color of the second object. The contributions from all four samples may be evaluated when determining the visible color for the pixel using well known techniques such as multi sample anti aliasing that improve image quality by among other things reducing edge artifacts in images.

Some GPUs increase the efficiency of multi sample anti aliasing by using a variety of compression techniques to reduce memory bandwidth and computational work. For example if all of the samples included in a particular pixel are the same color then the GPU may determine that the pixel is compressible and may represent all four samples i.e. the pixel using the information needed to represent only a single color. Similarly if all of the pixels included in an image tile of proximally located pixels are compressible then the GPU may determine that the image tile is compressible and may represent the image tile using a reduced amount of color information. Reducing the data used to represent the pixels and image tiles reduces the memory bandwidth used when accessing the pixels and tiles in memory. Further the GPU may save computational work by performing blending operations and the like using the compressed pixel representations instead of the sample representations.

In some approaches to determining the visible color of each pixel the objects in an image may need to be rendered in a specific order to ensure that the visible color of each pixel in the generated image is realistic. However in other approaches the sample data representing the intersections of samples by the various objects may be collected sorted and reduced to an image that accurately displays advanced effects irrespective of the order in which the objects are rendered. One structure that computing systems may implement in these various approaches is an A Buffer a memory structure that maintains sample data associated with each polygon that intersects the pixels of an image frame being rendered.

In one approach to organizing an A Buffer the A Buffer stores a linked list of the sample data. One drawback to this approach is that the A Buffer structure is not conducive to some of the most frequently used sample data access patterns. For example when a polygon is rendered much of the corresponding sample data is located in adjacent pixels at the same per sample rendering order index PSROI . As is well known memory accesses are usually most efficient if they can be grouped such that successive accesses target data that is closely located within the memory known as memory locality. Thus an efficient memory structure would enable sample data of this nature located at the same index to be simultaneously accessed. However since each sample in the A Buffer has a separate linked list sample data corresponding to adjacent samples at the same PSROI may be far apart in memory leading to poor memory locality. Consequently accesses to the A Buffer may be inefficient. Another drawback is that the sample data corresponding to each sample is stored discretely and therefore such an approach does not support the compression techniques that GPUs oftentimes use to reduce memory bandwidth and increase efficiency.

As the foregoing illustrates what is needed in the art is a more effective technique for creating and accessing an A Buffer that supports multi sample anti aliasing.

One embodiment of the present invention sets forth a method for generating an A Buffer for storing sample information. The method includes the steps of receiving an image frame comprised of a plurality of pixels where each pixel is comprised of a plurality of samples dividing the image frame into one or more pixel groups where a number of pixels in each of the one or more pixel groups is based on a tile size and a number of samples in each pixel and generating a sample depth complexity image based on the image frame where each entry in the sample depth complexity image reflects a maximum per sample rendering order index or number of potentially visible surfaces associated with a different one of the samples in the image frame. The method also includes the steps of determining a stack height for each pixel group based on the sample depth complexity image where the stack height reflects a maximum maximum per sample rendering order index PSROI associated with the samples in the pixel group determining a number of tiles associated with the A Buffer based on the stack heights determined for the one or more pixel groups and allocating memory space for the A Buffer based on the number of tiles associated with the A Buffer.

One advantage of the disclosed method is that organizing the A Buffer by both pixel proximity and PSROI improves the memory locality thereby increasing the efficiency of memory accesses used when rendering image data.

The system data bus connects the CPU the input devices the system memory and the graphics processing subsystem . In alternate embodiments the system memory may connect directly to the CPU . The CPU receives user input from the input devices executes programming instructions stored in the system memory operates on data stored in the system memory and configures the graphics processing subsystem to perform specific tasks in the graphics pipeline. The system memory typically includes dynamic random access memory DRAM used to store programming instructions and data for processing by the CPU and the graphics processing subsystem . The graphics processing subsystem receives instructions transmitted by the CPU and processes the instructions in order to render and display graphics images on the display devices .

The system memory includes an application program an application programming interface API high level shader programs and a graphics processing unit GPU driver . The application program generates calls to the API in order to produce a desired set of results typically in the form of a sequence of graphics images. The application program also transmits one or more high level shading programs to the API for processing within the GPU driver . The high level shading programs are typically source code text of high level programming instructions that are designed to operate on one or more shaders within the graphics processing subsystem . The API functionality is typically implemented within the GPU driver . The GPU driver is configured to translate the high level shading programs into machine code shading programs that are typically optimized for a specific type of shader e.g. vertex geometry or fragment .

The graphics processing subsystem includes a graphics processing unit GPU a GPU local memory and a GPU data bus . The GPU is configured to communicate with the GPU local memory via the GPU data bus . The GPU may receive instructions transmitted by the CPU process the instructions in order to render graphics data and images and store these images in the GPU local memory . Subsequently the GPU may display certain graphics images stored in the GPU local memory on the display devices .

The GPU includes one or more streaming multiprocessors . Each of the streaming multiprocessors is capable of executing a relatively large number of threads concurrently. Advantageously each of the streaming multiprocessors can be programmed to execute processing tasks relating to a wide variety of applications including but not limited to linear and nonlinear data transforms filtering of video and or audio data modeling operations e.g. applying of physics to determine position velocity and other attributes of objects and so on. Furthermore each of the streaming multiprocessors may be configured as one or more programmable shaders e.g. vertex geometry or fragment each executing a machine code shading program i.e. a thread to perform image rendering operations. The GPU may be provided with any amount GPU local memory including none and may use GPU local memory and system memory in any combination for memory operations.

The GPU local memory is configured to include machine code shader programs an A Buffer a stack compression buffer and a frame buffer . The machine code shader programs may be transmitted from the GPU driver to the GPU local memory via the system data bus . The machine code shader programs may include a machine code vertex shading program a machine code geometry shading program a machine code fragment shading program or any number of variations of each. The A Buffer may be used to store a collection of sample data associated with each polygon that intersects the pixels in an image frame that is being rendered for display. The stack compression buffer may be used to store information related to the A Buffer for purposes of compression. The frame buffer stores data for at least one two dimensional surface that may be used to drive the display devices . Furthermore the frame buffer may include more than one two dimensional surface so that the GPU can render to one two dimensional surface while a second two dimensional surface is used to drive the display devices .

The display devices are one or more output devices capable of emitting a visual image corresponding to an input data signal. For example a display device may be built using a cathode ray tube CRT monitor a liquid crystal display or any other suitable display system. The input data signals to the display devices are typically generated by scanning out the contents of one or more frames of image data that is stored in the frame buffer .

The data assembly unit is a fixed function unit that collects vertex data from the application program for high order surfaces primitives and the like and passes the vertex data to the vertex shader . The data assembly unit may gather data from buffers stored within system memory and the GPU local memory as well as from API calls from the application program used to specify vertex attributes. The vertex shader is a programmable execution unit that is configured to execute a machine code vertex shading program processing vertex data as specified by the vertex shading program. For example the vertex shader may be programmed to transform the vertex data from an object based coordinate representation object space to an alternatively based coordinate system such as world space or normalized device coordinates NDC space. The vertex processing unit may access data that is stored in GPU local memory .

The primitive assembly unit is a fixed function unit that receives processed vertex data from vertex shader and constructs graphics primitives e.g. points lines triangles or the like for processing by the geometry shader . In alternative embodiments a second primitive assembler not shown may be included subsequent to the geometry shader in the data flow through the GPU . The geometry shader is a programmable execution unit that is configured to execute a machine code geometry shading program processing graphics primitives received from the primitive assembly unit as specified by the geometry shading program. For example in addition to well known per primitive operations such as clipping the geometry shader may be programmed to subdivide the graphics primitives into one or more new graphics primitives and calculate parameters such as plane equation coefficients that are used when the new graphics primitives are rasterized. The geometry shader may access data that is stored in the GPU local memory . The geometry shader outputs the parameters and new graphics primitives to the rasterizer .

The rasterizer is a fixed function unit that scans the new graphics primitives and outputs fragments each containing fragment data which may include raster position or interpolated vertex attributes such as texture coordinates and opacity to the fragment shader .

The fragment shader is a programmable execution unit that is configured to execute a machine code fragment shading program processing fragments received from rasterizer as specified by the machine code fragment shading program. For example the fragment shader may be programmed to perform operations such as perspective correction shading blending and the like to produce shaded fragments that are output to the raster operations unit . The fragment shading engine may access data that is stored in buffers in the GPU local memory such as the A Buffer and the stack compression buffer . The raster operations unit optionally performs fixed function computations such as near and far plane clipping and raster operations such as stencil z test blending and the like and outputs pixel data as processed graphics data for storage in a buffer in the GPU local memory such as the A Buffer or the frame buffer . Together the rasterizer the fragment shader and the raster operations unit represent the fragment processing domain of the GPU where the raster operations unit may be used to operate on individual pixels or small squares of pixels and the fragment shader may be programmed to iterate across groups of pixels. Further the fragment shader and the raster operations unit may be configured to treat samples as pixels.

As shown in detail for the array S T each of the stacks may be subdivided into any number of two dimensional tiles . And as shown in detail in each tile may be configured to include an N by M set of pixel data selected and arranged to correspond to the N by M group of pixels represented by a specific stack . Similarly each pixel may be subdivided into an F by G set of samples and each pixel data may be configured to include an F by G set of sample data selected and arranged to correspond to the F by G samples included in the pixel represented by the pixel data . Consequently the total number of sample data included in each tile is F N by G M. In the example of each pixel is subdivided into a two by two set of samples and therefore the total number of sample data included in each tile is 2 N by 2 M.

Each tile may be further configured to include only sample data at a given PSROI. In such a configuration the tiles included in a given stack may together represent all of the sample data associated with the N by M group of pixels represented by the stack where each of the tiles represents the subset of the sample data at a particular PSROI. As set forth in greater detail herein organizing the sample data in such a manner by both PSROI and associated pixel proximity optimizes the locality of memory accesses.

The size of the tiles and consequently the size of the group of pixels represented by each stack may be chosen by the designer and may be uniform across the A Buffer . The size of the tiles in conjunction with the size of the image frame may determine the number of the stacks in the A Buffer . Suppose for example that a tile size of eight by four samples is chosen and that each pixel includes four samples arranged in a two by two configuration. And suppose the size of a given image frame is eight by four pixels. The pixels in the image frame may be divided into four subsets of four by two pixels and the A Buffer may be configured to include four stacks of eight by four tiles each tile including eight pixels represented by thirty two samples. In other embodiments the tile size may be chosen to be more or less than eight by four and the number of stacks in the A Buffer may be more or less than four. Furthermore the tiles may be chosen to be the units of compression and consequently the size of the tiles may be chosen in any technically feasible fashion to facilitate various compression techniques.

Referring back now to the number of tiles in each stack may differ. Since each of the tiles corresponds to a specific PSROI the number of tiles in a given stack corresponds to the maximum depth complexity associated with any of the samples represented by the stack . For example if a given stack were to represent samples having two different per sample rendering order indices such as indices zero and one then the stack would include two tiles that include one or more sample data at each of these two indices. Similarly if a given stack were to include three tiles then the stack would include sample data at three different PSROI such as indices zero one and two. The GPU is configured to assign tiles to each of the stacks calculating the maximum depth complexity associated with the F N by G M group of samples represented by a particular stack to determine the appropriate number of tiles to allocate for that stack .

When populating the A Buffer with sample data the GPU is configured to optimally pack the sample data by allowing the set of sample data included in each pixel data to represent the intersection of one or more polygons with that particular pixel. Suppose for example each pixel includes four samples and four polygons intersect a particular pixel. If each polygon covers a different one of the samples included in the pixel then the PSROI for each of the four samples would be one. And the GPU may configure a single pixel data included in a single tile included in the A Buffer to represent the intersection of all four polygons with this particular pixel.

As shown in detail in each tile also includes tile compression bits reflecting any technically feasible compression format that is supported by the GPU . For example the tile compression bits included in a particular tile may specify that the tile uses a compression format that allows a two color compression scheme. In such a compression scheme two colors may be stored for each pixel represented by the tile and one bit may be stored for each sample included in each of these pixels indicating which of the two colors is correct for the sample. The tile compression bits associated with a particular tile may indicate that the tile is not compressed in which case the sample data is stored in uncompressed form as described above.

As is well known accessing a compressed tile typically involves transferring less data than accessing an uncompressed tile. Consequently the memory bandwidth used to access compressed tiles included in the A Buffer is usually less than the memory bandwidth used to access uncompressed tiles included in the A Buffer . In alternate embodiments the tiles may not include the tile compression bits and the tile compression bits may be stored in another location that is accessible by the GPU. In other embodiments the A Buffer may not support compressed tiles and consequently the tile compression bits may not exist.

Although any number of the tiles included in the A Buffer may be compressed in various embodiments the computing system is configured to ensure that the A Buffer is large enough to store all of the tiles included in the A Buffer in an uncompressed fashion. Again the computing system determines the structure of the A Buffer by the size and complexity of each image frame. In one embodiment the CPU preallocates a fixed size buffer. If the size of the A Buffer for a given image frame turns out to be larger than the size of the fixed size buffer then the CPU subdivides the image frame into image subsets. The CPU ensures that each image subset fits within the preallocated fixed size buffer and then configures the GPU to process each image subset separately. In alternative embodiments the GPU may reallocate the A Buffer for each image frame allocating only enough memory to store the A Buffer specific to the image frame.

As part of determining the structure of the A Buffer the GPU receives pixel writes indicating the intersection of polygons associated with the various graphics objects in an image frame with the pixels expands the pixel writes into sample writes and for each covered sample increments the PSROI associated with the covered sample. In this fashion the GPU configures the maximum PSROIs to represent the maximum rendering order index of every sample in a particular image frame. Subsequently for each stack the GPU determines the maximum of the subset of maximum PSROIs that correspond to the subset of samples represented by the stack . For each stack this stack specific maximum maximum PSROI determines the number of tiles that the GPU allocates for the stack . As will be clear to one skilled in the art operations on the depth complexity image itself may also be compressed in accordance with existing techniques.

The GPU typically but not necessarily uses the fragment shader to create the sample depth complexity images and to determine the structure of the A Buffer . Subsequently the GPU may use either the raster operations unit or the fragment shader to populate and access the A Buffer . The raster operations unit may be more efficient at performing some A Buffer operations however since the fragment shader may execute a machine code geometry shading program the fragment shader may be more flexible.

As shown in detail in the stack compression bits associated with a particular stack include an all compressed bit that indicates whether all of the tiles included in the stack are similarly compressed. If all of the tiles included in the stack are similarly compressed then the GPU may perform blending and other operations between tiles in the same stack using the compressed pixel representation instead of the sample representation of the pixels in the group of pixels represented by the stack . Thus the all compressed bit indicates whether the GPU can operate on the stack at the more efficient pixel level as opposed to the less efficient sample level.

The stack compression bits associated with a particular stack also include an N by M set of pixel coverage masks selected and arranged to correspond to the N by M group of pixels represented by the stack . Each pixel coverage mask includes an F by G set of sample bits . The set of sample bits includes a separate sample bit for each sample included in the pixel. In the example of each pixel includes four samples arranged in a two by two array. Consequently each pixel coverage mask includes four sample bits arranged in a two by two array. For each pixel coverage mask the included sample bits indicate a specific coverage of the corresponding pixel on a per sample basis. For example the sample bits included in a particular pixel coverage mask may be set to the same value indicating that all of the samples included in the corresponding pixel are covered by the same polygon.

The set of pixel coverage masks included in the stack compression bits is only meaningful when the all compressed bit is set to true. When the all compressed bit is set to true the sample coverage of each of the tiles included in the stack corresponding to the stack compression bits is the same matching the sample bits in the set of pixel coverage masks . While populating the A Buffer the GPU also populates the stack compression buffer . When the GPU writes the first tile to a particular stack the GPU initializes the stack compression bits corresponding to the stack . If the first tile in a particular stack is compressed as indicated by the tile compression bits then the GPU sets the all compressed bit to true. The GPU also initializes the set of pixel coverage masks to depict the coverage of the samples included in the first tile in the stack . Subsequently as the GPU adds each additional tile to the stack if the GPU determines that the additional tile and the first tile in the stack are not similarly compressed then the GPU sets the all compressed bit to false.

Generally a particular tile included in a particular stack and the first tile included in the stack are similarly compressed when two criteria are met. The first criterion is that both of the tiles are compressed in the same fashion. The GPU makes this determination by comparing the tile compression bits included in the tiles . The second criterion is that the per sample coverage of the tiles match. In other words the coverage of each sample included in the particular tile should match the coverage of the corresponding sample included in the first tile . The GPU makes this second determination by comparing the sample coverage of the particular tile to the set of pixel coverage masks associated with the stack .

In alternative embodiments the stack compression buffer may include an all compressed bit corresponding to each stack in the A Buffer but may not include pixel coverage masks. In such a embodiment the GPU may determine that all of the tiles in a particular stack are similarly compressed when all of the tiles included in the stack are compressed in the same fashion and the sample data included in each pixel data included in the stack has the same value. In other words at each PSROI represented by a tile all of the sample data corresponding to a particular pixel has the same value. However the pixel data may differ throughout the tile and throughout the stack.

Again the GPU may use either the raster operations unit or the fragment shader to populate and access the stack compression buffer . In alternative embodiments the information in the stack compression buffer may be stored in any technically feasible fashion using any number and type of data structures. In other embodiments the GPU may not maintain any stack compression information in conjunction with the A Buffer and consequently the stack compression buffer may not exist.

The method begins at step where the GPU receives an image subset consisting of an entire image frame and a compression efficient tile size F N by G M. As described above in conjunction with the tile size corresponds to the size of the group of samples represented by each of the stacks in the A Buffer . At step the raster operations unit creates a sample depth complexity image by calculating the maximum rendering order index for each sample included in the image subset. A series of method steps for calculating a sample depth complexity image is described in greater detail below in .

At step the fragment shader calculates the maximum PSROI for each stack in the A Buffer based on the sample depth complexity image . More specifically the fragment shader divides the sample depth complexity image into F N by G M groups of maximum PSROIs where F N by G M is the tile size received in step . As part of step the fragment shader assigns each F N by G M group of samples to a specific stack in the A Buffer . Also as part of step the fragment shader evaluates the maximum PSROI of each of the samples associated with each of the F N by G M groups of samples and determines a single maximum maximum per sample rendering order index for each F N by G M group of samples. The single maximum maximum PSROI defines the number of tiles assigned to the stack in the A Buffer associated with the F N by G M group of samples.

At step the CPU or the GPU calculates the total number of tiles in the A Buffer . In one embodiment the CPU sums the total number of tiles assigned to each of the stack in the A Buffer to determine the total number of tiles in the A Buffer . At step if the CPU or the GPU determines that the size of the A Buffer is not supported by a preallocated fixed sized buffer then the method proceeds to step . The determination of whether the size of the A Buffer is supported by the preallocated fixed size buffer may be made in any technically feasible fashion. For example the total number of tiles required to represent the A Buffer my be compared with the total number of tiles that may be represented using the preallocated fixed size buffer. At step the CPU alters the image subset e.g. the CPU may halve the image subset and the method returns to step . The method continues in this fashion looping through steps until an image subset is identified that fits in the preallocated fixed size buffer reserved for the A Buffer structure.

If at step the CPU or the GPU determines that the size of the A Buffer is supported by the preallocated fixed size buffer then the method proceeds to step . At step the fragment shader or the raster operations unit populates the preallocated A Buffer and the associated stack compression buffer using the various sample data associated with the image subset as described herein and the method terminates.

As shown the method begins at step where the raster operations unit initializes the sample depth complexity image by setting all of the maximum PSROIs included in the sample depth complexity image to zero. At step the raster operations unit receives a write to a target pixel. At step the raster operations unit selects the first covered sample in the target pixel. The raster operations unit may order the samples in any technically feasible fashion such as primarily by X coordinates and secondarily by Y coordinates. At step the raster operations unit increments the maximum PSROI associated with the selected sample. At step if the raster operations unit determines that the selected sample is not the last covered sample included in the target pixel then the method proceeds to step .

At step the raster operations unit selects the next covered sample in the target pixel and the method returns to step where the raster operations unit increments the maximum PSROI associated with the selected sample. The method continues in this fashion looping through steps until the raster operations unit increments each of the sample depth complexities that are associated with a covered sample in the target pixel.

If at step the raster operations unit determines that the selected sample is the last covered sample in the target pixel then the method proceeds to step . At step if the raster operation unit determines that there are more pixel writes then the method returns to step where the raster operations unit receives a pixel write to a target pixel. The method continues in this fashion looping through steps until the raster operations unit receives all of the pixel writes and reflects the pixel writes in the sample depth complexity image .

As shown the method begins at step where the raster operations unit receives a compressed write to a target tile of pixels. At step the raster operations unit determines the A Buffer stack index and identifies the stack associated with the stack index and included in the A Buffer . The raster operations unit may determine the two dimensional stack index in any technically feasible fashion. For example the raster operations unit may use the tile size of the A Buffer to calculate the stack index using integer division operations. At step the raster operations unit determines the tile index within the identified stack and identifies the tile associated with the tile index and included in the identified stack . The raster operations unit may determine the one dimensional tile index in any technically feasible fashion. For example the raster operations unit may maintain an index for each stack that indicates the index of the next unpopulated tile and the raster operations unit may set the tile index to match the index of the next unpopulated tile for the identified stack.

At step the raster operations unit populates the identified tile using the data received during the compressed write. As part of step the raster operations unit updates the tile compression bits included in the identified tile to reflect the compression format for the identified tile . At step the raster operations unit identifies the stack compression bits included in the stack compression buffer and associated with the stack index. At step if the raster operations unit determines that the tile index equals zero i.e. the identified tile is the first tile in the identified stack then the method proceeds to step . At step the raster operations unit initializes the all compressed bit included in the identified stack compression bits to true. In other words the raster operations unit sets the all compressed bit included in the identified stack compression bits to indicate that the single tile in the identified stack is compressed. At step the raster operations unit initializes the sample bits included in the identified stack compression bits to match the sample coverage of the identified tile and the method terminates.

If at step the raster operations unit determines that the tile index does not equal zero i.e. the identified tile is not the first tile in the identified stack then the method proceeds to step . At step if the raster operations unit determines that the value of the all compressed bit included in the identified stack compression bits is not equal to true then the method terminates. If at step the raster operations unit determines that the value of the all compressed bit included in the identified stack compression bits is equal to true then the method proceeds to step .

At step if the raster operations unit determines that the identified tile is not compressed in the same format as all of the previous tiles included in the identified stack then the method proceeds to step . The raster operations unit may determine whether the identified tile is compressed in the same format as all of the previous tiles included in the identified stack in any technically feasible fashion. Since all of the previous tiles in the identified stack are compressed in the same format the raster operations unit only needs to determine whether the identified tile is compressed in the same format as one of the previous tiles included in the identified stack . Thus the raster operations unit may determine whether the identified tile is compressed in the same format as the previous tiles in the identified stack by comparing the tile compression bits included in the identified tile to the tile compression bits included in the first tile in the identified stack . At step the raster operations unit sets the all compressed bit included in the identified stack compression bits to false and the method terminates.

If at step the raster operations unit determines that the identified tile is compressed in the same format as all of the previous tiles included in the identified stack then the method proceeds to step . At step if the raster operations unit determines that the sample coverage of the identified tile matches the sample bits included in the identified stack compression bits then the method terminates. The raster operations unit may determine whether the sample coverage of the identified tile matches the sample bits included in the identified stack compression bits in any technically feasible fashion. For example the raster operations unit may examine the sample coverage represented by the data included in the identified tile and compare this data to the sample bits included in the identified stack compression bits . If at step the raster operations unit determines that the sample coverage of the identified tile does not match the sample bits included in the identified stack compression bits then the method proceeds to step . At step the raster operations unit sets the all compressed bit included in the identified stack compression bits to false and the method terminates.

In sum image rendering performance may be improved by using an A Buffer structure that allows sample data to be stored in a way that increases the memory locality and supports existing compression techniques. In one embodiment the A Buffer is organized in three dimensional stacks of uniformly sized two dimensional rectangular tiles each stack representing a group of pixels and the samples included in the group of pixels. Each tile in a given stack includes the set of sample data at a specific PSROI that are associated with the group of pixels represented by the stack. Since each tile corresponds to a specific PSROI the number of tiles in a given stack corresponds to the maximum maximum per sample rendering order index associated with the samples in the group of pixels represented by the stack. To reduce memory usage the GPU may assign a different number of tiles to each stack calculating and using the maximum maximum PSROI of the samples included in the pixels represented by each stack to determine the appropriate number of tiles to allocate for the stack.

Each tile also includes tile compression bits. For a particular tile the tile compression bits may specify a tile compression format that is supported by the GPU and that the tile uses to reduce the amount of data that the tile accesses to represent the set of sample data assigned to the tile. Further during A Buffer creation a corresponding stack compression buffer is created. For each stack in the A Buffer the stack compression buffer includes an all compressed bit that indicates whether all of the tiles in the stack are similarly compressed. In one embodiment a stack of tiles is determined to be similarly compressed only when all of the tiles in the stack are compressed and for each pixel and each PSROI represented by the stack the sample data for a particular pixel and a particular PSROI all have the same values. In other words each pixel is fully covered by a single object at each level of PSROI used to represent the group of pixels included in the stack. The all compressed bit may be used by the GPU to determine whether to operate on the data included in a particular stack on a more efficient per pixel basis or a less efficient per sample basis.

Advantageously organizing the A Buffer by both pixel proximity and pixel PSROI improves the memory locality thereby increasing the efficiency of memory accesses used when rendering image data. Moreover selecting a tile size that facilitates compression including tile compression bits in each tile and creating the stack compression buffer enable the GPU to fully utilize existing compression techniques that reduce memory bandwidth and increase computational efficiency. Consequently the overall performance of the graphics pipeline is improved.

While the forgoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present invention are embodiments of the present invention. Therefore the scope of the present invention is determined by the claims that follow.

