---

title: Synthesized singing voice waveform generator
abstract: Various technologies for generating a synthesized singing voice waveform. In one implementation, the computer program may receive a request from a user to create a synthesized singing voice using the lyrics of a song and a digital file containing its melody as inputs. The computer program may then dissect the lyrics' text and its melody file into its corresponding sub-phonemic units and musical score respectively. The musical score may be further dissected into a sequence of musical notes and duration times for each musical note. The computer program may then determine a fundamental frequency (F), or pitch, of each musical note.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07977562&OS=07977562&RS=07977562
owner: Microsoft Corporation
number: 07977562
owner_city: Redmond
owner_country: US
publication_date: 20080620
---
Text to speech TTS synthesis systems offer natural sounding and fully adjustable voices for desktop telephone Internet and other various applications e.g. information inquiry reservation and ordering email reading . As the use of speech synthesis systems increased the expectation of speech synthesis systems to generate a realistic human like sound capable of expressing emotions also increased. Singing voices that provide flexible pitch control may be used to provide an expressive or emotional aspect in a synthesized voice.

Described herein are implementations of various technologies for generating a synthesized singing voice waveform. In one implementation the computer program may receive a request from a user to create a synthesized singing voice using the lyrics of a song and a digital file containing its melody as inputs. The computer program may then dissect the lyrics text and its melody file into its corresponding sub phonemic units and musical score respectively. The musical score may be further dissected into a sequence of musical notes and duration times for each musical note. The computer program may then determine the fundamental frequency F or pitch of each musical note.

Using the database of statistically trained contextual parametric models as a reference the computer program may match each sub phonemic unit with a corresponding or matching statistically trained contextual model. The matching statistically trained contextual parametric model may be used to represent the actual sound of each sub phonemic unit. After all of the matching statistically trained contextual parametric models have been ascertained each model may be linked with the duration time of its corresponding musical note. The sequence of statistically trained contextual parametric models may be used to create a sequence of spectra representing the sequence of sub phonemic units with respect to its duration times.

The sequence of spectra may then be linked to each musical note s fundamental frequency to create a synthesized singing voice for the provided lyrics and melody file.

The above referenced summary section is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description section. The summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

In general one or more implementations described herein are directed to generating a synthesized singing voice waveform. The synthesized singing voice waveform may be defined as a synthesized speech with melodious attributes. The synthesized singing waveform may be generated by a computer program using a song s lyrics its corresponding digital melody file and a database of statistically trained contextual parametric models. One or more implementations of various techniques for generating a synthesized singing voice will now be described in more detail with reference to in the following paragraphs.

Implementations of various technologies described herein may be operational with numerous general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with the various technologies described herein include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The various technologies described herein may be implemented in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. The various technologies described herein may also be implemented in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network e.g. by hardwired links wireless links or combinations thereof. In a distributed computing environment program modules may be located in both local and remote computer storage media including memory storage devices.

The computing system may include a central processing unit CPU a system memory and a system bus that couples various system components including the system memory to the CPU . Although only one CPU is illustrated in it should be understood that in some implementations the computing system may include more than one CPU. The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus. The system memory may include a read only memory ROM and a random access memory RAM . A basic input output system BIOS containing the basic routines that help transfer information between elements within the computing system such as during start up may be stored in the ROM .

The computing system may further include a hard disk drive for reading from and writing to a hard disk a magnetic disk drive for reading from and writing to a removable magnetic disk and an optical disk drive for reading from and writing to a removable optical disk such as a CD ROM or other optical media. The hard disk drive the magnetic disk drive and the optical disk drive may be connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The drives and their associated computer readable media may provide nonvolatile storage of computer readable instructions data structures program modules and other data for the computing system .

Although the computing system is described herein as having a hard disk a removable magnetic disk and a removable optical disk it should be appreciated by those skilled in the art that the computing system may also include other types of computer readable media that may be accessed by a computer. For example such computer readable media may include computer storage media and communication media. Computer storage media may include volatile and non volatile and removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media may further include RAM ROM erasable programmable read only memory EPROM electrically erasable programmable read only memory EEPROM flash memory or other solid state memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computing system . Communication media may embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and may include any information delivery media. The term modulated data signal may mean a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media may include wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above may also be included within the scope of computer readable media.

A number of program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs a singing voice program program data and a database system . The operating system may be any suitable operating system that may control the operation of a networked personal or server computer such as Windows XP Mac OS X Unix variants e.g. Linux and BSD and the like. The singing voice program will be described in more detail with reference to in the paragraphs below.

A user may enter commands and information into the computing system through input devices such as a keyboard and pointing device . Other input devices may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices may be connected to the CPU through a serial port interface coupled to system bus but may be connected by other interfaces such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device may also be connected to system bus via an interface such as a video adapter . A speaker or other type of audio device may also be connected to system bus via an interface such as audio adapter . In addition to the monitor the computing system may further include other peripheral output devices such as printers.

Further the computing system may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be another personal computer a server a router a network PC a peer device or other common network node. Although the remote computer is illustrated as having only a memory storage device the remote computer may include many or all of the elements described above relative to the computing system . The logical connections may be any connection that is commonplace in offices enterprise wide computer networks intranets and the Internet such as local area network LAN and a wide area network WAN .

When using a LAN networking environment the computing system may be connected to the local network through a network interface or adapter . When used in a WAN networking environment the computing system may include a modem wireless router or other means for establishing communication over a wide area network such as the Internet. The modem which may be internal or external may be connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the computing system or portions thereof may be stored in a remote memory storage device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

It should be understood that the various technologies described herein may be implemented in connection with hardware software or a combination of both. Thus various technologies or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible media such as floppy diskettes CD ROMS hard drives or any other machine readable storage medium wherein when the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus for practicing the various technologies. In the case of program code execution on programmable computers the computing device may include a processor a storage medium readable by the processor including volatile and non volatile memory and or storage elements at least one input device and at least one output device. One or more programs that may implement or utilize the various technologies described herein may use an application programming interface API reusable controls and the like. Such programs may be implemented in a high level procedural or object oriented programming language to communicate with a computer system. However the program s may be implemented in assembly or machine language if desired. In any case the language may be a compiled or interpreted language and combined with hardware implementations.

In one implementation statistically trained parametric models may be created by the singing voice program . In this case the singing voice program may use a standard speech database as an input for a statistical training module . The standard speech database may include a standard speech and a standard text . In one implementation the standard speech may consist of up to eight or more hours of a speech recorded by one individual. The standard speech may be recorded in a digital format such as a WAV MPEG or other similar file formats. The file size of the standard speech recording may be up to one gigabyte or larger. The standard text may include a type written account of the standard speech such as a transcript. The standard text may be typed in a Microsoft Word document a notepad file or another similar text file format. The standard speech database may be stored on the system memory the hard drive or on the database system of the computing system . The standard speech database may also be stored on a separate database accessible to the singing voice program via LAN or WAN .

As described earlier the singing voice program may use the standard speech database as an input to the statistical training module . The statistical training module may determine or learn the pitch gain spectrum duration and other essential factors of the standard speech speaker s voice with respect to the standard text .

After the statistical training module dissects the standard speech into these essential factors a summary of these factors may be created in the form of statistically trained parametric models . The statistically trained parametric models may contain one or more statistical models which may be sequences of symbols that represent phonemes or sub phonemic units of the standard speech . In one implementation the statistically trained parametric models may be represented by statistical models such as Hidden Markov Models HMMs . However other implementations may utilize other types of statistical models. The singing voice program may store the statistically trained parametric models on a statistically trained parametric models database which may be stored on the system memory the hard drive or on the database system of the computing system . The statistically trained parametric models database may also be stored on a separate database accessible to the singing voice program via LAN or WAN .

In one implementation the size of the statistically trained parametric models database may be significantly smaller than the size of the corresponding standard speech database . After the statistically trained parametric models have been stored on the statistically trained parametric models database the singing voice program may match the text input to a corresponding statistically trained parametric model found in database to create a synthesized voice. The voice may be synthesized by a PC or another similar device. The synthesized voice may sound similar to the speaker of standard speech because the statistically trained parametric models have been created based on his voice.

The statistically trained parametric models database may also be used by an adaptation module to create new statistically trained parametric models by adapting the existing statistically trained parametric models to another speaker s voice. This may be done so that the synthesized voice may sound like another individual as opposed to the speaker of standard speech .

In one implementation the singing voice program may use a personal speech database as another input into the adaptation module . The personal speech database may include a personal speech and a personal text . The personal speech may be obtained from an individual other than the speaker for the standard speech . Here the personal speech may be a recording that is significantly shorter than that of the standard speech . The personal speech may consist of 1 hour of a recorded speech. The personal speech may be recorded in a digital format such as a WAV MPEG or other similar file formats. The personal text may correspond to the personal speech in the form of a transcript and it may be typed in a Microsoft Word document a notepad file or another similar text file format.

The personal speech database may be stored on the system memory the hard drive or on the database system of the computing system . The personal speech database may also be stored on a separate database accessible to the singing voice program via LAN or WAN .

The adaptation module may use the personal speech database and the statistically trained parametric models database as inputs to modify the existing statistically trained parametric models to a number of adapted statistically trained parametric models . The singing voice program may store the adapted statistically trained parametric models in the statistically trained parametric models database .

After the adapted statistically trained parametric models have been added to the existing statistically trained parametric models database the singing voice program may match the adapted models to a text input to create a synthesized voice. The synthesized voice may be heard through speaker or another similar device. In this case the synthesized voice may sound like the speaker of personal speech because the adapted statistically trained parametric models have been created based on his voice.

Although it has been described that the standard speech database the statistically trained parametric models database and the personal database may have been created or updated by the singing voice program it should be noted that each database may have been created with another program at an earlier time. In case these databases have not been created the singing voice program may be used to create these databases. Otherwise the singing voice program may use an existing statistically trained parametric models database to generate a synthesized voice.

At step the singing voice program may receive a request from a user to create a synthesized singing voice. In one implementation the user may make this request by pressing ENTER on the keyboard .

At step the user may provide the singing voice program a text file containing a song s lyrics. The text file may include a type written account of the song in a Microsoft Word document a notepad file or another similar text file format. The user may also provide the singing voice program a melody file containing the song s melody. The melody file may be provided in a digital format such as a Musical Instrument Digital Interface MIDI file or the like.

At step the singing voice program may begin the process to convert the provided song lyrics and melody into a synthesized singing voice. The process will be described in greater detail in .

The following description of flow diagram is made with reference to method of and method of in accordance with one or more implementations of various techniques described herein. Additionally it should be understood that while the operational flow diagram indicates a particular order of execution of the operations in some implementations certain portions of the operations might be executed in a different order.

In one implementation the singing voice program may use the song s lyrics and its corresponding melody as inputs. The lyrics may be in the form of a text file such as a type written account of a song in a Microsoft Word document a notepad file or another similar text file format. The melody of the song may be provided in a digital format such as a Musical Instrument Digital Interface MIDI file or the like.

The lyrics may be used as an input by a lyrics analysis module . The lyrics analysis module may break down the sentences of the lyrics into phrases then into words then into syllables then into phonemes and finally into sub phonemic units. The sub phonemic units may then be converted into a sequence of contextual labels . The contextual labels may be used as input to a matching contextual parametric models module . The matching contextual parametric models module may use a contextual parametric models database to find a matching contextual parametric model for each contextual label . In one implementation the contextual parametric models database may include the statistically trained parametric model database described earlier in . In another implementation the contextual parametric models database may also be adapted with the adaptation module as described in to synthesize another user s voice.

The matching contextual parametric models module may use a predictive model such as a decision tree to find the matching contextual parametric model for the contextual label from the contextual parametric models database . The decision tree may search for a contextual parametric model such that the contextual label is used in a similar manner. For example if the contextual label was the phoneme ah for the word cat the decision tree may find the matching contextual parametric model such that the phoneme to the left of ah is c and to the right of ah is t. Using this type of logic the matching contextual parametric models module may find a matching contextual parametric model for each contextual label .

The matching contextual parametric models may then be used as inputs to a resonator generation module along with duration times provided by a melody analysis module . The melody analysis module and the duration times will be described in more detail in the paragraphs below.

As explained earlier the singing voice program may receive a request from a user to create a synthesized singing voice given a song s lyrics and its corresponding melody . The melody of the song typically obtained from a MIDI file may be used as an input for the melody analysis module . The melody analysis module may break down the melody into its musical score. The musical score may be further dissected by the melody analysis module into a sequence of musical notes and the corresponding duration times for each note. The musical notes may contain the actual sequence of musical notes and the prosody parameters of the melody. Prosody parameters generally include duration pitch and the like. The duration times may typically be measured in milliseconds but it may also be measured in seconds microseconds or in any other unit of time.

At this point the resonator generation module may then use the matching contextual parametric models and the duration times to create spectra . The spectra may be a sequence of multidimensional trajectory representation of the matching contextual parametric models and its corresponding duration times . In one implementation the spectra may be represented in a sequence of LSP line spectral pairs coefficients. However the spectra may also be represented in a variety of other formats other than a sequence of LSP coefficients format.

The duration times obtained from the melody analysis module may also be used as input for a pitch generation module along with the musical notes . The pitch generation module may determine the fundamental frequency F or pitch for each musical note based on the musical notes and the corresponding duration times . For example the MIDI number may correlate to the musical note C which may then correlate to a fundamental frequency of 110 Hz.

The duration times may also be attached to each musical note by the pitch generation module . As such a duration time may also be attached to each fundamental frequency . The sequence of fundamental frequencies and the spectra may then be used as input to the LPC linear predictive coding synthesis module to produce a synthesized singing voice.

The LPC synthesis module may combine the sequence of fundamental frequencies with the spectra of matching contextual parametric models to create a synthesized singing voice . The synthesized singing voice may be a waveform of the singing synthesized voice in the time domain. In one implementation before the LPC synthesis module creates the final waveform a user may add features to the synthesized singing voice such as vibrato and natural jittering in pitch to create a more human like sound. The final waveform may be played on the computing system via speaker or any other similar device.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

