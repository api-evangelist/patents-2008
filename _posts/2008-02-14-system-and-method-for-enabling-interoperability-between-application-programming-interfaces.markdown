---

title: System and method for enabling interoperability between application programming interfaces
abstract: One embodiment of the present invention sets forth a method for sharing graphics objects between a compute unified device architecture (CUDA) application programming interface (API) and a graphics API. The CUDA API includes calls used to alias graphics objects allocated by the graphics API and, subsequently, synchronize accesses to the graphics objects. When an application program emits a “register” call that targets a particular graphics object, the CUDA API ensures that the graphics object is in the device memory, and maps the graphics object into the CUDA address space. Subsequently, when the application program emits “map” and “unmap” calls, the CUDA API respectively enables and disables accesses to the graphics object through the CUDA API. Further, the CUDA API uses semaphores to synchronize accesses to the shared graphics object. Finally, when the application program emits an “unregister” call, the CUDA API configures the computing system to disregard interoperability constraints.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08539516&OS=08539516&RS=08539516
owner: NVIDIA Corporation
number: 08539516
owner_city: Santa Clara
owner_country: US
publication_date: 20080214
---
The present invention relates generally to the field of computer processing and more specifically to a system and method for enabling interoperability between application programming interfaces APIs .

A typical computing system includes a host such as a central processing unit CPU and a compute device such as a graphics processing unit GPU . Some compute devices are capable of very high performance using a relatively large number of small parallel execution threads on dedicated programmable hardware processing units. The specialized design of such compute devices allows these compute devices to perform certain tasks such as rendering 3 D scenes and tessellation much faster than a host. However the specialized design of these compute devices also limits the types of tasks that the compute devices can perform. The host is typically a more general purpose processing unit and therefore can perform most tasks. Consequently the host usually executes the overall structure of software application programs and configures the compute device to perform specific data parallel compute intensive tasks.

To fully realize the processing capabilities of advanced compute devices compute device functionality may be exposed to application developers through one or more application programming interfaces APIs of calls and libraries. Among other things doing so enables application developers to tailor their application programs to optimize the way compute devices function. Typically each API is designed to expose a particular set of hardware features and is suitable for a specific set of problems. For example in some compute devices a graphics API enables application developers to tailor their application programs to optimize the way those compute devices process graphics scenes and images. Similarly in some compute devices a compute API enables application developers to tailor their application programs to optimize the way those compute devices execute high arithmetic intensity operations on many data elements in parallel. Some application programs include algorithms that are most efficiently implemented by using a graphics API to perform some tasks and a computation API to perform other tasks.

In one approach to developing such an application program the application developer implements a computation algorithm using the compute API and implements subsequent graphics operations that utilize the output of the computation algorithm using the graphics API. To allow the graphics API to consume the data written via the compute API the application developer copies the data from the memory associated with the compute API to the host memory. The application developer then submits this data via the graphics API thereby copying the data from the system memory into graphics objects associated with the graphics API. One drawback to this approach is that the application program allocates three buffers and makes two copies of the data that is accessed by both the compute API and the graphics API. Allocating and copying buffers in this fashion may reduce the speed with which the host and compute device execute the application program and consequently may hinder overall system performance.

As the foregoing illustrates what is needed in the art is a more efficient and flexible technique for enabling APIs to inter operate.

One embodiment of the present invention sets forth a method for accessing a shared memory in a system having multiple application programming interfaces APIs . The method includes the steps of registering a memory buffer for address mapping to allow the memory buffer to be accessed by a plurality of APIs requesting access to the memory buffer synchronizing access to the memory buffer among two or more of the APIs in the plurality of APIs using a semaphore mechanism for purposes of accessing the memory buffer and generating one or more calls that cause a processing unit to operate on data stored in the memory buffer.

One advantage of the disclosed method is that mapping a graphics object into a CUDA address space allows application programs to use both a graphics API and a CUDA API to access the data in the graphics object without allocating additional buffers or copying data. Moreover using the one or more semaphore mechanisms to synchronize access to the graphics object enables the compute device to efficiently ensure exclusive access to the graphics object.

The host connects to the input devices the host memory and the compute device subsystem via a system bus . In alternate embodiments the host memory may connect directly to the host . The host receives user input from the input devices executes programming instructions stored in the host memory operates on data stored in the host memory and configures the compute device subsystem to perform specific data parallel compute intensive tasks. The host memory typically includes dynamic random access memory DRAM used to store programming instructions and data for processing by the host and the compute device subsystem . The compute device subsystem receives instructions that are transmitted by the host and processes the instructions in order to perform data parallel compute intensive tasks such as tessellation and rendering graphics images. Subsequently the compute device subsystem may transmit rendered graphics images through one or more video cables to one or more display devices . Each display device is an output device capable of emitting a visual image corresponding to an input graphics image.

The host memory includes a graphics software stack a compute unified device architecture CUDA software stack and one or more application programs . The graphics software stack is a set of programs that issue and manage specific tasks in the graphics pipeline the collection of processing steps performed to transform 3 D images into 2 D images that operate on components in the compute device subsystem . The CUDA is a general purpose computing environment which uses the compute device subsystem to perform various computing tasks. The CUDA software stack is a set of programs included in the CUDA that issue and manage general purpose computations that operate on components in the compute device subsystem .

The graphics software stack includes a graphics API and a graphics driver and the CUDA software stack includes a CUDA API and a CUDA driver . The application program generates calls to the graphics API the CUDA API or any combination thereof in order to produce a desired set of results. A portion of the graphics API functionality is implemented within the graphics driver . Similarly a portion of the CUDA API functionality is implemented within the CUDA driver . Both the graphics driver and the CUDA driver are configured to translate high level instructions into machine code commands that execute on components within the compute device subsystem . In alternate embodiments the CUDA software stack and or the graphics software stack may be replaced with any set of software programs that expose and manage compute device functionality. For example the CUDA software stack may be replaced with a different general purpose compute API and associated driver or another graphics API and associated driver.

The compute device subsystem includes a compute device such as a graphics processing unit and a device memory . The compute device receives and processes instructions transmitted from the graphics driver and the CUDA driver . The compute device includes one or more streaming multiprocessors not shown . Each of the streaming multiprocessors is capable of executing a relatively large number of threads i.e. part of a program concurrently. Further each of the streaming multiprocessors can be programmed to execute processing tasks relating to a wide variety of applications including but not limited to linear and nonlinear data transforms filtering of video and or audio data modeling operations e.g. applying of physics to determine position velocity and other attributes of objects and so on.

The device memory typically includes DRAM and is used to store data and programming that requires relatively fast access by the compute device . Components in both the graphics software stack such as the graphics API and the graphics driver and the CUDA software stack such as the CUDA API and the CUDA driver access the device memory . Moreover the compute device may be configured to synchronize the commands emitted by the graphics driver and the CUDA driver to ensure that the drivers and have mutually exclusive access to the same location in device memory . The compute device may be provided with any amount of device memory and may use the device memory and the host memory in any combination for memory operations. In alternate embodiments the device memory may be incorporated into the host memory.

The graphics context includes a graphics control state and graphics handles . The graphics control state includes information regarding the state of the compute device. The graphics handles include resources such as buffer objects or vertex buffers. The CUDA context includes CUDA handles that are used for resource management such as module handles and object handles and a CUDA address space . The device memory includes a graphics object that is accessible through the graphics API and a CUDA memory that is accessible through the CUDA API.

As shown the graphics handles include a graphics object handle that references the graphics object in the device memory . Similarly the CUDA address space references the CUDA memory in the device memory . The graphics object is suitable for processing by the CUDA. However in the prior art computing system the CUDA API cannot access the graphics object directly.

As shown in to allow the CUDA API to access the graphics object in prior art computing systems the application developer first allocates the intermediate buffer in the host memory and sufficient CUDA memory in the device memory . The application developer then copies the graphics object from the device memory to the intermediate buffer . Finally the application developer copies the intermediate buffer to the CUDA memory .

Similarly as shown in to allow the graphics API to access data in the CUDA memory in prior art computing systems the application developer first allocates the intermediate buffer in the host memory and the graphics object in the device memory . The application developer then copies the appropriate data from the CUDA memory to the intermediate buffer . Finally the application developer uses the graphics API to copy the data from the intermediate buffer into the graphics object .

To facilitate the development of application programs that efficiently utilize both the graphics API and the CUDA API the graphics software stack and the CUDA software stack include functionality that enable the software stacks and to inter operate. More specifically the software stacks and incorporate techniques that allow the software stacks and to alias and therefore share data included in the device memory . Further the software stacks and incorporate techniques that enable the compute device to synchronize access to the shared data.

The device memory includes a graphics object and a semaphore buffer . As shown the graphics object is referenced by the graphics object handle and is also mapped into the CUDA address space . Consequently the graphics object is shared between the graphics software stack and the CUDA software stack and is accessible using either the graphics API or the CUDA API . The semaphore buffer is associated with the graphics object and may be used as a control by one or more semaphore mechanisms included in the compute device to enforce mutually exclusive access to the graphics object by the graphics API and the CUDA API . The semaphore buffer and associated semaphore mechanisms may be implemented using any protocols known in the art.

Advantageously mapping the graphics object into the CUDA address space enables the graphics API and the CUDA API to share the graphics object without allocating any additional memory or executing any memory copies. In alternate embodiments the CUDA API may allocate objects and subsequently create an alias e.g. an object handle to enable the graphics API to share the object with the CUDA API.

The interoperability functionality is exposed to the application developer through the CUDA API . To allow the application developer to further optimize application programs the CUDA API consolidates the heavy weight i.e. memory intensive and or compute intensive interoperability setup tasks into a single register call that is designed to be executed infrequently. Furthermore while executing a register call the CUDA API launches tasks that are designed to increase the efficiency of subsequent interoperability calls.

The register call is used to enable interoperability functionality for the graphics object . Among other things while executing a register call the CUDA API performs synchronization operations establishes the semaphore associated with the graphics object and maps the graphics object into the CUDA address space . Before mapping the graphics object into the CUDA address space the CUDA API launches tasks that evaluate the location of the graphics object and potentially move the graphics object to a location designed to optimize the accesses to the graphics object by both the software stacks and . For example if a graphics object is in the host memory then the graphics software stack moves the graphics object to the device memory.

Further still while executing the register call the CUDA API configures the graphics software stack to mark the graphics object as registered for CUDA interoperability. Among other things marking the graphics object in this fashion influences the memory manager included in the graphics software stack to preferentially retain the graphics object in the device memory at the current location. This procedure reduces the likelihood that the memory manager will move the graphics object to the host memory or to another location in the device memory in response to the needs of any of the application programs .

After registering the graphics object for interoperability using the register call map and unmap calls may be used to respectively enable and disable accesses to the graphics object by the CUDA API . Since an application program is likely to emit map and unmap calls at a high frequency the map and unmap calls are designed to execute the most common scenarios relatively quickly. While executing a map call the CUDA API first launches a task that determines if the graphics object has been moved since the most recent register or map call. If the graphics object has not been moved then the CUDA API configures the CUDA driver and the graphics driver to synchronize the access of the graphics object thereby ensuring that the graphics object is not simultaneously referenced by the CUDA context and the graphics context . As described in greater detail in the CUDA driver and the graphics driver use one or more semaphore mechanisms included in the compute device to perform this synchronization.

Advantageously since the graphics object is marked as registered for CUDA interoperability the location of the graphics object will typically remain stationary after the initial register call and consequently the map call executes quickly. More specifically while executing the map call the CUDA API does not launch any memory mapping operations unless the location of the graphics object has changed since the most recent register or map call. However if the graphics object has been moved then the CUDA API re registers the graphics object before proceeding with the map call.

Similarly while executing an unmap call the CUDA API configures the CUDA driver and the graphics driver to synchronize the access of the graphics object thereby ensuring that the graphics object is not simultaneously referenced by the CUDA context and the graphics context . Again as described in greater detail in the CUDA driver and the graphics driver use one or more semaphore mechanisms included in the compute device to perform this synchronization.

Finally after the application program has completed all the CUDA processing tasks associated with the graphics object an unregister call may be used to signal that the application program is no longer using the CUDA API to access the graphics object . While executing an unregister call the CUDA API configures the graphics software stack to mark the graphics object as unregistered for CUDA interoperability. Among other things this allows the graphics software stack to disregard interoperability constraints and restore the standard resource manager policies associated with the graphics object .

In alternate embodiments the interoperability functionality may be exposed to the application developer through the graphics API or any other programming interface and may operate on any types of data. Further data may be allocated and aliased in any technically feasible fashion and subsequent accesses to the shared data may be coordinated using any protocols known in the art.

As the host executes the application program the application program may emit calls using both the graphics API and the CUDA API . In response to these calls the graphics API and the CUDA API configure the graphics driver to append commands to the graphics push buffer and concurrently configure the CUDA driver to append commands to the CUDA push buffer . The compute device receives the commands included in the graphics push buffer via a graphics channel and encapsulates these commands inside the graphics context . Similarly the compute device receives the commands included in the CUDA push buffer via a CUDA channel and encapsulates these commands inside the CUDA context . The compute device reads and executes the commands inside the graphics context and concurrently reads and executes the commands inside the CUDA context .

To ensure proper execution of the various application programs and to avoid corrupting data the compute device may be configured to acquire and release semaphores that reside in shared memory locations such as the semaphore residing with the semaphore buffer of . These semaphores synchronize the execution of two or more channels such as the graphics channel and the CUDA channel . For example a semaphore acquire command causes a particular channel to suspend execution until the specified semaphore memory is released and a semaphore release command causes the compute device to release the specified semaphore memory.

The graphics driver and the CUDA driver collaborate using the semaphore mechanism to ensure mutually exclusive access to any shared graphics objects such as the graphics object . Again when the CUDA API executes the register call targeting the graphics object the CUDA API launches tasks that allocate and setup the semaphore buffer that is associated with the graphics object . Subsequently when the CUDA API executes a map call the CUDA API configures the graphics driver to insert a semaphore release command into the graphics push buffer and configures the CUDA driver to insert a semaphore acquire command into the CUDA push buffer . Both the semaphore release command and the semaphore acquire command reference the semaphore buffer . The compute device reads and executes the pending CUDA commands . However the semaphore acquire command causes the CUDA channel to suspend further execution until the compute device receives and executes any pending graphics commands that may reference the graphics object and the semaphore release command . These synchronization steps ensure that the graphics object is not simultaneously referenced by both the CUDA context and the graphics context .

In some embodiments after inserting the semaphore release command into the graphics push buffer the graphics driver may mark the graphics object as inaccessible to the graphics software stack . Marking the graphics object in the fashion ensures that the graphics software stack does not access the graphics object while the CUDA software stack is using the graphics object .

When the CUDA API executes an unmap call not shown the CUDA API configures the graphics driver to insert a semaphore acquire command into the graphics push buffer and configures the CUDA driver to insert a semaphore release command into the CUDA push buffer . Upon receiving the semaphore acquire command the graphics channel suspends execution until the compute device executes the CUDA commands preceding the semaphore release command and the semaphore release command. Again these synchronization steps ensure that the graphics object is not simultaneously referenced by both the CUDA context and the graphics context .

In alternate embodiments the graphics driver and the CUDA driver may communicate with the compute device in any technically feasible manner such as inserting different commands into the push buffers or employing a communication technique other than the push buffers.

As shown the method begins at step where the application program allocates a graphics object using the graphics API . At step the application program registers the graphics object for CUDA mapping by emitting a register call. The CUDA API receives and executes the register call. As part of step the CUDA API launches tasks that map the graphics object into the CUDA address space and establish a semaphore associated with the graphics object. A series of method steps for registering a graphics object for CUDA mapping is described in greater detail below in . At step if the next API call included in the application program is a call to the graphics API then the method skips steps through and proceeds to step . If at step the next API call included in the application program is a call to the CUDA API then the method proceeds to step .

At step the application program maps the graphics object for the CUDA by emitting a map call. The CUDA API receives and executes the map call. As part of step the CUDA API launches tasks to validate the current mapping of the graphics object into the CUDA memory space. Subsequently the CUDA API configures the graphics driver and the CUDA driver to use the semaphore established during the register call to ensure that the graphics object is not simultaneously referenced by the CUDA context and the graphics context . A series of method steps for mapping a graphics object for the CUDA is described in greater detail below in . At step the application program performs CUDA processing using the CUDA API . At step the application program unmaps the graphics object for the CUDA by emitting an unmap call. The CUDA API receives and executes the unmap call. As part of step the CUDA API configures the graphics driver and the CUDA driver to use the semaphore established during the register call to ensure that the graphics object is not simultaneously referenced by the CUDA context and the graphics context .

At step the application program performs graphics operations using the graphics API . At step if the application program includes any more calls to the CUDA API then the method returns to step where the application program again maps the graphics object for the CUDA. The method continues to execute steps through performing CUDA processing and graphics operations using the graphics object until the application program has performed all the specified CUDA processing and graphics operations.

If at step the application program does not include any more calls to the CUDA API then the application program proceeds to step . At step the application program unregisters the graphics object for CUDA mapping by emitting an unregister call. The CUDA API receives and executes the unregister call. As part of step the CUDA API disables subsequent map and unmap calls associated with the graphics object and notifies the graphics API that CUDA interoperability is no longer required for the graphics object. At step the application program frees the graphics object and the method terminates.

As shown the method begins at step where the CUDA API receives a request to register a graphics object for CUDA mapping. At step the CUDA API launches tasks that configure the computing system to perform any host synchronization that is necessary to allow the graphics object to be registered for CUDA mapping. At step the CUDA API configures a resource manager to allocate a semaphore buffer that is associated with the graphics object. The semaphore buffer enables the compute device to synchronize between the graphics context and the CUDA context . At step the CUDA API further configures the resource manager to make the semaphore available to both the graphics context and the CUDA context .

At step the CUDA API configures the resource manager to duplicate the graphics object handle that the graphics context uses to reference the graphics object for the CUDA context . At step the CUDA software stack allocates a virtual address range within the CUDA address space that is sized to address the graphics object. At step the CUDA API configures the graphics software stack to analyze the location of the graphics object. After analyzing the location of the graphics object the graphics software stack may elect to move the graphics object to a more suitable location. For example the graphics software stack may elect to move the graphics object from the host memory to the device memory. Similarly the graphics software stack may elect to move the graphics object to a location within the device memory that optimizes subsequent unmap and map operations. At step the CUDA software stack maps the memory corresponding to the duplicated graphics object handle into the address range in the CUDA address space allocated at step . Advantageously steps through enable the CUDA context to address the same memory as the graphics context without executing any memory copies or allocating any additional memory.

At step the CUDA API configures the graphics software stack to mark the graphics object as registered for CUDA interoperability. By marking the graphics object in this fashion the graphics software stack influences the memory manager included in the graphics software stack to preferentially retain the graphics object in the device memory at the current location thereby optimizing subsequent map and unmap calls.

As shown the method begins at step where the CUDA API receives a request to map a graphics object for the CUDA. At step if the CUDA API determines that the graphics object has not been moved since the most recent register or map call then the method skips steps through and proceeds to step . If at step the CUDA API determines that the graphics object has been moved since the most recent register or map call then the method proceeds to step . At step the CUDA API configures the graphics software stack to analyze the location of the graphics object. After analyzing the location of the graphics object the graphics software stack may elect to move the graphics object into a more suitable location. For example the graphics software stack may elect to move the graphics object from the host memory into the device memory. At step the CUDA API re registers the graphics object for CUDA mapping performing the same steps that the CUDA API performs upon receiving a register call from the application program .

At step the CUDA API configures the CUDA driver to insert a semaphore acquire command into the CUDA channel . This command references the semaphore buffer that was created when the graphics object was registered for CUDA mapping. The semaphore acquire command causes the CUDA channel to suspend execution until the semaphore is released. At step the CUDA API configures the graphics driver to insert a semaphore release command into the graphics channel . Again this command references the semaphore buffer that was created when the graphics object was registered for CUDA mapping. After the compute device executes the semaphore release command the CUDA channel resumes execution. Advantageously steps and synchronize the access to the graphics object by the CUDA API and the graphics API thereby ensuring that the graphics object is not simultaneously accessed by both the CUDA API and the graphics API .

In sum an application developer may tailor an application program to efficiently utilize multiple APIs to seamlessly interoperate on shared data by including interoperability calls. In one embodiment the CUDA API the CUDA driver and the graphics driver are enhanced to enable the specification and execution of these interoperability calls. When an application program emits a register call the CUDA API ensures that the targeted graphics object is accessible to the CUDA. Among other things while executing the register call the CUDA API launches heavy weight tasks such as ensuring that the graphics object is in the device memory and mapping the graphics object into the CUDA address space. Further a resource manager allocates a semaphore buffer in the device memory. Subsequently when the application program emits map and unmap calls the CUDA API launches typically lighter weight tasks that respectively enable and disable CUDA API access to the graphics object. Moreover while executing the map and unmap calls the CUDA API configures the CUDA driver and the graphics driver to use the semaphore buffer in conjunction with the semaphore mechanisms in the compute device to synchronize the access to the graphics object. Finally when the application program emits an unregister call the CUDA API disables subsequent map and unmap calls and notifies the graphics API that CUDA interoperability is no longer required for the graphics object.

Advantageously mapping the graphics object into the CUDA address space allows application programs to use both the graphics API and the CUDA API to access the data in the graphics object without allocating additional buffers or copying data. Moreover using one or more semaphore mechanisms to synchronize access to the graphics object enables the compute device to efficiently ensure exclusive access to the graphics object. Finally by partitioning the tasks involved in sharing the graphics object into a heavy weight register call and typically lighter weight map and unmap calls the CUDA API allows application developers to further optimize the performance of application programs.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program s of the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present invention are embodiments of the present invention. Therefore the scope of the present invention is determined by the claims that follow.

