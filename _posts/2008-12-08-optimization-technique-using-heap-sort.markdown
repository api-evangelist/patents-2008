---

title: Optimization technique using heap sort
abstract: A method and a corresponding computer-readable medium are provided for optimizing a decision assignment based on a sought benefit. The optimization operations include mapping agents to actors into pairs, designating a benefit to each pair for a set of nodes, arranging the nodes into heaps (with each heap corresponding to an agent), selecting the node with the sought benefit as the head of the heap for all the heaps, and summing each benefit of the heads to establish a cumulative benefit. The benefit designation further includes associating the node with the benefit, action and agent that correspond to that pair, and disposing the node into the heap that corresponds to the agent. Arranging the heap further includes comparing first and second nodes to determine which has the sought benefit within the heap, and ordering the peak node as the head of the heap. Further operations include deconflicting first and second heaps that have heads with equal benefit, and truncating tail nodes from the head of each heap.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08095491&OS=08095491&RS=08095491
owner: The United States of America as represented by the Secretary of the Navy
number: 08095491
owner_city: Washington
owner_country: US
publication_date: 20081208
---
The invention described was made in the performance of official duties by one or more employees of the Department of the Navy and thus the invention herein may be manufactured used or licensed by or for the Government of the United States of America for governmental purposes without the payment of any royalties thereon or therefor.

The invention relates generally to optimization. In particular this invention provides an expedient technique for maximizing decision benefits for multiple agents and actions by heap sorting.

Many fields involving multiple interacting parameters assign a first series of agents to a second series of actions. This is known to have no perfect solution that can be calculated in real time for very large data sets. A simple example can be described for two planes and two flight plans. Given the specific speeds and distance of each flight one objective might include assigning the planes to the flights so that the planes arrive at most nearly the same time. In such a simplistic example there are only four potential solutions for inspection to determine the optimal.

For practical applications the potential solutions may lie far beyond the acceptable bounds of real time computation. For this reason optimization algorithms are necessary to determine which set of assignments correspond to the best indicators of a beneficial outcome. This type of problem is a subset of integer programming.

Conventional optimization techniques yield disadvantages addressed by various exemplary embodiments of the present invention. In particular the deterministic method to optimize assignments of agent to action necessitates more computation time than practical operations allow. Various exemplary embodiments provide expeditious operation techniques using heap sorting.

In various exemplary embodiments a na ve or brute force version of the deterministic method is used for comparison with the heap sorting method. This conventional method called Probabilistic always computes the correct solution but suffers from the classic problem of excessive computation time. This deterministic method has origins in the military domain for selecting the set of decisions that offers the sought benefit value. An example benefit for a weapon agent against a target action would be best probability of kill.

Various exemplary embodiments provide a method and a corresponding computer readable medium for optimizing a decision assignment based on a benefit. The optimization operations include mapping agents to actors into pairs designating a benefit to each pair creating a node for each pair and associated benefit arranging the nodes into heaps selecting a head node among the head nodes that has a sought benefit as an assignment repeating the selection operation iteratively until each heap has a corresponding assignment and summing the selected heads to establish a cumulative benefit.

In various exemplary embodiments the benefit designation further includes associating the node with the benefit action and agent that correspond to that pair and inserting the node into the heap that corresponds to the agent. Arranging the heap further includes comparing first and second nodes to determine which has the sought benefit within the heap and ordering the peak node as the head of the heap. Further operations include deconflicting first and second heaps that have heads with equal benefit and truncating tail nodes from the head of each heap.

In the following detailed description of exemplary embodiments of the invention reference is made to the accompanying drawings that form a part hereof and in which is shown by way of illustration specific exemplary embodiments in which the invention may be practiced. These embodiments are described in sufficient detail to enable those skilled in the art to practice the invention. Other embodiments may be utilized and logical mechanical and other changes may be made without departing from the spirit or scope of the present invention. The following detailed description is therefore not to be taken in a limiting sense and the scope of the present invention is defined only by the appended claims.

Various exemplary embodiments described herein illustrate advantages of heap sorting as compared to deterministic solutions for optimizing decision assignments based on calculated benefit.

A tabular comparison shows a series of set benefit calculations. The first set benefit derives from the assignment of the first agent P to the first action J and the assignment of the second agent P to the first action P which corresponds to minimal gain Ofor any assignment set possible from array . The third set benefit derives from the assignment of the first agent P to the second action J and the assignment of the second agent P to the first action J which corresponds to break even gain O. By contrast the last set benefit derives from the assignment of the first agent P to the second action J and the assignment of the second agent P to the second action J which corresponds to maximum gain O. A sought benefit can be maximum minimum or break even gain or relate to alternate quantifiably comparable objective.

While the exemplary embodiments related herein are examples of a search for the maximum gain O those skilled in the art will have no trouble adapting the method to search for either of the other optimal solutions as well as optimal objectives based on other constraints. The process of adapting the method includes altering the heap order relationship and making comparisons during each iterative step.

Deterministic methods can be used to obtain the optimal solution. Unfortunately deterministic methods have a very high order of complexity driven by the number of agents and actions. This renders these conventional methods as impractical for real time calculations that involve large numbers of agents and actions. Various exemplary embodiments describe advantages of heap sorting as compared to deterministic solutions for optimizing decision assignments based on calculated benefit.

There exist heuristic algorithms which use a best guess method and attempt to derive the optimal answer. Genetic variation algorithms are representative of the set of heuristic solutions. Genetic algorithms vary assignments as genes and attempt to produce an optimal generation. However such algorithms require many iterations. Moreover although these can judge overall fitness of the solution calculated these cannot determine the degree of accuracy of the final solution.

One commonly used deterministic algorithm is called branch and bound in which each possible agent action assignment takes place in a descending tree of possibilities i.e. examining a first agent at the base of the tree with a branch existing for all possible assignments examining a second agent at the next level and so forth . This also calculates every single solution and thus provides no advantage over the brute force method unless bound by some constraint to disqualify some as yet incomplete branches. This bound enables a multitude of potential solutions to be ignored as less advantageous or inconsistent with the constraint. This leads to more rapid calculations and a completely accurate solution but in practical applications fewer constraints or more options quickly expand the calculation time beyond control. Alternatively the use of a heuristic algorithm may be faster but at worst the calculation can require an indefinite calculation time. Although the calculation time might be arbitrarily controlled for very simple examples the degree of accuracy of a heuristic solution cannot be known. Neither branch and bound nor a genetic variation algorithm presents desirable characteristics for high order problems in which accuracy ranks high in priority.

Decision assignment problems based on calculated benefit begin by calculating the benefit from all assignments. An array of agents and actions can be selected with assigned benefit values for each array element. This may involve each agent selecting an action or no action. The assignments and benefits can be represented as a probability table to identify probable benefit value of each assignment. The deterministic algorithm needs to examine each possible permutation of assignments the storage and calculation requirements of which can rapidly grow exponentially. By contrast for the heap algorithm these steps include having each agent select each action to form a heap limited in size to the number of agents.

The heap algorithm orders the heaps according to a sought benefit as the desired optimum. For the condition in which the desired optimum is O the heaps are ordered with their heads as the highest benefit values. Then in the first iteration the heap algorithm selects the highest probability of benefit from the heads of heaps after removing conflicts with the same benefit and action by determining the next greatest benefit from the superior combination. The heap algorithm removes the selected agent from the next iteration and removes the selected action from the remaining heaps. These assignments can be stored with the corresponding benefit yielding on average 92 of the optimal solution from the probabilistic analysis . One major advantage of the heap algorithm provides calculation times and storage requirements several orders of magnitude less than for the deterministic algorithm.

The general methodology for heap sort can be described in context of a ship defense example. Asset defense e.g. a combat ship as an objective can be performed by w agents e.g. weapons . This asset can be threatened by t possible actions e.g. targets . The benefit for defense can be characterized by a known set of pvalues e.g. kill probabilities for each agent to action e.g. weapon to target assignment. Each w agent can be limited to a single t action although there may be more targets than weapons. The optimal solution of w t can be selected to maximize the probable benefit e.g. number of kills as for a total operation.

Optimization techniques as provided in various exemplary embodiments employ heap sorting to reduce the number of calculations. A heap represents a collection of objects organized into a tree of nodes. shows an exemplary binary tree with a head denoted at the top. The size of the heap constitutes the number of nodes in the tree. The height of a heap corresponds to the number of node levels. For example the heap includes seven nodes in three levels. Each node that connects to a lower node constitutes a parent of that lower node. Each node connecting to a higher node is a child of that higher node. The head of the heap represents a node having no parent.

A heap operation represents an instruction regarding the heap order. provide examples of such operations. The operation Head presents the object or node at the head of the heap . The operation Tail provides the remainder of the restructured heap. These operations may be nested. The operation Tail Tail removes the head rearranges the nodes so that a child node becomes head of the remainder and then repeats the action on the new heap. The operation Head Tail Tail isolates that head of the Tail Tail .

Such an order insures that the Head of an ordered heap returns the node that satisfies the relationship for all other nodes. shows that the head on the left satisfies such a relationship with each of the child nodes of the tail . Additionally such an order insures that the Tail can be reordered to maintain that relationship. shows the Tail of the heap so that the second tail node has become the new head and its child node previously in position for the tail node in the third level directionally shown by a curved arrow in the heap . Another third level node previously corresponding to the third level connects to the repositioned second level node . Such an order also insures that successive Head of Tail operations constitutes and ordered list. provides such an ordered list sequenced nodes and by value.

For a positive response to the second query the process examines the next unassigned agent and proceeds to a third query to determine whether the assignment represented by the head of the stored agent is more beneficial than that represented by the head of the agent under examination. For a negative response the process refines the examination with a fourth query to determine whether two assignments equal each other. For a positive response to the third query the process concludes that no change is needed and returns to the second query . For a positive response to the fourth query the process diverts to a deconfliction operation in phase IIa followed by a return to the second query . For a negative response to the fourth query the process must store the agent currently under examination as the most beneficial and returns to the second query . A positive response to the first query i.e. that all agents have been assigned terminates the process at the output .

The optimization process may include the following steps first calculate benefit for all assignments second select the highest probability of benefits from among the heads of heaps third repeat the second step until all agents have an assignment. The stored assignments provide on average 92 of the optimal solution.

Calculating the assigned benefits in the first step includes a iterative selection of every action Ac for each agent Ag b assessing the benefit of each action agent pair Ag Ac c dynamic storage of data in a heap for each agent as pairs of action number and corresponding benefit value B d limit of heap size to the order i.e. the number of agents Ag and e order heaps with the head as the maximum value.

Selecting the highest probability of benefit from heads of heaps includes a iterate through the unassigned heaps to determine the maximum benefit represented by the head of each heap b deconflict where two heaps have the same potential benefit from the same action including operations to calculate next greatest benefit for each heap and select from superior combination of the two assignments c remove selected agent from next iteration d removing selected action from remaining heaps and e store assignment corresponding to selected benefit.

An optimal solution can be represented as a binary table indicating assignments rather than benefits. shows an example binary assignment array of a typical form of integer programming with a series of four columns. A list of actions Ac Ac Ac represents the first column . A binary value of one for an assignment or zero for no assignment can be inserted into each agent to action block of the array . The second column shows an assignment of the first agent Agto the first action Ac. The third column shows an assignment of the second agent Agto the third action Ac. The fourth column shows an assignment of the third agent Agagent to the second action Ac.

Constraints can impose limitations on assignments. In some cases a row or column sum can also be constrained to impose some assignment behavior. The first kind of constraint requires that no agent assignment sum exceeds unity. The second kind of constraint requires that no action assignment sum exceeds unity. A first constraint assures that no agent can perform more than one action simultaneously. A second constraint indicates that only one agent can perform each action concurrently. In the absence of such a constraint a single action could be selected for multiple agents to each perform. The heap method imposes the first constraint automatically.

The total benefit from the whole set of assignments can be determined through a single probability calculation that depends on the interdependency of each action. Assuming that each of these actions is completely independent of the other a sum of the product of assignments and benefits can be performed by multiplying each binary assignment term in the array with the corresponding benefit term in the array . This can be expressed as 1 2.2 0 1.1 0 0.02 0 0.3 0 0.25 1 1.1 0 0.05 1 1.2 0 1.1 4.5 total.

As the algorithm executes beginning at the phase II input to select the highest value among the head nodes and remove the corresponding action from all heaps . As shown in the first assignment is performed as initialization default at operation for the first agent Ag with the action and benefit pair in bold font this default operation starts the iteration started but does not necessitate that assignment which may change many times during the loop from operations to or . Also the remaining nodes for the first agent Ag identified by dash oval and the nodes for the second and third agents corresponding to the first action Acrespectively identified by dash ovals and are removed in the heaps at assignment operation . In the next iteration examines the remaining heaps in at query to select the highest value that corresponds to the third agent Acassociated with the second action Ac.

This leads to heaps in to set the second assignment for the third agent Ag also in bold as well as removals of its corresponding tail nodes and any nodes associated with the second action Ac. In the final iteration as shown in only a single heap for the second agent Agand its one remaining node that corresponds to the third action Ac. Nonetheless the assignment should be considered as this could be a negative and therefore lessen the value of the whole . At the conclusion in for the assigned heaps in bold font all assignments are shown to have been completed.

Ordering of a heap can be performed as a set of operations. First each assignment has a benefit calculated operation for insertion into the heap operation . Second the optimal benefit can be determined from the set of assignments determined from operation . Under select circumstances conflicts in priority may be identified resolvable by supplemental deconfliction and assignment operations that call their respective subroutine processes .

The first option sums the values for nodes of the first agent Agand of the third agent Ag corresponding to the selection of the first assignment Ag Ac as 2 1.2 3.2 total. The second option sums the values for nodes of the third agent Agand of the first agent Ag corresponding to the selection of the second assignment Ag Ac as 2 1.1 3.1 total. The superior solution employs the first head node for retention having the greater combined sum and removes the second head to be replaced with the second tail node directionally shown by a curved arrow as the maximum alternate between the pair of options. The retained values in the set are denoted by gray continuous ovals around the nodes and and the discarded values by dash ovals around the nodes and .

The heap sort engenders two advantages and two disadvantages over the conventional methods. The advantages are described as follows First the heap algorithm is many orders of magnitude faster computationally than the deterministic method. The algorithm increases in complexity only by the number of agents whereas both deterministic and heuristic methods depend on both agents and actions. Second the average degree of accuracy can be limited below 8 error and in most cases can be significantly below 2 error. This produces for heap sort an exceptionally accurate and predictable error rating which is an improvement on any heuristic algorithm.

The primary disadvantage lies in the error rating. Although the average case has very low in error the individual results may be quite varied and yield high error. In a set of comparison experiments the heap method was compared with a deterministic method in the naval domain called Probabilistic which selects the optimal assignment set which has the highest probability of kill as the benefit. The highest degree of error observed in example calculations produced 55 of the optimal answer corresponding to a 45 error. However this circumstance occurs only very infrequently in low orders of agents w for weapons and actions t for targets . For increases of w and t in general the error decreases rapidly.

The second disadvantage as with most heuristic algorithms corresponds to the inability to determine the proximity of the approximated optimal answer to the correct solution. For any single calculation whether the result indeed represents the optimal answer cannot be established. Thus in low order problems where the calculation time does not present a limiting factor another more accurate algorithm might be selected. The extent of difference between result and the optimal answer also cannot be established. For that reason alone the heap algorithm is constrained by uncertainty for individual calculations. However when applied uniformly over a period of time with multiple calculations the algorithm yields a low and acceptable average error and with much less computation time than conventional techniques.

The heap algorithm might be used in conjunction with several other methods. For circumstances in which branch and bound becomes too cumbersome for high order problems the rapid calculations of a likely perfect answer by the heap algorithm can be used as a bound for the branch and bound algorithm. In this way inferior answers might be pruned quickly and the branch and bound algorithm might more quickly ascertain the true optimal answer.

The heap sort algorithm has been developed for situations in which the number of actions equals or exceeds the number of agents. This assumes that the row sum be limited to a maximum of unity. These assumptions yield less accuracy for situations in which the optimal solution may include more than one agent assigned with the same action. Removing the row sum constraint may enable the heap sort algorithm to operate satisfactory for low orders of agents and actions by omitting conflict checks of the same benefit and removing selected actions from the heap.

Limits of Error The error of the heap algorithm varies from run to run and cannot be predicted with precision. However the algorithm s accuracy can be expressed as an average error for a set of runs. Each of the plotted points in the graphs described herein represents the error for a sample set of five thousand runs and statistical calculations on that sample. From this sample all zero error cases were removed so that only the erroneous solutions could be analyzed. Thus these calculations are pertinent to error alone rather than an average case for the whole set.

Error values can be compared to calculation time for the heap sort. plots a first graph of worst case error fraction with calculation time in milliseconds as the abscissa and error fraction as the ordinate . The open squares represent worst case error data for example calculations. These worst case errors gradually taper with increasing time to about 10 although at early times reach 45 . plots a second graph of average error fraction with the same scales as the first graph . The open diamonds represent average error data. The average error is very low for most of the data indicating the exceptional nature of the worst case error.

In each data group the number of targets increases from t w on the left to t w on the right. The IQR reveals a very limited range for error in all calculations. Nearly all of the data have an IQR limited to less than ten percent 

As can be observed error increases as the w number of weapons agents approaches the t number of targets actions . plots a fourth graph of IQR as an error fraction with the same ordinate as in the third graph but a continuous calculation time as the abscissa . This illustrates the interaction between proximate values of weapon agents and target actions regarding error. plots a fifth graph of IQR with the same ordinate as the third graph but employing number of targets as the abscissa .

Generally an increasing t number of target actions trends with error reduction particularly for such a number exceeding the corresponding w number of weapon agents. The points closest to the ordinate in the fifth graph correspond to w t 2 which presents a counter example of error exceeding 10 . The few IQR values that extend beyond 10 all represent the highest error and highest deviation in which w t such that the agents and actions approach each other in quantity.

For the fifth graph the mean error for all weapon numbers shows an obvious trend of rapid reduction of error into the range of 1 2 . This trend is partially attributed to the error generating factors in the heap algorithm. In some circumstances in which one assignment precludes a slightly better total allocation by ignoring a better individual allocation the algorithm may produce significant error. As the number of possible allocations increase with t target actions and w weapon agents the probability of yielding such a situation diminishes leading to a reduction in large error bounds and a significant decrease in average error.

Calculation Time To compare the probabilistic and heap techniques calculations were performed for random data sets for both paradigms. The time for calculation was recorded for each random data set accordingly. For each data set d the respective probabilistic and heap times and were recorded in milliseconds. Then the cumulative times T for all data sets were summed for the whole of five thousand calculations. The probabilistic and heap cumulative times are expressed as

The graph shows the effects of w weapons and t targets on the probabilistic calculation time. The probabilistic cumulative time Tincreases significantly with respect to t for each value of w. Comparison of an exemplary second degree polynomial line shows each order of w appears to increase the exponent. Thus probabilistic cumulative time Tdepends on both w and t with t increasing the probabilistic calculation time according to some degree of w.

In order to characterize calculation time Big O order analysis was performed on each algorithm. The probabilistic method consists of two parts the first involves calculating the shooting solution the second determines the expected value for each shooting solution. As this second step can be per formed in constant time that offset can be neglected. Determination of shooting solutions can be simplified by selecting one of t targets for each w weapon or t multiplied by itself w times or t actions to the w exponent power which is of order O t .

The heap algorithm consists of two stages the first stores the kill probability pvalues in separate heaps for each w weapon the second extracts the data of n nodes from the heaps again. The first step involves the creation of a heap which is of order O logn . However in this case the heap time truncates to order w so that this step is only of order O logw . The second step exhibits the greatest variability and depends a largely on the individual data set. At worst the step involves an order O w operation but at best is merely order O w . Therefore for the heap algorithm the worst term is of order O w but can be as low as order O w . This result remains consistent with the observations that indicate an increase associated with w but can be variable due to the indeterminate length of the second stage.

As evident from the contour plot the heap contour shows increase with w weapons and lack of dependence on t targets whereas the probabilistic contour compounds increases with both parameters. The heap contour reaches time level of four hundred milliseconds at w 20 irrespective of t with a sensitivity to weapons within the range w h t w w. By contrast the probabilistic contour extends beyond 10milliseconds at t w 20. By comparison the estimated age of the universe is only about 4.3 10milliseconds. The sensitivity of probabilistic time can be characterized by exponential function p t w tthat increases rapidly.

Cumulative Trends in Error and Risk The summation of certain trends often leads to more unusual trend that better defines the situation. The limits of error as described for graphs and relates to erroneous data to define the nature of that error. For error trends and risk the optimal solutions found by the heap algorithm are compared to determine the expected frequency of error and the total error risk to any system using the heap algorithm.

Probable error can be distinguished from probability of non optimal solution. shows a fourteenth non contour graph of error frequency trends with complexity in number of target actions. The abscissa represents the number t of target actions and the ordinate represents the probability of non optimal solutions. A legend identifies symbols for different w number of weapon agents. In particular filled squares denote two weapons filled triangles denote three weapons open squares denote four weapons saltires denote five weapons and crosses denote six weapons. The probability of error generally rises with increasing w number of weapons diminishes with increasing t number of targets.

Concerns regarding error frequency arise from the fact that as with most greedy algorithms the heap algorithm produces the correct answer only on occasion. In most cases especially where t is very high the algorithm can be expected to produce the correct result upwards of 95 of the circumstances. The trend in the graph shows that as t increases the probability of a non optimal solution actually decreases. However in terms of w that solution trend reverses showing a natural disposition to increase the probability of a non optimal solution with rising w. The increase appears to be without bound up to a perfect probability. The fifteenth graph and shows the probability of non optimal solution generally rise with increasing w number of weapons diminishes with increasing t number of targets.

Due to a lack of proof that all answers are incorrect for any value of w a worst case can be assumed to set no bound on the percentage of wrong answers. However the trends show that as t increases this error probability decreases rapidly. In addition the trend identified in graph shows minimization the degree of error in correlation with an increase in t or w. This trend tends to augment the error reducing effect of t in graph while mitigating the increase effect for w.

In comparison shows a fifteenth non contour graph of error risk with complexity in number of target actions. This presents a line graph analogous to the surface graph from left side. The abscissa represents the number t of target actions and the ordinate represents the probable error as a fraction of the solution. A legend identifies symbols for different w number of weapon agents. In particular filled squares denote two weapons filled triangles denote three weapons open squares denote four weapons saltires denote five weapons and crosses denote six weapons. These values indicate the error risk. Error risk is the combination of probability of occurrence shown in the fourteenth graph and the consequence of occurrence shown in the tenth graph .

The definition of error risk depends on two variables probability of an event and the consequence from limiting error trends of the event. These two factors can be combined to accurately predict the expected values of error for any data set. These values represent merely an average that can be expected out of many trials and individual error ranges may be larger or smaller than average. However even with these qualifications the results are extremely encouraging.

The trend shows that although the initial error rating nonetheless increases for values of w the error risk actually remains limited. Thus although the probability of an error increases the value of that expected error decreases. This indicates that a natural bound exists between 6 and 8 error. In addition the combined trends create such a steep drop off in error that the algorithm can be expected to return an answer which is 99 accurate in most cases.

Summary of analysis The heap sorted optimization algorithm is highly accurate especially as the values of w and especially t increase. For low values of t the algorithm can be expected to create a large number of non optimal solutions as w increases but the average degree of error remains very low. Because the heap algorithm provides a good approximation of the probabilistic answer while requiring several magnitudes less time to compute the approximation this process represents an advantageous procedure with which to determine the optimal solution. At any rate conditions in which a finite number of agents e.g. w weapons must be selected among a larger number of actions e.g. t targets the heap algorithm may be used to create a rapid near perfect approximation of the actual optimal answer.

Heap Algorithm Example shows a series of benefit arrays illustrating heap operations for a set of four columns of agents w . . . w and six rows of actions t . . . t . The first array shows an initial set of benefits as provided in operation . Initially the maximum benefit among all agents i.e. the maximum value of heap heads corresponds to the first agent assignment as provided in operation . The second array identifies the largest benefit of 0.9 as corresponding to the first agent w identified by oval to indicate assignment to the fifth action t. As the array has no larger benefit the query maintains the initial maximum assignment unchanged.

The third array identifies a conflict in query of the same benefit value of 0.8 for the same fourth action tbetween two heaps for the second and third agents wand wshown by dash oval . The deconfliction process considers the next most beneficial assignment. The second agent whas a next highest benefit of 0.5 for the second action t while the third agent whas a next highest benefit of 0.8 for the second action t. In this example the third agent wbenefits as much from the next highest assignment resulting in the conflicted benefit for the third agent w. Hence the fourth array re moves the fourth action tfrom the third agent w resolving the second assignment in favor of the second agent w identified by assigned oval .

By removing the head of the third heap for the third agent w from consideration in the fourth array the remaining tail values are reordered into a new heap. The new head of this heap includes another benefit of the same value of 0.8 at the second action t. This is the highest of the remaining unassigned heaps and the fifth array assigns the third agent wto that value for the second action t identified by oval . Finally the sixth array assigns the remaining fourth agent wto the third action tfor the benefit value of 0.7 identified by oval . A cancel circle in the fourth array denotes the removal of the deconflicted value for the third agent at the fourth action.

Examination of the next highest benefit shows that the second agent wdiminishes to a benefit of 0.5 at the second action t whereas the third agent wexperiences maintains a benefit of 0.8 at the second action t. The process removes the initial head from the third heap shown by cancel circle and reassigns the highest tail node as replacement. The second assignment sets the head of the second heap identified with oval . The third iteration sets the third assignment as the replacement head of the third heap with oval . In the fourth iteration the only remaining heap for the fourth agent whas a head with benefit of 0.7 at the third action tto be set as the fourth assignment identified by oval .

In the first array the rows distinguish arrangements of the agents wand wamong the actions tand t. The columns include first action t second action t first probability of killing the first target P second probability of killing the second target P summarized probability of killing any one target P 1 and summarized probability of killing both targets P 2 . In the first row the first action thas coupled value bb. In the second row the second action thas coupled value bb. In the third row the actions have values respective values of band b. In the fourth row the actions have values respective values of band b. These represent all the possible assignment sets.

The kill probabilities are described as follows In the first row the first kill probability Pcorresponds to 1 1 b 1 b 0.36 due to the product nature of that benefit whereas the second kill probability corresponds to zero. In the second row the first kill probability is zero and the second kill probability Pcorresponds to 1 1 b 1 b 0.24. In the third row the first and second kill probabilities are band b respectively. In the fourth row the first and second kill probabilities are band b respectively.

The summary probability of killing any one target P 1 employs the kill probabilities Pand P as well as their respective opposite probabilities 1 P and 1 P . The first row sums the probability product of P 1 P plus 1 P Pas 0.64 1 0.36 0 0.64. The second row sums the probability product as 0.24 1 0.76 0 0.24. The third row sums the probability product as 0.4 0.95 0.6 0.05 0.41. The fourth row sums the probability product as 0.4 0.8 0.6 0.2 0.44.

The summary probability of killing both targets P 2 multiplies the first and second kill probabilities together. Thus for the first two rows the summary probability of killing both targets is zero. For the third row the kill probability product is bb 0.4 0.05 0.02. For the fourth row the kill probability product is bb 0.4 0.2 0.08.

The EVK list in the table provides weighted values corresponding to number of targets killed times the summarized probabilities of that number of kills as 1 P 1 2 P 2 . The first row features 0.64 0 0.64. The second row features 0.24 0 0.24. The third row features 0.41 2 0.02 0.45. The fourth row features 0.44 2 0.08 0.60. The first and fourth rows correlate closely in benefit value. The first row as the maximum expected kill value corresponds to the probabilistic solution. The fourth row corresponds to the heap solution and represents 93.8 of the optimal.

A comparison table lists the kill and summary probabilities as described for the table identifying the parameters in the first row. The probabilistic values are presented in the second row. The heap values are presented in the third row. The probabilistic EVK is 1.6 as optimal in comparison to the heap EVK as 1.32 that corresponds to 82.5 of the optimal. However the example values are contrived to favor the probabilistic solution. Thus in a more typical problem the heap solution should correspond more closely to the probabilistic with the advantage of improved computation speed.

Thus the heap algorithm provides an expeditious solution for optimization problems. The solutions described by these exemplary methods provide acceptable correlation to probabilistic methods while enabling results within practical time limits.

While certain features of the embodiments of the invention have been illustrated as described herein many modifications substitutions changes and equivalents will now occur to those skilled in the art. It is therefore to be understood that the appended claims are intended to cover all such modifications and changes as fall within the true spirit of the embodiments.

