---

title: Request processing for stateless conformance engine
abstract: A method and an apparatus to increase conformance of a storage implementation of a data set to a storage policy are presented. In one embodiment, the method includes performing a conformance check of a data set state and an associated data management policy. The method includes identifying a set of tasks that can be performed to increase conformance of the data set state to the associated policy, and generating a task list using tasks from the set of tasks. The method further includes outputting an indication of the task list to a user and accepting from the user an approval of the task list before generating and executing a second task list.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08321867&OS=08321867&RS=08321867
owner: Network Appliance, Inc.
number: 08321867
owner_city: Sunnyvale
owner_country: US
publication_date: 20080124
---
The present invention relates to networked data storage systems and more particularly to managing data storage using data sets.

A networked data storage system can be used for a variety of purposes such as providing multiple users access to shared data or facilitating backups or data mirroring. A networked data storage system may include a number of storage servers. A storage server provides services related to the accessing and organizing data on mass storage devices such as disks. Some storage servers are commonly referred to as file servers as these storage servers provide clients with block level access to data. Some storage servers provide clients with sub file level access to data e.g. block level access . An example of a storage server is any of the file server products made by Network Appliance Inc. in Sunnyvale Calif. A storage server may be implemented with a special purpose computer or a general purpose computer programmed in a particular way. Depending on the application various networked storage systems may include different numbers of storage servers.

Logical units of storage may be created and manipulated on storage servers such as files directories volumes qtrees which is a subset of a volume optionally associated with a space usage quota logical unit numbers LUNs etc. Such logical units are referred to as storage objects in this document. Creating a single storage object is typically fast and easy but managing a storage object over time is more difficult. A storage administrator has to make numerous decisions such as how to monitor the available space for the storage object how to schedule data backups how to configure backups whether the data should be mirrored where data should be mirrored etc. Answers to the above questions may be summarized in a data management policy. When the data management policy is determined the administrator works to ensure that the policy is correctly implemented on all relevant storage objects that the required space is available that the data protection operations succeed and the like. If the administrator decides to change the policy for example extending the amount of time that backups should be retained the administrator normally must find all of the affected storage objects and then manually re configure all of the relevant settings.

As the number of storage objects grows in the system the administrator s job becomes more difficult and complex. It becomes increasingly likely that the administrator may not readily determine what policy was supposed to apply to a given storage object or why a given volume is mirrored e.g. copying data from a given volume to a backup volume so that the data can be recovered . In addition the administrator normally has to perform many tedious manual tasks for each storage object which can be error prone and unreliable. A large data center may have hundreds to over a thousand storage servers. Each storage server may manage hundreds of storage objects e.g. volumes and thousands of qtrees . This leads to a total of tens to hundreds of thousands of storage objects to manage with a similar number of backup and mirror relationships. The number of objects typically grows faster than the number of administrators that are employed so each administrator manages more and more objects over time. Eventually the sheer number of objects makes it increasingly less economical if not impossible for an administrator to reliably implement data management policies and to accurately check for conformance to the data management policies.

A data management policy is used to describe how stored data is to be protected against data loss. The policy describes an intended behavior for data storage using storage objects. In some embodiments a data management policy may be represented by a tree graph having a number of nodes and branches. shows a tree graph of one embodiment of a data management policy. The tree graph includes nodes and branches . Each node represents a storage object and is coupled to another node via a branch which describes the relationship between the two corresponding storage objects. For example branch is marked as a backup connection between nodes and . Thus storage object represented by node is a backup copy of the storage object . Backup copies of storage objects thus provide redundant storage. Another relationship that can be specified is a snapshot process in which the active tile system e.g. a file system to which data can be both written and read at the storage site is captured and the snapshot is transmitted as a whole over a network to the remote storage site. A snapshot is a persistent point in time PPT image of the active file system that enables quick recovery of data after data has been corrupted lost or altered. Snapshots can be created by copying the data at each predetermined point in time to form a consistent image or virtually by using a pointer to form the image of the data. Accordingly the graph represents how the administrator intends to manage data in the data storage system.

Conformance is determined by comparing the configuration of storage objects actually used to store a data set against a set of user defined policies and configurations. If the policies are not being adhered to then the system is out of conformance. Software applications have been written to attempt to help ease the burden of management for ensuring conformance with data management policies.

In conventional policy driven management applications such as IBM Tivoli HP OpenView Calif. Unicenter and BMC Patrol an administrator is normally expected to understand the state of the systems under management and to know what changes should be made to the system to accomplish a goal. A storage management application from Replicus allows a user to specify levels of redundancy but does not allow a user to see the consequences of the specification before applying the results. Additionally the conventional management applications do not scale well as the complexities of data storage systems grow in an exponential fashion. Furthermore conventional approaches use an if then approach for every state of a system and do not abstract away many of the technical details that administrators may not understand nor would care to deal with. Thus calculating actions to perform for reconfiguring a system in response to a given policy change is of unbounded complexity as systems become more complex and storage administrators desire help in identifying nonconformities abstracting details and determining the effects of bringing a system into conformance.

The present disclosure includes a method and an apparatus to provide request processing for a stateless conformance engine. A state is a unique configuration of information in a program or machine or engine. A state machine is a behavioral model that is composed of a finite number of states transitions between those states and actions that describe an activity to be performed at a given point. In contrast the conformance engine is stateless because the conformance engine does not need to have rules that describe an existing state of a storage system and the actions that are to be taken to bring the storage system as it currently exists into a state of conformance. The state of conformance can be determined by comparing a state of a data set against a data management policy associated with the data set to determine if the data set currently conforms to the data management policy. The method includes performing a conformance check of a state of a data set and an associated data management policy. The method includes identifying a set of tasks that can be performed to increase conformance of the data set state to the associated policy and generating a task list using tasks from the set of tasks. The method further includes outputting an indication of the task list to a user and accepting from the user an approval of the task list a dry run task list before generating and executing a second task list the task list to be actually executed .

Other features of the present disclosure will be apparent from the accompanying drawings and from the detailed description that follows.

A method and an apparatus to provide request processing for a stateless conformance engine are described. In the following description numerous specific details are set forth. However it is understood that embodiments of the invention may be practiced without these specific details. In other instances well known components structures and techniques have not been shown in detail in order not to obscure the understanding of this description.

In one embodiment the method includes automatically measuring the conformance of a data set having a set of storage objects to a data management policy and allowing an administrator of a network data storage system to view a report of the conformance or lack of conformance . Each storage object may include logical representations of a collection of data and replicas of the collection of data. The collection of data is normally stored in one or more storage containers. A storage container can be a device used for long term storage of memory such as a disk RAID group plex of one or more RAID groups aggregate of plexes volumes qtrees LUNs logical unit number and the like. The storage containers are managed by one or more storage servers in the data storage system and are independent of the logical representation.

The method further includes executing a conformance check that compares the state of the storage system to a policy for the storage system and automatically provides a user with a list of proposed remedial tasks actions. The list of actions can be based on the degree of non conformance. The list of proposed actions can be evaluated by the severity of the potential impact to the system. Actions that can have potentially severe effects on the system such as copying an entire storage volume that is heavily loaded can be grouped together and put into categories that for example contain actions that require administrator approval and actions that require the intervention of the administrator. The effects of a potential change to a policy or to a data set can be estimated by evaluating the potential change by using the conformance checker. The impact of the potential change can thus be evaluated by an administrator before sending the changes to a conformance engine that commits the changes to the system. Thus using a conformance checker can vastly reduce the workload determining and correcting conformance of data sets to management policies. The data sets storage objects and data management policy are further discussed below.

In one embodiment data is stored and transferred in units of files in the data storage system . Therefore the system may be a file based networked storage system. In such an embodiment the system can be a network attached storage NAS system that provides clients with access to data at the file level. A NAS system uses file access protocols to retrieve data such as for example Network File System NFS or Common Internet File System CIFS . The files are logically arranged into directories. A volume of storage devices may be mapped to one or more directories. Alternatively the system may include or be part of a storage area network SAN to provide clients with access to data at the block level of storage servers. A block is the basic unit used to store data in the SAN.

Note that any or all of the components of system and associated hardware may be used in various embodiments of the present invention. However it can be appreciated that other configurations of the networked data storage system may include more or fewer devices than those discussed above.

In one embodiment the client machine is used by a storage administrator and thus may be referred to as an administrative client. In contrast the other client machines and are used by users of the network data storage system to access data and thus may be referred to as storage clients. Of course a storage client and an administrative client may not be mutually exclusive that is both the administrator and users may use the same client machine in some embodiments. The client machines and may be implemented on personal computers PCs laptop computers special purpose computing devices etc. The client machines and often belong to users that work for different organizations and or groups.

Still referring to the client machine is coupled to the storage manager which is further coupled to the storage manager persistent store . The storage manager is an application that is used by an administrator to implement and manage data storage solutions such as where a group s data should be stored and how it should be backed up . The storage manager may be implemented on one or more servers personal computers PCs special purpose computing machines etc. The storage manager may include an application programming interface API to interface with the client machine . Further the storage manager may include a data set support module to manage data sets and implement related policies. The storage manager may also include a data set conformance module to for example manage conformance of storage solutions to a defined storage management policy. The storage manager may further include a user interface module to create a user interface e.g. graphical user interface GUI command line interface CLI etc. and to provide the user interface to the client machine via the API . In some embodiments the API may be implemented on a separate server coupled between the storage manager and the client machine . The client machine includes a display e.g. a monitor to present the user interface e.g. the GUI to an administrator of the data storage system . Using the GUI the administrator may input information of data sets and data management policies to the storage manager and review a list of potential actions for enhancing the conformance of the system. In some embodiments the GUI is presented via a network access application such as an interne browser to the administrator. An exemplary embodiment of screen displays of the GUI is illustrated in .

Based on the administrator inputs the data set support module creates removes and or updates data sets where each data set is associated with a data management policy. Objects representing the data sets and the data management policy are stored in the storage manager persistent store . The storage manager persistent store may be implemented using a storage device that stores data persistently such as a disk a read only memory ROM etc. Using the data sets and the data management policies the storage manager manages data in the data storage system . More details of the data sets data management policies and data management using data sets are discussed below.

In addition to the client machine and the storage manager persistent store the storage manager is further coupled to the storage server the backup storage server and the mirror storage server . It should be apparent that the storage servers and are shown in as examples for illustrative purpose only. Other embodiments of the data storage system ay include more or fewer storage servers each storage server managing a set of physical storage devices such as magnetic disks optical disks tape drives etc. in different configurations.

Still referring to the storage server manages two disks A and B. The disks A and B may hold various storage containers either in whole or in part. A storage container is a unit for storing data such as a file a directory a qtree a volume a LUN etc. For instance the disk A holds two qtrees A and B. As another example a disk may hold part of a volume where the volume spans multiple disks.

The client machines and may access the disks managed by the storage server . For example the client machine stores data in the qtree A while the client machine stores data in the qtree B. To protect the data in the qtrees A and B the storage server may send the data in the qtrees A and B to the backup storage server which creates a backup copy of the data in the qtrees A and B in the disk . In addition the backup storage server may further mirror the disk onto the disk managed by the mirror storage server . In some embodiments the client machine may store data in an internal disk not shown and have the internal disk backed up in the disk managed by the backup storage server . Note that the above are merely one example of data protection policy topologies. It should be appreciated that many different data protection policy topologies may be implemented in the syste . Thus the use of system can cause the conformance of a storage solution to a policy to change for example when resources are not available to meet user demand.

As the numbers of storage servers and disks grow in the networked data storage system the workload as well as the complexity of data management increases. Thus it becomes more difficult for the administrator to manage the effects of changes to a data storage system to bring it into conformance. In order to improve efficiency and to reduce the potential for adversely affecting the system the storage manager automatically determines conformance for example on a periodic basis or in response to user input according to data management policies from the administrator before potential solutions are applied to the system. Details of data sets and the use of data sets are discussed below.

To efficiently manage data the data set support module in the storage manager uses data sets to manage data in some embodiments. In one embodiment a data set includes references to a set of storage objects associated with a data management policy. The data management policy is applied to the data set directing how the administrator wishes the data in the storage objects to be managed as a single unit. In other words a data set is a collection of storage objects grouped by virtue of the storage objects to be managed as a single unit so that the same data management policy and any changes thereof is applied to each storage object of the data set. For example a storage object may be defined to be a home directory of an employee in a company group which is a member of a data set of the home directories of all employees in the company division. The storage objects may be referred to as members of the data set. Thus each set of data stored for different divisions of a company can be managed individually by referencing the data set and associated policies of each division. Before going further into the details of the data set and the data management policy details of a storage object are described below.

A storage object may include a logical representation of a collection of data in one or more storage containers and replicas of the collection of data e.g. a mirrored copy of the data and or a backed up copy of the data . Referring back to the above example a logical representation of the storage object of the employee s home directory may be the employee s identification ID such as jsmith. The collection of data may be created by users or the administrator of the data storage system . In some embodiments the data of a storage object is stored in a storage container or a set of storage containers e.g. the disk managed by one or more storage servers such as the storage server in the data storage system . For example the content of the employee s home directory in the above example may be stored in the qtree A in the disk A.

Some examples of storage objects include qtrees volumes directories etc. These examples may also be referred to as elementary storage objects because they are logical representations of data in basic units of storage in the networked data storage system . Further a storage object may be a reference to a collection of elementary storage objects such as a reference to all volumes managed by a storage server.

Note that the state of the storage containers is independent of the logical representation of the data. Thus the data is not necessarily managed by where the data is stored or how the data is accessed. Rather the data is managed by the logical representation which may be associated with the content of the data. For example the data may be a word processing document employee review.doc stored in the disk A. In the current example the logical representation may be the name of the document e.g. employee review.doc . The storage manager may manage the document by the name of the document i.e. employee review.doc rather than by the storage container e.g. the disk A in the current example or the set of storage containers in which the document is stored. The state of the disk A is independent of the name of the document e.g. employee review.doc stored in the disk A. As such the storage object as well as the data set having the storage object are not bound to any actual physical location or storage container and may move to another location or another storage container over time. For example the storage containers associated with a data set may become obsolete in performance over time and the storage manager may therefore move the data to a set of new storage containers with or without alerting the administrator. Any movement of data sets may be substantially transparent from the administrator s perspective in order to provide a separation of the logical representation from the physical location. Thus the storage manager may re balance resources to enhance conformance e.g. the disks A B and in the data storage system over time. In other words the data set provides the virtualization of the physical storage containers used to hold the data.

In some embodiments a data set includes user created data as well as meta data. Meta data generally is information about the user created data. Examples of meta data include exported names language settings storage server association LUN mappings replication configuration quotas policies consistency groups etc. Meta data may be used to move or restore the corresponding data set. A complete data set backup i.e. both user data and meta data is thus useful in handling disaster recovery scenarios. If the storage system e.g. a file server that hosts the primary storage set associated with the data set is destroyed the data set may be reconstructed on another storage server using another storage set that is a replica of the primary storage set to provide client data access without manual configuration by the administrator.

In some embodiments the storage manager may perform various operations on a data set. Some examples of operations include changing or modifying an associated data management policy of a data set provisioning new members in a data set listing members in a data set adding members to a data set deleting or removing members from a data set migrating a data set to a different set of storage containers generating performance views specific to a data set generating storage usage reports of a data set setting quota on a data set or individual members within a data set. Each of the operations is capable of changing the conformance of a data set to an associated data management policy. The above list is not an exhaustive list of all of the possible operations.

As mentioned above the storage objects in the data set are associated with a data management policy. In general a data management policy includes a description of the desired behavior of the associated data set. For instance a data management policy may describe how the storage should be used and configured. One exemplary data management policy is a data protection policy which describes how storage objects in a data set should be protected. Attributes associated with a data management policy are abstracted at the highest level possible allowing implementation of underlying technology to change over time without adversely impacting the administrator. The use of abstraction in specifying data management policies allows attributes of the data to be described using terms the administrator is comfortable with out having to understand the technicalities of how the storage manager implements the details. The state may be modified without violating or impacting the data management policy. Thus the administrator may be shielded from the implementation details of various underlying implementations that allow the data set to be upgraded without the administrator having to be aware of all of the implementation details.

Once the administrator has added the desired members to the data set the storage manager can automatically start applying the data management policy associated with the data set to all members in the data set. For instance the storage manager can configure storage objects in the data set schedule backup of the storage objects in the data set etc. according to the data management policy. A conformance checker module can produce a list of actions to be executed to bring the state of the data set into compliance. The list of actions provides an approximation of the effort that would be required to bring a snapshot of the ever changing configuration of the storage system into conformance for example a snapshot relationship between the root node and a secondary node that has not been implemented can require considerable bandwidth to implement . This approach provides a stateless conformance check because the checker works on the system as it is at a point in time rather than by using a conventional state machine approach where each change is typically modeled using an if then approach where actions are specified for each contingency. When approval is given for performing the changes listed by the conformance check a second conformance check is run on the system as it now exists which provides stateless conformance checking because the second conformance check does not necessarily depend on the state of the first conformance check .

As discussed above various tasks in the task list that typically could be expected to cause relatively large changes can be presented to administrator for the administrator s approval and or intervention whereas tasks that typically could be expected to have relatively minor changes can be pre approved for example . Approval from other users such as a supervisor can be required before executing tasks that typically can be expected to cause relatively large changes. The secondary approval allows the work flow of a user to be managed which can reduce the risk of negative impacts on system performance.

One embodiment of the storage manager may be implemented on a server as illustrated in . Referring to the storage manager includes a processor a memory a network interface and a storage adaptor which are coupled to each other via a bus system . The bus system may include one or more buses and or interconnects. The storage manager communicates with a network e.g. the Internet via the network interface which can be an Ethernet adaptor fiber channel adaptor etc. The network interface may be coupled to a public network a private network or a combination of both in order to communicate with a client machine such as the client machine usable by an administrator of the data storage system.

In one embodiment the processor reads instructions from the memory and executes the instructions. The memory may include any of various types of memory devices such as for example random access memory RAM read only memory ROM flash memory one or more mass storage devices e.g. disks etc. The memory stores instructions of an operating system . The processor may retrieve the instructions from the memory to run the operating system . The storage manager interfaces with the storage servers e.g. the storage server via the storage adaptor which can be a small computer system interface SCSI adaptor fiber channel adaptor etc.

In one embodiment of the data set conformance module may be implemented on a server as illustrated in . Referring to data set conformance module includes an API a data set edit commit handler a transaction table a policy user interface A conformance checker a storage manager persistent store a conformance engine an edited data set and an edited policy data set conformance module is an example of data set conformance module .

The operation of data set conformance module can be understood with reference to . illustrates a flow diagram of one embodiment of a process to provide conformance checking in a data storage system using data sets. The process is performed by processing logic that is typically hosted by the storage manager that comprises hardware e.g. circuitry dedicated logic etc. or software such as is run on a general purpose computer system or a dedicated machine such as the storage manager in or a combination of both.

Referring to processing logic creates a GUI to receive inputs from an administrator of the data storage system processing block . Processing logic then receives administrator inputs on data sets and or data management policies processing block . For example the administrator may provide information via the GUI to define data sets e.g. names and description of the data set storage objects to be included in the data set etc. and to define data management policies e.g. a data protection policy . The provided information is passed via an API to data set edit commit handler . The data set edit commit handler then causes the conformance checker to perform conformance check of the defined or edited data sets and or associated policies specified by the administrator processing block . The conformance checker produces a list of tasks to take actions to bring the system into conformance as discussed below complete conformance is not always possible such as when not enough memory is available for storage objects .

The task list is evaluated the data set edit commit handler to determine which tasks in the task list require user input or approval. The determination can be made for example by comparing whether a task to be performed is included in a list of tasks that require user approval and or a list of tasks that require user input processing logic .

When tasks in the task list require user approval processing logic the processing logic can present the tasks to a user for example by using a GUI as described above processing logic to obtain user approval. When a user does not approve of a task the processing logic can return to processing logic where the user can provide further edits. In an alternate embodiment tasks that are not approved can be removed from the list and the processing logic can continue at processing logic . When tasks in the task list require user input processing logic the processing logic can present the tasks to a user using a GUI to obtain input from a user to be used to execute tasks in the task list requiring user input. When a user does not provide input for a task the processing logic can return to processing logic . In an alternate embodiment tasks that for which a user does not supply input can be removed from the list and the processing logic can continue at processing logic . At processing logic the processing logic runs a new conformance check and uses a conformance engine to execute and commit the conformance tasks generated by the conformance checker. Thus a conformance check can be run on a system having an arbitrary data set state suggest solutions and bring a system into better conformance with or without human intervention.

Referring to data set conformance module performs conformance checking to determine whether volumes qtrees backup relationships and mirroring relationships match the intent of the administrator when the administrator defined a data set and applied a policy to the data set. If the data set conformance module determines that the implementation of the data policy to the data set does not match the data set policy module then can execute the necessary tasks to bring the data set state into conformance with the data set policy.

Conformance checking can be performed in various situations. For example when a policy is applied to the data set for the first time the data set state will normally not be in conformance. Conformance checking can also be applied when an administrator has edited the data set or edited a policy using a policy user interface for example which is a GUI for creating editing and managing policies the edited policies can be stored in persistent store or changed various resources used by the data set. In such cases the data set conformance module identifies and if appropriate executes tasks to bring the data set state into conformance with the data set policy. Because a single policy can be applied to many different data sets editing the single policy can cause many different conformance checks to be run with each conformance check determining the conformance of each data set that is associated with the edited policy. 

The conformance checker checks the conformance to a data management policy by examining relationships of the storage objects of the data set to other storage objects as specified by the data management policy. For example a data set includes three volumes namely volume A volume B and volume C. The data set is associated with a data management policy that specifies some backup and mirroring relationships between the volumes. Specifically the data management policy specifies that volume A should be backed up on volume B and volume B should be mirrored to volume C. Then the data set conforms to the data management policy if volume A is backed up on volume B and volume B is mirrored to volume C. On the other hand the data set violates the data management policy if volume A is not backed up on volume B and or volume B is not mirrored to volume C. In other words the data set violates the data management policy if the storage objects are not related to each other as specified in the data management policy. Moreover the data management policy may specify more details on the relationships between the storage objects e.g. the frequencies of backup and mirroring . More details on how the conformance checker determines if a data set conforms to or is in violation of a data management policy are described below.

Conformance checking can also be applied when various physical resources and the data set state change outside of the control of the data set conformance module . An example of a data set state change outside of the control of data set conformance module includes an administrator adding a volume to a storage server that is associated with the data set. When the administrator adds a volume to the storage server the data set conformance module discovers the new volume and works to identify and if appropriate execute tasks to protect the contents of the new volume.

A task includes one or more specific machine executable or machine readable instructions to cause a storage server to perform a specific function such as to create a storage object to create a relationship between a set of storage objects to delete a storage object etc. For example when the conformance checker determines that the data set is not in conformance with the data management policy because there is no existing storage object in the data set to backup a storage object the conformance checker may generate a task including instructions to prepare a storage object in order to create anew storage object. The task may further include the parameters of what needs to be done in order to make the data set conform to its policy. Some of the above questions may lead to situations irresolvable by the conformance checker . For example if the data set does not contain enough storage objects to provide a backup the conformance checker cannot resolve this issue unless the administrator supplies more storage objects. The tasks corresponding to these situations are considered to be irresolvable. Other tasks are resolvable meaning that the conformance checker has enough information to decide on the appropriate corrective action. The conformance checker puts the tasks generated into a task list.

As discussed above some of the generated tasks can be excessively source intensive and are thus brought to the attention of an administrator. For example operations such as backup and mirroring baseline transfers are extremely resource intensive. Accordingly the conformance checker generates a task list to be performed so that a list of such operations can be presented to the administrator for approval. For less resource intensive operations e.g. reserving more storage space on a storage element the conformance engine can automatically execute the tasks to bring the data set state into conformance without human intervention. The administrator can specify a list of certain operations having a higher probability of great impact so that the administrator can be notified automatically.

For example a backup task has not been executed on schedule perhaps because enough storage is no longer available and thus is identified as a nonconformity by the conformance check. Because the task is for example included in a notification task list requiring administrator approval to execute the administrator is notified of the nonconformity so that the administrator can lessen the impact of implementing the change such as scheduling the task to run at night or assigning more storage elements .

The function of the conformance checker is normally separated from conformance engine The conformance checker determines what actions should be taken whereas the conformance engine implements the actions to be taken. The separation of the conformance engine from the conformance checker allows the user to evaluate the potential effects of executing the task list before the task list is executed. Conformance checker takes as input a data set definition and an associated policy. Referring now to the conformance checker determines if each child node of the data set corresponding to a parent node of the tree graph is protected by a relationship between storage servers according to the policy block . For example the policy may require volume A to be mirrored to volume B where volume A is on storage server A and volume B is on storage server B. Then the conformance checker checks whether there is a mirroring relationship between storage server A and storage server B. If not then the data set is not in conformance. Otherwise the conformance checker continues at block to determine if there are any source nodes protected by relationships that do not terminate at a destination node of the tree graph. If there are then the data set is not in conformance. Otherwise the conformance checker determines if there are any destination nodes that are end points for relationships not corresponding to the source node block . If there are then the data set is not in conformance. Next the conformance checker determines if there is a missing physical relationship in the tree graph block . If there is then the data set is not in conformance. Otherwise the process continues in .

Referring to the conformance checker determines if there is an existing storage object already in the data set to hold a copy of the source node block . If not the data set is not in conformance. Otherwise the conformance checker determines if the storage object is large enough to hold the data block . If not the data set is not in conformance. Next the conformance checker determines if there is an appropriate destination object block . If so the data set is in conformance. Otherwise the conformance checker determines if an appropriate destination object can be constructed block . If so the data set is in conformance. Otherwise the data set is not in conformance.

Referring to when the state of the data set is not in conformance with the policy the conformance checker generates the task list to be executed as described above. Each task in the task list encapsulates information that is used to perform a particular task. The task list can be presented as a dry run e.g. a trial run without implementing the results report to the user or given to the conformance engine to be committed. The conformance engine executes the tasks on the task list generated by the conformance checker . When the user makes a change to the configuration or policies the effects of those changes can be approximated by running the conformance checker against the modifications without committing those changes. This dry run report allows the user to re consider dramatic changes with the probable effect in mind. Using the dry run report allows users to see the predicted effects of a change based on a simulated conformance check.

The control flow for executing conformance checks is now described in greater detail. When a user such as a system administrator starts to edit an object such as a data set policy or schedule an edit session identifier is used to track the edit transaction the edit session identifier can be obtained from the data set edit commit handler for example . The user performs edit operations on the object for example using a GUI from the policy user interface or data set edit commit handler . As the user edits the objects each editing operation is associated with the edit identifier such that an edit operation can be correlated with the intended object. As the user performs the edits to the object a list of sub objects within the hierarchy of the object can be recorded in transaction table . For example when a data set and an associated policy are edited transaction table contains pointers to an in memory representation of the data set being edited edited data set and an in memory representation of a policy being edited edited policy . The in memory representation of the policy and data set allow changes to these objects to be reviewed e.g. by performing conformance checks before the changes to the objects are committed e.g. written to the storage manager persistent store .

When a user desires to see the potential effects e.g. the dry run results of an edit for an object such as the data set the user can use a graphical user interface generated by for example handler to select a dry run command. The edit commit request can specify whether the results are for a dry run or to be applied to a data set. The API forwards the request to the data set edit commit handler . The data set edit commit handler obtains the data set pointer for the data set being edited from transaction table . The data set edit commit handler also obtains a pointer to the policy from policy user interface that is associated with the data set pointer. The obtained data set pointer and a policy pointer are passed to conformance checker .

In another example where the object being edited is a policy a user can be asked if the edited policy is to apply to individual data sets or is to apply to all data sets that are associated with the changed policy. Thus at least one pointer to one of the data sets associated with the policy is passed to the conformance checker because both a data set and an associated policy are used to evaluate and or generate conformance actions.

A list of all impacted data sets e.g. data sets to which the changed policy is applied can be presented to the user. For example when many data sets use a default policy and the default policy is then edited each of the data sets would then require a conformance check which would require relatively large amounts of CPU and bus bandwidth . The user can be notified of the amount of data sets impacted by the change to the policy so that the user can choose an appropriate way of applying the changes.

The conformance checker can obtain information such as volumes qtrees and relationships thereof for building a storage set from storage manager persistent store . The conformance checker performs the conformance check by traversing the nodes of the structure of the objects for which pointers were passed. The nodes can be traversed using a breadth first traversal although depth first traversal and or combinations thereof can be used. During the traversal the conformance checker looks for conformance actions to be taken for a data set to generate a storage set that is in conformance with a pointed to policy. The conformance checker does not have to be aware that the edited object implementation has not yet been committed to and physically implemented in the data set because of for example the in storage representations of the edited objects and .

For example a directory structure such as data structure shown in can be traversed to check for conformance. According to an embodiment of the present invention conformance checker visits each node in the structure i.e. traverses the structure to identify nodes that represent directories and places these nodes into a processing queue. Various algorithms can be used to traverse a hierarchical structure to identify nodes that represent directories. These algorithms can differ in the order in which the nodes are visited. In one implementation a breadth first search BFS algorithm is used to traverse the data structure. Briefly using this method the traversal of the structure begins at the root and explores all the neighboring nodes. A neighboring node is a node that is connected to a node that is being traversed. Then for each of those nearest nodes it explores their unexplored neighbor nodes and so on until there are no more nodes in the structure. The following steps describe the BFS algorithm as used in the present invention to traverse directory structure shown in 

4. Otherwise push all the so far unexamined successors of this node e.g. nodes and into the end of the queue if there are any 

5. If the queue is empty every node in the structure has been examined discontinue the search and return not found 

As a result of traversing structure using the BFS algorithm the queue will include the following directory nodes and . According to other embodiments the traversal of the structure can be performed using a depth first search DFS algorithm. A person of ordinary skill in the art would understand that other algorithms that produce similar results can be used to traverse a hierarchical data structure.

For each node traversed a storage set e.g. nodes and that is associated with an encountered node e.g. node is determined by the conformance checker e.g. a list of storage elements used to implement storage for the node is determined by the conformance checker . For the determined storage set a list of volumes qtrees backup relationships and mirroring relationships that originate in the storage set are evaluated to determine ingoing towards parent nodes and outgoing towards child nodes relationships are defined by the list. For each outgoing connection from the source storage set to a destination storage set the conformance checker verifies that there is a corresponding backup or mirroring relationship from each volume or qtree in the source storage set that terminates in a volume or qtree in the destination storage set. Where redundant or unnecessary backup or mirroring relationships are found after checking over each volume and qtree in a source storage set the conformance checker can generate a task to delete those relationships.

When the conformance checker determines that a new backup or mirroring relationship is desired a corresponding destination volume is selected. The conformance checker can optionally use an existing volume or it can provision in a new volume from a resource pool. Typically the conformance checker attempts to reuse volumes that are already used by the data set.

For each node of a storage set the conformance checker verifies that each volume in a storage set contains sufficient memory space to implement the provisioning policy. When a flexible volume e.g. a logical storage container inside an aggregate in a storage set does not contain sufficient memory to implement a desired backup or mirroring relationship the aggregate data set containing the flexible volume can grow the volume by using an assigned resource pool. Additionally some backup or mirroring relationships can be moved to new volumes already in the storage set that contain sufficient memory. If sufficient memory space cannot be found the user can be notified.

The conformance checker can free additional memory by determining whether any backups or snapshots of storage are not required by a data set policy. For example a list of backups for each storage set is maintained and each backup in the list has an expiration date. Conformance checker can consult the list of backups and delete any backup versions that are past their retention date. After deleting backup versions snapshots holding those backup versions can also be deleted by conformance engine . The conformance checker can generate tasks in a task list to indicate that those snapshots should also be deleted.

Each task that is generated by the conformance checker encapsulates all the information or pointers to the information that is used to perform the task. For example each task typically contains an execute task method that does the actual work of executing the task. Each task also has a user message member which is used to provide a human readable description of what the task is intended to accomplish. The user message member is used to present a message to users when the request a dry run before executing the task list using the configuration engine .

Each task can also have an equivalence operator method e.g. A B which means A is equivalent with B which is used when queuing numerous tasks. When a pending task is to be queued the conformance checker searches the tasks already queued in the configuration engine to determine whether an equivalent task has already been queued. Where an equivalent task has already been queued for example when pending task A is equivalent to queued task B the pending task can simply be skipped.

When the conformance checker has completed the conformance check the generated task list is sent to the data set edit commit handler . The data set edit commit handler determines whether the generated task list is for dry run results or is to be committed. The data set edit commit handler can make the determination by referencing an edit identifier that is associated with the generated task list and the original edit request. If the edit commit request specified a dry run the results are passed back to the API for display see below . If the edit commit request specified a commitment the generated task list is sent to the conformance engine where the conformance engine executes the tasks to commit the changes implicated by the tasks. Conformance engine can use transaction table and local in memory copies of edited data set and edited policy to implement the changes. Note the results of the to be committed conformance check are often not the same as the results of the dry run conformance check due to dynamic changes in the data set state that are beyond the immediate purview of the administrator. 

Some portions of the preceding detailed description are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the tools used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here and generally conceived to be a self consistent sequence of operations leading to a desired result. The operations are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms is numbers or the like.

It should be kept in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the above discussion it is appreciated that throughout the description discussions utilizing terms such as processing or computing or calculating or determining or displaying or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

The present invention also relates to an apparatus for performing the operations described herein. This apparatus may be specially constructed for the required purpose or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a machine accessible medium also referred to as a computer readable medium such as but is not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions and each coupled to a computer system bus.

The processes and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with programs in accordance with the teachings herein or it may prove convenient to construct a more specialized apparatus to perform the operations described. The required structure for a variety of these systems will be evident from the description below. In addition the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein.

The foregoing discussion merely describes some exemplary embodiments of the present invention. One skilled in the art will readily recognize from such discussion the accompanying drawings and the claims that various modifications can be made without departing from the spirit and scope of the invention.

