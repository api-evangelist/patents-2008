---

title: Participant positioning in multimedia conferencing
abstract: A multimedia conference technique is disclosed that allows physically remote users to participate in an immersive telecollaborative environment by synchronizing multiple data, images and sounds. The multimedia conference implementation provides users with the perception of being in the same room visually as well as acoustically according to an orientation plan which reflects each remote user's position within the multimedia conference environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07840638&OS=07840638&RS=07840638
owner: Microsoft Corporation
number: 07840638
owner_city: Redmond
owner_country: US
publication_date: 20080627
---
Video camera and audio systems have been developed for improving communication among individuals who are separated by distance and or time. These systems and the process are generally referred to as videoconferencing . Videoconferencing seeks to emulate the range level and intensity of interpersonal communication and information sharing that would occur if the people or meeting participants were face to face in the same room at the same time.

Conventional videoconferencing systems provide video conference participants located at different locations with only an incomplete simulation of the perception or feeling of being in the same physical space. Typically a videoconference system includes one or more standard definition cameras and one or more television sized monitors in each room. The overall approach is simply to enable participants in each room to see each other on their respective video monitors much like watching television. Where the camera is set to capture an image of the entire room the participants in that room often appear small and remote to the viewers in the destination room. Where the camera is zoomed to capture the face of one or the participants then it appears oversized in scale and without any of the context of the rest of the participants. In particular the viewers in the remote room cannot see the reactions body language or other activity of the participants in the source room when the camera is zoomed in on only one of the participants there. Overall no effort is made to create the perception of a single shared physical space between the participants where participants in both rooms can see the entire other room in a realistic and properly scaled fashion.

Further conventional videoconferencing systems are not conducive to how individuals normally interact in a group setting such as in a group meeting with respect to eye contact with each other use of body language and other non verbal cues. As a result participants rely primarily on voice communication and less on useful visual information and cues in order to communicate and thereby fail to convey much of the emotional content experienced with in person meetings.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

As provided herein techniques are described for synchronizing within a multimedia conference multi source data images and sounds to provide a single seamless immersive telecollaborative environment for a plurality of participants respectively located in a plurality of different locations. This permits multiple participants to experience simulated immersion in a real meeting. Furthermore although the participants are physically separated from each other the images of each participant appear in the space of each other participant and synchronized integrated stereo sound provides a sensation of juxtaposition with other participants in the meeting. The systems and methods may be configured to run on personal computers e.g. desktop laptop etc. .

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

Video and telephone conferencing have been widely used technologies to address the scenario wherein remotely located participants to work together and share information. The overall approach of conventional videoconferencing systems is to enable participants in each room to see each other on their respective displays. Such multimedia conferencing tools are constrained however in that they do not allow for telepresence which is generally defined as the experience of presence in an environment by means of communication medium. Participants do not obtain the realistic feel of eye contact or hand gestures among others.

Further the television to television model of videoconferencing systems is not conducive to the normal interaction of individuals in a group setting such as in a group meeting. In actual physical meetings individuals make eye contact with each other and use body language and other non verbal cues user posture . The typical arrangement of a conventional video conference room all but makes realistic eye contact between individual participants impossible and either overly exaggerates or suppresses body language and other non verbal cues. A participant does not experience realistic eye contact when looking at the enlarged face of another person on a television monitor or the display of an entire source room which may hold multiple participants. The result is a rather primitive form of videoconferencing where participants rely primarily on voice and much less on useful visual information and cues in order to communicate and which thereby fails to convey much of the emotional content experienced with in person meetings.

By utilizing an orientation plan for a multimedia conference users are provided with the perception of a shared work environment and can effectively communicate and interact with one another as if they were actually meeting and working in person. The orientation plan may be implemented on personal computer configurations e.g. desktops laptops etc. 

A user group may comprise users and a device group of input and output devices such as monitor speaker keyboard microphone camera etc. . An orientation plan may be devised to position multiple remote users with multiple input and output devices connected to each other to create a semi immersive multimedia conference MMC environment. An example of method is where a first remote user and second remote user each have a microphone input device which records audio data and produces an output signal of the audio data. A third remote user has two speakers. In devising an orientation plan the audio output signal from the first remote user may be mapped to the third remote user s left speaker. The audio output signal from the second remote user may be mapped to the third remote user s right speaker. The advantage of this orientation plan is the creation of the perception that the first remote user is on the left and the second remote user is on the right of the third remote user. The orientation plan may configure the same mapping orientation for video output from the first remote user and second remote user to the third remote user.

An example of a system for devising an orientation plan may be a device e.g. server host computer a remote user computer etc. that each remote user connects to e.g. via an Internet connection . Each remote user may send information to the device such as IP address available input devices available output devices user specified position relationship of remote user to other remote users internet connection rate and or any other relevant information used to devise an orientation plan. The device may then take the information from each remote user and configure each remote user s output signals e.g. camera microphone stylus outputs etc. to each remote user s input e.g. monitor speaker lightbars etc. .

The configuration may comprise mapping specific inputs and outputs to create an orientation plan that positions the remote users in such a way that creates a user experience emulating a person to person conference e.g. each user perceives the other users as if they were located around a large conference table . The environment may provide a user the visual experience viewing through one or more monitors and speakers two remote users facing and communicating with each as if they were in a face to face conversation. The goal of the orientation plan is to provide an environment that emulates the remote user participants as if they were sitting in person around a conference table.

After inputs and outputs of users have been linked the multimedia conference may be facilitated through a common software user interface. The common software user interface may be an application installed on at least one or every user s computer. The common software user interface may facilitate the multimedia conference by providing an interactive environment for a user to participate within the multimedia conference. The common software user interface may also control the input and output devices e.g. turn a lightbar on and off render video output signals within the computing environment and any other management of input and or output devices that provide a multimedia conference environment .

The arrangement comprises for example MMC devices which may establish and facilitate participation of the users in the MMC. As discussed further below with regard to such devices may include at least one set of inputs such as microphones and cameras and a keyboard mouse stylus and tablet . Cameras may comprise any suitable hardware and or software to facilitate capturing an image and or video of users as well as providing the image and or video to other users as an output signal. Devices may further comprise at least one set of outputs for example lightbars speakers and visual displays and and the like. Audio and visual information generated by users using devices are mutually communicated amongst devices through network communication component . Network communication component represents communication equipment including hardware and any appropriate controlling logic for interconnecting devices coupled to network and facilitating communication between remote locations. Network may include a local area network LAN a metropolitan area network MAN a wide area network WAN any other public or private network a local regional or global communication network an enterprise intranet other suitable wireline or wireless communication link or any combination of the preceding. Network may include any combination of gateways routers hubs switches access points base stations and any other hardware software or a combination of the preceding that may implement any suitable protocol or communication.

In there is illustrated an embodiment of an orientation for a detailed device for participation in a MMC e.g. device as illustrated in . By way of example each of the devices from has similar structures and explanation for each individual device will be omitted. It may be appreciated that each device and may have different structures and orientations.

Device comprises user output devices which generate audio visual experiences based upon output signals from other users visual displays and and speakers and outputs. Device also comprises user input devices which produce output signals microphones and cameras and stylus tablet keyboard and mouse inputs. An example of a devised orientation plan involving user and user is user receives audio output signal from user which is mapped oriented to speaker based upon user orientation to the right of user . The visual output signal from user is mapped to monitor based upon the spatial orientation of user being to the right of user .

An example of a devised orientation plan involving user and user is user receives audio output signal from user which is mapped oriented to speaker based upon user orientation being across from user . The visual output signal from user is mapped to monitor based upon the spatial orientation of user being across from user . Likewise image and sound data transmitted from remote user will be produced on visual display and speaker .

The orientation plan provides a MMC environment where user perceives user on the right user on the left and user in front of user . This orientation plan may provide user audio and visual feedback that allows user to perceive user turn and communicate with user through lighting speaker setup and the visual image of turning towards the visual image of user . Similarly the orientation plan may position the output signals generated from the input devices of user from user to the output devices of user and .

In one embodiment users will have corresponding devices for participation in the MMC. In an alternative embodiment inputs and outputs of users may be varied by type of inputs and outputs or by the number of inputs and outputs. For example in there is illustrated an alternative embodiment of an orientation . Rather than an individual display for each user device includes a single display on which image data from users is produced. Device further includes speaker output and microphone and camera inputs oriented to remote user speaker output and microphone and camera inputs oriented to remote user and speaker output and microphone and camera inputs oriented to remote user . User is equipped with keyboard stylus tablet and mouse inputs.

A further alternative embodiment is depicted in in which there is an illustrated orientation . The device comprises a display on which image data output from users and is mapped and displayed in a window format on a single display . Each user visual output signal is mapped to a window.

Device further comprises user input devices microphones and tablet stylus keyboard mouse and cameras and . The user input devices produce output signals that are oriented to other remote users and output devices monitors speakers etc. . For example user may orient the user output signals from microphone and camera . These output signals may be oriented to a monitor and speaker on user device according to an orientation plan.

Device also comprises user output devices speakers and and display . These output devices may be oriented to a remote user s and output signal to provide for audio or visual MMC experience. Depending upon the orientation a user may experience a semi immersive environment where user will be able to detect if user is speaking towards user or towards another remote user such as . This may occur by lighting effects directional sound and or visual notification of a user s head turning towards the monitor representing the user that the user is speaking with.

Orientation of image and sound data produced from users will be devised according to an orientation plan which configures signals from users inputs and outputs to reflect each remote user s position in the MMC environment and conforms the signals to users inputs and outputs. Referring to there is illustrated a depiction of a MMC with four users . Outputs displayed in as visual displays are disposed as if users were present in one location around a conference table .

In one embodiment an orientation plan is created involving each user and . Each user participates in the MMC by communicating with a central server. Users may send information to the server. The information may include hardware devices the user has available number of monitors number of speakers presence of a tablet or stylus etc. and the number of users at the user device. A determination is made as to the spatial relationship e.g. where each user is located in proximity to another user between users and . The spatial relationship between users may be specified according to one or more user s relative position in relation to other users within the multimedia conference. In another embodiment the spatial relationship between users may be specified by a plan generating component. In a further embodiment the spatial relationship between users may be specified according to a predetermined configuration.

One aspect that may vary among embodiments of these techniques relates to the manner in which the orientation plan is devised. In one embodiment the orientation plan may be devised according users preference where users determine the position at which they are seated in the MMC user specifies the position of being on the right of user across from user and to the left of and plan orients their position accordingly for video and or audio output. For example audio output signals from user on the right will map to the speaker on the right of user . In another embodiment the orientation plan may be devised according to a single or host . In a still further embodiment the orientation plan may be devised according to a network program. The plan may be devised manually or automatically.

Once the spatial relationship of the users is created output signals from input devices of other remote users are mapped to other remote users output devices. One mapping may comprise remote users and output signals being mapped to user s output devices monitor speaker lighting system etc. . This same mapping may be done for each user and . This may be accomplished by matching the appropriate output signal with the appropriate user device for example audio signals from user on the left to left speaker video from user on the left to left monitor etc. corresponding to the spatial relationship within the orientation plan . For example the device of user comprises three cameras left camera middle camera and right camera . The orientation plan may specify that user is to the left of user to the right of user and in front of user . The orientation plan may map the output signal from user s camera input device to user s monitor output device . The orientation plan may also map the output signal from user s camera input device to user monitor output device . The orientation plan may also map the output signal from user s camera input device to user monitor output device .

The orientation plan maps output signals to input signals to provide an orientation of image and sound data. The orientation reflects each remote user s position within the MMC environment. Each user will experience a MMC environment that provides a semi immersive experience by means of one user device group of input devices output devices .

In one embodiment the orientation plan may determine and adjust the output signals to a specific remote user based upon at least one criteria for example bandwidth hardware configuration resource availability user posture environmental conditions and the like. For example a user may have one display device e.g. as illustrated by user in and one audio device speaker while there are three other remote users within the MCC. The orientation plan may combine the audio output signals into one audio signal and map the one audio signal to the user s one speaker. Likewise the orientation plan may send the output visual signal of each participant in a lower resolution to the user with one monitor because the user will have three windows that display a smaller resolution than a user with three large monitors. On the other hand a user may have three speakers and three monitors in which case the orientation plan sends three separate audio signals and three separate high resolution visual signals to the user for a well simulated experience. Further where the number of speakers per user varies the orientation plan may generate a virtual space audio in which a virtual speaker corresponds to a user.

A communication component is configured to send data from at least one input of a user group to at least one other user group as an output signal. Communication component processes information and signals received from input such as visual data from a camera or audio data from a microphone and allows exchange of information between input and output of user groups. Communication component includes any suitable hardware software or both that operate to control and process signals for example a programmable logic device a microcontroller a microprocessor or any suitable processing device or combination thereof.

Plan generating component comprises a wrapper configured to generate a plan and send the plan to users within the MMC to manage the experience of users within the MMC. In one embodiment plan generating component may be provided to pre configure a plan for use in the MMC and facilitate the performance of the MMC by users. In another embodiment plan may be provided by input from users such that plan generating component may obtain files and information from users and load and activate in system memory the plan to run the MMC. In a further embodiment plan generating component may be configured to conclude the multimedia conference upon completion by the user groups. Those of ordinary skill in the art may devise many techniques for configuring the plan generating component to manage the multimedia conference while implementing the techniques discussed herein.

In the system described herein a rendering component operatively connected to outputs is provided. The rendering component in one embodiment is configured to perform visual rendering on output devices such as monitors or displays. In another embodiment the rendering component is configured to further perform audio rendering of the MMC on outputs such as speakers headphones or other audio devices. It can further be utilized to accept user input from devices such as a keyboard a mouse a microphone or other like input for example. The inputs and outputs of users may be connected to a common hardware component such as an I O device a hub or any other device for connecting inputs and outputs.

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply one or more of the techniques presented herein. An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to one or more of the principles set forth herein. In one such embodiment the processor executable instructions may be configured to perform a method for orienting a multimedia conference among users such as the exemplary method of for example. In another such embodiment the processor executable instructions may be configured to implement a system for enabling users to participate in a multimedia conference such as the exemplary system of for example. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions or some instructions may be executed at computing device and some at computing device .

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described are not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Users as used herein generally means one or more users and not necessarily all of the users engaging in a particular activity concurrently.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

