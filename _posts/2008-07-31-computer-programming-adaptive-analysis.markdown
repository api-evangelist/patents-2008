---

title: Computer programming adaptive analysis
abstract: A method and apparatus for evaluating quality of a codebase is provided. The evaluation is provided by developing metrics, indicators, and indices for all levels of a codebase to provide indicators of quality and to enable identification of code blocks that need to be improved.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08473907&OS=08473907&RS=08473907
owner: Coverity, Inc.
number: 08473907
owner_city: San Francisco
owner_country: US
publication_date: 20080731
---
This is a United States Patent Application that claims priority under 35 U.S.C. 119 e to United States Provisional Patent Application titled COMPUTER SYSTEM ARCHITECTURE ADAPTIVE ANALYSIS Ser. No. 60 953 077 filed on Jul. 31 2007 which is incorporated by reference in its entirety herein.

In general software are developed using a hierarchical structure. For example the hierarchical structure may include functions or procedures at a lowest level applications at a next higher level packages at yet another higher level and so on. A codebase is a collection of codes at the package level and all associated levels. One problem with developing codebase using the hierarchical structure is that it is difficult to identify design problems and to evaluate the quality of the codebase at the various levels.

The features utilities and advantages of the invention will be apparent from the following description of example embodiments as illustrated in the accompanying drawings.

For some example embodiments methods and systems for evaluation of quality of a codebase are disclosed. The evaluation of the codebase may be based on a hierarchical structure having multiple levels. One or more metrics and indicators may be used to evaluate the codebase at one or more levels. An indicator associated with a level may be natively defined at that level or it may be defined based on indicators associated with lower levels.

In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of some example embodiments. It will be evident however to one skilled in the art that the present invention may be practiced without these specific details.

The methods and systems explained herein will be described in the context of an example hierarchical structure but one of ordinary skill in the art will recognize that the methods and systems may be implemented using other example structures or in relation to other example embodiments. Any embodiment described herein is not necessarily to be construed as preferred or advantageous over other embodiments. Additionally unless explicitly stated otherwise any embodiment provided should be considered an example embodiment.

Referring to the method level may include one or more methods. The method level may include method to method . One or more of the method to the method may represent a specific implementation of an operation that can be executed in response to a request. For example one or more of the method to the method may perform a particular function or application on a specific request.

The class level may include one or more classes. In the example embodiment shown in the class level may include class to class . Although the class level includes a plurality of classes e.g. to it should be noted that the class level may include only a single class e.g. class .

The package level may include one or more packages. In the package level is shown by way of example to include package to package . Although the package level includes a plurality of packages e.g. to it should be noted that the package level may include only a single package e.g. e.g. .

For some example embodiments a group of methods may form a class. For example a group of methods which includes the methods and may form the class . In an example embodiment the number of classes in the structure may be less than the number of methods however that may not be a requirement. For some example embodiments a group of classes which includes the classes and may form the package . In an example embodiment the number of packages in the structure may be less than the number of classes however that may not be a requirement.

The group of packages to may form the codebase which may correspond to the structure for some example embodiments. As one of ordinary skill in the art would recognize the structure may include multiple levels of similarly classified software functional blocks or generically referred to as code blocks . For example the structure may include a second class level illustrated in dotted lines in . The second class level may contain a grouping of one or more classes from the class level . As shown a group of classes may include the classes to from the class level . Although not shown additional package levels may also be applicable.

For some example embodiments metrics are used to evaluate quality of one or more logical modules of the structure . A logical module may be a method a class or a package. Metrics are measurements or benchmarks that are typically objectively calculable. For example one common metric includes counting the lines of code LOC for a method. The metrics may be used to help software developers avoid releasing software packages that may have less than desirable quality.

In the example shown in there are metrics to . Each of the metrics to may relate to some objectively measurable or calculable characteristic of a logical module. When using Java a logical module may correspond to a method class package codebase as described in the example structure of . As mentioned above possible metrics may include a calculation of the LOC contained in a method a calculation of a number of lines of comment LCOM contained in a method a calculation of the number of nested loops in the method a calculation of the number of lines of Javadoc comments. Javadoc comments generally start with the character string and end with the character string as is known to one skilled in the art. For example the method may have 200 lines of code the class may contain 67 nested loops etc. A more detailed description of different metrics is described below.

The metrics may be normalized to generate normalized metrics which may provide a more subjective evaluation of quality. As illustrated in the evaluation hierarchy includes multiple normalized metrics to at level which is above the metric level . The level may be referred to as normalized metric level . For some example embodiments the metrics may be normalized based on industry standard information. For example a desirable number of LOC for a method may be no more than 75 e.g. an upper bound number of LOC for a method . As such a method having 150 LOC would have a metric of 150 and a normalized metric of 2 or 150 75 . Similarly a method having 25 LOC would have a metric of 25 and a normalized metric of or 25 75 . It may be noted that the metrics may be normalized based on information other than the industry standard information or both. Referring to the metrics to may be normalized into normalized metrics to .

For some example embodiments a method associated with a higher normalized metric is considered to be of lower quality than a method associated with a lower normalized metric. Thus in the above examples the normalized metric of 2 is lower or worse than the normalized metric of . However those examples are described in this manner for convenience. It may be noted that the normalized metric and the related quality evaluation corresponds to the portion e.g. a method of the codebase that is measured.

For some example embodiments not all metrics are associated with normalized metrics. For example as shown in the metric is not associated with a normalized metric. As can be appreciated the LOC metric is objective and may be a simple counting of the lines of code whereas the normalized metric is related to a subjective determination. As an example the subjective determination for the LOC is that an upper bound of 75 may be acceptable. It may be noted that although the normalized metric examples relate to linear scaling non linear scaling may also be possible.

As described above a metric may provide an objective or calculative evaluation of a feature such as a method a class a package or a codebase. However a normalized metric may provide a better evaluation for the codebase. As can be appreciated the normalized metric may provide a first type of subjective evaluation of a method a class a package or a codebase.

As illustrated in the evaluation hierarchy includes multiple indicators to at level which is above the normalized metric level . The level may be referred to as indicator level . For some example embodiments an indicator may be defined natively at a level. One or more metrics may be combined with one or more normalized metrics to form an indicator. The indicator may be used to provide quality measurement regarding a particular method class package or codebase. As an example the evaluation hierarchy includes indicators to which are formed using various metrics and or normalized metrics at the metric level and at the normalized metric level .

The indicators may be defined at each level. For some example embodiments indicators formed from one or more metrics may be referred to as type A indicators. The type A indicator may be formed by one single metric that may be normalized using static values or other metrics. The following is an example formula that may be used to define a type A indicator based on a cyclomatic complexity metric as described below at the basic level e.g. method . CYC Formula 1 where Iis an indicator M is a method and Cis a number around 11.

The following is another example formula that may be used to define a type A indicator based on lines of code LOC and lines of Javadoc J metrics LOC 1 Formula 2 where Iis an indicator formed of two metrics LOC and J for a given method where LOC is the line of code in the method J is the lines of Javadoc in the method and is a constant.

For some example embodiments the indicators formed from a combination of other indicators may be referred to as type B indicators. It may be noted that although the type B indicators are not specifically illustrated in they may be similar to the indices at a level above the indicator level .

An index at the index level may be constructed from a number of indicators independently at every level. For a hierarchy level M let I . . . Ibe the n indicators participating in the index under consideration. Let weights w . . . wbe selected for participating indicators and a number m n be fixed. The index I M where M is a module is defined as the sum of the largest m values of the n set wI . . . wI. It may be noted that the weights can be level dependent.

A combination of all the evaluation processes from the lower levels of the evaluation hierarchy may result in an overall evaluation at the top level also referred to as a super index level .

A type B indicator may be formed from several type A indicators. A type B indicator may be defined successively from a set of other type B indicators. The value of the final indicator may be dependent on the order that the participating indicators are employed in the computation. Given a set of type A indicators I1 I2 and I3 a type B indicator I may be defined by successively defining I12 from I1 and I2 followed by defining I123 from I12 and I3 and so on. When defining a type B indicator I using a pair of indicators Iand Iand their possible values the possible resulting value for the indicator I is also dependent on the relationship of the two indicators i.e. whether they reinforce badness or not. The following table shows the two main cases 

For some example embodiments the type B indicators may include a volume indicator that is defined at a basic level using two type A indicators. For example the basic level may be the method level. The two type A indicators may include an Iindicator associated with a LOC metric and an Iindicator associated with a Halstead length metric. More description about the Halstead length metric is described below. For example the resulting type B indicator Imay correspond to the case 1 illustrated above in the Table 1. Since it is required that both of the type A indicators Iand Iare associated with Good values the resulting type B indicator Imay also be associated with a Good value. As described above a low value may be interpreted as a preferred or Good value and a high value may be interpreted as a non preferred or Bad value. The following is an example formula that may be used to define a type B indicator based on two or more indicators square root over Formula 3 where Iand Iare two different indicators and where 0 R 1 with R being a correlation factor described below .

For some example embodiments the type B indicators may include a comment indicator that is defined at a basic level using two type A indicators. For example the basic level may be the method level. The two type A indicators may include an Iindicator associated with lines of comment LCOM metric and an Iindicator associated with lines of Javadoc. For example the resulting type B indicator Imay correspond to the case 2 illustrated above in the Table 1. When a software package is designed such that either of the type A indicators Iand Iare associated with low values the resulting type B indicator Imay also be associated with a low value. Following is an example formula that may be used to define a type B indicator based on two or more indicators 

As described above an indicator may be defined natively at a level. For some example embodiments indicators defined at lower levels may be pushed up or rolled up into a higher level to enable defining an indicator at the higher level. For example an indicator at the class level may be rolled up to another higher class level or to a package level etc. For some example embodiments when an indicator is also natively defined at a higher level the indicators from the lower level and the natively defined indicator may be combined to define the indicator at that higher level. For example when there is an indicator defined natively both at the method level and the class level then at the class level the two indicators may be combined forming a rolled up indicator for that class.

An element of the evaluation hierarchy containing only elements of lower levels in the evaluation hierarchy may be referred to as a simple element. An element that contains elements of the same level of the evaluation hierarchy may be referred to as a compound element. For example a class that only contains methods is a simple class while a class containing another class is a compound class. A compound class may or may not contain any methods. Referring to the class or class is an element. Similarly the method is an element. The class of the class level contains three methods to or method method and method of the lower method level . Assuming that an indicator under consideration is dependent only on metrics defined natively at the method level the indicators may be rolled up from all the elements at the method level method method and methodcontained in the class to the classprovided that class is a simple element i.e. classdoes not contain other class elements .

For some example embodiments when a class element contains other class elements as in situations of compound elements the rolled up process may be performed recursively. For simplicity the methods of the method level may be referred to collectively as M and the classes at the class level may be referred to collectively as C. In recursive roll up after an indicator is defined for a simple element e.g. class element the indicator is defined for an element that only contains M elements and simple C elements and so on until it is defined for a class C in general.

The roll up process may be used to extend an indicator from one evaluation hierarchy level to a next higher evaluation hierarchy level. As described above when an indicator I is also natively defined at a level then in addition to the rolled up indicator from the lower level the indicator defined natively may also need to be factored in to determine the indicator at that level.

The following is an example that demonstrates one embodiment of how an indicator may be defined. Let S be a set of elements that is contained in a class e.g. class . The elements may be in the same level as the class or they may be in a lower level. It may be noted that for simplicity a class is used however other components of the hierarchy structure may also be used. Let S be a set of methods and classes that are either immediate children of or contained in a class. Let The a given threshold and let S be a subset of S containing all the elements s with I s T. In addition the following definition may also be used 

For some example embodiments the rolled up part of the indicator at a C level may be defined based on mean of the indicator values and the standard deviation of the indicator values over a set of elements. The following is an example formula that may be used to define a rolled up indicator based on the mean and the standard deviation of the indicator values square root over Formula 5 0 1 is an offset constant to control the growth of rolled up values. When the indicator also is defined natively at the C level as I C the combined indicator may be defined as max Formula 6 Volume indicator may be used to make the definitions and concepts more concrete although other types of indicators may also be used.

Following is an example that demonstrates another embodiment of how an indicator may be defined. Let indicator I be defined over the members of a non empty set S. Hence I s for s S is defined. It is assumed that the indicator I is associated with non negative values. For a given threshold of significance I the following values are defined 

The following is an example of defining a volume indicator Iusing lines of code LOC and Halstead length Hl metrics described below . Both metrics are defined at all levels. However only the method and class levels are associated with the natively defined indicator. Thus at the package and codebase levels the volume indicator Iwill contain only the rolled up indicator component from the method levels and the class levels. As an example the following indicators may be defined 

Using the Formula 3 above with two type A indicators I M I M may be derived for every method since the methods are assumed to be the lowest level of the hierarchy. There is no roll up component for the methods. For every simple class i.e. those containing only methods it is possible to roll up the volume indicator I C for every simple class. By rolling up combinations of native indicator component and rolled up indicator component defining the indicator Imay be extended to all methods and classes simple or compound and to packages and codebases by rolling up . Whenever necessary recursive roll up may need to be performed.

As described above a metric may relate to some objectively measurable or calculable characteristic. Some common metrics include lines of codes LOC metric which relates to determining the number of lines of codes lines of Javadoc LJDOC metric which relates to determining the number of Java comment lines and Cyclomatic complexity metric which relates how much unstructured logic exists in a module e.g. a loop with an exiting GOTO statement .

The following are example embodiments of some metrics that may be applicable to methods and systems described herein. It may be noted that one of ordinary skill in the art may recognize that the design of the metrics may be implementation dependent to provide various evaluation needs.

Rules Violation Metric may be defined natively at the method level. A rule set may have been selected based on some basic coding standards. Each rule may be associated with a penalty score. The penalty score may be against for example one of the five following quality categories 

The penalty score may be an integer having a value between 0 and 9. For example when low penalty scores correspond to negative rating the penalty scores such as the following may correspond to a violation 

It may be noted that the categories the number of categories and the penalty scores may be implementation dependent and may vary from the example above.

For some example embodiments the rule violation metric may be implemented by defining an aggregate penalty score P V of a violation V as an upper bound of the category penalties. The rules violation metric may be defined at the method level for a method M by adding the weighted penalty violations of each violation encountered in the method M. The weight may be inversely proportional to the inverse square of the occurrence rank. Hence a first time that the violation V occurs in the method M the metrics is increased by P V the second time by P V 2 and the nth occurrence by P V n. The rules violation indicator is a type A indicator related to the rules violation metric and normalized by Halstead metric at the method level. The indicator may then be rolled up to all higher levels.

The similar code blocks metric is based on an equivalence relation determined using signatures. A signature is an integer associated to a module e.g. code blocks packages or codebase formed from a series of bits derived from module attributes. It may be noted that how a signature is defined is highly dependent on the application that it is designed for. Since the code blocks are at the lowest levels of a hierarchy a signature is attached to the code blocks in order to find the code blocks that are similar. This may include code blocks that are almost identical. This has applications for improving polymorphisms leading to better maintainability and software architecture.

A signature may be represented by X where X is a code block. For some example embodiments the signature X may be a 24 bit integer composed of twelve 12 2 bit values of the lowest two 2 significant bits of the following indicators 

The entropy metric is defined based on risk index associated with the code blocks. The entropy metric may be defined natively at the package and codebase levels. The code blocks may be sorted according to their risk index. The risk index may be determined based on the values of multiple indicators including volume complexity comments rules violation and testability indicators the testability indicator is driven by metrics such as cyclomatic complexity and number of parameters . The highest three values are averaged to define the risk index.

For some example embodiments the top 20 of code blocks are placed into five 5 groups where each group contains 4 of sorted code blocks. The mean values of the risk indices for each group are normalized to sum to 1 so they form a probability distribution. Let p1 . . . p5 be the probabilities. The entropy metric may be defined as 

The practice of commenting out unused code can significantly distort the LCOM metric. The following process detects unused code resulting in a much more accurate LCOM metric. A Java program consists of tokens. Valid Java syntax has limitations on how the different kinds of tokens can be combined. By implication only certain kinds of tokens are permitted to occur in sequence. For example the only token that can possibly follow the keyword for is an open parenthesis the keyword for followed by any other kind of token is not valid Java syntax. Determining whether the text of a comment is source code e.g. commented out code can be done by tokenizing the text as Java tokens and analyzing successive sequences of two or more non whitespace non comment tokens.

The more sequences of tokens that can or cannot occur in valid Java syntax the greater the likelihood that the text is or is not source code. This mechanism requires that the comment text comprise more than one non whitespace non comment token. For comment text that comprises a single token whether the text is source code can be at least partially determined by the kind of the token and the surrounding context provided by neighboring comments. Large comments which may comprise both description and source code can be analyzed in sections according to valid invalid token sequences and line boundaries.

The Halstead metric is defined based on a number of operators and number of operands in the code blocks. For a given module or code block the following four scalar values may be derived 

It is assumed that every file is associated with date information. The date information may be from a source control tool. The date information indicates the dates when the file was touched. For example touching may include viewing editing copying or the like. The source control tool may also have information about the different individuals or users who touch or access the file. For some example embodiments the VM is assigned a penalty with every touch with increasing values as a function of time. This metric may assign a penalty if the files are touched frequently close to a release date as the frequent touching may correspond to the files having problems.

The following is an example that demonstrates one embodiment of how a volatility metric may be defined. Let d d . . . dbe the dates associated with the file F. Let D be a latest date or most recent date of all the dates captured in the codebase. In other words D is the latest date of record. The volatility metric VM F may be defined as 

Let T be a tree associated with the hierarchy of a root module X in a codebase. For example the module can be a class a package or a codebase. Every node of the tree T may correspond to a sub module of the root module X. A quality value such as a risk value may be attached to every node of the tree T. Other quality value such as indicators indices or metrics with reference to the hierarchical structure may also be attached and used. The DST metric may enable quantifying the local distribution of the given indicator over the module. For example the DST metric may be used in the enhancement of an architectural integrity indicator which is driven by similar codeblocks entropy metric and other metrics as described below. In order to define the DST metric the center of the module X may be defined with respect to the indicator I.

As described above an indicator may be used to provide quality measurement regarding a particular method class package or codebase. An indicator may be based on one or more metrics and one or more normalized metrics.

The following are example embodiments of some indicators that may be applicable to methods and systems described herein. It may be noted that one of ordinary skill in the art may recognize that the design of the indicators may be implementation dependent to provide various measurement needs.

A complexity indicator may be defined natively only at the method level. Because it is only defined at the method level the values at the class and the package levels have only rolled up components. For some example embodiments the complexity indicator Imay be defined using the following process 

A code coverage indicator may be natively defined at the method level. The code coverage indicator may provide a fraction or ratio of lines or branches covered by a module e.g. code block being evaluated. A line coverage indicator I described below may be defined as a type A indicator driven by line coverage metric. A line coverage metric is a ratio of the lines of code of a module by total lines of code. A branch coverage indicator Imay be defined as a Type A indicator driven by a branch coverage metric. The coverage indicator Imay then be defined as a Type B indicator using the line and branch coverage indicators. Line coverage indicators and branch coverage indicators are similar and for convenience and brevity only line coverage indicators are described herein.

Initially the fraction of lines covered is mapped to a penalty function more in agreement with software development standards. For example coverage of less than 20 may result in a high penalty and coverage of above 80 may result in a low penalty or no penalty. For coverage that is in between 20 and 80 the penalty may be computed using a function specific for a codebase. The function may be non linear. For example the mapping between 20 coverage and 80 coverage may approximate a logarithmic curve. Subsequent to the mapping the metric may be normalized. It may be noted that for this particular line coverage metric high values may correspond to good values the coverage indicator may be defined so that high values may correspond to bad values.

The indicator at the method level where the penalty metric is natively defined is then defined by normalizing the penalty function to a complexity metric such as cyclomatic complexity. The indicator is then extended to all levels by the roll up process. The following is an example embodiment of a process that may be used to determine the line coverage indicator. Let 0 x 1 be the fraction of lines covered by tests in a method. A penalty function may be defined as 

For some example embodiments the line coverage indicator may be defined be converting the ratio of lines covered into a coverage metric. A coverage software may be used to determine the ratio of lines covered. The conversion may be performed using a non linear look up table which represents more closely the value of coverage. This also inverts the values so that large values may correspond to bad values. The following is an example look up table 

The volatility indicator is defined using the physical hierarchy of file level package and codebase. The information needed to define the volatility indicator is more naturally associated with files etc. The volatility indicator hence is not defined for methods or classes. Because the volatility indicator is defined at the file level they may be rolled up to the package and the codebase levels. The volatility indicator may be defined as a Type A indicator using a single metric. The volatility indicator may be defined based on the volatility metric described above .

The architectural integrity indicator may be defined natively at the package and codebase levels. This indicator is based on similar code blocks metric and entropy metric. Additionally when References dependencies are available two other metrics may also be used. These two metrics are Coupling between Object Classes CBO and Lack of Cohesion in Methods 2 LOCOM2 metrics. The architectural integrity indicator without references may be defined as 

Consider a list of numerical attributes associated to a population. Examples from the field of Economics such as household annual income of a population are abundant. Different attributes associated to the methods in a codebase such as lines of code LOC is an example but many numerical attributes may be associated with the population which may be similar to methods classes or packages.

In general concentration analysis evaluates or analyzes such a list when it is sorted and segmented into a small number of groups. Using the example from the field of Economics suppose the population is sorted according to income and segmented into 1 percentile. The array of size 100 generated as a result is the subject of concentration analysis. Merely as an example the situation of a single numerical attribute is examined even though there may be multi dimensional attributes situations .

For example let L be a population sorted according to an attribute. For a fixed n divide the sorted population into n equal segments and let abe the average of values of the kth segment. The array a . . . a is referred to as the n concentration average. When n is fixed the average may be referred to simply as the concentration average and tacitly assume the value n. Let p a T where

Let L be the list of methods in a codebase and the attribute under consideration be Risk. For n 100 all the methods can be divided into 100 segments then the percentile averages and ratios can be considered. This example can be generalized to any attribute and any fixed n. Moreover the methods can be generalized to classes files etc.

Based on the choice of list L and value n the concentration average and hence the concentration ratio can be defined with different properties. For any choice the value of pand a the first concentration ratio and the first average ratio are of primary importance and form two metrics used in indicators such as the architectural integrity indicator.

The values pand aare referred to as the first concentration metrics. To incorporate them into indicators first they may need to be normalized. The concentration ratio pis naturally normalized but the value aneeds to be normalized appropriately in the process of indicator definition.

Another useful concept that can be applied to the concentration ratio p is Shannon entropy. Shannon entropy which was first defined in the context of information theory is a measure of deviation from uniformity. In that sense large entropy applied to concentration ratio is in general a sign of low quality in particular with respect to architectural integrity indicators.

Another application of information theory to software quality evaluation is to use the Kullback Leibler divergence as a means comparing two codebases and a codebase with a theoretical ideal one. The Kullback Leibler divergence for two probability density functions p and q may be defined as 

Let p be a fixed density function representing an ideal concentration ratio. Define the Kullback Leibler relative top metric as . Formula 19 Evaluation Examples

The display interface may display multiple fields relating to indices. In the presently shown example the fields are associated with two indices. Indices include Risk . Risk is a quality index and is an assessment of drivers that cause source code to create unexpected or incorrect behavior of an application or project from the end user s perspective. Drivers of the risk index include a volume indicator a complexity indictor a comment indicator a rules violation indicator and a testability indicator. Indices also include Un maintainability . Un maintainability is an index representing the inability to modify a software system to change or add capabilities improve performance or correct defects without introducing new defects. Un maintainability may be driven by many indicators and metrics but currently driven by volume complexity and comment indicator.

The display interface also provides indicators for codebase . Indicators in this case include volume . Volume is an indicator driven by metrics such as LOC Halstead length or the like. Another indicator is complexity . Complexity is an indicator driven by metrics related to code complexity such as for example cyclomatic complexity. Complexity may drive indices such as for example un maintainability described above. Another indicator is comments . Comments may be driven by metrics such as in line comments lines of Javadoc or the like. Another indicator is rules violation . The rules violation field is driven by metrics as defined above.

Another indicator is architectural integrity . Architectural integrity is driven by similar codeblocks and entropy metric and other metrics as described above. It may also be driven by metrics such as copy and paste instances. Another indicator is testability . Testability is driven by metrics such as cyclomatic complexity and number of parameters. Another indicator is code coverage . Code coverage is driven by metrics such as line coverage and complexity as described above.

As explained above indices and indicators are designed such that higher values generally provide indication of worsening values. Thus code coverage of 0.54 shows the codebase has a relatively good code coverage. Rules violation indicator of over 5.55 however shows a poor evaluation relating to rules violation of the code base. While providing the standard high value bad display is beneficial for a user each index or indicator may have its own thresholds of badness e.g. red yellow and green thresholds as indicated by the legend . For ease of display and reference it is possible to provide a legend which may provide a visual indicator for each field such that a good indicator or index may be color coded for example green a bad indicator or index may be color coded for example red and an average indicator or index may be color coded yellow. Numerous other visual cues are possible and limited only by the choice of the designer and or customer. As shown in display interface legend provides thresholds for when each indicator or index changes from one visual cue to the next. Volume indicator includes a sort arrow . Sort arrow allows the particular index or indicator or metric to be sorted as desired. While only shown and described for volume indicator the sort feature could be provided on any portion of the display.

While useful to identify codebases or codebases with at least one or more portions that are considered to be of low quality display interface is of limited value as the end user cannot easily identify the poor performing portions of the code from display interface . Thus display interface provides a drilldown icon for each displayed codebase .

Drilling further down in codebase is shown in display interface of which is the second package layer comprising a single package under first package layer . Again the indices and indicators from the second package layer were rolled up to first package layer . As shown in the display interface of drilling further down using the drill down icon provides a third package layer comprising a single package under the second package layer .

Using the drill down icon provides display shown in display interface of . Display interface includes a fourth package layer comprising packages . Packages includes respectively a mail package a bzip2 package a tar package an ant package and a zip package. As can be seen from indices and indicators the indices and indicators at a fourth package layer are different than previous package layers or a codebase layer and comprise a combination of indicators providing better or worse indication. As explained above the worse indication is propagated through the evaluation tool to ensure the administrator can identify issues at the highest level and flow down to the point where the problem exists.

As shown in rules violation indicator indicates a red or poor performance. Rules violation indicator for packages shows none of the packages individually exceed the threshold quality indicator although none are shown to provide relatively good performance using the presently provided indicator . Thus the system administrator can readily determine that the problem branches into multiple directions at this point with the two major violators being packages and for example. In this case package is selected to drill further down into the structure to determine whether the quality can be further traced.

As shown in display interface of under fourth package layer resides the first class layer having eleven classes comprising in this example AsiExtraField ExtraFieldUtils JarMarker UnixStat UnrecongnizedExtraField ZipEntry ZipExtraField ZipFile ZipLong ZipOutputStream and ZipShort. Looking at rules violation field it can be readily determined that the poor performing component of package resides largely in class by referring to its associated rules violation indicator .

As shown in the display interface of selecting the drill down icon associated with class provides a first method layer under the first class layer . Similar to package layers there could have been numerous class layers however in this example and for brevity class layer results in method layer as shown in part by the display interface in . Method layer comprises as shown 27 methods of which methods are shown. Looking to rule violation indicator it is seen that method and method have the largest rules violation which likely caused the high violation indication in class and so on up the chain which ultimately provided a poor performance indication in the rules violation indicator associated with codebase in .

It may be noted that although the examples illustrated in refer to using a display and or displaying evaluation information to an end user embodiments of the invention may also enable presenting the evaluation information via other techniques other than via a display. For example the evaluation information may be communicated to a program via an application programming interface API .

Obtaining the indicators for the next hierarchy level may include calculating native and roll up values for the indicators at the first hierarchy level as shown in block . At block it is determined whether additional class levels exist. If additional class levels exist the process may return to block . If additional class levels do not exist metrics indicators and indices for successive package layers are obtained as shown in block .

Obtaining metrics indicators and indices for the package level may include calculating native and roll up values for indicators and indices at the package level and selecting the worse indicator as the metric indicator or index for the package as shown in block . At block it is determined whether additional package levels exist. If additional package levels exist the process may return to block . If additional package levels do not exist metrics indicators and indices for the codebase are obtained as shown in block .

Obtaining metrics indicators and indices for the codebase includes calculating native and roll up values for indicators and indices at the codebase and selecting the worse indicator as the metric indicator or index for the codebase as shown in block . Each metric indicator or index for each of the one or more methods classes packages and codebase may be displayed as shown in block . The dotted lines that connect blocks and to the block are used to illustrate that the information calculated from blocks and may also be displayed.

The end user may continue to drill down into until the poor performing method is discovered as shown in block . At which time appropriate resources may be directed to the poor performing method to improve its quality as shown in block . Once the quality of the identified code is improved or corrected the codebase is evaluated block and it is determined whether the codebase is performing adequately as shown in block . If the codebase is performing adequately the process may end as shown in block . If it is determined that the codebase is not performing adequately the process or a portion thereof may be repeated as shown in block .

At block it is determined whether additional class levels exist. If additional class levels exist control returns to step when roll up is from first class level to the next successive one. If additional class levels do not exist the process continues to block where natively defined metrics and indicators for the package level are obtained. Obtaining indicators for the package level includes calculating native and roll up values for indicators at the package level and selecting the worse indicator as the indicator for the package. The indices for a package are then computed after all indicators are computed for the package.

Although not shown the process may then continue with determining whether additional package levels exist. If additional package levels exist the process may return to block . If additional package levels do not exist natively defined metrics and indicators for the codebase are obtained. Obtaining indicators for the codebase includes calculating native and roll up values for indicators and indices at the codebase and selecting the worse indicator as the indicator for the codebase. The indices for a codebase are computed after all indicators are computed for the codebase. Each metric indicator or index for each of the one or more methods classes packages and codebase may be displayed in block . The dotted lines illustrated in indicate that information generated from the connected blocks may be displayed in block .

Certain embodiments are described herein as including logic or a number of components modules or mechanisms. A component may be a tangible unit capable of performing certain operations and is configured or arranged in a certain manner. In example embodiments one or more computer systems e.g. a standalone client or server computer system or one or more components of a computer system e.g. a processor or a group of processors may be configured by software e.g. an application or application portion as a component that operates to perform certain operations as described herein.

In various embodiments a component may be implemented mechanically or electronically. For example a component may comprise dedicated circuitry or logic that is permanently configured e.g. within a special purpose processor to perform certain operations. A component may also comprise programmable logic or circuitry e.g. as encompassed within a general purpose processor or other programmable processor that is temporarily configured by software to perform certain operations. It will be appreciated that the decision to implement a component mechanically in dedicated and permanently configured circuitry or in temporarily configured circuitry e.g. configured by software may be driven by cost and time considerations.

Accordingly the term component should be understood to encompass a tangible entity be that an entity that is physically constructed permanently configured e.g. hardwired or temporarily configured e.g. programmed to operate in a certain manner and or to perform certain operations described herein. Considering embodiments in which components are temporarily configured e.g. programmed each of the components need not be configured or instantiated at any one instance in time. For example where the components comprise a general purpose processor configured using software the general purpose processor may be configured as respective different components at different times. Software may accordingly configure a processor for example to constitute a particular component at one instance of time and to constitute a different component at a different instance of time.

Components can provide information to and receive information from other components. Accordingly the described components may be regarded as being communicatively coupled. Where multiple of such components exist contemporaneously communications may be achieved through signal transmission e.g. over appropriate circuits and buses that connect the components. In embodiments in which multiple components are configured or instantiated at different times communications between such components may be achieved for example through the storage and retrieval of information in memory structures to which the multiple components have access. For example a one component may perform an operation and store the output of that operation in a memory device to which it is communicatively coupled. A further component may then at a later time access the memory device to retrieve and process the stored output. Components may also initiate communications with input or output devices and can operate on a resource e.g. a collection of information .

The term module as used herein should be understood to refer more broadly to a tangible component or a software component or any combination thereof. Accordingly a module may be implemented in electronic circuitry hardware firmware software or a combination thereof.

Example embodiments may be implemented using a computer program product e.g. a computer program tangibly embodied in an information carrier e.g. in a machine readable medium for execution by or to control the operation of data processing apparatus e.g. a programmable processor a computer or multiple computers.

A computer program can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module subroutine or other unit suitable for use in a computing environment. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.

In example embodiments operations may be performed by one or more programmable processors executing a computer program to perform functions by operating on input data and generating output. Method operations can also be performed by and apparatus of example embodiments may be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs miming on the respective computers and having a client server relationship to each other. In embodiments deploying a programmable computing system it will be appreciated that that both hardware and software architectures require consideration. Specifically it will be appreciated that the choice of whether to implement certain functionality in permanently configured hardware e.g. an ASIC in temporarily configured hardware e.g. a combination of software and a programmable processor or a combination permanently and temporarily configured hardware may be a design choice. Below are set out hardware e.g. machine and software architectures that may be deployed in various example embodiments.

The example computer system includes a processor e.g. a central processing unit CPU a graphics processing unit GPU or both a main memory and a static memory which communicate with each other via a bus . The computer system may further include a video display unit e.g. liquid crystal display LCD or a cathode ray tube CRT . The computer system also includes an alphanumeric input device e.g. a keyboard a user interface UI navigation device e.g. a mouse a disk drive unit a signal generation device e.g. a speaker and a network interface device .

The disk drive unit includes a machine readable medium on which is stored one or more sets of instructions and data structures e.g. software embodying or utilized by any one or more of the methodologies or functions described herein. The software may also reside completely or at least partially within the main memory and or within the processor during execution thereof by the computer system the main memory and the processor also constituting machine readable media.

While the machine readable medium is shown in an example embodiment to be a single medium the term machine readable medium may include a single medium or multiple media e.g. a centralized or distributed database and or associated caches and servers that store the one or more instructions. The term machine readable medium shall also be taken to include any tangible medium that is capable of storing encoding or carrying instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present invention or that is capable of storing encoding or carrying data structures utilized by or associated with such instructions. The term machine readable medium shall accordingly be taken to include but not be limited to solid state memories and optical and magnetic media. Specific examples of machine readable media include non volatile memory including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM and DVD ROM disks.

The software may further be transmitted or received over a communications network using a transmission medium via the network interface device utilizing any one of a number of well known transfer protocols e.g. HTTP . Examples of communication networks include a local area network LAN a wide area network WAN the Internet mobile telephone networks Plain Old Telephone POTS networks and wireless data networks e.g. WiFi and WiMax networks The term transmission medium shall be taken to include any intangible medium that is capable of storing encoding or carrying instructions for execution by the machine and includes digital or analog communications signals or other intangible media to facilitate communication of such software.

Although an embodiment has been described with reference to specific example embodiments it will be evident that various modifications and changes may be made to these embodiments without departing from the broader spirit and scope of the invention. Accordingly the specification and drawings are to be regarded in an illustrative rather than a restrictive sense. The accompanying drawings that form a part hereof show by way of illustration and not of limitation specific embodiments in which the subject matter may be practiced. The embodiments illustrated are described in sufficient detail to enable those skilled in the art to practice the teachings disclosed herein. Other embodiments may be utilized and derived therefrom such that structural and logical substitutions and changes may be made without departing from the scope of this disclosure. This Detailed Description therefore is not to be taken in a limiting sense and the scope of various embodiments is defined only by the appended claims along with the full range of equivalents to which such claims are entitled.

Such embodiments of the inventive subject matter may be referred to herein individually and or collectively by the term invention merely for convenience and without intending to voluntarily limit the scope of this application to any single invention or inventive concept if more than one is in fact disclosed. Thus although specific embodiments have been illustrated and described herein it should be appreciated that any arrangement calculated to achieve the same purpose may be substituted for the specific embodiments shown. This disclosure is intended to cover any and all adaptations or variations of various embodiments. Combinations of the above embodiments and other embodiments not specifically described herein will be apparent to those of skill in the art upon reviewing the above description.

The Abstract of the Disclosure is provided to comply with 37 C.F.R. 1.72 b requiring an abstract that will allow the reader to quickly ascertain the nature of the technical disclosure. It is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition in the foregoing Detailed Description it can be seen that various features are grouped together in a single embodiment for the purpose of streamlining the disclosure. This method of disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather as the following claims reflect inventive subject matter lies in less than all features of a single disclosed embodiment. Thus the following claims are hereby incorporated into the Detailed Description with each claim standing on its own as a separate embodiment.

