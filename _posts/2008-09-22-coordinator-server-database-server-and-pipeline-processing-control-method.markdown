---

title: Coordinator server, database server, and pipeline processing control method
abstract: A first transmitting unit transmits a processing command to a plurality of parallelized database servers. A second transmitting unit integrates data sets transmitted from the database servers in response to the processing command, and transmits an integrated data set to a client. An integrating unit integrates data sets buffered in a buffer unit. A determining unit determines a transmission start or a transmission suspend of the data sets based on a data size in the buffer unit. A third transmitting unit transmits a control command for the transmission start or the transmission suspend to the database servers based on a result of determination by the first determining unit.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08112438&OS=08112438&RS=08112438
owner: Kabushiki Kaisha Toshiba
number: 08112438
owner_city: Tokyo
owner_country: JP
publication_date: 20080922
---
This application is based upon and claims the benefit of priority from the prior Japanese Patent Application No. 2007 280649 filed on Oct. 29 2007 the entire contents of which are incorporated herein by reference.

The present invention relates to a coordinator server and a plurality of database servers constituting a parallel database and a pipeline processing control method performed by the parallel database.

Conventionally as a high speed technology of a processor that performs reading interpretation and execution of commands and writing of results thereof for example there is a pipeline processing technology. Pipeline processing independently operates a process of each phase in which before a processing cycle of a previous phase finishes a process of the next phase is started and this process is repeated. Accordingly an assembly line operation is realized and the performance of the entire processing is improved.

Meanwhile there is a parallel database technology as a technique for managing a large amount of data. In the parallel database technology a system including a plurality of servers is established to correspond to a large amount of data. A large amount of data set having a uniform data format is arranged in a plurality of databases. There is also a case that the data set is arranged not in a distributed manner but in an overlapped manner on a plurality of databases. By arranging the data set in this manner an improvement of throughput can be expected in a case that the number of simultaneous accesses to the same data is high.

A system of managing the data in such a parallel database is largely divided into three methods that is a system in which a plurality of servers do not share a disk disk nonshared system a system in which the servers share a disk disk sharing system and a system in which the servers share a disk and a memory memory sharing system .

The disk nonshared system is mainly explained here. When the data set is divided into a plurality of databases and arranged two methods of vertical division of data set and horizontal division of data set can be considered fragmentation . The horizontal division of the data set is to create a subset of data set. A data partitioning technique described later becomes important. The vertical division of the data is to divide the data in a unit of attribute or column. Each division method includes a merit and demerit according to an individual access pattern. For example in the vertical division of data high speed can be acquired if data scanning of a size with few inquiries is good enough. However if original data is required data coupling is required between servers and the performance is greatly deteriorated.

Each server used in the parallel database in the disk nonshared system can perform parallel access by individually accessing a plurality of databases in which the data set is arranged in the divided manner and improvement of performance corresponding to the number of databases can be expected. Accordingly processing efficiency and response time can be improved partition parallelization .

As the data partitioning method key range partitioning and hash partitioning are known. For example it is assumed here that a large amount of data set is expressed with relation. In the key range partitioning and the hash partitioning there are a case of using one column value of a table and a case of using a plurality of column values of the relation. When such data partitioning is performed although loads are concentrated in search with a range condition with respect to a target column inefficiency caused by accessing an irrelevant database can be avoided. Further in the search including natural coupling in the target column coupling between different databases is not required thereby enabling to considerably improve the performance.

In the parallel database loads are concentrated on a specific database at the time of search unless balanced data partitioning is performed thereby making it difficult to exhibit a parallelization effect. However respective data sizes may be unbalanced due to a change in the trend of input data which cannot be avoided by using a predetermined data division rule. Therefore improvement techniques such as dynamically changing the key range and changing the hash value have been proposed. With these techniques however the load due to data shift related to the change increases.

The parallel database often includes one coordinator server and a plurality of database DB servers. In such a configuration following processing is performed in the parallel database. That is the coordinator server having received a request from a client analyzes the request to generate a plan and divides and distributes the plan to each of the DB servers. Each DB server executes the distributed plan and transmits data set of a processing result to the coordinator server. The coordinator server performs aggregation processing such as merge with respect to the transmitted data set and transmits the aggregation result to the client. The data transferred between the servers is stream transmitted on a network such as a local area network LAN . Therefore in the parallel database also the network is often realized on distributed parallel platforms such as interconnect between high speed servers.

To realize high speed in the above processing in the parallel database a mechanism for performing phase processing such as scanning sorting and joining of internal processing of structured query language SQL in parallel by a plurality of processes and a plurality of servers is incorporated. In a part of database products a pipeline system in which the process in each phase is operated independently and before a previous phase process finishes the next phase process is started has been adopted pipeline parallelization .

With regard to the pipeline parallelization for example JP A 2001 147847 KOKAI discloses a method in which the number of respective nodes is determined corresponding to database operation to be executed by each node constituting the parallel database system and when there is a difference in division of data the data is equally distributed to each node. According to the technique disclosed in JP A 2001 147847 KOKAI because respective database operation to be executed by each node is parameterized to equalize the expected processing time there is no deviation in the processing time between respective nodes and smooth operation can be realized in the pipeline processing.

However the technique described in JP A 2001 147847 KOKAI is for equalizing central processing unit CPU processing other than disk input output I O processing such as sort and merge in the parallel database by distributing the CPU processing to a plurality of nodes. Therefore there can be a problem described below in the pipeline processing such as fetch associated with a data acquisition request from the client. That is when the processing performed by a coordinator server cannot catch up with the processing of the DB server the data set can be accumulated on the coordinator server side thereby putting pressure on resources such as a memory of the coordinator server.

According to one aspect of the present invention there is provided a coordinator server that is configured to be connected to a plurality of parallelized database servers each storing data and that is capable of performing a pipeline processing. The coordinator server includes a first transmitting unit that transmits a processing command to the database servers in response to a query request for requesting a data acquisition from a client a buffer unit that buffers data sets transmitted from the database servers as a result of a processing according to the processing command 

an integrating unit that integrates the data sets buffered in the buffer unit to obtain a merged data set 

a second transmitting unit that transmits the merged data set to the client and a third transmitting unit that transmits a control command instructing the transmission start or the transmission suspend of the data sets to the database servers based on a result of determination by the first determining unit.

Furthermore according to another aspect of the present invention there is provided a database server that is one of a plurality of parallelized database servers and that performs a processing in response to a processing command transmitted from a coordinator server and transmits a data set that is a result of the processing to the coordinator server. The database server includes a setting unit that sets a transmission amount for a single time of transmission of the data set to be transmitted as the result of the processing to the coordinator server such that the transmission amount is increased every time a transmission is performed and a transmitting unit that transmits the data set of a set transmission amount to the coordinator server.

Moreover according to still another aspect of the present invention there is provided a pipeline processing control method to be executed in a coordinator server that is connected to a plurality of parallelized database servers each storing data and that is capable of performing a pipeline processing. The pipeline processing control method includes transmitting a processing command to the database servers in response to a query request for requesting a data acquisition from a client transmitting including integrating data sets transmitted from the database servers as a result of a processing according to the processing command and transmitting a data set obtained by integrating the data sets to the client integrating the data sets transmitted from the database servers and buffered in a buffer unit determining a transmission start or a transmission suspend of the data sets from the database servers based on a data size of the data sets buffered in the buffer unit and transmitting a control command instructing the transmission start or the transmission suspend of the data sets to the database servers based on a result of determination at the determining.

Furthermore according to still another aspect of the present invention there is provided a pipeline processing control method to be executed in a coordinator server that is connected to a plurality of parallelized database servers each storing data and that is capable of performing a pipeline processing. The pipeline processing control method includes setting a transmission amount for a single time of transmission of the data set to be transmitted as the result of the processing to the coordinator server such that the transmission amount is increased every time a transmission is performed and transmitting the data set of a set transmission amount to the coordinator server.

Exemplary embodiments of the present invention will be explained below in detail with reference to the accompanying drawings.

The client the coordinator server and the DB servers A to B respectively includes a controller such as a central processing unit CPU that controls the entire apparatus memories such as a read only memory ROM for storing various data and various programs and a random access memory RAM an external memory such as a hard disk drive HDD or a compact disk CD drive for storing various data and various programs a display device such as a display that displays information an input unit such as a keyboard and a mouse for a user to input various processing requests a communication controller that communicates with an external computer via the network and a bus for connecting these and have a hardware configuration using a normal computer.

In such a hardware configuration various functions to be realized by the coordinator server by executing various programs stored in the memory and the external memory are explained. Each unit which is an entity of various functions realized by the coordinator server is explained. The coordinator server includes a receiving unit a transmitting unit a query analyzing unit a distributed plan generator a distributed plan executing unit a transmitting unit a receiving unit a fetch controller and a data merge unit .

The receiving unit receives data such as the query request from the client . The transmitting unit transmits data such as the processing result to the client . The query analyzing unit analyzes the query request from the client . The distributed plan generator generates distributed plans to be performed by each of the DB servers A and B based on the analyzed query request. The distributed plan executing unit executes the generated distributed plan. The receiving unit receives data such as the processing result transmitted from the DB servers A and B. The transmitting unit transmits data such as the distributed plan to the DB servers A and B.

The data merge unit merges two data sets acquired as the processing result from the respective DB servers A and B to integrate the data set. When the processing request such as a fetch request of a cursor is received as the processing request relating to the transmission of the processing result via the receiving unit from the client the data merge unit performs processing corresponding to the request. The fetch controller determines whether to start or suspend transmission of the data set from the DB servers A and B based on the data size of the data set at the time of acquiring GET the data set of the processing result from the respective DB servers A and B and appropriately transmits a control command indicating a determination content to the DB servers A and B to thereby control transmission of the data set from the DB servers A and B. The fetch controller transmits the data set merged by the data merge unit as the processing result to the client via the transmitting unit .

Functions realized by executing various programs stored in a storage unit or an external storage unit by the DB server A are explained. Each unit which becomes the entity of the various functions realized by the DB server A is explained. The DB server A includes a receiving unit A a transmitting unit A a query analyzing unit A a single plan generator A a single plan executing unit A and a fetch controller A. The DB server A further includes for example a DB A stored in the external storage unit. The receiving unit A receives data such as a processing request from the coordinator server . The transmitting unit A transmits data such as a processing result to the coordinator server . The query analyzing unit A analyzes the processing request such as a command or a plan transmitted from the coordinator server . The single plan generator A generates a single plan for accessing the DB A from the analyzed query. In the single plan for example a DB access operator such as index scanning data acquisition and data comparison is included. The single plan executing unit A executes the generated single plan. The fetch controller A transmits the data set acquired as a result of executing the single plan as the processing result to the coordinator server via the transmitting unit A. The fetch controller A controls transmission of the data set corresponding to a control command described later transmitted from the coordinator server .

The DB server B includes a receiving unit B a transmitting unit B a query analyzing unit B a single plan generator B a single plan executing unit B and a fetch controller B. Because configurations of these respective units are substantially the same as those of the receiving unit A the transmitting unit A the query analyzing unit A the single plan generator A the single plan executing unit A and the fetch controller A explanations thereof are omitted. The DB server B has for example a DB B stored in the external storage unit. The DB B and the DB A included in the DB server A are relational database including a plurality of records having the same relational schema and are in a state with the database being divided into two by horizontal division.

 a Respective DB servers A and B return data set including publication with the published year being in or after 1996 and with the title being arranged in ascending order by publisher name to the coordinator server .

 b The coordinator server merges two data sets acquired from the DB servers A and B in ascending order by publisher name column.

A result acquired by executing the distributed plan becomes the data set corresponding to the query request shown in .

 c Index scanning Index scanning is performed according to character string index added to the publisher name in the bibliographic data to acquire sets of record ID added to each record in ascending order.

 d Data acquisition Column values of three columns that is title publisher name and published year are acquired among the columns included in each record of the bibliographic data based on each record ID acquired as a result of the index scanning.

 e Data comparison Only the record with the acquired column value in published year exceeding 1996 is filtered.

The single plan executing unit A in the DB server A executes such a single plan to generate a result list indicating data sets acquired as a result of filtering in . The fetch controller A acquires a data set based on the result list and transmits the data set as a processing result to the coordinator server via the transmitting unit A. The DB server B performs the same processing as that of the DB server A.

An outline of a process in which the data sets transmitted from the DB servers A and B as the processing result are merged by the data merge unit in the coordinator server is explained next. depicts a concept of the merge process performed by the data merge unit . The data set acquired from the DB server A is buffered in an input line A and the data set acquired from the DB server B is buffered in an input line B. The data merge unit merges the data sets buffered in the input lines A and B in ascending order by publisher name and buffers the merged data set in an output line D. A request such as a cursor fetch request transmitted from the client is input to a control line C. The data merge unit determines whether to transmit the data set buffered in the output line D to the client based on the request such as the cursor fetch request input to the control line C.

The input lines A and B the output line D and the control line C have a predetermined configuration structure respectively. For example the configuration structure is a queue structure such as a ring buffer added with a tail cursor and a top cursor respectively. is a schematic diagram of a data structure of the input lines A and B and the output line D. For example an input line A.tail for specifying the last data of the data set and an input line A.top for specifying the first data of the data set are added to the input line A. Likewise an input line B.tail and an input line B.top are added to the input line B. An output line.tail for specifying the last data and an output line.top for specifying the first data of the data set which has not been transmitted to the client are added to the output line D.

The fetch controller in the coordinator server determines to start or suspend transmission of the data sets from the DB servers A and B based on the data size of the data sets buffered in the output line D and the input lines A and B. Details of this processing will be explained in an operation section below.

On the other hand in the present embodiment the fetch controller A in the DB server A and the fetch controller B in the DB server B increase stepwise the transmission block size of the data sets to be transmitted to the coordinator server and suspend or resume transmission of the data sets according to the control command transmitted from the coordinator server . Details of the processing performed by the fetch controllers A to B will be also explained in the operation section below.

The operation of the parallel database system according to the present embodiment is explained next. First a process procedure performed by the coordinator server is explained with reference to . The query analyzing unit in the coordinator server analyzes the query transmitted from the client and the distributed plan generator generates each distributed plan and transmits the plan to each of the DB servers A and B via the transmitting unit . As a result each data set transmitted from the DB servers A and B is respectively buffered in the input lines A and B which is then merged and buffered in the output line D. At this time the coordinator server determines whether the data size of the data set buffered in the output line D satisfies condition Step S . The condition is such that the data size is equal to or lower than a first low watermark LWM . When the determination result is positive the coordinator server determines that the data set in the output line is insufficient or scant.

The coordinator server then determines whether processing has been performed with respect to all input lines A and B Step S . When the determination result is negative the coordinator server determines whether the data size of each data set buffered in each of the input lines A and B satisfies condition Step S . The condition is such that the data size is equal to or lower than a second low watermark LWM x . When the data size of the data set in at least one of the input lines A and B satisfies the condition the coordinator server determines that the data sets in the input line satisfying the condition referred to as an insufficient input line is insufficient or scant. The coordinator server then determines whether the DB server at least one of the DB servers A and B which buffers the data set in the insufficient input line is in a suspended SUSPEND state Step S . When the determination result is positive the coordinator server transmits a control command instructing transmission of the data set RESTART command to the DB server which buffers the data set in the insufficient input line to increase the data set in the insufficient input line Step S .

When the determination result at Step S is negative the coordinator server determines whether the data size of the data set buffered in the output line satisfies condition Step S . The condition is such that the data size is equal to or higher than a first high watermark HWM . When the determination result is positive the coordinator server determines that the data set in the output line D is excessive. The coordinator server then determines whether all the input lines A and B have been processed Step S and when the determination result is negative determines whether the data size of the data set buffered in the input lines A and B satisfies condition Step S . The condition is such that the data size is equal to or higher than a second high watermark HWM x . When the data size of the data set in at least one of the input lines A and B satisfies the condition the coordinator server determines that the data sets in the input line satisfying the condition referred to as an excessive input line are excessive. The coordinator server then determines whether the DB server at least one of the DB servers A and B which buffers the data set in the excessive input line is in a start START state Step S . When the determination result is positive the coordinator server transmits a control command instructing to suspend transmission of the data set SUSPEND command to the DB server which buffers the data set in the excessive input line to decrease the data sets in the excessive input line Step S .

When the determination result at Step S is negative or the determination result at Step S is positive control proceeds to Step S. At Step S the coordinator server determines whether there is a data acquisition GET request from the client and when the determination result is positive advances the output line.tail Step S . The coordinator server then determines whether the output line.tail is higher than the output line.top Step S . When the determination result is positive transmission is possible and an untransmitted data set has already been buffered in the output line. Therefore the coordinator server transmits the data set to the client as the processing result Step S to proceed to Step S. Also when the determination result at Step S is negative control proceeds to Step S.

At Step S the coordinator server determines whether the data set has been received from at least one of the DB servers A and B. When the determination result is positive the coordinator server buffers the data set in the corresponding input line at least one of the input lines A and B and advances the corresponding input line.tail at least one of the input line A.tail and the input line B.tail .

When the determination result at Step S is negative the coordinator server determines whether the data set buffered in at least one of the DB servers A and B can be output to the output line D Step S . When the determination result is positive the coordinator server pops the data from the input line in which the minimum data is buffered hereinafter input line y returns the input line y .top and pushes the data to the output line D to advance the output line.top Step S .

The coordinator server then determines whether the output line.tail is higher than the output line.top Step S . When the determination result is positive transmission is possible and an untransmitted data set has already been buffered in the output line D. Therefore the coordinator server transmits the data set to the client as the processing result Step S .

Respective values of the first high watermark HWM the second high watermark HWM x the first low watermark LWM and the second low watermark LWM x are preset and stored in the storage unit or the external storage unit. Further the respective values can be set to appropriate values by taking statistics of the input data size and the output data size by each phase processing. Alternatively it can be determined by pre analysis according to a query request SQL . For example configuration examples of respective values of the first high watermark HWM and the first low watermark LWM are as follows. 2 where W is a value obtained by dividing the input data size and the output data size by a block size.

It is assumed that the phase processing is performed by designating one block for example 4 KB as one unit.

A process procedure performed by the fetch controller A in the DB server A is explained with reference to . It is assumed here that the query analyzing unit A in the DB server A analyzes the distributed plan transmitted from the coordinator server and a data set acquired as a result of execution of the single plan generated by the single plan generator A by the single plan executing unit A is buffered in the storage unit such as a RAM as a result list. At Step S the fetch controller A determines whether a control command has been received from the coordinator server . When the determination result is positive the fetch controller A determines whether the received control command is RESTART command Step S . When the determination result is positive and if the DB server A is in the suspended SUSPEND state the DB server A is changed to the START state Step S to return the transmission block size to an initial value Step S to proceed to Step S. The initial value of the transmission block size is prestored in the storage unit or the external storage unit.

When the determination result at Step S is negative the fetch controller A determines whether the received control command is SUSPEND command Step S . When the determination result is positive the DB server A is changed to the SUSPEND state Step S to proceed to Step S. Further when the determination result at Step S is negative control proceed to Step S.

At Step S the fetch controller A determines whether the own controller is in the SUSPEND state and when the determination result is negative increases the transmission block size Step S . For example the fetch controller A calculates the transmission block size using 2 1 where y is transmission block size x is the number of transmission and C block size or the like is a constant.

By calculating the transmission block size according to such Equation 1 the transmission block size can be monotonously increased according to the number of transmission. In this case the initial value of the transmission block size returned at Step S becomes C .

Thereafter the fetch controller A takes out data sets from the result list for the transmission block size Step S determines whether all the data sets in the result list have been processed Step S and when the determination result is negative determines whether the total data size of the data sets to be transmitted exceeds the transmission block size Step S . When the determination result is positive the fetch controller A transmits the data sets to the coordinator server Step S . When all the data sets in the result list have been transmitted YES at Step S the fetch controller A transmits termination status TERM to the coordinator server Step S .

The fetch controller A transmits the data set as the processing result in response to the control command from the coordinator server . Because the process procedure performed by the fetch controller B in the DB server B is the same as the above procedure explanations thereof are omitted.

A change in the transmission block size of the data set transmitted by the DB server A is explained here. is a schematic diagram for explaining a characteristic involved with a monotonous increase of the transmission block size of the data set transmitted by the DB server A. In it is shown that the transmission block size is small in the first transmission and increases stepwise until the transmission block size becomes constant in and after the second transmission. Further it is shown that when the DB server A once becomes the SUSPEND state the transmission block size becomes 0 and when the DB server A becomes the START state the transmission block size increases stepwise from the same size as in the first transmission.

On the other hand depicts a chronologically simplified flow of the pipeline processing when the processing performed by the coordinator server cannot catch up with the processing performed by the DB servers A and B in the conventional pipeline processing. In such a case the data sets transmitted from the DB servers A and B are accumulated too much in the coordinator server which can put pressure on the resources such as the memory of the coordinator server . In the present embodiment pressure on the resources can be avoided by appropriately determining the data size of the data set accumulated in the coordinator server to appropriately transmit a control command SUSPEND command instructing to suspend transmission of the data set to the DB servers A and B.

According to the above configuration the pipeline processing can be smoothly realized in the parallel database without putting pressure on the resources such as the memory of the coordinator server.

When the processing performed by the DB servers A and B cannot catch up with the processing performed by the coordinator server deterioration of the initial responsiveness for example the waiting time of the coordinator server can increase or the data acquisition request from the client cannot be immediately responded can be suppressed.

Further an increase of the overhead can be suppressed by increasing stepwise the data size to be transmitted from the DB servers A and B to the coordinator server . Accordingly improvement of the initial responsiveness and reduction of the overhead can be balanced well.

Furthermore unnecessary data processing can be reduced because processing is performed with respect to the necessary input line in response to the command from the client and not all the input data is processed. Particularly in data search even if a large amount of data corresponding to a search condition is hit only the first several items can be referred to in many cases. Even in this case the respective phase processing is continued until all the input data is processed in the pipeline processing. However if the respective phase processing is controlled gently all the input data is processed thereby causing execution of unnecessary data processing.

In the above embodiment various programs to be executed by the coordinator server can be stored on a computer connected to the network such as the Internet and downloaded via the network. Further various programs can be recorded on a computer readable recording medium such as a CD ROM a flexible disk FD a CD recordable CD R and a digital versatile disk DVD and provided in an installable or executable format file. The same applies to various programs to be respectively executed by the DB server A to B.

In the above embodiment the coordinator server has the data merge unit however the coordinator server can have a unit that integrates data according to various methods by union or join other than or instead of the data merge unit .

Additional advantages and modifications will readily occur to those skilled in the art. Therefore the invention in its broader aspects is not limited to the specific details and representative embodiments shown and described herein. Accordingly various modifications may be made without departing from the spirit or scope of the general inventive concept as defined by the appended claims and their equivalents.

