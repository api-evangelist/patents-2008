---

title: Real-time validation of interactive applications
abstract: A validation tool providing real-time validation of interactive content applications includes a static analysis engine that extrapolates the timeline of an application and the application's behavior over that timeline. The static analysis engine watches various types of data associated with the application's markup document and works through an editor to inform the user if the application has exceeded defined limits as the application is being built. The validation tool is further configured with a dynamic simulator that is arranged as a state machine that shares state information with the static analysis engine to enable the validation tool to display useful information such as pixel buffer usage at a given time code. The validation tool is further configured to provide a real-time application preview with which the user may interact to immediately evaluate cause and effect of any changes that are made in the application code using the editor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08539447&OS=08539447&RS=08539447
owner: Microsoft Corporation
number: 08539447
owner_city: Redmond
owner_country: US
publication_date: 20080604
---
Developers of applications that support interactivity in environments that have restricted resources typically face many challenges. For example with Microsoft Corporation s HDi interactivity technology developers can facilitate advanced navigation and interaction with features and content called interactive content on platforms as diverse as video game consoles and mobile devices such as personal media players and phones. HDi applications are written using a mix of markup such as XML eXtensible Markup Language and script such as ECMAScript standardized by Ecma International in the ECMA 262 specification which can provide powerful and rich user experiences when engaging with interactive content and features. However the development environment for HDi applications can be complex. HDi applications are typically developed in compliance with various restrictions and design rules that may be imposed due to platform and resource limitations as well as those that may be associated with application portability or standardization for example. Developers have to deal with time synchronicity of the interactive content using the markup and script while complying with restrictions on how many lines of code and XML elements may be used how many pixels can be ready to draw onto a device display at a time and so on.

Current validation tools having applicability to HDi application development will typically only validate the XML schema or verify the ECMAScript syntax. In addition such post authoring tools do not enable developers to interactively verify the correctness of their applications in a real time manner i.e. as the application code executes as in a runtime environment . Application developers may need to resort to trial and error which can lengthen the development cycle and add costs or the developers may become overly conservative in their application design to avoid running afoul of the rules or restrictions.

This Background is provided to introduce a brief context for the Summary and Detailed Description that follow. This Background is not intended to be an aid in determining the scope of the claimed subject matter nor be viewed as limiting the claimed subject matter to implementations that solve any or all of the disadvantages or problems presented above.

A validation tool providing real time validation of interactive content applications such as HDi applications includes a static analysis engine that extrapolates the timeline of an application and the application s behavior over that timeline. The static analysis engine watches various types of data associated with the application s markup and works through an editor i.e. a user interface or UI to inform the user of changes in compliance with applicable requirements and or performance implications for the application as the application is being built. For example if the user generates an XML document that is too large creates an attribute that is too long or overflows the pixel buffer the validation tool will immediately point out such error conditions so that the user may make corrections before going any further.

The validation tool is further configured with a dynamic simulator that is arranged as a state machine. The dynamic simulator and the static analysis engine may share state information to enable the validation tool to display a time graph of the application lifetime and useful information such as pixel buffer usage at a given time code or other resource utilization. The validation tool is further configured to provide a real time application preview with which the user may interact to immediately evaluate cause and effect of any changes that are made using the editor to the application code. This preview feature enables a user to engage in rapid prototyping of interactive content without needing to write an entire application or perform other tasks that would normally be required to simulate the application.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

The devices shown in are typically designed to operate with fewer resources such as memory and processing power as compared with a personal computer for example. Accordingly in this illustrative example devices run the Microsoft Windows CE operating system which is also called Windows Embedded CE . However in alternative arrangements other operating systems including for example Microsoft Windows and other types of devices such as desktop and laptop personal computers may be utilized. It is noted that the Windows Vista operating system for PCs and the Xbox game platform for example provide native support for Microsoft s HDi technology. However resources are generally less restricted with such alternatives.

As indicated by reference numeral an illustrative interactive UI is supported by the devices . UI is implemented in a graphics environment that uses multiple graphic planes as shown in and described in the accompanying text. In this example the UI is implemented using the interactive features provided by HDi technology to enable interactive content such as advanced viewing features including enhanced content interactive user experiences navigation and other functionality to be rendered in real time as media content such as a movie or other content plays on a device . Other examples of interactive content include such things as picture in picture commentary tracks zoom features and user defined bookmarks.

HDi uses standards including XML HTML Hypertext Markup Language CSS Cascading Style Sheets SMIL Synchronized Media Integration Language and ECMAScript also known as JavaScipt . In alternative implementations other technologies that can support interactive content may be used and the present arrangement is not intended to be limited solely to the use of HDi.

The OSD on screen display plane is the topmost plane i.e. perceived by user as being on top in the graphics plane stack and includes OSD objects such as date and time information. In applications using an STB such OSD objects could also include channel or video source information for example.

The remaining planes are arranged from the top of the display to the bottom from left to right as indicated by arrow in . All planes in the graphics plane stack use a common xy coordinate system. A third dimension is described by a z axis which projects outwardly from the display as indicated by reference numeral in . Typically applications running in an interactive content environment belong to specific planes as described below. In addition characteristics of each plane in the stack may differ. For example the frame rate color space resolution and the size and position of a given plane may be specified independently of other planes in the stack .

The cursor plane is the second plane in which cursor objects like pointers are displayed. The graphics plane is the third plane of the graphics plane stack and is generated by the presentation engine as described below in the text accompanying . HDi applications that generate interactive content such as graphics and menus in an interactive media environment are typically rendered into the graphics plane .

The subpicture plane is the fourth plane of the graphics plane stack and is typically used to display subtitles and or captions produced by respective applications. The subvideo plane is the fifth plane in the graphics plane stack and is typically used as a secondary video display in a picture in picture PIP arrangement. A PIP window like that indicated by reference numeral is often smaller than the main video display and may have other differing characteristics such as reduced resolution different aspect ratio etc.

The main video plane is the sixth plane in the graphics plane stack and is positioned at the bottom of the stack of planes. The main video plane is typically used to display video content in the interactive media environment. As shown in all the planes in the graphics plane stack are mixed and composited into a single display through a mixing process as indicated by reference numeral .

Referring to an illustrative block diagram of the elements making up an HDi application used in an interactive media environment is shown. Applications are typically used in the interactive media environment to enable interaction between a user and an interactive media player rendering graphics and video on a display. More specifically applications control presentation behavior of various content objects including video playback in the environment. Presentation of graphic objects such as menus and interactive buttons over the video is also realized using applications.

Applications further manage and control audio playback and sounds in the environment . It is contemplated that multiple applications will generally be running simultaneously in most interactive media settings. However there is no requirement that the multiple applications run simultaneously and the decision to divide or aggregate applications in a particular setting is a design choice of the interactive media developer or author. Applications may also be logically subdivided into application pages depending on the requirements of a specific setting.

Applications will generally attempt to run in a time synchronous manner with the video on the main video plane and will thus be aware of time that is kept by various clocks in the HDi runtime environment. These may include for example a media clock that takes account of trick play where the main video is put into fast forward backwards or slow motion etc. as well as a presentation clock that keeps time just as a real world clock.

The progression of context execution by applications in the interactive media environment is guided by a playlist which describes among other things the relationship among objects in the environment including presentation objects that are rendered by the player onto the display device. These presentation objects typically include video and graphics produced by the applications. The playlist further manages resources across the interactive media environment as a single management entity in order to efficiently allocate and control the consumption of resources by applications.

The application comprises a script host containing zero or more script files and and zero or more markup documents that are used to generate a document object model DOM . The markup documents include information relating for example to content style timing and layout of graphic objects. Thus the markup context is used generally to provide graphics on the graphics plane in the interactive media environment.

In this illustrative example the markup documents are XML document files in accordance with W3C World Wide Web Consortium standards. As indicated in multiple physical XML files may be accessed using the element in the section of the markup. In some settings it may be preferable for an application to not have more than one active markup at a time. However an application may switch its markup by using a element in the markup. Alternatively an application may switch its markup by utilizing an application programming interface API that enables applications to gain access to functional objects within a current application. Using a loadMarkup call through the API an application may switch markup files by passing the Uniform Resource Identifier URI of the new markup through an API.

In cases where an application accesses a new markup the API call takes effect only after a current event handler in the application finishes executing its current task. Any current markup related event handlers that are pending are also cancelled as the new markup once loaded will invalidate those event handlers.

As noted above script host contains script files and which are used along with the markup to implement interactive media experiences. Script files and may be implemented for example using ECMAScript as defined by Ecma International in the ECMA 262 specification. Common scripting programming languages falling under ECMA 262 include JavaScript and JScript. In some settings it may be desirable to implement scripts and using a subset of ECMAScript 262 in particular ECMA 327 along with a host environment and a set of common APIs. Script context in most settings is utilized to deal with interactive control issues from the user along with system events graphics control video playback resource management e.g. use of caching or persistent store resources and other issues that are not readily or efficiently implemented solely using markup .

The availability of APIs and resources to application is indicated by reference numeral in . Resources include for example audio and video files fonts pictures and images e.g. in common file formats including PNG JPEG GIF BMP TIFF etc. and other resources as may be required by an application according to the circumstances of a specific setting.

Each application maintains its own script host that maintains the context for the script s variables functions and other states. In most settings variables and functions in one application are not visible to another application unless the applications are specifically set up to enable such cross application visibility for example by using an object that is shared across all applications.

As shown in the static analysis engine will contain an XML parser that is used to parse the XML markup . A logic component is provided in the engine to assign meaning to the XML code that is parsed from the markup . A predictive algorithm in the static analysis engine is utilized to extrapolate the timeline of the application and then analyze the behavior of the application over that timeline.

The static analysis engine is configured to internally complete any incomplete XML markup for example by automatically closing any open XML tags. This completion ensures that the markup will be in an appropriate format to be analyzed. The static analysis engine in this example is configured to monitor and analyze various types of data including 

Returning to when the user enters text into the editor to edit the markup changes to the markup may be evaluated as indicated by reference numeral by the static analysis engine . The engine will evaluate the markup with regard to the monitored and analyzed data listed above. If a pre defined value or threshold which could be a value from an applicable specification design requirement or other set limit etc. is exceeded by the markup which triggers an error condition then the error is indicated to the user through the editor .

Advantageously the feedback to the user can be provided as an application is being built. For example if the user creates a DOM that is too large creates an attribute that is too long or overflows the pixel buffer the validation tool will immediately point such error conditions out so that the user may correct the code before going any further.

The dynamic simulator may be configured to provide several functionalities. As a simulator it may be configured as a state machine . The state machine gets built up from the begin and end XPath expressions in the markup . The dynamic simulator will need to evaluate the XPath expressions but rather only use them as entry and exit conditions of the state. The dynamic simulator is configured to share state information with the static analysis engine as necessary for the engine to evaluate scenarios driven by the markup that require state information. However it is noted that the static analysis engine will also evaluate parts of the markup that do not require state information such as element count and attribute length in the XML code.

Utilization of the state machine enables the validation tool to display pixel buffer usage by the application at an exact time code through the UI embodied in the editor . For example the user may set i.e. force a given XPath query in the markup to true to drive the state machine and then evaluate the effect on the pixel buffer. The dynamic simulator may then return information to the editor to display as a timeline UI as shown below in and described in the accompanying text .

It may be possible for the validation tool to test all possible combinations of XPath expressions using a projected input model and verify if there is any possibility that the pixel buffer will overflow. If so then the static analysis engine can flag the appropriate time code and the combination of cues that would cause such error.

In some implementations the timeline graph may be configured so that additional and or detailed information is made available to the user when a portion of the graph is selected. For example when the red bar is clicked by the user it expands to show a bar graph that indicates the level of the pixel buffer to provide a more comprehensive editing experience.

A variety of other indicators may be utilized in the editor window to inform the user of issues with the XML code . For example a pop up indicator shows that an image FailButtonDown.png included in the code may not comply with an applicable specification. In addition in a text editing area in the window different types of errors in the XML code are indicated by different colored underlines. In this example red and yellow lines are used as representatively indicated by reference numerals and . It is emphasized that the timeline graph bar graph pop up indicator and underlines shown in this example are intended to be illustrative and that other types and kinds of indicators including textual and graphical indicators may be used to provide the user with awareness of changes in compliance with applicable requirements or performance of the application as may be required to meet the requirements of a particular implementation.

The validation tool may be further configured to provide a real time application preview. In this mode the user can preview and interact with the interactive content that would be generated by the application during runtime. It is assumed for this example that the application provides a menu that flies into position over a movie as it plays on a device and then the menu dissolves when a menu choice is made.

As shown in a preview of the menu indicated by reference numeral includes some text and a choice of two buttons A and B as respectively indicated by reference numerals and . The user may interact with the previewed menu for example by manipulating the buttons and while also editing the XML code in the editor window . In this way the user may readily see cause and effect how any animation used in the application progresses over time and what would happen in the menu if a specific cue in the code were to be triggered.

This level of real time validation provides the user with enhanced functionality that goes beyond evaluating only pixel buffer usage. This enhanced functionality may be expected to typically enable a user to engage in rapid prototyping of interactive content such as menus and other navigation aids without needing to step through all the normal intermediate steps such as creating an entire application writing a playlist and starting up a full blown simulator or media player device.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

